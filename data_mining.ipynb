{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0c2bb71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\linag\\anaconda3\\lib\\site-packages (4.15.2)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\linag\\anaconda3\\lib\\site-packages (from selenium) (1.26.16)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\linag\\anaconda3\\lib\\site-packages (from selenium) (0.23.1)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\linag\\anaconda3\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\linag\\anaconda3\\lib\\site-packages (from selenium) (2023.7.22)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\linag\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\linag\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\linag\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in c:\\users\\linag\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\linag\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\linag\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\linag\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\linag\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\linag\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\linag\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Collecting PyPDF2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "     ---------------------------------------- 0.0/232.6 kB ? eta -:--:--\n",
      "     - -------------------------------------- 10.2/232.6 kB ? eta -:--:--\n",
      "     ---- -------------------------------- 30.7/232.6 kB 435.7 kB/s eta 0:00:01\n",
      "     ----------- ------------------------- 71.7/232.6 kB 563.7 kB/s eta 0:00:01\n",
      "     --------------------------------- ---- 204.8/232.6 kB 1.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- 232.6/232.6 kB 1.1 MB/s eta 0:00:00\n",
      "Installing collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium\n",
    "!pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "662bfef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from PyPDF2 import PdfReader\n",
    "from pathlib import Path\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "858aa217",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = webdriver.ChromeOptions()\n",
    "options.add_experimental_option('prefs', {\n",
    "    \"download.default_directory\": \"C:\\\\Users\\\\linag\\\\Science\\\\pdfs\",\n",
    "    \"plugins.always_open_pdf_externally\": True\n",
    "})\n",
    "\n",
    "with webdriver.Chrome(options=options) as driver:\n",
    "    driver.get('https://elibrary.ru/')\n",
    "    #Регистрация на elibrary\n",
    "    login = driver.find_element(By.ID, 'login')\n",
    "    password = driver.find_element(By.ID, 'password')\n",
    "    login.send_keys('khrustitskayaSK')\n",
    "    password.send_keys('Metalorka12HP&')\n",
    "    time.sleep(2)\n",
    "    button = driver.find_element(By.CLASS_NAME, 'butred')\n",
    "    ActionChains(driver).move_to_element(button).click(button).perform()\n",
    "    time.sleep(2)\n",
    "    \n",
    "    #Поиск по сайту\n",
    "    search = driver.find_element(By.ID, 'ftext')\n",
    "    search.send_keys('Машинное обучение')\n",
    "    button = driver.find_element(By.CLASS_NAME, 'butblue')\n",
    "    ActionChains(driver).move_to_element(button).click(button).perform()\n",
    "    time.sleep(5)\n",
    "    \n",
    "    #Скачивание 100 научных публикаций в pdf\n",
    "    count_page = 1\n",
    "    count_publ = 0\n",
    "    inf_publ = []\n",
    "    while count_publ < 100:\n",
    "        time.sleep(5)\n",
    "        table_center = driver.find_element(By.CSS_SELECTOR, '#restab')\n",
    "        publications = table_center.find_elements(By.TAG_NAME, 'tr')[1:]\n",
    "        for publication in publications:\n",
    "            ActionChains(driver).move_to_element(publication).perform()\n",
    "            try:\n",
    "                img = publication.find_element(By.CSS_SELECTOR, 'a img')\n",
    "                if 'green' in img.get_attribute('src'):\n",
    "                    count_publ += 1\n",
    "                    ActionChains(driver).move_to_element(img).click().perform()\n",
    "                    time.sleep(5)\n",
    "            except NoSuchElementException:\n",
    "                continue\n",
    "        count_page += 1\n",
    "        menus_page = [element for element in driver.find_elements(By.CSS_SELECTOR, '.menus td') if element.text == str(count_page)][0]\n",
    "        ActionChains(driver).move_to_element(menus_page).click().perform()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6951c59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "XRef object at 2614 can not be read, some object may be missing\n"
     ]
    }
   ],
   "source": [
    "# pdf2txt\n",
    "\n",
    "pdfs = Path(Path.cwd(), 'pdfs')\n",
    "\n",
    "res_text = []\n",
    "\n",
    "for pdf_file in pdfs.rglob('*'):\n",
    "    pdf_file = open(pdf_file, 'rb')\n",
    "    pdf_reader = PdfReader(pdf_file)\n",
    "    text = ''\n",
    "    for page_num in range(len(pdf_reader.pages)):\n",
    "        text += pdf_reader.pages[page_num].extract_text()\n",
    "    res_text += [text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0afc5d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Имя\\n:\\nПароль\\n:\\nВход\\nЗабыли\\n \\nпароль\\n?', 'Обзор алгоритмов машинного обучения,  \\nрешающих задачу обнаружения спама  \\nСкляренко Н.С. , МГТУ им. Н.Э. Баумана  \\nnikolay .skliarenko @gmail .com \\n \\nАннотация  \\nДанная работа посвящена решению задачи \\nфильтрации спама методами машинного \\nобучения. Проведён обзор алгоритмов \\nидентификации спама, предложена их \\nклассификация. Дано описание \\nматемат ического аппарата рассмотренных \\nалгори тмов, приведены данные о точности \\nсущес твующих их реализаций. Выделены \\nперспективные направления исследований \\nс целью повышения качества \\nидентификации спама.  \\n1 Введение  \\nСпам – массово рассылаемые сообщения \\n(как напрямую, так и косвенно), \\nпредназн аченные лицам, не выражавшим \\nжелания их получать, несмо тря на \\nпредпринятые меры по предотвращению этой \\nрассылки [ Cormack , 2008]. Борьба со спамом \\nидет уже не один десяток лет, и несмотря на \\nуспехи в разрабо тке и исследовании \\nразличных подходов к р ешению данной \\nзадачи, согласно исследов анию, \\nпроведенному Лабора торией Касперск ого \\n[Спам и фишинг во втором квартале 2016], \\nдоля спама в мировом и отечественном \\nпочтовом трафике всё ещё велика (рис. 1).  \\n \\nРис. 1 . Доля спама в почтовом трафике за 2016 г.  Приведенная статистика указывает на \\nнеобходимость разработки новых  и \\nулучшения существующих алгоритмов \\nфильтрации сп ама. В данной работе \\nрассматриваются алг оритмы, позволяющие \\nрешить задачу идент ификации спама при \\nпомощи машинного об учения.  \\n2 Классификация алгоритмов  \\nНа текущий момент существует множество \\nалгоритмов идентификации спама. Исходя из \\nэтого, целесообразно произвести их \\nкласс ификацию по некоторому критерию. \\nПредл агается классификация по \\nиспользуемому по дходу, или категории \\nположенного в основу алгоритма фильтрации \\nспама математическ ого аппарата (рис. 2). \\nДанная классификация является \\nсистематизацией, обобщением и \\nрасширением классификации, приведенной в \\nработе [ Cormack , 2008] . \\n2.1 Условные обозначения  \\nПусть есть множество документов D=\\n{d୧}, множество классов, \\nC={spam,non-spam}, множество терминов \\nT={t୧}. Будем считать, что |T|=n. Для \\nобучения алгоритмов будем считать, что \\nимеется некоторое обучающее множество \\nдокументов D′⊆D, то есть множ ество \\nдокументов, класс которых заранее и звестен.  \\nЗададим некоторую функцию class:D→C, \\nкоторая корректно сопоставляет каждый \\nдокумент с некоторым классом.  \\nДокумент может быть представлен в \\nразличных формах (к примеру, в виде \\nмульти множества терминов, либо вектора в \\nпростра нстве терминов), для учёта этого \\nвведем пон ятие формы документа d∈D R(d). \\nФорма д окумента и определение термина \\nзависят от конкретного алгоритма извлечения \\nтерминов из документа [ Cormack , 2008] .  \\nНа основании этой терминологии \\nрассмо трим существующие алгоритмы \\nфильтрации спама, основанные на машинном \\nобучении.  \\nДля сравнения классификаторов будем \\nиспользовать точность (отношение числа \\nкорректно классифицированных документов \\nк общему числу документов) и статистику (1 -\\nAUC ) %, оценивающую область под ROC -\\nкривой1 (представляет AUC  = 0.999 как 0.1 %, \\nт.е. чем ближе значение к 0, тем точнее \\nклассификатор) [ Hanley , McNeil , 1983].  \\n \\nРис. 2 . Классификация алгоритмов \\nидентифик ации спама по используемому подходу  \\n2.2 Вероятностные классификаторы  \\nВведём понятие «мягкого» ( soft) и \\n«жёс ткого» ( hard) вероятностного \\nклассификатора. Под «мягким» \\nвероятностным классификат ором будем \\nпонимать функцию вида  \\ncୱ୭\\u0b64୲(d,c)=p(class(d)=c|R(d)=x), (1) \\nто есть некоторую функцию, равную \\nвероятности, что данный документ, \\nпредставле нный в форме ݔ ,является спамом. \\nАнглийский термин « soft» в данном случае \\n                                                        \\n1 ROC -кривая используется для оценки качества \\nбинарных классификаторов , представля я \\nотношение доли верно классифицир ованных \\nобъе ктов к доле ошибочно классифицированных \\nотносительно некоторого класса.  эквивалентен « fuzzy », то есть предполагает \\nнечёткую кла ссификацию.  \\nПод «жестким» вероятностным \\nклассиф икатором будем понимать функцию \\nвида:  \\nc୦ୟ୰ୢ(d,c)=p(class(d)=c|R(d)=x)>ݐ. \\nТаким образом, «жесткий» классификатор \\nотличается от «мягкого» наличием \\nнекотор ого порогового значения t∈[0;1), \\nпри прев ышении которого документ \\nклассифицируется как спам (т.е. \\nосуществляется переход к б инарному \\nклассификатору).  \\nНаиболее известными представителями \\nданного класса алгоритмов являются:  \\n• логистическая регрессия [Corm ack, 2008] ; \\n• алгоритм «наивной» байесовской \\nкласс ификации  [Barber  D. 2012; Better  \\nBayesian  Filtering ]; \\n• алгоритм, осн ованный на марковских \\nполях [Chhabra , Yerazunis , Siefkes , 2004; \\nCRM 114 Notes  for the TREC  2005 Spam  \\nTrack ]. \\nАлгоритм «наивной» байесовской \\nклассификации. Пусть документ \\td∈D \\nпредста влен в форме вектора в пространстве \\nтерминов x[ୢ]={xଵ,xଶ,…,x୪}.  «Наивный» \\nбайесовский классификатор определяет класс \\nдокумента как наиболее вероятный из всех \\nвозможных классов, то есть с помощью \\nоценки апостер иорного максимума ( MAP ). \\nc\\u0b51\\u0b45\\u0b54≡argmaxୡ∈େP൫c|x[ୢ]൯.  \\nВ случае идентификации спама эта \\nформ ула задаёт следующий критерий для \\nклассиф икации:  \\nc\\u0b51\\u0b45\\u0b54==ቐspam,если\\tcୱ୭\\u0b64୲(d,spam)>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tcୱ୭\\u0b64୲(d,non-spam),\\nnon-spam,иначе.\\t\\t\\t\\t\\t\\t\\t\\x01\\t(2) \\nПрименим теорему Байеса к формуле (1):  \\ncୱ୭\\u0b64୲(d,c)=p(c)∙p൫x[ୢ]หc൯\\np(R(d)=x[ୢ]).  \\nТак как вероятности рассчитываются для \\nодного и того же документа, вероятность  \\np൫R(d)=x[ୢ]൯ не будет влиять на результат \\nсравнения при использовании критерия (2), \\nследовательно, её можно опустить:  \\ncୱ୭\\u0b64୲(d,c)=\\tp(c)∙p൫x[ୢ]หc൯. (3) \\nВероятность p൫x[ୢ]หc൯ может быть \\nполучена из обучающего множества данных, \\nно для её получения требуется громадный \\nнабор да нных [ Hovold , 200 5]. Для решения \\nэтой пр облемы было предложено \\nвоспользоваться «наивным» предположением \\nо статистич еской независимости всех \\nтерминов в пре дставлении документа (что, \\nвообще говоря, не верно). При этом  \\np൫x[ୢ]หc൯=ෑp(x୧|c)\\n୧. (4) \\nС учётом формулы (4) формула (3) может \\nбыть преобразована к виду:  \\ncୱ୭\\u0b64୲(d,c)=\\tp(c)∙ෑp(x୧|c)\\n୧.  \\nОсновными  преимуществами  данного  \\nклассификатора  являются  малое  время  \\nобучения  [Christina , Karpagavalli , Suganya , \\n2010], сравнительно  высокая  точность  (98.6 % \\n[Christina , Karpagavalli , Suganya , 2010] и выше  \\n[Better  Bayesian  Filtering ]). Недостаток – \\nвозможная уязвимость к атакам с подбором \\n«хороших» слов [ Lowd , Meek , 2005].  \\nАлгоритм «не столь наивной» \\nбайесо вской классификации. Для \\nулучшения кач ества классификации в работе \\n[Su, Xu, 2009] был предложен \\nмодифицированный вариант  байесовского \\nклассификатора. Основная идея данного \\nалгоритма состоит в аппроксимации \\nстатистической зависимости между \\nтермин ами. \\nРассмотрим следующую вероятность:  \\np൫x[ୢ]หc൯=p(xଵ,xଶ,…,x୪|c)\\n=p(xଵ|c)\\n∙p(xଶ,xଷ,…,x୪|xଵ,c)\\n=p(xଵ|c)∙θ൫x[ୢ],xଵ,c൯\\n∙p(xଶ,xଷ,…,x୪|c).  \\nПри этом \\n  является некоторым неизвестным, \\nно существующим распределением.  \\nДалее предлагается следующая \\nаппрокс имация, используемая вместо \\nформулы (4):  \\np൫x[ୢ]หc൯=ෑp(x୧|c)\\n୧∙θ(x୧,c). (5) \\nθ(x୧,c) изначально устанавливается в 1 для \\nвсех i (при этом формула (5) становится \\nаналогичной формуле (4), то есть случаю \\nклассического «наивного» байесовского \\nкласс ификатора). При каждой ошибке в \\nклассиф икации происходит коррекция \\nпараметра \\n  с помощью так называемых \\nкоэффициентов уверенности α\\tи\\tβ. \\nПо результатам статьи [ Su, Xu, 2009] \\nданный классификатор обладает высокой \\nточн остью классификации,  высокой \\nскоростью, сравнительно низким \\nпотреблением памяти. Основной проблемой \\nявляется то, что данный алгоритм \\nнедостаточно изучен (автор данной статьи нашёл упоминание о данном алгори тме \\nтолько в статье [ Su, Xu, 2009]).  \\nВероятностный алгоритм Роккио. \\nКлассический алгоритм Роккио уступает в \\nточн ости вероятностным алгоритмам \\n(точность п орядка 86 % [ Joachims , 1997]), \\nThorsten  Joachims  в своей статье [ Joachims , \\n1997] пр иводит сравнение классического \\nалгоритма Роккио, предложенную им \\nвероятностную версию ал горитма Роккио и \\n«наивного» бай есовского классификатора. \\nВероятностный алгоритм Роккио по точности \\nсравним с «н аивным» байесовским \\nклассификатором.  \\nMRF -классификатор. Пусть F=\\n{Fଵ,Fଶ,…,F୫} – множество случайных \\nвеличин, имеющих одинаковые, с точностью \\nдо значений параметров, распределения, \\nопред елённые на дискретном множестве \\nячеек \\n , в каждой из которых случайная \\nвеличина F୧ принимает значение f୧ из \\nдискретного множ ества меток \\n . Под \\nконфигурацией случайного п оля F=f будем \\nпонимать произведение с обытий «случайная \\nвеличина  F୧\\tприняла \\tзначение \\tf୧». Для \\nмножества меток \\n  вероятность того, что \\nслучайная величина F୧\\tприняла \\tзначение \\tf୧, \\nбудем обозначать P(F୧=f୧), вероятность \\nпроизведения событий (Fଵ=fଵ,Fଶ=\\nfଶ,…,F୫=f୫) будем обозначать P(F=f). \\nДля решения задачи классификации спама \\nячейкой будет относительное полож ение \\nслова в последовательности, метки будут \\nсоответствовать терминам.  \\nБудем говорить, что \\n  является марковским \\nслучайным полем над \\n  по отношению к \\nсоседству ( neighborhood ) \\n тогда и только \\nтогда, когда выполняются следующие \\nусловия:  \\n1. P(f)>0,∀݂∈ܨ, \\n2. P(f୧|fୗି{୧})=P൫f୧|f\\u0b52\\u0c5f൯, \\nгде f\\u0b52\\u0c5f={f୧ᇲ|iᇱ∈N୧}, то есть множество всех \\nсобытий являющихся соседями ячейки i. \\nНа практике MRF  классификатор можно \\nполучить при помощи модификации \\nстандартного «наивного» байесовского \\nклассиф икатора [ Yerazunis , 2003]. Для этого \\nтребуется:  \\n1. при извлечении терминов учитывать \\nцепочки токенов, а не отдельные токены;  \\n2. учесть, что более длинные цепочки \\nимеют больший вес (подробное изучение \\nразличных подходов для назначения веса \\nцепо чке представлено в работе [5]).  В работе [ Yerazunis , 2003] указывается \\nчрезвычайная эффективность данного \\nалгоритма (точность порядка 99.95 %), но \\nсущес твующая реализа ция в известном \\nфильтре спама CRM 114, по мнению \\nразработчиков [ CRM 114 Notes  for the TREC  \\n2005 Spam  Track ], является достаточно \\nсложной и отн осительно неэффективной.  \\nИнтерес представляет дальнейшее создание \\nэффективной реализации алгоритма и его \\nтестирован ие. \\n2.3 Линейные классификаторы  \\nПод линейным классификатором будем \\nпонимать вектор из n коэффициентов β=\\n(βଵ,βଶ,…,β୬), n=|T|, и некоторое грани чное \\nзначение \\n .  \\nРассмотрим уравнение плоскости в \\nпространстве терминов:  \\nβ̇∙x[୫]=t.  \\nДанная гиперплоскость  делит пространство \\nтерминов на два подпространства, одно из \\nкоторых будет содержать точки, \\nклассифиц ируемые как спам, другое – как не \\nспам.  \\nГиперплоскость будем называть \\nразделяющей, если  \\n(∀d∈D)\\t\\nቀ൫β∙x[୫]>ݐ൯⟺class(m)==spamቁ& \\nቀ൫β∙x[୫]≤t൯⟺class(m)==non-spamቁ.  \\nБудем говорить, что множество \\nдокуме нтов \\n  является линейно разделимым, \\nесли для него существует разделяющая \\nгиперпл оскость.  \\nОсновная проблема линейных \\nклассифик аторов – нахождение наилучшей \\nразделяющей гиперплоскости для некоторого \\nмножества документов.  \\nПерсептрон. Данный алгоритм итеративно \\nнаходит для заданного множества документов \\n разделяющую плоскость (любую), если она \\nсуществует (то есть множество документов \\nлинейно разделимо). В случае, когда \\nразделяющей плоскости не существует, \\nалгоритм зациклива ется, если максимальное \\nколичес тво итераций не было задано. На \\nкаждой ит ерации алгоритма происходит \\nкоррекция к оэффициентов \\n , \\nсоответствующих терминам некорректно \\nклассифицированных точек (коррекция \\nпроизводится путем прибавления либо \\nвычитания некоторой константы). \\nОсновными преимуществами алгоритма являются простота, скорость, адаптивность \\n[Cormack , 2008] . Недостаток – получен ная \\nгипе рплоскость необязательно является \\nнаилучшей для данного набора документов. \\nЧисленная оценка качества найдена не была.  \\nАлгоритм Winnow . Данный алгоритм \\n[Littlestone , 1988; Siefkes  et al., 2004] схож с \\nперсептроном, основными отличиями \\nявляются следу ющие положения:  \\n• элементы \\n  всегда положительны;  \\n• коррекция коэффициентов происходит \\nмультипликативно, а не аддитивно.  \\n В случае ошибки первого рода происходит \\nумножение коэффициентов \\n , \\nсоответству ющим терминам некорректно \\nопределенн ого документа, на некоторый \\nкоэффициент α>1. Аналогично в случае \\nошибки второго рода происходит их \\nумножение на некоторый к оэффициент \\n0<ߛ<1. \\nМодификация данного алгоритма \\nиспол ьзованием ортогональных разреженных \\nбиграмм (формирующих базис  в \\nпространстве терминов и допускающих \\nналичие в тексте других слов между словами, \\nвходящими в биграмм) [ Siefkes  et al., 2004] \\nимеет дост аточно высокую точность (порядка \\n99 %).  \\nАлгоритм опорных векторов. Данный \\nалгоритм высчитывает разделяющую \\nгиперпл оскость, максимально удалённую от \\nближа йших точек обучающего множества \\nдокуме нтов.  Разделяющая гиперплоскость \\nполностью определяется на основе \\nнебольшого колич ества точек, называемых \\nопорными векторами, линейная комбинация \\nкоторых будет являться классификаторо м. \\nСуществуют эффективные реализации \\nэтого алгоритма для идентификации спама \\n[Drucker , Wu, Vapnik , 1999; Sculley , Wachman , \\n2007].  \\n2.4 Классификаторы на основе сходства  \\nРассмотрим документ d∈D и множество \\nкорректно классифицированных документов \\nD′⊆D. Пусть задана некоторая функция \\nрасстояния distance:D×D→ℝ, являющаяся \\nметрикой на пространстве терминов \\n , то есть \\nудовлетворяющая следующим требованиям:  \\n1. ∀x,y∈D,distance(x,y)=0⟺x=y; \\n2. ∀x,y∈D,distance(x,y)=distance(y,x); \\n3.∀x,y,z∈D,distance(x,z)≤\\ndistance(x,y)+distance(y,z).Данный \\nалгоритм основан на предположении о том, что документы, принадлежащие одн ому и \\nтому же классу, расположены в векто рном \\nпространстве близко друг к другу, а \\nдокументы, принадлежащие разным классам, \\nрасположены далеко друг от друга.  \\nАлгоритм k-ближайших соседей. \\nНаиб олее просты м подходом будет \\nприсваивание документу класса, \\nсовпадающего с классом ближайшего \\nизвестного документа.  Более эффективным \\nподходом является алгоритм k-ближайших \\nсоседей [ Barber  D. 2012; Shakhnarovich , G. \\nDarrell , T., Indyk , 2006], учитывающий классы \\nk наиболее близких к рассматриваемому \\nдокументов, и делающий выбор в пользу \\nкласса, которому принадл ежит большинство \\nдокументов.  \\nДанные методы не достигают высокой \\nточности при решении проблемы \\nидентификации спама [Cormack , 2008] . \\n2.5 Логические классификаторы  \\nДанная группа алгоритмов основана на \\nиспользовании аппарата логики для описания \\nсвязи между терминами.  \\nДеревья принятия решений. Деревья \\nпринятия решений [ Breiman  et al. 1984] при \\nобучении последовательно по одному \\nатрибуту за раз разбивают тренировочный \\nнабор данных по некоторому критерию (к \\nпримеру, по наибольшей информационной \\nвыгоде [Большакова и др]). Обычно деревья \\nприн ятия решений плохо подходят для \\nклассиф икации спама, но при помощи \\nнекоторых м одификаций можно добиться \\nсущественного прироста качест ва [Cormack , \\n2008] .  \\nЛогический вывод на основе набора \\nправил. Алгоритмы, основанные на \\nлогич еском выводе из набора правил \\nсравнимы по эффективности с алгоритмами \\nна деревьях принятия решений  [Cormack , \\n2008], но сущ ествуют комбинированные [ Wu, \\n2009] подх оды, имеющие более высокую \\nточность.  \\n2.6 DCM классификаторы  \\nПусть \\n  – случайная величина, каждая \\nреализация которой \\n  является текстом \\nдокуме нта из множества \\n . Представим \\nдокумент d∈D в виде последовательности \\nсимволов  произвольной длины  x[ୢ]=xଵxଶ…x୬∈Σ∗, \\nпринадлежащих алфавиту \\n  (x[ୢ] – реализация \\nслучайной величины \\n ).  \\nМодель сжатия данных ( Data Compression  \\nModel ) [Bratko  et al., 2006] ु рассчитывает \\nинформационное содержание ( information  \\ncontent ) документа x[ୢ]: \\nIु(x[ୢ])=−log൫Pु(x=x[ୢ])൯  \\nPु(x=x[ୢ]) – вероятность сообщения x[ୢ] \\nв модели сжатия данных ु.  \\nБудем считать, что модель сжатия данных \\nुଵ лучше моделирует сообщение x[ୢ], если \\nIुଵ(x[ୢ])<Iुమ(x[ୢ]). \\nДля решения проблемы идентификации \\nспама построим две модели: ुୱ୮ୟ୫  и \\nु୬୭୬ିୱ୮ୟ୫ , и получим следующий критерий \\nдля классификации:  \\nc(d)=ቐspam,если\\tIु౩౦\\u0c57ౣ൫x[ୢ]൯<\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tIु\\u0c64\\u0c65\\u0c64ష౩౦\\u0c57ౣ൫x[ୢ]൯,\\nnon-spam,иначе.\\x01  \\nЧасто используются итерационные модели: \\nпредсказание по частичному совпадению \\n(PPM ) [Bratko , Filipic , Zupan , 2006; Bratko  et \\nal., 2006], динамическое марковское сжатие \\n(DMC ) [Bratko  et al., 2006].  \\n3 Вывод ы \\nСуществующая классификация расширена \\n\"не столь наивным\" байесовским и MRF -\\nклассификаторами. Описан математический \\nаппарат всех рассмотренных классов и дано \\nподробное описание алгоритмов (в \\nрасшир ение сведений, данных в [Cormack, \\n2008]). Б ыли учтены результаты более \\nпоздних работ: так, в [Cormack, 2008] \\nалгоритмы логического вывода на основе \\nнабор а правил сравнимы по точности с \\nдеревьями принятия решений, а в данной \\nработе приведён пример комбинир ованного \\nметода с большей точностью.  \\nВ результате проведённого обзора методов \\nидентификации спама была составлена \\nтаблица, отражающая данные о точности \\nрассмотренных методов (см. табл. 1) по \\nпоказ ателям точности классификации и мере \\n(1-AUC ) %. \\nКак следует из приведённой таблицы, \\nнаиболее точными являются вероятностные и \\nлинейные классификаторы.  \\nВ результате проведённого обзора можно \\nвыделить следующие персп ективные \\nнапра вления исследований:  • исследование не вполне изученных \\nалгоритмов («не столь наивный» \\nбайесовский классификатор);  \\n• разработка комбинированных методов, \\nобладающих высокой точностью;  \\n• анализ точности существующих \\nалгори тмов на одинаковых корпусах с \\nобщим кр итерием оценки точности.  \\nВ частности, интерес представляет \\nкомб инация MRF -классификатора с \\nподходом «не столь наивного» байесовского \\nклассификат ора, так как первый обладает \\nвысокой точн остью классификации, а второй \\nимеет более высокую точность по  сравнению \\nсо стандар тным «наивным» байесовским \\nклассификат ором, являющимся основой для \\nMRF -классификатора.  Табл. 1.   Сравнение точности рассмотренных алгоритмов  \\nКласс  Метод  Точность  \\n(1-AUC) %  Доля корректно \\nклассифицированных \\nдокументов, %  \\nВероятностные \\nклассификаторы  «наивный» байесовский \\nклассификатор  - 90-97 [Christina, \\nKarpagavalli, Suganya, \\n2010; Better Bayesian \\nFiltering;  Joachims, \\n1997 ] \\n«не столь наивный» \\nбайесо вский классификатор  0.0344 [Su, Xu, \\n2009]  - \\nвероятностный алгоритм \\nРоккио  - 91 [Joachims, 1997 ] \\nMRF -классификатор  - 99.95 [Yerazunis, 2003]  \\nЛинейные \\nклассификаторы  персептрон  - - \\nалгоритм Winnow  - 98-99 [Siefkes et al., \\n2004]  \\nSVM  0.024 [ Sculley, \\nWachman, \\n2007 ] 99 [Drucker, Wu, \\nVapnik, 1999 ] \\nКлассификаторы на \\nоснове сходства  kNN  0.3056 \\n[Yerazunis, \\n2006 ] - \\nЛогические \\nклассификаторы  деревья принятия решений  - 88 [Carreras, Marquez, \\n2001]  \\nлогический вывод на основе \\nправил  - 92 [Androutsopoulos, \\nPaliouras, Michelakis, \\n2006]  \\nDCM классификаторы  DMC  0.013 [Bratko et \\nal., 2006]  - \\nPPM  0.019 [Bratko et \\nal., 2006]  - \\n 4 Заключение  \\nВ данной работе были рассмотрены алг оритмы, позволяющие осуществить фильтр ацию спама \\nметодами машинного обучения. В качестве расширения существующей [Cormack, 2008] \\nпредложена классификация алгоритмов идентификации спама, состоящая из 5 классов, \\nсоответственно применяемым в их рамках подходам. Проведён сравнител ьный анализ \\nрассмотрен ных алгоритмов с приведением точности идентификации ими спама. Выделены \\nнаиболее перспективные направления для дальнейшего исследования и употребления в разработке \\nновых методов идентификации спама.  \\nСписок  литературы  \\nCormack G. V. Email spam filtering: A s ystematic review //Foundations and Trends in Information Retrieval. – \\n2008. – Vol. 1. – №. 4. – P. 335 -455. \\nСпам и фишинг во втором квартале 2016. [Эле ктронный ресурс]. Режим доступа: \\nhttps ://securelist .ru/analysis /spam -quarterly /29116/ spam -and-phishing -in-q2-2016/ (дата обращения: 20.02.17)  \\nБольшакова Е.И., Клышинский Э.С., Ландэ Д.В., Носков А.А., Пескова О.В., Ягунова Е.В. Авт оматическая \\nобработка текстов на естественном языке и компьютерная лингвистика: учеб. п особие — М.: МИЭМ, \\n2011. — 272 с.  \\nBarber D.  Bayesian reasoning and machine learning. – Cambridge University Press, 2012.  \\nChhabra S., Yerazunis W. S., Siefkes C. Spam filte ring using a markov random field model with vari able weighting \\nschemas //Data Mining, 2004. ICDM\\'04. Fourth IEEE International Conference on. – IEEE, 2004. – Pp. 347 -350.  \\nCRM114 Notes for the TREC 2005 Spam Track [Электронный ресурс]. Режим доступа \\nhttp://crm114.sourceforge .net/docs/NIST _TREC _2005_ paper .html (дата обращения: 20.02.17)  \\nHovold J. Naive Bayes Spam Filtering Using Wo rd-Position -Based Attributes //CEAS. – 2005. – Pp. 41 -48. \\nChristina V., Karpagavalli S., Suganya G. Email spam filtering using supervised machine learning tec hniques \\n//International Journal on Computer Science and Engineering (IJCSE). – 2010. – Vol. 2. – Pp. 3126 -3129.  \\nLowd D., Meek C. Good Word Attacks on Statistical Spam Filters //In Proceedings of the Second Co nference on \\nEmail and Anti -Spam (CEAS). – 2005.  \\nSu B., Xu C. Not So Naıve Online Bayesian Spam Filter //Proceedings of the Twenty -First Innovativ e Applications \\nof Artificial Intelligence Conference. – 2009.  \\nBetter Bayesian Filtering. [Электронный ресурс]. Режим доступа http://www .paulgraham .com/better .html (Дата \\nобращения: 20.02.17)  \\nJoachims T. A Probabilistic Analysis of the Rocchio Algorithm with  TFIDF for Text Categorization. // Proceedings \\nof ICML -97, 14th International Co nference on Machine Learning. – 1997. – Pp. 143 -151. \\nYerazunis W. S. The spam -filtering accuracy plateau at 99.9% accuracy and how to get past it //Proceedings of the \\n2004 MIT Spam Conference. – 2004.  \\nLittlestone N. Learning quickly when irrelevant a ttributes abound: A new linear -threshold algorithm //Machine \\nlearning. – 1988. – Vol. 2. – №. 4. – Pp. 285 -318. \\nSiefkes C., Assis, F., Chhabra, S., Yerazunis, W. S. Combining winnow and orthogonal sparse bigrams for \\nincremental spam filtering //European Confe rence on Principles of Data Mining and Knowledge Discovery. – \\n2004. – Pp. 410 -421. \\nWu C. H. Behavior -based spam detection using a h ybrid method of rule -based techniques and neural  networks \\n//Expert Systems with Applications. – 2009. – Vol. 36. – №. 3. – Pp. 4321 -4330.  \\nBratko A., Filipic B., Zupan B. Towards Practical PPM Spam Filtering: Experiments for the TREC 2006 Spam \\nTrack // Proceedings of the 15th Text REtrieval Conference (T REC 2006). – 2006.  \\nBratko A., Cormack, G. V., Filipič, B., Lynam, T. R., Zupan, B. Spam filtering using statistical dat a compression \\nmodels //Journal of machine learning research. – 2006. – Vol. 7. – Pp. 2673 -2698.  \\nBreiman L.  , Friedman, J., Stone, C. J., Olshen, R. A. Classification and regression trees. – CRC press, 1984.  \\nShakhnarovich, G. Darrell, T., Indyk, P. Nearest -neighbor methods in learning and vision. Theory and Practice. – \\nMIT Press. – 2006.  Hanley J. A., McNeil B. J. A method of comparing the areas under receiver operating characteristic c urves derived \\nfrom the same cases //Radiology. – 1983. – Vol. 148. – №. 3. – Pp. 839-843. \\nDrucker H., Wu D., Vapnik V. N. Support vector m achines for spam c ategorization //IEEE Transactions on Neural \\nnetworks. – 1999. – Vol. 10. – №. 5. – Pp. 1048 -1054.  \\nSculley D., Wachman G. M. Relaxed online SVMs for spam filtering //Proceedings of the 30th annual in ternational \\nACM SIGIR conference on Research and developme nt in information retrieval. – 2007. – Pp. 415 -422. \\nCarreras X., Marquez L. Boosting trees for anti -spam email filtering // In 4th International Conference on Recent \\nAdvances in Natural Language Processing.  – 2001.  – Pp. 58 -64. \\nAndroutsopoulos I., Paliouras  G., Michelakis E. Learning to filter u nsolicited commercial e -mail. Technical report \\n2004/2, National Center for Scie ntific Research  “Demokritos” . – 2004.  \\nYerazunis W. S. Seven Hypothesis about Spam Filte ring // Proceedings of the 15th Text REtrieval Co nference \\n(TREC 2006).  – 2006.  \\n ']\n"
     ]
    }
   ],
   "source": [
    "print(res_text[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9530c181",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
