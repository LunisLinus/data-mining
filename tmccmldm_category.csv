title;;;authors;;;date;;;source;;;abstract;;;link;;;category
Text mining for incoming tasks based on the urgency/importance factors and task classification using machine learning tools;;;['Yasser Ali Alshehri'];;;March 2020;;;ICCDA '20: Proceedings of the 2020 4th International Conference on Compute and Data Analysis;;;In workplaces, there is a massive amount of unstructured data from different sources. In this paper, we present a case study that explains how can through communications between employees, we can help to prioritize tasks requests to increase the efficiency of their works for both technical and non-technical workers. This involves managing daily incoming tasks based on their level of urgency and importance.To allow all workers to utilize the urgency-importance matrix as a time-management tool, we need to automate this tool. The textual content of incoming tasks are analyzed, and metrics related to urgency and importance are extracted. A third factor (i.e., the response variable) is defined based on the two input variables (urgency and importance). Then, machine learning applied to the data to predict the class of incoming tasks based on data outcome desired. We used ordinal regression, neural networks, and decision tree algorithms to predict the four levels of task priority. We measure the performance of all using recalls, precisions, and F-scores. All classifiers perform higher than 89% in terms of all measures.;;;https://dl.acm.org/doi/10.1145/3388142.3388153;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Text mining for malware classification using multivariate all repeated patterns detection;;;['Konstantinos F. Xylogiannopoulos', 'Panagiotis Karampelas', 'Reda Alhajj'];;;August 2019;;;ASONAM '19: Proceedings of the 2019 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining;;;Mobile phones have become nowadays a commodity to the majority of people. Using them, people are able to access the world of Internet and connect with their friends, their colleagues at work or even unknown people with common interests. This proliferation of the mobile devices has also been seen as an opportunity for the cyber criminals to deceive smartphone users and steel their money directly or indirectly, respectively, by accessing their bank accounts through the smartphones or by blackmailing them or selling their private data such as photos, credit card data, etc. to third parties. This is usually achieved by installing malware to smartphones masking their malevolent payload as a legitimate application and advertise it to the users with the hope that mobile users will install it in their devices. Thus, any existing application can easily be modified by integrating a malware and then presented it as a legitimate one. In response to this, scientists have proposed a number of malware detection and classification methods using a variety of techniques. Even though, several of them achieve relatively high precision in malware classification, there is still space for improvement. In this paper, we propose a text mining all repeated pattern detection method which uses the decompiled files of an application in order to classify a suspicious application into one of the known malware families. Based on the experimental results using a real malware dataset, the methodology tries to correctly classify (without any misclassification) all randomly selected malware applications of 3 categories with 3 different families each.;;;https://dl.acm.org/doi/10.1145/3341161.3350841;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Comparative Study between Traditional Machine Learning and Deep Learning Approaches for Text Classification;;;['Cannannore Nidhi Kamath', 'Syed Saqib Bukhari', 'Andreas Dengel'];;;August 2018;;;DocEng '18: Proceedings of the ACM Symposium on Document Engineering 2018;;;In this contemporaneous world, it is an obligation for any organization working with documents to end up with the insipid task of classifying truckload of documents, which is the nascent stage of venturing into the realm of information retrieval and data mining. But classification of such humongous documents into multiple classes, calls for a lot of time and labor. Hence a system which could classify these documents with acceptable accuracy would be of an unfathomable help in document engineering. We have created multiple classifiers for document classification and compared their accuracy on raw and processed data. We have garnered data used in a corporate organization as well as publicly available data for comparison. Data is processed by removing the stop-words and stemming is implemented to produce root words. Multiple traditional machine learning techniques like Naive Bayes, Logistic Regression, Support Vector Machine, Random forest Classifier and Multi-Layer Perceptron are used for classification of documents. Classifiers are applied on raw and processed data separately and their accuracy is noted. Along with this, Deep learning technique such as Convolution Neural Network is also used to classify the data and its accuracy is compared with that of traditional machine learning techniques. We are also exploring hierarchical classifiers for classification of classes and subclasses. The system classifies the data faster and with better accuracy than if done manually. The results are discussed in the results and evaluation section.;;;https://dl.acm.org/doi/10.1145/3209280.3209526;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Where is the road for issue reports classification based on text mining?;;;['Qiang Fan', 'Yue Yu', 'Gang Yin', 'Tao Wang', 'Huaimin Wang'];;;November 2017;;;ESEM '17: Proceedings of the 11th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement;;;Currently, open source projects receive various kinds of issues daily, because of the extreme openness of Issue Tracking System (ITS) in GitHub. ITS is a labor-intensive and time-consuming task of issue categorization for project managers. However, a contributor is only required a short textual abstract to report an issue in GitHub. Thus, most traditional classification approaches based on detailed and structured data (e.g., priority, severity, software version and so on) are difficult to adopt. In this paper, issue classification approaches on a large-scale dataset, including 80 popular projects and over 252,000 issue reports collected from GitHub, were investigated. First, four traditional text-based classification methods and their performances were discussed. Semantic perplexity (i.e., an issues description confuses bug-related sentences with nonbug-related sentences) is a crucial factor that affects the classification performances based on quantitative and qualitative study. Finally, A two-stage classifier framework based on the novel metrics of semantic perplexity of issue reports was designed. Results show that our two-stage classification can significantly improve issue classification performances.;;;https://dl.acm.org/doi/10.1109/ESEM.2017.19;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Identification of Overpricing in the Purchase of Medication by the Federal Government of Brazil, Using Text Mining and Clustering Based on Ontology;;;['Marco Aurelio O. S. Correa', 'Adriano Galindo Leal'];;;August 2018;;;ICCBDC '18: Proceedings of the 2018 2nd International Conference on Cloud and Big Data Computing;;;Increasing the transparency level in his actions and spending is one of the primary duties of the Brazilian Federal Government. The creation of laws that oblige full disclose of all its expenditures through transparency portals enables citizens to supervise all government entities. However, only the dissemination of these data, without a definite standard or the availability of data analysis tools, does not guarantee that the citizen is empowered to play his role. Therefore hence, the objective of this work is to identify overprice in the acquisition of products purchased by the federal government of Brazil using the unstructured data available on the Transparency Portal. The last two-years' worth of purchasing data, available in the Transparency Portal, were extracted, processed and stored. Due to his diverse nature and high volume of data, this study focused only on medicines purchased by the Ministry of Health. Ontology-based text mining and clustering techniques were applied for automatic identification and classification of products. The processing of this information was done through text mining and clustering, based on the ontology registered in another database of the Brazilian government. Because of this work, a consolidated price base per medication was created to allow the identification of distortions in prices practised, facilitating the identification of cases that merit further investigation to unravel fraud to the treasury.;;;https://dl.acm.org/doi/10.1145/3264560.3264569;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Computational Estimation by Scientific Data Mining with Classical Methods to Automate Learning Strategies of Scientists;;;['Aparna S. Varde'];;;None;;;ACM Transactions on Knowledge Discovery from Data;;;Experimental results are often plotted as 2-dimensional graphical plots (aka graphs) in scientific domains depicting dependent versus independent variables to aid visual analysis of processes. Repeatedly performing laboratory experiments consumes significant time and resources, motivating the need for computational estimation. The goals are to estimate the graph obtained in an experiment given its input conditions, and to estimate the conditions that would lead to a desired graph. Existing estimation approaches often do not meet accuracy and efficiency needs of targeted applications. We develop a computational estimation approach called AutoDomainMine that integrates clustering and classification over complex scientific data in a framework so as to automate classical learning methods of scientists. Knowledge discovered thereby from a database of existing experiments serves as the basis for estimation. Challenges include preserving domain semantics in clustering, finding matching strategies in classification, striking a good balance between elaboration and conciseness while displaying estimation results based on needs of targeted users, and deriving objective measures to capture subjective user interests. These and other challenges are addressed in this work. The AutoDomainMine approach is used to build a computational estimation system, rigorously evaluated with real data in Materials Science. Our evaluation confirms that AutoDomainMine provides desired accuracy and efficiency in computational estimation. It is extendable to other science and engineering domains as proved by adaptation of its sub-processes within fields such as Bioinformatics and Nanotechnology.;;;https://dl.acm.org/doi/10.1145/3502736;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Comparative Study of Heart Disease Diagnosis Using Top Ten Data Mining Classification Algorithms;;;['I. Ketut Agung Enriko'];;;June 2019;;;ICFET '19: Proceedings of the 5th International Conference on Frontiers of Educational Technologies;;;Data mining has been used for many purposes, especially for prediction system. In healthcare, data mining algorithms often used in disease diagnosis. Meanwhile, heart disease is known as a primary cause of death over the years. Many studies have been performed in heart disease diagnosis using data mining methods. There are some popular data mining algorithms that can be used in heart disease diagnosis, for example, k-Nearest Neighbor, CART, and AdaBoost. The algorithms are used to analyze a sample of cardiovascular patients data and predict the heart disease type that they suffer. Some parameters are taken from the patient, including EKG morphology, blood pressure, and information about the existence of chest pain, shortness of breath, palpitation, and cold sweat. In this study, medical records data are collected from Harapan Kita Hospital and utilized as a dataset sample in this research. Top ten data mining classification algorithms are used in diagnosing heart disease from Harapan Kita Hospital data and examining their performance by checking the accuracy and speed.;;;https://dl.acm.org/doi/10.1145/3338188.3338220;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Feature Selection based Arabic Text Classification using Different Machine Learning Algorithms: Comparative Study;;;['Sakina Rim Bennabi', 'Zakaria Elberrichi'];;;June 2020;;;ICIST '20: Proceedings of the 10th International Conference on Information Systems and Technologies;;;Feature selection is a method of data pre-processing widely used when mining large data, such as textual classification. Several studies have been conducted to compare the different methods of feature selection applied to corpora in English. Unfortunately, a small number of works concern the Arabic language. This article aims to present a comparative study of different feature selection techniques including: Chi2, the ANOVA method and mutual information, applied on a corpus in Arabic language, while also diversifying the machine learning algorithms (Naive Bayes, SVM and KNN). This experimental study has shown in general that reducing dimensionality with feature selection techniques has slightly affected the performance of textual classification, reducing the size of the corpus by up to 1%.;;;https://dl.acm.org/doi/10.1145/3447568.3448531;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Clustering Algorithms for Spatial Data Mining;;;['Chetashri Bhadane', 'Ketan Shah'];;;April 2020;;;ICGDA '20: Proceedings of the 2020 3rd International Conference on Geoinformatics and Data Analysis;;;With the advances in mobile and wireless technologies, there has been a rise in applications that track and share the users' geospatial data. People use several social networking sites such as Twitter, Facebook and Flickr, where they share their status updates. With the integration of Global Positioning System (GPS) with mobile phones, it is now possible to share one's locations on these social networks. GPS allows us to record and track a person's movement along with the timestamp. The data set obtained from these GPS logs is vast and is widely used to analyze the users' movement patterns. Specifically, we can find out significant locations based on the number of users present at that location and the time spent by them at such places. Once significant places have been identified, it is also possible to identify the semantic importance of these locations. This paper presents an overview of the clustering techniques used to find important places of interest using large GPS based mobility datasets. Four clustering algorithms, K-Means, DBSCAN, OPTICS and Hierarchical, are implemented, and performance is tested using real-time data of 50 users collected over 2--5 years. Performance summary depicts that K-Means and DBSCAN perform well for spatial data.;;;https://dl.acm.org/doi/10.1145/3397056.3397068;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Applying text mining to predict learners' cognitive engagement;;;['Hayati Hind', 'Mohammed Khalidi Idrissi', 'Samir Bennani'];;;October 2017;;;SCAMS '17: Proceedings of the Mediterranean Symposium on Smart City Application;;;In academic process, engagement represent one of the important success' factor. This paper proposes a predictive system for learners' cognitive engagement based on their online discussion forums participation. In the first level the ontology OWL and the LSA method are used to perform a semantic classification system of the threads according to a specific context chosen by the tutor. Then the Text mining, as a predictive method, is applied to the classified threads and learners' participation in the forums.;;;https://dl.acm.org/doi/10.1145/3175628.3175655;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Text Mining Approach for Identifying Research Trends;;;['Snezhana Sulova'];;;June 2021;;;CompSysTech '21: Proceedings of the 22nd International Conference on Computer Systems and Technologies;;;With the increase of unstructured data, the issues connected with automatic text processing, the categorization of documents and the discovery of topics have become objects of growing interest. In order to improve the process of grouping and processing research publications, we would like to propose a method based upon natural language processing. It is based on text mining technologies which aim to identify key tendencies in documents. It processes the content of publications by clustering and identifies the topics of each identified group. This analysis helps by identifying key tendencies as well as discovering emerging new areas of research. Publications from the research literature database, Scopus, were used to test the approach. The topic of the publications is “the application of digital technologies in the logistics business”. The experiments were completed using the RapidMiner Studio software.;;;https://dl.acm.org/doi/10.1145/3472410.3472433;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Investigate Transitions into Drug Addiction through Text Mining of Reddit Data;;;['John Lu', 'Sumati Sridhar', 'Ritika Pandey', 'Mohammad Al Hasan', 'Georege Mohler'];;;July 2019;;;KDD '19: Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining;;;Increasing rates of opioid drug abuse and heightened prevalence of online support communities underscore the necessity of employing data mining techniques to better understand drug addiction using these rapidly developing online resources. In this work, we obtained data from Reddit, an online collection of forums, to gather insight into drug use/misuse using text snippets from users narratives. Specifically, using users' posts, we trained a binary classifier which predicts a user's transitions from casual drug discussion forums to drug recovery forums. We also proposed a Cox regression model that outputs likelihoods of such transitions. In doing so, we found that utterances of select drugs and certain linguistic features contained in one's posts can help predict these transitions. Using unfiltered drug-related posts, our research delineates drugs that are associated with higher rates of transitions from recreational drug discussion to support/recovery discussion, offers insight into modern drug culture, and provides tools with potential applications in combating the opioid crisis.;;;https://dl.acm.org/doi/10.1145/3292500.3330737;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Assessment of Vulnerability Severity using Text Mining;;;['Georgios Spanos', 'Lefteris Angelis', 'Dimitrios Toloudis'];;;September 2017;;;PCI '17: Proceedings of the 21st Pan-Hellenic Conference on Informatics;;;Software1 vulnerabilities are closely associated with information systems security, a major and critical field in today's technology. Vulnerabilities constitute a constant and increasing threat for various aspects of everyday life, especially for safety and economy, since the social impact from the problems that they cause is complicated and often unpredictable. Although there is an entire research branch in software engineering that deals with the identification and elimination of vulnerabilities, the growing complexity of software products and the variability of software production procedures are factors contributing to the ongoing occurrence of vulnerabilities, Hence, another area that is being developed in parallel focuses on the study and management of the vulnerabilities that have already been reported and registered in databases. The information contained in such databases includes, a textual description and a number of metrics related to vulnerabilities. The purpose of this paper is to investigate to what extend the assessment of the vulnerability severity can be inferred directly from the corresponding textual description, or in other words, to examine the informative power of the description with respect to the vulnerability severity. For this purpose, text mining techniques, i.e. text analysis and three different classification methods (decision trees, neural networks and support vector machines) were employed. The application of text mining to a sample of 70,678 vulnerabilities from a public data source shows that the description itself is a reliable and highly accurate source of information for vulnerability prioritization.;;;https://dl.acm.org/doi/10.1145/3139367.3139390;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Intelligent Data Analysis using Optimized Support Vector Machine Based Data Mining Approach for Tourism Industry;;;['Ms Promila Sharma', 'Uma Meena', 'Girish Kumar Sharma'];;;None;;;ACM Transactions on Knowledge Discovery from Data;;;Data analysis involves the deployment of sophisticated approaches from data mining methods, information theory, and artificial intelligence in various fields like tourism, hospitality, and so on for the extraction of knowledge from the gathered and preprocessed data. In tourism, pattern analysis or data analysis using classification is significant for finding the patterns that represent new and potentially useful information or knowledge about the destination and other data. Several data mining techniques are introduced for the classification of data or patterns. However, overfitting, less accuracy, local minima, sensitive to noise are the drawbacks in some existing data mining classification methods. To overcome these challenges, Support vector machine with Red deer optimization (SVM-RDO) based data mining strategy is proposed in this article. Extended Kalman filter (EKF) is utilized in the first phase, i.e., data cleaning to remove the noise and missing values from the input data. Mantaray foraging algorithm (MaFA) is used in the data selection phase, in which the significant data are selected for the further process to reduce the computational complexity. The final phase is the classification, in which SVM-RDO is proposed to access the useful pattern from the selected data. PYTHON is the implementation tool used for the experiment of the proposed model. The experimental analysis is done to show the efficacy of the proposed work. From the experimental results, the proposed SVM-RDO achieved better accuracy, precision, recall, and F1 score than the existing methods for the tourism dataset. Thus, it is showed the effectiveness of the proposed SVM-RDO for pattern analysis.;;;https://dl.acm.org/doi/10.1145/3494566;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Integration of data mining techniques in e-learning systems: Clustering Profil of Lerners and Recommender Course System;;;['A. El Moustamid', 'E. En-Naimi', 'J. El Bouhdidi'];;;March 2017;;;BDCA'17: Proceedings of the 2nd international Conference on Big Data, Cloud and Applications;;;Data mining aims at the extraction of knowledge from large quantities of data by automatic or semi-automatic methods. In the field of education and training e-learning, Data Mining techniques as clustering (The aim of this technique is to identify groups that are similar in some aspect) [21], prediction (is used for developing model where combination of data viewed from different aspects can effect single viewed data. Here, is important to watch how predictors variables are effecting predicted variable)[21], classification are applied in e-learning to improve the level of learners by providing learning according to the learners' requirement) are used to analyze learners profile, to predict and improve student performance. The aim of our project is to develop a system capable of analyzing learners profile and indexing web videos in order to offer learners a rich database with courses that correspond to their levels.;;;https://dl.acm.org/doi/10.1145/3090354.3090453;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Text Mining in Cybersecurity: A Systematic Literature Review;;;['Luciano Ignaczak', 'Guilherme Goldschmidt', 'Cristiano André Da Costa', 'Rodrigo Da Rosa Righi'];;;None;;;ACM Computing Surveys;;;The growth of data volume has changed cybersecurity activities, demanding a higher level of automation. In this new cybersecurity landscape, text mining emerged as an alternative to improve the efficiency of the activities involving unstructured data. This article proposes a Systematic Literature Review (SLR) to present the application of text mining in the cybersecurity domain. Using a systematic protocol, we identified 2,196 studies, out of which 83 were summarized. As a contribution, we propose a taxonomy to demonstrate the different activities in the cybersecurity domain supported by text mining. We also detail the strategies evaluated in the application of text mining tasks and the use of neural networks to support activities involving unstructured data. The work also discusses text classification performance aiming its application in real-world solutions. The SLR also highlights open gaps for future research, such as the analysis of non-English content and the intensification in the usage of neural networks.;;;https://dl.acm.org/doi/10.1145/3462477;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Feature-based Facebook reviews process model for e-management using data mining;;;['Anish Kumar Varudharajulu', 'Yongsheng Ma'];;;January 2019;;;IC4E '19: Proceedings of the 10th International Conference on E-Education, E-Business, E-Management and E-Learning;;;The data generated from online communication acts as potential gold mines for discovering knowledge for researchers. A large amount of data is also generated in the form of web documents, emails, blogs, and feedback, etc. Text analytics is being significantly employed to mine important information. Opinion mining is the process of extracting human thoughts and perceptions from unstructured texts. The showstopper for designing an opinion mining system for analyzing reviews arise from the fact that customer reviews are often noisy. These reviews are informally written. In addition, they are subjected to spelling mistakes, grammatical errors, improper punctuation and irrational capitalization. This paper focuses on analyzing the different classification and clustering algorithms aimed at extracting and consolidating opinions of customers from social media sites like Facebook, Twitter and through surveys, at multiple levels of granularity to monitor and measure customer satisfaction. Ours is an automated approach, in which the system aids in the process of knowledge assimilation for knowledge-based building and also performs the analytics. Domain experts ratify the knowledge base and also provide training datasets for the system to intuitively gather more instances for ratification. The system identifies opinion expressions as phrases containing opinion words, opinionated features and also opinion modifiers. These expressions are categorized as positive, negative or neutral. Opinion expressions are identified and categorized using localized linguistic techniques. Opinions can be congregated at any desired level of specificity i.e. feature level or product level, user level or service level, etc. We have developed a system based on this approach, which provides the user with a platform to analyze opinion expressions crawled from a set of pre-defined datasets.;;;https://dl.acm.org/doi/10.1145/3306500.3306514;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Automatic topic classification of test cases using text mining at an Android smartphone vendor;;;['Junji Shimagaki', 'Yasutaka Kamei', 'Naoyasu Ubayashi', 'Abram Hindle'];;;October 2018;;;ESEM '18: Proceedings of the 12th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement;;;Background: An Android smartphone is an ecosystem of applications, drivers, operating system components, and assets. The volume of the software is large and the number of test cases needed to cover the functionality of an Android system is substantial. Enormous effort has been already taken to properly quantify "what features and apps were tested and verified?". This insight is provided by dashboards that summarize test coverage and results per feature. One method to achieve this is to manually tag or label test cases with the topic or function they cover, much like function points. At the studied Android smartphone vendor, tests are labelled with manually defined tags, so-called "feature labels (FLs)", and the FLs serve to categorize 100s to 1000s test cases into 10 to 50 groups. Aim: Unfortunately for developers, manual assignment of FLs to 1000s of test cases is a time consuming task, leading to inaccurately labeled test cases, which will render the dashboard useless. We created an automated system that suggests tags/labels to the developers for their test cases rather than manual labeling. Method: We use machine learning models to predict and label the functionality tested by 10,000 test cases developed at the company. Results: Through the quantitative experiments, our models achieved acceptable F-1 performance of 0.3 to 0.88. Also through the qualitative studies with expert teams, we showed that the hierarchy and path of tests was a good predictor of a feature's label. Conclusions: We find that this method can reduce tedious manual effort that software developers spent classifying test cases, while providing more accurate classification results.;;;https://dl.acm.org/doi/10.1145/3239235.3268927;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Discriminative Topic Mining via Category-Name Guided Text Embedding;;;['Yu Meng', 'Jiaxin Huang', 'Guangyuan Wang', 'Zihan Wang', 'Chao Zhang', 'Yu Zhang', 'Jiawei Han'];;;April 2020;;;WWW '20: Proceedings of The Web Conference 2020;;;Mining a set of meaningful and distinctive topics automatically from massive text corpora has broad applications. Existing topic models, however, typically work in a purely unsupervised way, which often generate topics that do not fit users’ particular needs and yield suboptimal performance on downstream tasks. We propose a new task, discriminative topic mining, which leverages a set of user-provided category names to mine discriminative topics from text corpora. This new task not only helps a user understand clearly and distinctively the topics he/she is most interested in, but also benefits directly keyword-driven classification tasks. We develop CatE, a novel category-name guided text embedding method for discriminative topic mining, which effectively leverages minimal user guidance to learn a discriminative embedding space and discover category representative terms in an iterative manner. We conduct a comprehensive set of experiments to show that CatE mines high-quality set of topics guided by category names only, and benefits a variety of downstream applications including weakly-supervised classification and lexical entailment direction identification.;;;https://dl.acm.org/doi/10.1145/3366423.3380278;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Text classification of Diseases Treated by Traditional Chinese Medicine Prescription based on machine learning;;;['Hanqing Zhao', 'Bo Han', 'Chen Li'];;;September 2020;;;ISAIMS '20: Proceedings of the 1st International Symposium on Artificial Intelligence in Medical Sciences;;;OBJECTIVE: To explore the application of machine learning in th e identification of diseases treated by traditional Chinese medicine prescriptions. METHODS: Based on the composition of the text document of Chinese medicine prescriptions, the prescriptions were divided into cough, headache and diarrhea. THUTCT were introduced to establish and train two machine learning text classification models, LibSVM and LibLinear, and the prescriptions to be deter mined were put into the model for classification and prediction. R ESULTS: The Precision rate of LibSVM model and Liblinear mod el were 0.7283 and 0.6690. Seven prescriptions were classified an d predicted, and the results were in line with expectations. CONCLUSION: THUCTC has good universality for the content of TCM prescriptions, high classification accuracy and fast testing speed, which is suitable for the text classification and discrimination research of TCM prescriptions for diseases.;;;https://dl.acm.org/doi/10.1145/3429889.3429895;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Petroleum Engineering Data Text Classification Using Convolutional Neural Network Based Classifier;;;['Tzuhan Hsu', 'Yaoqin Zhang'];;;May 2018;;;ICMLT '18: Proceedings of the 2018 International Conference on Machine Learning Technologies;;;In this paper, authors introduce a convolutional neural network (CNN) based classification approach for petroleum engineering event. Recently, text classification problem has raised substantial attention in the field of machine learning. The aim of text classification process is to assign correct label to a text on the basis of its content. However, due to the imprecise of feature representation, most of former text classification methods cannot export satisfying result. To solve this problem, authors propose a model based on convolutional neural network. Authors conduct experiments with real world petroleum engineering data text, artificially labelled into 6 categories. Beside purposed CNN-based model, the authors also implement other baseline machine learning approaches: k nearest neighbor, random forest, support vector machines, recurrent neural network, gated recurrent units, long short-term memory. Among all these models, our CNN-based model reach best performance in text classification task. In the last part of this paper, authors compare and analysis their purpose and baseline model.;;;https://dl.acm.org/doi/10.1145/3231884.3231898;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Text classification using Fuzzy TF-IDF and Machine Learning Models;;;['Mariem Bounabi', 'Karim El Moutaouakil', 'Khalid Satori'];;;October 2019;;;BDIoT '19: Proceedings of the 4th International Conference on Big Data and Internet of Things;;;The representation of the information has an important impact on the text classification task. Several weighting methods were proposed in the literature, and the term frequency-inverse term frequency (TFIDF), the most know on the text treatment field. The FTF-IDF is a vector representation where the components of the TFIDF are presented as inputs to the Fuzzy Inference System (FIS). In this work, we compare several Machin Learning algorithms such as Naïve Bayes and its derivatives, SVM and Random forest classifiers, using the FTF-IDF representation. To improve the quality of the used classifiers, we call sum attribute selection methods. The recognition rate, for the tested systems, is satisfied, where the system based on naïve Bayes classifier, the FTF-IDF weighting terms, and the info gain select attributes method gives 98.7% as accuracy.;;;https://dl.acm.org/doi/10.1145/3372938.3372956;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Text mining for plagiarism detection: multivariate pattern detection for recognition of text similarities;;;['Konstantinos Xylogiannopoulos', 'Panagiotis Karampelas', 'Reda Alhajj'];;;August 2018;;;ASONAM '18: Proceedings of the 2018 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining;;;The problem of plagiarism the recent years has been intensified by the availability of information in digital form and the accessibility of the electronic libraries through the Internet. As a result, plagiarism detection has been transformed into a big data analytics problem since the number of digital sources is extravagant and a new document needs to be compared with millions of other existing documents. In this paper, a text mining methodology is proposed that can detect all common patterns between a document and the documents in a reference database. The technique is based on a pattern detection algorithm and the corresponding data structure that enables the algorithm to detect all common patterns. The methodology has been applied in a well-defined dataset providing very promising results identifying difficult cases of plagiarism such as technical disguise.;;;https://dl.acm.org/doi/10.5555/3382225.3382424;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Mining Moocs Videos Metadata Using Classification Techniques;;;['El Harrak Othman', 'Ghadi Abderrahim', 'El Bouhdidi Jaber'];;;March 2017;;;BDCA'17: Proceedings of the 2nd international Conference on Big Data, Cloud and Applications;;;In few years, the internet has become the first source of information for most people, Today MOOCs makes it possible for everyone to access to the education over the world, it's represents an emerging methodology of online teaching and an important development in open education. Due to the rapid development of Moocs and the rapid growth of digital data and video database over the Internet, it is becoming very difficult for learners to browsing and choosing the best training for them. The scientific community has increased the amount of research into new technologies, with a view to improve the digital video utilization: its archiving, indexing, accessibility, acquisition, store and even its process and usability. All these parts of the video utilization entail the necessity of the extraction of all important information of a video, especially in cases of lack of metadata information. Web video mining is retrieving the content using data mining techniques from World Wide Web. There are two approaches for web video mining using traditional image processing (signal processing) and metadata based approach. In this paper, we present the various research makes in this subject and we propose an effective methodology to extract the metadata from Moocs videos and classify them based on the extracted metadata by applying data mining techniques.;;;https://dl.acm.org/doi/10.1145/3090354.3090450;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Text mining with HathiTrust;;;['Eleanor Dickson Koehl', 'Ryan Dubnicek'];;;June 2019;;;JCDL '19: Proceedings of the 18th Joint Conference on Digital Libraries;;;This tutorial will introduce attendees to the HathiTrust Research Center and its tools and services for computational text analysis research. HTRC leverages the scope and scale of the HathiTrust Digital Library collection to create opportunities for researchers to perform text data mining on subsets of the corpus. Attendees will develop skills that will allow them to conduct basic text analysis research using HathiTrust data, learn techniques for engaging with scholars on their text data mining research, and explore strategies for computational access to large-scale digital collections.;;;https://dl.acm.org/doi/10.1109/JCDL.2019.00115;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Mining Free-Text Medical Notes for Suicide Risk Assessment;;;['Marios Adamou', 'Grigoris Antoniou', 'Elissavet Greasidou', 'Vincenzo Lagani', 'Paulos Charonyktakis', 'Ioannis Tsamardinos'];;;July 2018;;;SETN '18: Proceedings of the 10th Hellenic Conference on Artificial Intelligence;;;Suicide has been considered as an important public health issue for a very long time, and is one of the main causes of death worldwide. Despite suicide prevention strategies being applied, the rate of suicide has not changed substantially over the past decades. Advances in machine learning make it possible to attempt to predict suicide based on the analysis of relevant data to inform clinical practice. This paper reports on findings from the analysis of data of patients who died by suicide in the period 2013-2016 and made use of both structured data and free-text medical notes. We focus on examining various text-mining approaches to support risk assessment. The results show that using advance machine learning and text-mining techniques, it is possible to predict within a specified period which people are most at risk of taking their own life at the time of referral to a mental health service.;;;https://dl.acm.org/doi/10.1145/3200947.3201020;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Classifying Indonesian Online Articles as Advertisement Placement Base Using Text Mining;;;['Nadhira Tasya', 'Arian Dhini'];;;July 2017;;;ICBIM 2017: Proceedings of the International Conference on Business and Information Management;;;Rapid development in technological aspect resulting in growing level of human needs for the latest news, so that emerged a new trend of publishing and accessing news through online media or usually called online journalism. In addition, the number of people who sell and purchase through online sites also continues to increase and this opportunity is utilized by the company and the advertiser by implementing targeted web advertising. However, the high number of articles that have been published and accessed leads to great opportunities for errors in determining where to place the ads. Therefore, it needs a system that can categorize articles accessed by users as the basis of advertisement placement by the company and this classification system can be done by applying the method of Data Mining and Text Mining. This research uses document data in the form of article content that will be categorized into twenty categories of class of advertisement by using Text Mining technique with Support Vector Machine algorithm. The results of this study may be used by companies or advertisers as a basis for placement of ads on selected online media sites.;;;https://dl.acm.org/doi/10.1145/3134271.3134288;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Compare Machine Learning Models in Text Classification Using Steam User Reviews;;;['Youchen Miao', 'Zeyu Jin', 'Yumeng Zhang', 'Yuchen Chen', 'Junren Lai'];;;November 2021;;;ICSED '21: Proceedings of the 2021 3rd International Conference on Software Engineering and Development;;;Text Classification and Sentiment Analysis of game reviews are viewed as important parts in not only academic fields but also in game studies. In this paper, with more than 400 thousand game reviews on Steam platform, we preprocess the data using different libraries (sklearn, nltk, and spaCy) and use them as inputs to build three sentiment classification models based on different algorithms (Naive Bayes, SVM, and Random Forest). In contrast to previous studies that only focus on different sentiment analysis models, our paper also highlights the use of different APIs to preprocess the data and their corresponding model performance. The results show that no matter which API we choose, Random Forest models always perform the best. However, in terms of training time, Naive Bayes is the fastest. This work can be used to apply grid search for researchers to automatically find the optimum API before conducting sentiment analysis in the future.;;;https://dl.acm.org/doi/10.1145/3507473.3507480;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
To apply Data Mining for Classification of Crowd sourced Software Requirements;;;['Soonh Taj', 'Qasim Arain', 'Imran Memon', 'Asma Zubedi'];;;April 2019;;;ICSIE '19: Proceedings of the 8th International Conference on Software and Information Engineering;;;Now a day's main focus of developers is to build quality software that works according to customer needs and for this reason it is necessary to gather right requirements as requirement elicitation is the critical step that impacts on the success of software project as misinterpreted requirements leads to the failure of software project. By keeping this in mind a research is carried out on improving requirements elicitation process and automating the process of classifying requirements. In this research, a model is proposed which will help in this scenario for requirements elicitation and requirement classification. This paper presents a model in which crowd sourcing approach is used so that customers, end users, stakeholders, developers and software engineers can make active participation for requirement elicitation process and requirements gathered using crowdsourcing approach are used by model for classification process i.e. classification of requirements into functional and non-functional requirements. For the proof of proposed model a case study is conducted. Results of case study provided the usefulness and efficiency of proposed model for classification of crowd sourced software requirements.;;;https://dl.acm.org/doi/10.1145/3328833.3328837;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Evaluation of retweet clustering method classification method using retweets on Twitter without text data;;;['K. Uchida', 'F. Toriumi', 'T. Sakaki'];;;August 2017;;;WI '17: Proceedings of the International Conference on Web Intelligence;;;Burst phenomena, which frequently occur on social media, are caused by such social events as flaming on the internet, elections, and natural disasters. To understand people's thoughts and feelings, we must classify their opinions from burst phenomena. Therefore, classification methods that categorize tweets are critical. However, since most classification methods focus on text mining, they cannot group tweets by topics because each tweet has poor linguistic similarities. We used a non-text-based classification method proposed by Baba et al. that groups tweets by topics, even if they have poor linguistic similarities, and verified its validity by comparing it with a text-based classification method in two different evaluations: qualitative and quantitative. In the qualitative evaluation part, we did a questionnaire survey and validated the suitability of the topic clusters created using both the non-and text-based methods. Since evaluating the similarity of every pair of tweets in each topic is difficult, we evaluated the similarity between sampled pairs in the survey and acquired more appropriate topic clustering results using the non-text-based method than the text-based method. In the quantitative evaluation part, we focused on the robustness of each method against data reduction. Many approaches analyze social media data, especially because collecting data from social media is comparatively easy. However, since collecting the whole data of burst phenomena is very costly due to the vast amounts of available social media data, robustness against data reduction is an important index to evaluate classification methods. With the non-text-based method, over 55% of the pairs of tweets in the same cluster were also included in the same cluster even when the data were reduced to 10% in all three of our example cases. In this paper, as a source we focus on Twitter, one of the most popular microblogging services. Using clustering to conduct detailed case analyses, we scrutinized three burst cases that include natural disasters and flaming on the internet and found that a non-text-based method more effectively classified tweets in burst phenomena than a text-based method.;;;https://dl.acm.org/doi/10.1145/3106426.3106451;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Analysing digital banking reviews using text mining;;;['Li Chen Cheng', 'Legaspi Rhea Sharmayne'];;;December 2020;;;ASONAM '20: Proceedings of the 12th IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining;;;Digital banks are new entrants in the banking industry in the Philippines as they only started late 2018. Since then, a handful of players have and are still emerging. With more and more people becoming technologically savvy, it is very critical for financial institutions to develop a digital banking application that will stand out from the competition. This paper aims to use text mining methods to analyse digital banking application reviews. This study will perform topic modelling using LDA to explore customer concerns and will mine association rules between the digital banking features with the review score. The results will reveal which areas the digital banking application can further optimize for customer satisfaction and retention.;;;https://dl.acm.org/doi/10.1109/ASONAM49781.2020.9381429;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Transfer Learning to Timed Text Based Video Classification Using CNN;;;['Zenun Kastrati', 'Ali Shariq Imran', 'Arianit Kurti'];;;June 2019;;;WIMS2019: Proceedings of the 9th International Conference on Web Intelligence, Mining and Semantics;;;Open educational video resources are gaining popularity with a growing number of massive open online courses (MOOCs). This has created a niche for content providers to adopt effective solutions in automatically organizing and structuring of educational resources for maximum visibility. Recent advances in deep learning techniques are proving useful in managing and classifying resources into appropriate categories. This paper proposes one such convolutional neural network (CNN) model for classifying video lectures in a MOOC setting using a transfer learning approach. The model uses a time-aligned text transcripts corresponding to video lectures from six broader subject categories. Video lectures and their corresponding transcript dataset is gathered from the Coursera MOOC platform. Two different CNN models are proposed: i) CNN based classification using embeddings learned from our MOOC dataset, ii) CNN based classification using transfer learning. Word embeddings generated from two well known state-of-the-art pre-trained models Word2Vec and GloVe, are used in the transfer learning approach for the second case. The proposed CNN models are evaluated using precision, recall, and F1 score and the obtained performance is compared with both conventional and deep learning classifiers. The proposed CNN models have an F1 score improvement of 10-22 percentage points over DNN and conventional classifiers;;;https://dl.acm.org/doi/10.1145/3326467.3326483;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Clustering legal artifacts using text mining;;;['Zoi Lachana', 'Michalis Avgerinos Loutsaris', 'Charalampos Alexopoulos', 'Yannis Charalabidis'];;;October 2021;;;ICEGOV '21: Proceedings of the 14th International Conference on Theory and Practice of Electronic Governance;;;The globalization of communication networks and the possibilities offered by the information and communication technologies (ICTs) significantly change the public sector's operation and services. Digital Governance is now integrated into administrations' policies and programs at all levels: local, regional, national, European. At the national level, there is a requirement to provide electronic public services according to citizens' needs while, in the sense of globalization, at the European level, there are many programs (e.g., the Europe 2005 and i2010 program) emphasizing the Digital Governance world (or better Digital Governance community) that indicates rapid changes not only in the sense of the change in the public sector's systems but also in the mentality that the public sector operates. On the other hand, Digital Governance's evolution affects societies intensively, emphasizing the importance of cross-border interaction and information sharing between them. [6]. Concerning the legal informatics domain, this can result in changing governments' operations in many ways [2]. By now, the massive amount of each country's legal information currently remains fragmented across multiple national databases and systems or even better legal databases. Most of these legal databases result from the significant advancements in the “legal informatics” research field that observed since governments have started to promote the development of legal information systems [9]. This research contributes to this purpose by developing an open and automated legal system capable of providing any EU country's legal information based on the existing ontologies.;;;https://dl.acm.org/doi/10.1145/3494193.3494202;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Data Mining and Opinion Mining: A Tool in Educational Context;;;['Myriam Peñafiel', 'Stefanie Vásquez', 'Diego Vásquez', 'Juan Zaldumbide', 'Sergio Luján-Mora'];;;July 2018;;;ICoMS '18: Proceedings of the 2018 1st International Conference on Mathematics and Statistics;;;The use of the web as a universal communication platform generates large volumes of data (Big data), which in many cases, need to be processed so that they can become useful knowledge in face of the sceptics who have doubts about the credibility of such information. The use of web data that comes from educational contexts needs to be addressed, since that large amount of unstructured information is not being valued, losing valuable information that can be used. To solve this problem, we propose the use of data mining techniques such as sentiment analysis to validate the information that comes from the educational platforms. The objective of this research is to propose a methodology that allows the user to apply sentiment analysis in a simple way, because although some researchers have done it, very few do with data in the educational context. The results obtained prove that the proposal can be used in similar cases.;;;https://dl.acm.org/doi/10.1145/3274250.3274263;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Analyzing used-car web listings via text mining;;;['Ayhan Demiriz', 'Fatma Cantaş'];;;October 2017;;;IML '17: Proceedings of the 1st International Conference on Internet of Things and Machine Learning;;;Used car trade is one of the major components of the world economies. It is not uncommon to sell a car by placing an internet advertisement irrespective of the geography in these days. A typical content of an advertisement is usually composed of two parts namely the structured and the free text data. The structured data may include some information about the asking price, make, model, year, mileage of the car and the contact info. In most cases, seller may give important clues about the car's current conditions in the free text data where the title (head) of the advertisement can be included as free text too. This paper reports preliminary results from a text mining study conducted on 75K used car internet listings collected from two major car listing web sites in Turkey. As expected, the words and the phrases related to the description of the car are observed to be frequent. The leading concepts in the free text are found to be regarding how to describe the current condition of a car, for example "no crash history".;;;https://dl.acm.org/doi/10.1145/3109761.3109782;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Text Mining for Evaluating Authors' Birth and Death Years;;;['Dror Moghaz', 'Yaakov Hacohen-Kerner', 'Dov Gabbay'];;;None;;;ACM Transactions on Knowledge Discovery from Data;;;This article presents a unique method in text and data mining for finding the era, i.e., mining temporal data, in which an anonymous author was living. Finding this era can assist in the examination of a fake document or extracting the time period in which a writer lived. The study and the experiments concern Hebrew, and in some parts, Aramaic and Yiddish rabbinic texts. The rabbinic texts are undated and contain no bibliographic sections, posing an interesting challenge. This work proposes algorithms using key phrases and key words that allow the temporal organization of citations together with linguistic patterns. Based on these key phrases, key words, and the references, we established several types of “Iron-clad,” Heuristic and Greedy rules for estimating the years of birth and death of a writer in an interesting classification task. Experiments were conducted on corpora, including documents authored by 12, 24, and 36 rabbinic writers and demonstrated promising results.;;;https://dl.acm.org/doi/10.1145/3281631;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Unsupervised behavioural mining and clustering for malware family identification;;;['Khanh Huu The Dam', 'Thomas Given-Wilson', 'Axel Legay'];;;March 2021;;;SAC '21: Proceedings of the 36th Annual ACM Symposium on Applied Computing;;;More accurate and advanced detection and classification of malware requires exploiting program behaviour and not merely syntactic or static features. One approach is to use system call dependency graphs (SCDGs) that represent the program behaviour by interactions with the system, and the relations between these interactions. These SCDGs have been used with supervised learning techniques to very accurately detect and classify malware. This works considers the unsupervised learning challenge of mining for common clusters of behaviour without a priori knowledge. This allows for clustering of similar programs by behaviour, that can then be used for either classification or further analysis.;;;https://dl.acm.org/doi/10.1145/3412841.3441919;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Identifying Online Profiles of Distance Learning Students Using Data Mining Techniques;;;['Osama Islam', 'Muazzam Siddiqui', 'Naif Radi Aljohani'];;;October 2019;;;ICDTE '19: Proceedings of the 3rd International Conference on Digital Technology in Education;;;Educational data has grown over the years with the increased use of technology within educational environments. This has led to a huge amount of data being stored in various data sources representing the student, his/her activities, and other aspects relevant to the learning process. To meet this analytical need, Educational Data Mining (EDM) has emerged to assist educational institutions in identifying key benefits such as students at risk, the level of student engagement or predicting student performance. The aim of this research was to explore the various aspects of student interaction data using data mining techniques to identify relevant patterns of behaviors and possible key attributes that have higher degrees of influence on distance learning students. The main findings identified several patterns of user online profiles based on a set of adopted learning strategies, the research proposed a framework for analyzing such interaction data based on R and Hadoop platforms to correlate online profiles with student performance.;;;https://dl.acm.org/doi/10.1145/3369199.3369249;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Lost in Transduction: Transductive Transfer Learning in Text Classification;;;['Alejandro Moreo', 'Andrea Esuli', 'Fabrizio Sebastiani'];;;None;;;ACM Transactions on Knowledge Discovery from Data;;;Obtaining high-quality labelled data for training a classifier in a new application domain is often costly. Transfer Learning
(a.k.a. “Inductive Transfer”) tries to alleviate these costs by transferring, to the “target” domain of interest, knowledge available from a different “source” domain. In transfer learning the lack of labelled information from the target domain is compensated by the availability at training time of a set of unlabelled examples from the target distribution. Transductive Transfer Learning denotes the transfer learning setting in which the only set of target documents that we are interested in classifying is known and available at training time. Although this definition is indeed in line with Vapnik’s original definition of “transduction”, current terminology in the field is confused. In this article, we discuss how the term “transduction” has been misused in the transfer learning literature, and propose a clarification consistent with the original characterization of this term given by Vapnik. We go on to observe that the above terminology misuse has brought about misleading experimental comparisons, with inductive transfer learning methods that have been incorrectly compared with transductive transfer learning methods. We then, give empirical evidence that the difference in performance between the inductive version and the transductive version of a transfer learning method can indeed be statistically significant (i.e., that knowing at training time the only data one needs to classify indeed gives an advantage). Our clarification allows a reassessment of the field, and of the relative merits of the major, state-of-the-art algorithms for transfer learning in text classification.;;;https://dl.acm.org/doi/10.1145/3453146;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Multi-level mining and visualization of scientific text collections: Exploring a bi-lingual scientific repository;;;['Pablo Accuosto', 'Francesco Ronzano', 'Daniel Ferrés', 'Horacio Saggion'];;;December 2017;;;WOSP 2017: Proceedings of the 6th International Workshop on Mining Scientific Publications;;;We present a system to mine and visualize collections of scientific documents by semantically browsing information extracted from single publications or aggregated throughout corpora of articles. The text mining tool performs deep analysis of document collections allowing the extraction and interpretation of research paper's contents. In addition to the extraction and enrichment of documents with metadata (titles, authors, affiliations, etc), the deep analysis performed comprises semantic interpretation, rhetorical analysis of sentences, triple-based information extraction, and text summarization. The visualization components allow geographical-based exploration of collections, topic-evolution interpretation, and collaborative network analysis among others. The paper presents a case study of a bi-lingual collection in the field of Natural Language Processing (NLP).;;;https://dl.acm.org/doi/10.1145/3127526.3127529;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Hierarchical Topic Mining via Joint Spherical Tree and Text Embedding;;;['Yu Meng', 'Yunyi Zhang', 'Jiaxin Huang', 'Yu Zhang', 'Chao Zhang', 'Jiawei Han'];;;August 2020;;;KDD '20: Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining;;;Mining a set of meaningful topics organized into a hierarchy is intuitively appealing since topic correlations are ubiquitous in massive text corpora. To account for potential hierarchical topic structures, hierarchical topic models generalize flat topic models by incorporating latent topic hierarchies into their generative modeling process. However, due to their purely unsupervised nature, the learned topic hierarchy often deviates from users' particular needs or interests. To guide the hierarchical topic discovery process with minimal user supervision, we propose a new task, Hierarchical Topic Mining, which takes a category tree described by category names only, and aims to mine a set of representative terms for each category from a text corpus to help a user comprehend his/her interested topics. We develop a novel joint tree and text embedding method along with a principled optimization procedure that allows simultaneous modeling of the category tree structure and the corpus generative process in the spherical space for effective category-representative term discovery. Our comprehensive experiments show that our model, named JoSH, mines a high-quality set of hierarchical topics with high efficiency and benefits weakly-supervised hierarchical text classification tasks.;;;https://dl.acm.org/doi/10.1145/3394486.3403242;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Using Text Mining to Analyze the Financial Patents;;;['Yung-Feng Lu', 'Jia-Lang Xu', 'Mu-Yen Chen'];;;June 2019;;;WIMS2019: Proceedings of the 9th International Conference on Web Intelligence, Mining and Semantics;;;With the advancement and development of science and technology, Nowadays society is the development of information technology, cloud computing, mobile Internet, Internet of Things, block chain and information technology.The combination of finance and technology has made financial technology terms gradually emerging.. This research analyzes the patents of financial technology. However, Taiwan's financial technology patents are mostly G06Q-20 (payment plan, architecture or agreement), G06Q-30 (commercial, such as marketing, shopping, payment, auction or e-commerce). G06Q-40 (financial, investment or tax treatment, insurance).The research use text mining technology to analyze and understand Taiwan's trends and developments in financial technology. The research results show that G06Q-20 patents are biased towards information security and mobile payment. G06Q-30 patents favor shopping websites and advertising. G06Q-40 patents are biased towards diversity, such as securities, insurance, finance, and stocks.;;;https://dl.acm.org/doi/10.1145/3326467.3326478;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Multi-Media Content Clustering and Computer Intelligent Analysis by Text Mining;;;['Shiqi Ren'];;;October 2021;;;AIAM2021: 2021 3rd International Conference on Artificial Intelligence and Advanced Manufacture;;;The epidemic situation of covid-19 spread all over the world, which is not optimistic. In order to extract valuable information for the epidemic from the numerous Internet data. With data mining technology, this paper crawls more than 10000 pieces of data from the microblog platform of overseas anti epidemic diary topic, and preprocesses the obtained text data set with word segmentation, removing stop words and other data, extracts the keywords of each microblog through word vector model, counts word frequency, and clustes text. In addition, the emotional value of the text is analyzed. Finally, the data were grouped into seven categories, and the trend chart of emotion value was drawn, and each result was displayed in the way of graph. By analysing, on the one hand, valuable information can be extracted from the micro blog data generated by overseas Chinese to help the domestic people understand the real situation of the overseas epidemic and adjust the risk response measures; on the other hand, the general situation of social media data during the epidemic can be generally understood from the macro perspective to provide reference for government departments in terms of management of entry-exit and epidemic prevention and control. It is helpful to further improve the governance system and the modernization of governance capacity in response to public health emergencies in China.;;;https://dl.acm.org/doi/10.1145/3495018.3501088;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Machine Learning on Mining Potential Adverse Drug Reactions for Pharmacovigilance;;;['Ke Jia'];;;July 2021;;;DSIT 2021: 2021 4th International Conference on Data Science and Information Technology;;;Drugs are related to the lives and health of patients. Mining and discovering potential adverse drug reactions from a large number of unstructured texts play an important role in drug research and pharmacovigilance. It is a hot research issue in the field of biomedicine in recent years. A large number of scholars have discovered a large amount of information on adverse drug reactions from different data sources through effective machine learning methods. This paper reviews the research progress in recent years to provide a reference for future research.;;;https://dl.acm.org/doi/10.1145/3478905.3478964;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Classification of Faults in Web Applications using Machine Learning;;;['Akshi Kumar', 'Rajat Chugh', 'Rishab Girdhar', 'Simran Aggarwal'];;;March 2017;;;ISMSI '17: Proceedings of the 2017 International Conference on Intelligent Systems, Metaheuristics &amp; Swarm Intelligence;;;Web is huge, abundant and heterogeneous and so are the challenges that arise due to this versatility. Web Applications as the new task-centric and action-oriented facilities have assumed a distinguished role in today's Web. At the same time, faults in these Web Applications are tedious and hard to test due to the labor and resource intensive nature of testing. Thus, making it essential to use automated strategies like fault based testing that can test the continuously advancing web. Fault based testing uses fault classification as a baseline to make testing cost-effective and efficient, hence making fault classification necessary. Fault classification in Web Applications is a course of action of developing models to segregate the various kinds of faults for real world fault based testing. Manual classification tends to be strenuous and therefore in this paper, we intend to predict an efficient automated model which will classify the faults. Our model uses Text Mining and Machine Learning technique to classify the faults of three open source Web Applications, namely, the qaManager, bitWeaver and WebCalender. We provide a comparative study among four models in which different Machine Learning techniques are used namely Support Vector Machines (SVM), Decision Tree, Bernoulli Naïve Bayes and Multinomial Naïve Bayes. To analyze the performance of these models, Area Under the Curve (AUC) obtained from Receiver Operating Characteristics (ROC) and 10-fold validation are used. Results show that all considered Machine Learning techniques prove to be efficient in the classification of faults. Apart from this, analysis also shows that the performance of Multinomial Naïve Bayes Classifier is better than the other three classifiers.;;;https://dl.acm.org/doi/10.1145/3059336.3059353;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Using Spark for Text Mining on Large Scale Liver Cancer Literature;;;['Ming-Yen Lin', 'Yu-Ju Lin', 'Sue-Chen Hsueh'];;;January 2021;;;BDET 2021: 2021 the 3rd International Conference on Big Data Engineering and Technology (BDET);;;Cancer is one of the main causes of death. The number of known cancer to-date is more than one hundred. Liver cancer, ranked after trachea and lung cancer, has long been high in the cancer leading cause in Taiwan and even ranked as second in 2016. The number of scientific articles related to cancer proliferates every year. The number reaches as high as 20 million in PubMed so that discovering useful information from the massive collection is very difficult. In addition, using a single machine to sift through these articles is very time-consuming. Therefore, we present a big data analytic framework using the distributed Apache Spark platform for text mining in PubMed literature. We establish a prediction model for liver cancer articles so that researchers may effectively validate whether an article is related to liver cancer or not. Classification models in Spark MLlib including Linear Support Vector Machines (SVM), Logistic Regression, are used in our experiments. Relevancy to liver cancer is further confirmed by using MeSH (Medical Subject Headings) terms. Logistic regression is about 3 times faster than SVMs and the accuracy of both methods is close to 95% in the experiments using hold-out validation. When max_features is 500 and min_df ≤ 0.1 (or min_df = 1), the accuracy may reach 96%. In the experiments with K-fold cross-validation, the accuracy of SVMs methods is 96%. The experimental results show that that our prediction model may effectively classify liver cancer articles.;;;https://dl.acm.org/doi/10.1145/3474944.3474958;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Learning Adversarial Networks for Semi-Supervised Text Classification via Policy Gradient;;;['Yan Li', 'Jieping Ye'];;;July 2018;;;KDD '18: Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining;;;Semi-supervised learning is a branch of machine learning techniques that aims to make fully use of both labeled and unlabeled instances to improve the prediction performance. The size of modern real world datasets is ever-growing so that acquiring label information for them is extraordinarily difficult and costly. Therefore, deep semi-supervised learning is becoming more and more popular. Most of the existing deep semi-supervised learning methods are built under the generative model based scheme, where the data distribution is approximated via input data reconstruction. However, this scheme does not naturally work on discrete data, e.g., text; in addition, learning a good data representation is sometimes directly opposed to the goal of learning a high performance prediction model. To address the issues of this type of methods, we reformulate the semi-supervised learning as a model-based reinforcement learning problem and propose an adversarial networks based framework. The proposed framework contains two networks: a predictor network for target estimation and a judge network for evaluation. The judge network iteratively generates proper reward to guide the training of predictor network, and the predictor network is trained via policy gradient. Based on the aforementioned framework, we propose a recurrent neural network based model for semi-supervised text classification. We conduct comprehensive experimental analysis on several real world benchmark text datasets, and the results from our evaluations show that our method outperforms other competing state-of-the-art methods.;;;https://dl.acm.org/doi/10.1145/3219819.3219956;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Evolutionary role mining in complex networks by ensemble clustering;;;['Sarvenaz Choobdar', 'Pedro Ribeiro', 'Fernando Silva'];;;April 2017;;;SAC '17: Proceedings of the Symposium on Applied Computing;;;The structural patterns in the neighborhood of nodes assign unique roles to the nodes. Mining the set of existing roles in a network provides a descriptive profile of the network and draws its general picture. This paper proposes a new method to determine structural roles in a dynamic network based on the current position of nodes and their historic behavior. We develop a temporal ensemble clustering technique to dynamically find groups of nodes, holding similar tempo-structural roles. We compare two weighting functions, based on age and distribution of data, to incorporate temporal behavior of nodes in the role discovery. To evaluate the performance of the proposed method, we assess the results from two points of view: 1) goodness of fit to current structure of the network; 2) consistency with historic data. We conduct the evaluation using different ensemble clustering techniques. The results on real world networks demonstrate that our method can detect tempo-structural roles that simultaneously depict the topology of a network and reflect its dynamics with high accuracy.;;;https://dl.acm.org/doi/10.1145/3019612.3019815;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Extremely Fast Decision Tree Mining for Evolving Data Streams;;;['Albert Bifet', 'Jiajin Zhang', 'Wei Fan', 'Cheng He', 'Jianfeng Zhang', 'Jianfeng Qian', 'Geoff Holmes', 'Bernhard Pfahringer'];;;August 2017;;;KDD '17: Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining;;;Nowadays real-time industrial applications are generating a huge amount of data continuously every day. To process these large data streams, we need fast and efficient methodologies and systems. A useful feature desired for data scientists and analysts is to have easy to visualize and understand machine learning models. Decision trees are preferred in many real-time applications for this reason, and also, because combined in an ensemble, they are one of the most powerful methods in machine learning. In this paper, we present a new system called STREAMDM-C++, that implements decision trees for data streams in C++, and that has been used extensively at Huawei. Streaming decision trees adapt to changes on streams, a huge advantage since standard decision trees are built using a snapshot of data, and can not evolve over time. STREAMDM-C++ is easy to extend, and contains more powerful ensemble methods, and a more efficient and easy to use adaptive decision trees. We compare our new implementation with VFML, the current state of the art implementation in C, and show how our new system outperforms VFML in speed using less resources.;;;https://dl.acm.org/doi/10.1145/3097983.3098139;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
COVID-19 Vaccine Discussion: Evidence from Twitter Data Using Text Mining;;;['Johannes Schneider', 'Gramoz Sejfijaj', 'Jan vom Brocke'];;;December 2021;;;WI-IAT '21: IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology;;;COVID-19 vaccination has led to unrest within societies, and intense public debates are often carried out on social media platforms like Twitter. A better understanding of concerns, issues, and communication on COVID-19 vaccines is a first step to reducing tension within society and improving the negative effects of the pandemic. It can also contribute to addressing the concerns of advocates and opponents, which is essential in the battle against this and possible future pandemics. At the same time, many people report pressure to undergo vaccination in order to continue participating in social and professional life. COVID-19 vaccination has triggered a complex discussion among the public. We use text mining algorithms suitable for big datasets to identify relevant categories of discourse and sentiments from about 250,000 tweets. Our findings highlight (and quantify) expressed shortcomings in vaccination programs related to administration, planning, information, and protective measures. It also hints that rare and severe incidents related to vaccination have a more substantial impact than potential fears related to non-familiar technology such as “mRNA” causing uncertainty. We also provide an extensive discussion setting forth suggestions that might help deal with the current and future pandemic.;;;https://dl.acm.org/doi/10.1145/3498851.3498935;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Physical Role Limitation - It's Classification and Prediction using Machine Learning;;;['Sadaf Azad', 'Muna Al Fanah', 'Ci Lei'];;;March 2019;;;ICBDE '19: Proceedings of the 2019 International Conference on Big Data and Education;;;The focus of this study is to define the classification of physical role limitation in patients and predict patient physical role limitation based on other health factors, using machine learning. For this purpose, patients' records in National Child Development Study Dataset (NCDS), which started in 1958, were used. This study performs classification of patients' existing records and categorization of new records on the basis of trained model by implementing data mining techniques, including linear discriminant analysis (LDA), support vector machine (SVM), Decision Tree (CART), Random Forest, and k-nearest neighbor (KNN). Findings of this research will help medical practitioners to classify patients on the basis of other valuable health related information and observe the physical role limitations in patients at age of 50 and above. For instance, knowing the general health scales of patients can help practitioners to predict the physical activity scale in patients, and thus help practitioners in e.g. risk assessment and drawing up treatment and care plans. The contribution of this study is to utilize a study covering 55 years' observations of the candidates in order to help practitioners to identify and predict the physical role limitation in people when they turn 50 and over on the basis of other health related information. Of the five classifiers applied in this study, it can be confidently said that Random Forest is the best classifier with 72.48% accuracy to be used in data situations like NCDS.;;;https://dl.acm.org/doi/10.1145/3322134.3322144;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Interactive Visual Graph Mining and Learning;;;['Ryan A. Rossi', 'Nesreen K. Ahmed', 'Rong Zhou', 'Hoda Eldardiry'];;;None;;;ACM Transactions on Intelligent Systems and Technology;;;This article presents a platform for interactive graph mining and relational machine learning called GraphVis. The platform combines interactive visual representations with state-of-the-art graph mining and relational machine learning techniques to aid in revealing important insights quickly as well as learning an appropriate and highly predictive model for a particular task (e.g., classification, link prediction, discovering the roles of nodes, and finding influential nodes). Visual representations and interaction techniques and tools are developed for simple, fast, and intuitive real-time interactive exploration, mining, and modeling of graph data. In particular, we propose techniques for interactive relational learning (e.g., node/link classification), interactive link prediction and weighting, role discovery and community detection, higher-order network analysis (via graphlets, network motifs), among others. GraphVis also allows for the refinement and tuning of graph mining and relational learning methods for specific application domains and constraints via an end-to-end interactive visual analytic pipeline that learns, infers, and provides rapid interactive visualization with immediate feedback at each change/prediction in real-time. Other key aspects include interactive filtering, querying, ranking, manipulating, exporting, as well as tools for dynamic network analysis and visualization, interactive graph generators (including new block model approaches), and a variety of multi-level network analysis techniques.;;;https://dl.acm.org/doi/10.1145/3200764;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Deep Active Learning for Text Classification;;;['Bang An', 'Wenjun Wu', 'Huimin Han'];;;August 2018;;;ICVISP 2018: Proceedings of the 2nd International Conference on Vision, Image and Signal Processing;;;In recent years, Active Learning (AL) has been applied in the domain of text classification successfully. However, traditional methods need researchers to pay attention to feature extraction of datasets and different features will influence the final accuracy seriously. In this paper, we propose a new method that uses Recurrent Neutral Network (RNN) as the acquisition function in Active Learning called Deep Active Learning (DAL). For DAL, there is no need to consider how to extract features because RNN can use its internal state to process sequences of inputs. We have proved that DAL can achieve the accuracy that cannot be reached by traditional Active Learning methods when dealing with text classification. What's more, DAL can decrease the need of the great number of labeled instances for Deep Learning (DL). At the same time, we design a strategy to distribute label work to different workers. We have proved by using a proper batch size of instance, we can save much time but not decrease the model's accuracy. Based on this, we provide batch of instances for different workers and the size of batch is determined by worker's ability and scale of dataset, meanwhile, it can be updated with the performance of the workers.;;;https://dl.acm.org/doi/10.1145/3271553.3271578;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Multi-task Fuzzy Clustering–Based Multi-task TSK Fuzzy System for Text Sentiment Classification;;;['Xiaoqing Gu', 'Kaijian Xia', 'Yizhang Jiang', 'Alireza Jolfaei'];;;None;;;ACM Transactions on Asian and Low-Resource Language Information Processing;;;Text sentiment classification is an important technology for natural language processing. A fuzzy system is a strong tool for processing imprecise or ambiguous data, and it can be used for text sentiment analysis. This article proposes a new formulation of a multi-task Takagi-Sugeno-Kang fuzzy system (TSK FS) modeling, which can be used for text sentiment image classification. Using a novel multi-task fuzzy c-means clustering algorithm, the common (public) information among all tasks and the individual (private) information for each task are extracted. The information about clustering, for example, cluster centers, can be used to learn the antecedent parameters of multi-task TSK fuzzy systems. With the common and individual antecedent parameters obtained, a corresponding multi-task learning mechanism for learning consequent parameters is devised. Accordingly, a multi-task fuzzy clustering–based multi-task TSK fuzzy system (MTFCM-MT-TSK-FS) is proposed. When the proposed model is built, the information conveyed by the fuzzy rules formed is two-fold, including (1) common fuzzy rules representing the inter-task correlation information and (2) individual fuzzy rules depicting the independent information of each task. The experimental results on several text sentiment datasets demonstrate the validity of the proposed model.;;;https://dl.acm.org/doi/10.1145/3476103;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Text Mining on Player Personality for Game Recommendation;;;['Hsin-Chang Yang', 'Cathy S. Lin', 'Zi-Rui Huang', 'Tsung-Hsing Tsai'];;;July 2017;;;MISNC '17: Proceedings of the 4th Multidisciplinary International Social Networks Conference;;;Recommender systems have emergedrecently in many aspects due to enormous amount of information or items existed in e-commerce or social network services. Users find it convenient if the service can recommend interesting items to them automatically. Past systems adopted users' preference or social connections for such recommendation. In this work, we will try to identify a game player's personality traits and use them to recommend games that may be interested by the player. The personality traits of a player is identified by applying a text mining process on textual contents related to the player. The same process is also applied on the comments of the games to identified the personality traits of games. Recommendation is then performed based on the similarity between the traits of the user and the game. We performed experiments on 63 players and 2050 games and obtained promising results which may demonstrate the plausibility of personality-based recommender systems.;;;https://dl.acm.org/doi/10.1145/3092090.3092132;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Xiaomi Brand Appraisal Research Based on Zhihu by Text Mining Technology;;;['Aiting Xu', 'Fangyan Wang', 'Pingting Ying'];;;May 2019;;;ICBDC '19: Proceedings of the 4th International Conference on Big Data and Computing;;;As the largest knowledge social platform on the Chinese Internet, Zhihu has gradually become an important resource for merchants to improve publicity and optimize products, and the public to understand the brand image. The topic of "Xiaomi Technology" remains hot on Zhihu. In this context, this paper takes the essences of the "Xiaomi Technology" topic on Zhihu as the research object. First we carry on the data collection and preprocessing. Then by extracting feature based on word segmentation results, we build a corpus and construct an LDA topic model for text mining. Besides, by calculating and comparing the perplexity index, we select 20 as the number of topics. According to the results, the relationship between document-topic and topic-term is analyzed to form a topic description of the text, which shows that Xiaomi products have received great attention from consumers and are often used for comparison with other brands in the same industry; Xiaomi product launches have received much attention and had a direct impact on product sales; Xiaomi is widely recognized as one of the representatives of China's future technology.;;;https://dl.acm.org/doi/10.1145/3335484.3335515;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Twitter Association Rule Mining using Clustering and Graph Databases;;;['Alessandro Campi', 'Corrado Palese'];;;May 2021;;;ICISDM '21: Proceedings of the 2021 5th International Conference on Information System and Data Mining;;;In this scenario, the need to efficiently analyze this kind of data is increasing because of characteristics of such big data, especially their huge and sometimes unpredictable variety. Twitter alone, with 320 M active users every month and more than 500 M tweets per day, could represent an important source of information. For this research, we are focusing solely on social networks. The reason for this choice is that they are increasingly becoming a platform where people will comfortably update their status and share or retrieve information about the world in real time. Often news is spreading through them faster than in traditional channels because user capillarity worldwide makes it possible. In particular, we will focus on Twitter, because its micro-blogging nature makes it suitable for this kind of purpose. It questions the concept of a small private community of friends in favor of less private, less personal broadcast communications of common interest. Another reason why we chose Twitter is because semantic value of hashtags, their power in summarizing tweet content and the spreading model through the social network that allows us to highlight clusters of topics by focusing on these tags.One of the objectives of this thesis is to show how data mining can provide useful techniques to deal with these huge datasets for retrieving information to detect and analyze trending topics and the corresponding user's interactions with them. We identified in Association Rules identification and evolution in time, a systematic approach to conduct the analysis.;;;https://dl.acm.org/doi/10.1145/3471287.3471309;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Innovation of Data Mining & Screening System under Big Data: Take a case as NIMBY;;;['Minxuan Li'];;;April 2019;;;ICDMML 2019: Proceedings of the 2019 International Conference on Data Mining and Machine Learning;;;With the growing maturity of web crawler technology and the advent of the era of big data, when you want to study some problems, you can directly get all the data related to them through web crawlers and other means, but it is more important to mining and filter the data to get valuable data for the research content. This study which based on the word list of keywords uses CRN network to construct semantic distance table and TOPSIS evaluation system to sort data to make sure researchers can obtain quantitative screening data with research value and to provide researchers with scientific screening methods.;;;https://dl.acm.org/doi/10.1145/3335656.3335688;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Research on English Text Classification and Recognition Method Based on Machine Learning Technology;;;['Yinhua Chen'];;;December 2021;;;ICASIT 2021: 2021 International Conference on Aviation Safety and Information Technology;;;In recent years, with the rapid development of information network technology, especially the substantial increase in network usage, more and more information is expressed in the form of text. In short, the emergence of a large amount of text information on the Internet is undoubtedly an amazing trend. The rapid generation of massive data and information has greatly affected the efficient, rapid and complete utilization of these resources by human beings. The reason is that people can no longer rely solely on physical labor to effectively obtain the basic content of massive amounts of information. If a computer can help people identify and process information content, then it must provide good help and support in people's work and study in order to alleviate people's embarrassment that they cannot make full use of information. Therefore, we have reason to believe in computer-based texts. Sorting can increase the use of text information. The purpose of this paper is to study the English text classification and recognition method of machine learning technology, take this as the research direction and propose a text classification method based on context. The algorithm has two core parts, namely classification training set and environment learning classification. According to the number of occurrences of keywords, the frequency of occurrence is calculated and classified, and then an index is given to each category. Calculate the weights of the attribute words in all documents in each category, and give the attribute word scores through repetition. Firstly, the attribute words are mined through the association word rules, and then the attribute words form the environment attribute word matrix. The algorithm combines two analysis methods, namely traditional statistical analysis and context analysis, which can simultaneously learn all categories in the document. Experiments have shown that both the weight calculation algorithm and the simulation algorithm can efficiently classify texts and have strong practicability. Experimental research shows that the context learning algorithm proposed in this article has achieved obvious advantages in comparison with traditional algorithms. The recall rate is 47%, the accuracy rate is 89%, the error rate is as low as 11%, and all indicators are higher than Other algorithms.;;;https://dl.acm.org/doi/10.1145/3510858.3510935;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Data Mining for Discovering Cognitive Models of Learning;;;['Jinjin Zhao', 'Candace Thille', 'Dawn Zimmaro'];;;November 2021;;;ICAAI '21: Proceedings of the 5th International Conference on Advances in Artificial Intelligence;;;A cognitive model is a descriptive account or computational representation of human thinking about a given concept, skill, or domain. A cognitive model of learning, includes both a way of organizing knowledge within a subject area and an account of how humans develop accurate and complete knowledge of that subject area. Learning designers engage in a variety of practices to unpack knowledge from subject matter experts and novices to develop cognitive models of learning and use those models to guide the design of instruction or instructional technologies. Traditional approaches to eliciting and organizing knowledge, such as conducting a cognitive task analysis (CTA) [14] with experts and novices, are labor-intensive and require specific expertise that many learning designers do not have. However, learning data generated from learners’ interaction with courses, can provide insight into how humans think and develop knowledge. As a continued effort, we extend the framework presented in our earlier work [17] to discover and refine cognitive models of learning with learning data. The framework includes 1. a Variational Autoencoder (VAE) and a Gaussian Mixture Model (GMM) that models and clusters cognitive learning patterns; 2. a multidimensional measure that quantifies validity and reliability of the discovered cognitive models of learning; 3. a topic-based solution that interprets the cognitive models from a linguistic perspective; and 4. a simulation-based analysis for both accuracy measures and course refinement insights. We demonstrate the end-to-end solution with two applications and four case studies that are deployed in an openly navigated learning system in a workforce learning environment. We also report the usefulness of the discovered cognitive models of learning with subject matter expert evaluation.;;;https://dl.acm.org/doi/10.1145/3505711.3505729;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Hyperspectral Image Classification using Machine Learning;;;['Ranjana W. Gore', 'Abhilasha D. Mishra', 'Ratnadeep R. Deshmukh'];;;August 2021;;;DSMLAI '21': Proceedings of the International Conference on Data Science, Machine Learning and Artificial Intelligence;;;Hyperspectral images are of high resolution so helpful in classifying the land surface for variety of applications like land use and land cover, lithological discrimination, differentiating different land surfaces, segmentation, etc. This work focused on the hyperspectral image classification at Lonar Crater situated at Buldhana district, Maharashtra. This methodology consists of sequence of operations viz. bad band removal, destriping, atmospheric correction, minimum noise fraction, n-D visualization and classification. 242 images of Hyperion sensor are used for classification. The land surface at and near Lonar crater is classified with more user accuracy on an average. The Spectral angle mapper technique is used showing the 59.23% accuracy in classifying with respect to ground truths from image. The results are improved with Support Vector Machine.;;;https://dl.acm.org/doi/10.1145/3484824.3484883;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Report on the 1st ACM SIGIR/SIGKDD Africa School on Machine Learning for Data Mining and Search;;;['Ben Carterette', 'Hussein Suleman', 'Douglas W. Oard'];;;June 2019;;;ACM SIGIR Forum;;;We report on the inception, organization, and activities of the 1st ACM SIGIR/SIGKDD Africa School on Machine Learning for Data Mining and Search, which took place at the University of Cape Town in South Africa January 14--18, 2019.;;;https://dl.acm.org/doi/10.1145/3458537.3458538;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Application of Data Mining Classification in Job-Changing;;;['Xu Qian', 'Hayato Ohwada'];;;February 2018;;;ICMLC '18: Proceedings of the 2018 10th International Conference on Machine Learning and Computing;;;More and more people are using job-changing websites to change jobs. Every enterprise responsible for recruitment wants to attract excellent applicants from among the hundreds of people using the job-changing website. We propose the use of the clustering analysis on the data information that is accumulated from the job-changing website. Once the current job-changing applicants are classified according to the clustering rules, each enterprise could easily see the job-changing applicant's information. As an intermediary for applicants and enterprises, if the job-changing website uses a good classifier to help the enterprise find the right applicants, this website will attract more users.;;;https://dl.acm.org/doi/10.1145/3195106.3195136;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Identifying social networks of programmers using text mining for code similarity detection;;;['Konstantinos F. Xylogiannopoulos', 'Panagiotis Karampelas'];;;December 2020;;;ASONAM '20: Proceedings of the 12th IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining;;;The availability of code in many online repositories and collaborating platforms has posed new challenges in source code attribution not only for plagiarism detection but also in other settings such as in the use of insecure copied code in commercial application, etc. The sophistication of different type of attacks in the code sequence used especially by the students requires more effective code similarity detection algorithms. In this paper, a novel source code detection method is proposed that can identify programmers' social network based on advanced pattern detection text mining techniques. The proposed methodology has significant advantages against existing methods since ARPaD algorithm can detect all common patterns between all possible code sequences in one run. Therefore, the computational time is massively reduced to O(mn log n). In order to assess the performance of the methodology, a new dataset was created by assigning to 46 students a code project with specific instructions. The assessment results have been visualized, producing the social network graphs of possible collaboration teams.;;;https://dl.acm.org/doi/10.1109/ASONAM49781.2020.9381381;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
TACAM: Topic And Context Aware Argument Mining;;;['Michael Fromm', 'Evgeniy Faerman', 'Thomas Seidl'];;;October 2019;;;WI '19: IEEE/WIC/ACM International Conference on Web Intelligence;;;In this work we address the problem of argument search. The purpose of argument search is the distillation of pro and contra arguments for requested topics from large text corpora. In previous works, the usual approach is to use a standard search engine to extract text parts which are relevant to the given topic and subsequently use an argument recognition algorithm to select arguments from them. The main challenge in the argument recognition task, which is also known as argument mining, is that often sentences containing arguments are structurally similar to purely informative sentences without any stance about the topic. In fact, they only differ semantically. Most approaches use topic or search term information only for the first search step and therefore assume that arguments can be classified independently of a topic. We argue that topic information is crucial for argument mining, since the topic defines the semantic context of an argument. Precisely, we propose different models for the classification of arguments, which take information about a topic of an argument into account. Moreover, to enrich the context of a topic and to let models understand the context of the potential argument better, we integrate information from different external sources such as Knowledge Graphs or pre-trained NLP models. Our evaluation shows that considering topic information, especially in connection with external information, provides a significant performance boost for the argument mining task.;;;https://dl.acm.org/doi/10.1145/3350546.3352506;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Semi-Supervised Text Classification via Self-Pretraining;;;['Payam Karisani', 'Negin Karisani'];;;March 2021;;;WSDM '21: Proceedings of the 14th ACM International Conference on Web Search and Data Mining;;;We present a neural semi-supervised learning model termed Self-Pretraining. Our model is inspired by the classic self-training algorithm. However, as opposed to self-training, Self-Pretraining is threshold-free, it can potentially update its belief about previously labeled documents, and can cope with the semantic drift problem. Self-Pretraining is iterative and consists of two classifiers. In each iteration, one classifier draws a random set of unlabeled documents and labels them. This set is used to initialize the second classifier, to be further trained by the set of labeled documents. The algorithm proceeds to the next iteration and the classifiers' roles are reversed. To improve the flow of information across the iterations and also to cope with the semantic drift problem, Self-Pretraining employs an iterative distillation process, transfers hypotheses across the iterations, utilizes a two-stage training model, uses an efficient learning rate schedule, and employs a pseudo-label transformation heuristic. We have evaluated our model in three publicly available social media datasets. Our experiments show that Self-Pretraining outperforms the existing state-of-the-art semi-supervised classifiers across multiple settings. Our code is available at https://github.com/p-karisani/self-pretraining .;;;https://dl.acm.org/doi/10.1145/3437963.3441814;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Based on Hadoop's tech big data combination and mining technology framework;;;['Xu Zhichao', 'Zhao Jiandong', 'Huang Huan'];;;March 2018;;;ICIAI '18: Proceedings of the 2nd International Conference on Innovation in Artificial Intelligence;;;With the advent of the Internet + era in the field of Tech big data, the big data of Tech big data has a large amount of data and various characteristics. It is an important means to carry out research on the big data of Tech big data to realize the combination and mining of efficient multi-source foreign technology data. However, at present, the big data of Tech big data are divided into disciplines and different formats, which are difficult to realize the intersection of effective scientific and technological information and realize data sharing. This paper puts forward a kind of big data combined with Tech big data and mining technology based on the Hadoop framework.It includes a unified collection and preprocessing method of big data of Tech big data and the design of storage and management platform for data sources. It is based on Map/Reduce Tech big data parallelization computing model and system.Its correlation with important scientific data mining services.The framework has good practicability and expansibility.;;;https://dl.acm.org/doi/10.1145/3194206.3194229;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Failure Cause Extraction of Railway Switches Based on Text Mining;;;['Chunni Lin', 'Guang Wang'];;;December 2017;;;CSAI '17: Proceedings of the 2017 International Conference on Computer Science and Artificial Intelligence;;;Text mining is useful for knowledge extraction. As an effective textual data analysis technology, it has been widely promoted in many fields. In railway domain, millions of repair verbatims are recorded in the form of text. These ample but unexploited textual data can provide abundant knowledge for us to guarantee the normal operation of railway transportation and relieve maintainers' labor intensity. However, railway switches with different number of operation times, types, in different areas and climates will have various failure cause. Hence, in order to diagnose and predict failures of railway switches quickly and precisely, it is necessary to know all failure cause of the batch of equipment in advance. In this paper, we use text mining technology to extract fault cause using a real-world dataset. To our best knowledge, it is the first research which focuses on failure cause extraction of railway switches based on text mining, and CHI method is used for selecingt features. Experiment results turn that out our method can obtains a satisfactory performance and the proposed method is more persuasive than traditional experience-based methods.;;;https://dl.acm.org/doi/10.1145/3168390.3168402;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Data mining for electroencephalogram signal processing and analysis;;;['Rossana Mancuso', 'Marzia Settino', 'Mario Cannataro'];;;August 2021;;;BCB '21: Proceedings of the 12th ACM Conference on Bioinformatics, Computational Biology, and Health Informatics;;;Electroencephalography (EEG) is a complex signal that requires advanced signal processing and feature extraction methodologies to be interpreted correctly. EEG, is usually utilized to estimate the trace and the electrical brain activity. It is employed in the discovery and forecast of epileptic and non-epileptic seizures and neurodegenerative pathologies. In this article, we give an overview of the various computational techniques used in the past, in the present and the future to preprocess and analyze EEG signals. In particular, this work aims to briefly review the state of research in this field, trying to understand the needs of EEG analysis in the medical field, with special focus on neurodegenerative pathologies, and epileptic and not-epileptic diseases. After presenting the main pre-processing, feature selection and extraction phases, we focus on classification processes and on Data Mining techniques applied to classify EEGs. Then, through the EEG analysis a discussion of the implementation is provided to investigate, predict and diagnose some cognitive diseases and epilepsy.;;;https://dl.acm.org/doi/10.1145/3459930.3470905;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Visualization and Analysis of Research Field in University Laboratories by Text Mining;;;['Tatsukaze Naganawa', 'Hirotaka Itoh', 'Kenji Funahashi'];;;July 2019;;;ICEMT '19: Proceedings of the 3rd International Conference on Education and Multimedia Technology;;;The research field at a university is one of the factors to greatly influence student's future life. Therefore, when high school students choose a university, it is important to find out what research fields have been performed at the laboratories of the university there. However, research fields are diversified in recent years, and it takes a lot of time to examine them, and is hard work for students. In this research, a text mining method is applied for the title data set of theses of each university laboratory, and each research field is visualized as tables, figures and graphs, so that the students can easily understand them. We also analyze the annual trends of research fields.;;;https://dl.acm.org/doi/10.1145/3345120.3345141;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Impacts of Big Data on Data Mining Research: An Empirical Study of Chinese Journals;;;['Yue Huang'];;;July 2018;;;ICCSE'18: Proceedings of the 3rd International Conference on Crowd Science and Engineering;;;With the advent of big data, data mining theories and methods face new challenges. This paper tries to find the impacts of big data on data mining research through 23377 data mining-related papers published in Chinese academic journals during 1996--2016. By utilization of various methods of bibliometrics, this study conducts three different levels of analysis to gradually dig deeper into the contents of literature. For the macro-level, paper amount analysis results show that big data-related research began in 2012 and has brought new growth to data mining area. For the meso-level, journal distribution analysis results indicate that many other disciplines, such as arts and agriculture science, began to apply data mining techniques with the wide spread of big data. For the micro-level, co-word-based research topic clustering results imply that new topics emerged due to the easy access of big data, such as 'clouding computing' and 'teaching and learning analysis'.;;;https://dl.acm.org/doi/10.1145/3265689.3265706;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A Frequency-Category Based Feature Selection in Big Data for Text Classification;;;['Houda Amazal', 'Mohammed Ramdani', 'Mohamed Kissi'];;;September 2020;;;SITA'20: Proceedings of the 13th International Conference on Intelligent Systems: Theories and Applications;;;In big data era, text classification is considered as one of the most important machine learning application domain. However, to build an efficient algorithm for classification, feature selection is a fundamental step to reduce dimensionality, achieve better accuracy and improve time execution. In the literature, most of the feature ranking techniques are document based. The major weakness of this approach is that it favours the terms occurring frequently in the documents and neglects the correlation between the terms and the categories. In this work, unlike the traditional approaches which deal with documents individually, we use mapreduce paradigm to process the documents of each category as a single document. Then, we introduce a parallel frequency-category feature selection method independently of any classifier to select the most relevant features. Experimental results on the 20-Newsgroups dataset showed that our approach improves the classification accuracy to 90.3%. Moreover, the system maintains the simplicity and lower execution time.;;;https://dl.acm.org/doi/10.1145/3419604.3419620;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Data mining ancient scripts to investigate their relationships and origins;;;['Shruti Daggumati', 'Peter Z. Revesz'];;;June 2019;;;IDEAS '19: Proceedings of the 23rd International Database Applications &amp; Engineering Symposium;;;This paper describes a data mining study of a set of ancient scripts in order to discover their relationships, including their possible common origin from a single root script. The data mining uses convolutional neural networks and support vector machines to find the degree of visual similarity between pairs of symbols in eight different ancient scripts. Among the surprising results of the data mining are the following: (1) the Indus Valley Script is visually closest to Sumerian pictographs, and (2) the Linear B script is visually closest to the Cretan Hieroglyphic script.;;;https://dl.acm.org/doi/10.1145/3331076.3331116;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
The Application of Data Mining Algorithms in the Construction of Travel Recommendation System;;;['Chao Lou', 'Zhaonan Mu', 'Mengzhu Liu'];;;January 2021;;;CONF-CDS 2021: The 2nd International Conference on Computing and Data Science;;;Photos shared by users of online social network often associated with tags, texts, geographic and time information. These data are ideal research resource which can be used by researchers to observe people's interests and behaviors. They can also be used to analyze people's travel behaviors and interests because it can reflect people's travel activities and experiences directly. This project aimed to consolidate people into groups based on their travel preferences of travel season, travel time span, scenery type of travel location and then analyze popular travel places for different people groups. The travel preferences were analyzed from extracted data applying PHP language and Naive Bayes classification approach. According to the analyzed data, people were divided into groups. Then, DBSCAN clustering was used to get popular locations based on the different groups. As a result, 80 thousand photo data of 5 cities have been collected from Flickr by Phython. It has been showed that people's preference of season in most of the mined cities was spring and summer and the preference of time span was short. Moreover, mined people has been divided into 16 groups according to their preference and based on the groups popular locations have been calculated by DBSCAN clustering. Theses locations have been provided in a recommendation website which was built in this project. For the future work, mining Flickr data associated with other travel social network sites could be a good way to build a more effective recommendation system.;;;https://dl.acm.org/doi/10.1145/3448734.3450477;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Population-based metaheuristics for Association Rule Text Mining;;;['Iztok Fister', 'Suash Deb', 'Iztok Fister'];;;March 2020;;;ISMSI '20: Proceedings of the 2020 4th International Conference on Intelligent Systems, Metaheuristics &amp; Swarm Intelligence;;;Nowadays, the majority of data on the Internet is held in an unstructured format, like websites and e-mails. The importance of analyzing these data has been growing day by day. Similar to data mining on structured data, text mining methods for handling unstructured data have also received increasing attention from the research community. The paper deals with the problem of Association Rule Text Mining. To solve the problem, the PSO-ARTM method was proposed, that consists of three steps: Text preprocessing, Association Rule Text Mining using population-based metaheuristics, and text postprocessing. The method was applied to a transaction database obtained from professional triathlon athletes' blogs and news posted on their websites. The obtained results reveal that the proposed method is suitable for Association Rule Text Mining and, therefore, offers a promising way for further development.;;;https://dl.acm.org/doi/10.1145/3396474.3396493;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Using a Text Mining Assignment as an Intervention to Promote Student Engagement With DEI Issues;;;['Scott T. Leutenegger', 'Christina H. Paguyo'];;;March 2021;;;SIGCSE '21: Proceedings of the 52nd ACM Technical Symposium on Computer Science Education;;;The goal of the Partnership For Equity project is to build inclusive computing and engineering professional mindsets, which describes attitudes and identities of students who value knowledge in both technical and diversity, equity, and inclusion (DEI) areas of computer science. In this paper we present results from an intervention we piloted in a text mining special topics class. This intervention is directly applicable to any data mining class. Students applied naive Bayes classification to a survey result dataset and classified responses as "technical" or "equity", where technical meant the survey question response was focused on technical issues, whereas "equity" meant the response was focused on DEI issues. The survey data came from another course where students watched Ms. Joy Buolamwini's 2016 "How I'm fighting bias in algorithms" TedX talk and then answered several survey questions about the talk. In our text mining course students were first asked to watch the same TedX talk and answer several of the same survey questions. Their answers were added to the original data set. Students were then asked to apply naive Bayes classification to the combined survey results for one question. At the end of the course students took an end of class survey and answered more open-ended questions about whether the assignment influenced their thinking about DEI in computing. Results from this intervention indicate that including a DEI focus in technical programming assignments can positively impact students' views on the importance of DEI and contribute to the development of computing and engineering professional mindsets.;;;https://dl.acm.org/doi/10.1145/3408877.3432557;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Real-time Online Drilling Vibration Analysis Using Data Mining;;;['Marzieh Zare', 'Ari Visa', 'Sirpa Launis', 'Mikko Huova'];;;July 2019;;;DSIT 2019: Proceedings of the 2019 2nd International Conference on Data Science and Information Technology;;;While the data mining intermediaries play a critical role in the rock drilling industry, they also tend to provide an optimized real-time model for the drilling systems. In addition, proper online tool condition monitoring (OTOM) methods can improve the drilling performance by accessing real-time data. Hence, OTOM methods assist depreciating error and detect unspecified faults at early stages. In this study, we proposed appropriate OTOM algorithms to develop and enhance the quality of real-time systems and provide a solution to detect and categorize various stages of drilling operation with the aid of vibration signals (especially in terms of acceleration or velocity). In particular, the proposed methods in this article perform based on statistical approaches. Therefore, in order to recognize the drilling stages, we measured the Root Mean Square (RMS) values corresponding to the acceleration signals. In the meantime, we also succeeded to distinguish the drilling stages by employing estimated power spectral density (PSD) in the frequency domain. The acquired results in this publication confirm the real-time prediction and classification potential of the proposed methods for the different drilling stages and especially for the rock drilling engineering.;;;https://dl.acm.org/doi/10.1145/3352411.3352439;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Text Mining of English Picture Books;;;['Hiromi Ban', 'Takashi Oyabu'];;;August 2018;;;ICVISP 2018: Proceedings of the 2nd International Conference on Vision, Image and Signal Processing;;;Picture books play an important role as a material that develops children's linguistic competence. Thus, English picture books can be considered to be indispensable in children's English study. In this paper, metrical characteristics of some English picture books were investigated, compared with English textbooks for Japanese junior high schools students. In short, frequency characteristics of character- and word-appearance were investigated. These characteristics were approximated by an exponential function. Furthermore, the percentage of Japanese junior high school required vocabulary and American basic vocabulary was calculated to obtain the difficulty-level. As a result, it was clearly shown that the English picture books have a similar tendency to literary writings in the characteristics of character-appearance, and some books are more difficult than English textbooks.;;;https://dl.acm.org/doi/10.1145/3271553.3271616;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Ensemble Block Co-clustering: A Unified Framework for Text Data;;;['Séverine Affeldt', 'Lazhar Labiod', 'Mohamed Nadif'];;;October 2020;;;CIKM '20: Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management;;;In this paper, we propose a unified framework for Ensemble Block Co-clustering (EBCO), which aims to fuse multiple basic co-clusterings into a consensus structured affinity matrix. Each co-clustering to be fused is obtained by applying a co-clustering method on the same document-term dataset. This fusion process reinforces the individual quality of the multiple basic data co-clusterings within a single consensus matrix. Besides, the proposed framework enables a completely unsupervised co-clustering where the number of co-clusters is automatically inferred based on the non trivial generalized modularity. We first define an explicit objective function which allows the joint learning of the basic co-clusterings aggregation and the consensus block co-clustering. Then, we show that EBCO generalizes the one side ensemble clustering to an ensemble block co-clustering context. We also establish theoretical equivalence to spectral co-clustering and weighted double spherical k-means clustering for textual data. Experimental results on various real-world document-term datasets demonstrate that EBCO is an efficient competitor to some state-of-the-art ensemble and co-clustering methods.;;;https://dl.acm.org/doi/10.1145/3340531.3412058;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Differentially Private Feature Selection for Data Mining;;;['Balamurugan Anandan', 'Chris Clifton'];;;March 2018;;;IWSPA '18: Proceedings of the Fourth ACM International Workshop on Security and Privacy Analytics;;;One approach to analysis of private data is ε-differential privacy, a randomization-based approach that protects individual data items by injecting carefully limited noise into results. A challenge in applying this to private data analysis is that the noise added to the feature parameters is directly proportional to the number of parameters learned. While careful feature selection would alleviate this problem, the process of feature selection itself can reveal private information, requiring the application of differential privacy to the feature selection process. In this paper, we analyze the sensitivity of various feature selection techniques used in data mining and show that some of them are not suitable for differentially private analysis due to high sensitivity. We give experimental results showing the value of using low sensitivity feature selection techniques. We also show that the same concepts can be used to improve differentially private decision trees.;;;https://dl.acm.org/doi/10.1145/3180445.3180452;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Distributed Classification of Text Streams: Limitations, Challenges, and Solutions;;;['Artem Trofimov', 'Nikita Sokolov', 'Mikhail Shavkunov', 'Igor Kuralenok', 'Boris Novikov'];;;August 2019;;;BIRTE 2019: Proceedings of Real-Time Business Intelligence and Analytics;;;Text stream classification is an important problem that is difficult to solve at scale. Batch processing systems, widely adopted for text classification tasks, cannot provide for low latency. Distributed stream processing systems can offer low latency, but do not support the same level of fault tolerance and determinism as the batch systems. In this work, we demonstrate how the distributed stream processing features can affect the results of a typical text classification data flow. Our analysis shows emerged trade-offs between fault tolerance and reproducibility on the one side, and performance on the other side. We outline potential ways to solve the revealed issues and to handle streaming features.;;;https://dl.acm.org/doi/10.1145/3350489.3350491;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
CrowdTC: Crowd-powered Learning for Text Classification;;;['Keyu Yang', 'Yunjun Gao', 'Lei Liang', 'Song Bian', 'Lu Chen', 'Baihua Zheng'];;;None;;;ACM Transactions on Knowledge Discovery from Data;;;Text classification is a fundamental task in content analysis. Nowadays, deep learning has demonstrated promising performance in text classification compared with shallow models. However, almost all the existing models do not take advantage of the wisdom of human beings to help text classification. Human beings are more intelligent and capable than machine learning models in terms of understanding and capturing the implicit semantic information from text. In this article, we try to take guidance from human beings to classify text. We propose Crowd-powered learning for Text Classification (CrowdTC for short). We design and post the questions on a crowdsourcing platform to extract keywords in text. Sampling and clustering techniques are utilized to reduce the cost of crowdsourcing. Also, we present an attention-based neural network and a hybrid neural network to incorporate the extracted keywords as human guidance into deep neural networks. Extensive experiments on public datasets confirm that CrowdTC improves the text classification accuracy of neural networks by using the crowd-powered keyword guidance.;;;https://dl.acm.org/doi/10.1145/3457216;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Mining Personality Traits from Social Text Messages;;;['Hsin-Chang Yang', 'Chung-Hong Lee', 'Chia-Yi Yeh'];;;October 2020;;;MISNC2020&amp;IEMT2020: Proceedings of the 7th Multidisciplinary in International Social Networks Conference and The 3rd International Conference on Economics, Management and Technology;;;Recently, approaches of applying personality on practical applications have attracted attention from multidisciplinary areas beyond psychology. An example is the personality-based recommender systems that have been successfully applied to music, movie, and game recommendation tasks. However, finding the personality traits of a person is not a trivial task. In this work, we will propose an automatic scheme for identifying the Big Five personality traits using text mining techniques. We analyzed the social messages posted by Facebook users to find the correlations among keywords and personality traits. The personality traits of a person can then be identified by examining his social messages according to such correlations. We performed the experiments using the myPersonality dataset and obtained promising results.;;;https://dl.acm.org/doi/10.1145/3429395.3429412;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Machine Learning and Images for Malware Detection and Classification;;;['Konstantinos Kosmidis', 'Christos Kalloniatis'];;;September 2017;;;PCI '17: Proceedings of the 21st Pan-Hellenic Conference on Informatics;;;Detecting malicious code with exact match on collected datasets is becoming a large-scale identification problem due to the existence of new malware variants. Being able to promptly and accurately identify new attacks enables security experts to respond effectively. My proposal is to develop an automated framework for identification of unknown vulnerabilities by leveraging current neural network techniques. This has a significant and immediate value for the security field, as current anti-virus software is typically able to recognize the malware type only after its infection, and preventive measures are limited. Artificial Intelligence plays a major role in automatic malware classification: numerous machine-learning methods, both supervised and unsupervised, have been researched to try classifying malware into families based on features acquired by static and dynamic analysis. The value of automated identification is clear, as feature engineering is both a time-consuming and time-sensitive task, with new malware studied while being observed in the wild.;;;https://dl.acm.org/doi/10.1145/3139367.3139400;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Improvement of massive open online courses by text mining of students' emails: a case study;;;['Diego Buenaño-Fernández', 'Sergio Luján-Mora', 'W. Villegas-Ch'];;;October 2017;;;TEEM 2017: Proceedings of the 5th International Conference on Technological Ecosystems for Enhancing Multiculturality;;;In recent years, the constant increase in the number of online courses has led to radical changes in the education sector. These new online learning environments present a series of challenges that are difficult to manage using traditional methods. The challenges relate to the level of commitment and motivation shown by students on this type of course. Several articles have been identified from the analysed literature related to the application of text or opinion mining techniques for the analysis of comments made in social networks. In the educational field, articles related to the topic that focus on the analysis of opinion have been identified based on entries included in discussion forums for online courses. Many publications are geared towards solutions in the English language, and the nature of linguistic analysis of this type of study makes it necessary to adapt them for languages other than English. In this paper, we explore the opinion mining through text mining in emails from Massive Open Online Courses (MOOC). The opinion mining expressed in emails is a complex task due to the thematic disparity of emails, their size and the depth of linguistic analysis required. The purpose of this study is to analyse students opinions about their courses, their instructors, and the main tools used on the course. The research focus on the calculation and analysis of the frequency of terms, the analysis of concordances, groupings and n-grams. The case study used in this paper is a MOOC on the topic of web development with more than 40,000 enrolled students.;;;https://dl.acm.org/doi/10.1145/3144826.3145393;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Tracking food insecurity from tweets using data mining techniques;;;['Andrew Lukyamuzi', 'John Ngubiri', 'Washington Okori'];;;May 2018;;;SEiA '18: Proceedings of the 2018 International Conference on Software Engineering in Africa;;;Data mining algorithms can be applied to extract useful patterns from social media conversations to monitor disasters such as tsunami, earth quakes and nuclear power accidents. While food insecurity has persistently remained a world concern, its monitoring with this strategy has received limited attention. In attempt to address this concern, UN Global Pulse demonstrated that tweets reporting food prices from Indonesians can aid in predicting actual food price increase. For regions like Kenya and Uganda where use of tweets is considered low, this option can be problematic. Using Uganda as a case study, this study takes an alternative of using tweets from all over the world with mentions of; (1) uganda +food, (2) uganda + hunger, and (3) uganda + famine for years 2014, 2015 and 2016. The study however utilized tweets on food insecurity instead of tweets on food prices. In the first step, five data mining algorithms (D-tree, SVM, KNN, Neural Networks and N-Bayes) were trained to identify tweets conversations on food insecurity. Algorithmic performance were found comparable with human labeled tweet on the same subject. In step two, tweets reporting food insecurity were generated into trends. Comparing with trends from Uganda Bureau of Statistics, promising findings have been obtained with correlation coefficients of 0.56 and 0.37 for years 2015 and 2016 respectively. The study provides a strategy to generate information about food insecurity for stakeholders such as World Food Program in Uganda for mitigation action or further investigation depending on the situation. To improve performance, future work can; (1) aggregate tweets with other datasets, (2) ensemble algorithms, and (3) apply unexplored algorithms.;;;https://dl.acm.org/doi/10.1145/3195528.3195531;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A new data science framework for analysing and mining geospatial big data;;;['Mo Saraee', 'Charith Silva'];;;April 2018;;;ICGDA '18: Proceedings of the International Conference on Geoinformatics and Data Analysis;;;Geospatial Big Data analytics are changing the way that businesses operate in many industries. Although a good number of research works have reported in the literature on geospatial data analytics and real-time data processing of large spatial data streams, only a few have addressed the full geospatial big data analytics project lifecycle and geospatial data science project lifecycle. Big data analysis differs from traditional data analysis primarily due to the volume, velocity and variety characteristics of the data being processed. One of a motivation of introducing new framework is to address these big data analysis challenges. Geospatial data science projects differ from most traditional data analysis projects because they could be complex and in need of advanced technologies in comparison to the traditional data analysis projects. For this reason, it is essential to have a process to govern the project and ensure that the project participants are competent enough to carry on the process. To this end, this paper presents, new geospatial big data mining and machine learning framework for geospatial data acquisition, data fusion, data storing, managing, processing, analysing, visualising and modelling and evaluation. Having a good process for data analysis and clear guidelines for comprehensive analysis is always a plus point for any data science project. It also helps to predict required time and resources early in the process to get a clear idea of the business problem to be solved.;;;https://dl.acm.org/doi/10.1145/3220228.3220236;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Automatic recommendation of prognosis measures for mechanical components based on massive text mining;;;['Jorge Martinez-Gil', 'Bernhard Freudenthaler', 'Thomas Natschläger'];;;December 2017;;;iiWAS '17: Proceedings of the 19th International Conference on Information Integration and Web-based Applications &amp; Services;;;Automatically providing suggestions for predicting the likely status of a mechanical component is a key challenge in a wide variety of industrial domains. Existing solutions based on ontological models have proven to be appropriate for fault diagnosis, but they fail when suggesting activities leading to a successful prognosis of mechanical components. The major reason is that fault prognosis is an activity that, unlike fault diagnosis, involves a lot of uncertainty and it is not always possible to envision a model for predicting possible faults. In this work, we propose a solution based on massive text mining for automatically suggesting prognosis activities concerning mechanical components. The great advantage of text mining is that it is possible to automatically analyze vast amounts of unstructured information in order to find strategies that have been successfully exploited, and formally or informally documented, in the past in any part of the world.;;;https://dl.acm.org/doi/10.1145/3151759.3151774;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Classification of sentiments in short-text: an approach using mSMTP measure;;;['H M Keerthi Kumar', 'B S Harish', 'S V Aruna Kumar', 'V N Manjunath Aradhya'];;;February 2018;;;ICMLSC '18: Proceedings of the 2nd International Conference on Machine Learning and Soft Computing;;;Sentiment analysis or opinion mining is an automated process to recognize opinion, moods, emotions, attitude of individuals or communities through natural language processing, text analysis, and computational linguistics. In recent years, many studies concentrated on numerous blogs, tweets, forums and consumer review websites to identify sentiment of the communities. The information retrieved from social networking site will be in short informal text because of limited characters in blogging site or consumer review websites. Sentiment analysis in short-text is a challenging task, due to limitation of characters, user tends to shorten his/her conversation, which leads to misspellings, slang terms and shortened forms of words. Moreover, short-texts consists of more number of presence and absence of term/feature compared to regular text. In this work, our major goal is to classify sentiments into positive, negative or neutral polarity using new similarity measure. The proposed method embeds modified Similarity Measure for Text Processing (mSMTP) with K-Nearest Neighbor (KNN) classifier. The effectiveness of the proposed method is evaluated by comparing with Euclidean Distance, Cosine Similarity, Jaccard Coefficient and Correlation Coefficient. The proposed method is also compared with other classifiers like Support Vector Machine and Random Forest using benchmark dataset. The classification results are evaluated based on Accuracy, Precision, Recall and F-measure.;;;https://dl.acm.org/doi/10.1145/3184066.3184074;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Research on the Topic Mining of Learners' Interest Based on the Mongolian MOOC Platform Course Discussion Text;;;['Maowen Tan', 'Yun Song'];;;May 2021;;;CIPAE 2021: 2021 2nd International Conference on Computers, Information Processing and Advanced Education;;;At present, one of the key directions of MOOC research is to meet the individual learning needs of learners, while the focus of personalized learning is to model learners’ interest in learning, and whether the model can accurately reflect learners’ interest and admiration plays a central role in the lesson recommendation mechanism. This research takes "Introduction to Computer" course of the Mongolian MOOC platform as the research object, and discovers the topics of interest of the learners by digging the content of the course discussion area. First, after crawling the content of the discussion area, the text needs to be preprocessed, including encoding conversion, text proofreading, removing stop words, and removing affixes; secondly, the discussion text is described by the vector space model, and the keywords and their weights are calculated by the TF-IDF algorithm; finally, the semantic similarity of keywords is calculated through the cosine formula, and after clustering, the topics of interest of the learners are obtained. The experimental results show that the learner's reason for choosing a course is related to three themes, namely the content of the course, the teaching method and the learning experience.;;;https://dl.acm.org/doi/10.1145/3456887.3459721;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Toward a Progress Indicator for Machine Learning Model Building and Data Mining Algorithm Execution: A Position Paper;;;['Gang Luo'];;;December 2017;;;ACM SIGKDD Explorations Newsletter;;;For user-friendliness, many software systems offer progress indicators for long-duration tasks. A typical progress indicator continuously estimates the remaining task execution time as well as the portion of the task that has been finished. Building a machine learning model often takes a long time, but no existing machine learning software supplies a non-trivial progress indicator. Similarly, running a data mining algorithm often takes a long time, but no existing data mining software provides a nontrivial progress indicator. In this article, we consider the problem of offering progress indicators for machine learning model building and data mining algorithm execution. We discuss the goals and challenges intrinsic to this problem. Then we describe an initial framework for implementing such progress indicators and two advanced, potential uses of them, with the goal of inspiring future research on this topic;;;https://dl.acm.org/doi/10.1145/3166054.3166057;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Research on the Consumer Reviews of JD Bookstore Based on Text Mining Technology;;;['Aiting Xu', 'Pingting Ying', 'Fangyan Wang'];;;May 2019;;;ICBDC '19: Proceedings of the 4th International Conference on Big Data and Computing;;;With the rapid development of the Internet economy, the major online shopping platform has accumulated a large amount of consumer comment data containing rich information. This article takes the JD Bookstore consumer comments as the research object and uses the web crawler technology to collect consumer reviews. Further, depth mining and sentiment orientation analysis are performed on the comment data and the feature word list based on the dictionary and sentiment analysis algorithms. The results of the study show that the majority of users' comments have positive emotional tendencies, and comments with negative emotional tendencies are less than 10%. Although the majority of users maintain a more positive attitude towards JD Bookstore' logistics services, customer service, product quality, product packaging and prices, but logistics services and product quality still need to be further improved. Finally, this paper puts forward some suggestions on the distribution, purchase and pricing of JD Bookstore.;;;https://dl.acm.org/doi/10.1145/3335484.3335512;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Combining Machine Learning and Symbolic Representation of Time Series for Classification of Behavioural Patterns;;;['Paula Carballo Pérez', 'Felipe Ortega', 'Jorge Navarro García', 'Isaac Martín de Diego'];;;January 2019;;;ICSLT '19: Proceedings of the 5th International Conference on e-Society, e-Learning and e-Technologies;;;The emergence of affordable wireless sensors has enabled the development of information systems combining sophisticated data processing and machine learning algorithms for pattern recognition. In many cases, these systems deal with time-series data, continuously gathered by sensors that compile detailed activity records. However, these datasets are frequently affected by numerous problems, including noisy data acquisition, missing data and utilization of inefficient techniques for information representation, which lead to deficient performance in machine learning applications. In this paper, we introduce a novel method to combine the efficient symbolic representation of time-series data with machine learning to improve the performance of classification systems tailored to detection of behavioural patterns of interest.;;;https://dl.acm.org/doi/10.1145/3312714.3312726;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Machine Learning for Encrypted Malware Traffic Classification: Accounting for Noisy Labels and Non-Stationarity;;;['Blake Anderson', 'David McGrew'];;;August 2017;;;KDD '17: Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining;;;The application of machine learning for the detection of malicious network traffic has been well researched over the past several decades; it is particularly appealing when the traffic is encrypted because traditional pattern-matching approaches cannot be used. Unfortunately, the promise of machine learning has been slow to materialize in the network security domain. In this paper, we highlight two primary reasons why this is the case: inaccurate ground truth and a highly non-stationary data distribution. To demonstrate and understand the effect that these pitfalls have on popular machine learning algorithms, we design and carry out experiments that show how six common algorithms perform when confronted with real network data. With our experimental results, we identify the situations in which certain classes of algorithms underperform on the task of encrypted malware traffic classification. We offer concrete recommendations for practitioners given the real-world constraints outlined. From an algorithmic perspective, we find that the random forest ensemble method outperformed competing methods. More importantly, feature engineering was decisive; we found that iterating on the initial feature set, and including features suggested by domain experts, had a much greater impact on the performance of the classification system. For example, linear regression using the more expressive feature set easily outperformed the random forest method using a standard network traffic representation on all criteria considered. Our analysis is based on millions of TLS encrypted sessions collected over 12 months from a commercial malware sandbox and two geographically distinct, large enterprise networks.;;;https://dl.acm.org/doi/10.1145/3097983.3098163;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A Text Classification Approach using Parallel Naive Bayes in Big Data Context;;;['Houda Amazal', 'Mohammed Ramdani', 'Mohamed Kissi'];;;October 2018;;;SITA'18: Proceedings of the 12th International Conference on Intelligent Systems: Theories and Applications;;;Text classification is a domain that has been inspiring researchers since many years. Indeed, several approaches have been developed in order to find methods that improve the performance of text classification. But in last decades, because of the technological evolution, textual data becomes more and more abundant on the web. So that classical classification methods are unable to process this huge amount of data and consequently cannot produce satisfied results. Thus, new ways have been explored; to overcome the big dimensions of data, it was necessary to reduce the size of the features of documents and use parallel processing. For this, in our work, we developed a Term Frequency- Inverse Document Frequency (TF-IDF) parallel model to save only the most relevant words in documents. Then, we feed the dataset to a parallel Naive Bayes classifier. Both, the TF-IDF parallel model and parallel Naïve Bayes classifier were implemented on Hadoop system using the MapReduce architecture. The experimental results demonstrate the efficiency of the proposed method to improve the classification accuracy.;;;https://dl.acm.org/doi/10.1145/3289402.3289536;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Modelling Student Performance Using Data Mining Techniques: Inputs for Academic Program Development;;;['Mayreen V. Amazona', 'Alexander A. Hernandez'];;;May 2019;;;ICCDE '19: Proceedings of the 2019 5th International Conference on Computing and Data Engineering;;;This paper presents the outcomes of linking an educational data mining approach to model students' academic performance. Three data mining classification models (Naïve Bayes, Decision Tree and Deep Learning in Neural Network) were defined to analyze data set and to predict students' performance. The forecast presentation of the three classifiers were calculated and matched. Students' academic histories and data from the Registrar's Office were used to train the models. Results show that Deep Learning classifier beats other two classifiers by gaining the overall forecast accuracy of 95%. These results highlight the impact on student success while pointing to several promising directions for future work. These analysis and information about prediction is more helpful for college administration and faculty members to improve education and also make changes if necessary.;;;https://dl.acm.org/doi/10.1145/3330530.3330544;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Data Mining of Project Management Data: An Analysis of Applied Research Studies;;;['Gurdal Ertek', 'Murat Mustafa Tunc', 'Allan Nengsheng Zhang', 'Omer Tanrikulu', 'Sobhan Asian'];;;December 2017;;;ICIT '17: Proceedings of the 2017 International Conference on Information Technology;;;Data collected and generated through and posterior to projects, such as data residing in project management software and post-project review documents, can be a major source of actionable insights and competitive advantage. This paper presents a rigorous methodological analysis of the applied research published in academic literature, on the application of data mining (DM) for project management (PM). The objective of the paper is to provide a comprehensive analysis and discussion of where and how data mining is applied for project management data and to provide practical insights for future research in the field.;;;https://dl.acm.org/doi/10.1145/3176653.3176714;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Exploration of a Balanced Reference Corpus with a Wide Variety of Text Mining Tools;;;['Nicolas Turenne', 'Bokai Xu', 'Xinyue Li', 'Xindi Xu', 'Hongyu Liu', 'Xiaolin Zhu'];;;December 2020;;;ACAI '20: Proceedings of the 2020 3rd International Conference on Algorithms, Computing and Artificial Intelligence;;;To compare various techniques, the same platform is generally used into which the user will import a text dataset. Another approach uses an evaluation based on a gold standard for a specific task, but a balanced common language corpus is not often used. We choose the Corpus of Contemporary American English Corpus (COCA) as a balanced reference corpus, and split this corpus into categories, such as topics and genres, to apply families of feature extraction and machine learning algorithms. We found that the Stanford CoreNLP method was faster and more accurate than the NLTK method, and was more reliable and easier to understand. The results of clustering show that a higher modularity influences interpretation. For genre and topic classification, all techniques achieved a relatively high score, though these were below the state-of-the-art scores from challenge text datasets. Naïve Bayes outperformed the other alternatives. We hope that balanced corpora from a variety of different vernacular (or low-resource) languages can be used as references to determine the efficiency of the wide diversity of state-of-the-art text mining tools.;;;https://dl.acm.org/doi/10.1145/3446132.3446192;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A Cognitive Pragmatic Analysis of Conceptual Metaphor in Political Discourse Based on Text Data Mining;;;['Renqing Hu', 'Xue Wang'];;;September 2021;;;ICISCAE 2021: 2021 4th International Conference on Information Systems and Computer Aided Education;;;As a cognitive mechanism and thinking mode of human beings, conceptual metaphor is not only a way to make the world order, but also one of the main basic ways of human existence. Scholars at home and abroad have done a lot of research on conceptual metaphor and ideology in political discourse. But the research results, especially the domestic research results are not very rich. We should expand the scope of the number and types of corpus, and adopt a variety of methods to continue to deepen. From the perspective of cognitive pragmatics, based on Lakoff's conceptual metaphor theory and framework theory, this paper explores the framework of conceptual metaphor in political speeches from the official website of the Ministry of foreign affairs. This paper explores the powerful appeal of metaphor in political discourse and its influence on the audience's cognition and acceptance. This paper summarizes the similarities and differences of conceptual metaphors in Chinese and American political discourses, aiming to deepen the understanding of metaphors in political discourses, so that learners can better understand the characteristics of political language.;;;https://dl.acm.org/doi/10.1145/3482632.3482681;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Deep Belief Network based Machine Learning for Daily Activities Classification;;;['Tejtasin Phiasai', 'Nutchanun Chinpanthana'];;;July 2021;;;AIVR 2021: 2021 5th International Conference on Artificial Intelligence and Virtual Reality (AIVR);;;Human activity recognition has been a very active topic in pervasive computing for several years for its important applications in assisted living, healthcare, and security surveillance. Many researchers are finding and representing the details of human body gestures to determine human activity. While simple activities can be easily recognized only by acceleration data, our research has focused on the recognition and understanding the various activities in daily living. In this work, we address this problem by proposing approach theory of deep learning with the Deep belief network. Deep belief network comprises a series of Restricted Boltzmann Machines will be formed by superimposed multiple Restricted Boltzmann Machines and training the model parameters for data reconstruction, feature construction and classification. We tested our approach on PASCAL VOC datasets. The experimental results indicate that our proposed approach offers significant performance improvements with the maximum of 79.8%.;;;https://dl.acm.org/doi/10.1145/3480433.3480444;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Chinese Text Feature Extraction and Classification Based on Deep Learning;;;['Ruishuang Wang', 'Zhao Li', 'Jian Cao', 'Tong Chen'];;;October 2019;;;CSAE '19: Proceedings of the 3rd International Conference on Computer Science and Application Engineering;;;With the rapid development of deep learning, neural networks have been widely used in natural language processing tasks and achieved good results. Since convolutional neural networks can acquire high-level features that can better represent textual semantic information, convolutional neural networks (CNN) and convolutional recurrent neural networks (CRNN) are used to establish feature extraction models to extract text features. At the same time, tf-idf and word2vec methods are used to represent text features, and then feed them into SVM and Random forest classifier to classify Chinese academic papers dataset. Experimental results show that the classification results obtained by using the CNN and CRNN feature extraction model are better than using the TF-IDF and Word2vec feature extraction methods. In addition, the classification results obtained by using SVM and Random forest classifier are better than that of the original neural network.;;;https://dl.acm.org/doi/10.1145/3331453.3361636;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A comparative survey of machine learning classification algorithms for breast cancer detection;;;['Markos Marios Kaklamanis', 'Michael E. Filippakis'];;;November 2019;;;PCI '19: Proceedings of the 23rd Pan-Hellenic Conference on Informatics;;;In this paper four machine learning algorithms are compared in order to predict if a cell nucleus is benign or malignant using the Breast Cancer Wisconsin (Diagnostic) Data Set. The algorithms are K-Nearest Neighbours, Classification and Regression Trees (CART), Naïve Bayes and Support Vector Machines with Radial Basis Function Kernel. Data visualization and Pre-Processing using PCA will help in the understanding and the preparation of the dataset for the training phase while parameter tuning will determine the optimal parameter for every model using R as programming language. Also, 10-fold Cross Validation is used as a resampling method after comparing it with Bootstrapping, as it is the most efficient out of the two. In the end, our comparison shows that the machine learning model that marked the highest Accuracy is the one that is trained using K Nearest Neighbours. Nowadays, one of the most common forms of cancer among women is breast cancer with more than one million cases and nearly 600,000 deaths occurring worldwide annually [1]. It is the second leading cause of death among women and thus it must be detected at an early stage in order not to become fatal [2]. Thus, the importance of diagnosing if a biopsied cell is benign or malignant is vital. However, this process is quite complicated as it involves several stages of gathering and analysing samples with many variables, making the final diagnosis a demanding and timely procedure. The rapid growth of Artificial Intelligence and Machine learning and their implementation in Medicine give us a new perspective in the way we process and analyse medical data. Medical experts can use Data Mining techniques and improve their decision making by extracting useful information from massive amounts of data.;;;https://dl.acm.org/doi/10.1145/3368640.3368642;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Use Case Scenarios on Legal Text Mining;;;['Yannis Charalabidis', 'Michalis Avgerinos Loutsaris', 'Shefali Virkar', 'Charalampos Alexopoulos', 'Anna-Sophie Novak', 'Zoi Lachana'];;;April 2019;;;ICEGOV '19: Proceedings of the 12th International Conference on Theory and Practice of Electronic Governance;;;Europe's vision is to establish a well-functioning Digital Single Market, where Europeans are able to move and trade among the EU member states. On the other hand the large amount of information about laws that apply in each EU country has posed significant barriers in this vision. Moreover only legal experts can follow the latest legislation in each country consuming a large amount of business resources in order to follow the current legislation. However, Mass customization tools can help to filter and thereby reduce the flood of legal information and make it easier to be followed from businesses and citizens without legal expertise. The proposed solution is a novel ICT architecture utilising and built upon text mining, advanced processing and semantic analysis of legal information towards the provision of a set of services for citizens, businesses, and administrations of the European Union. In order to provide the most appealing, comprehensive and added value services in the legal domain, this paper presents six use case scenarios based on the opinion of different target groups. Conducting interviews and focus groups, we were able to identify the novel functionalities and services of great importance for the users highlighting and addressing users' daily problems regarding legal information. Generally, interviews with the different target groups reveal that at this point, users prioritise their needs towards more basic services such as search functionalities and correlation with previous laws. Lawyers on the other hand as more competent target group asked for summarisation and reporting services. All target groups where eager on the implementation of this service which as it seems it will directly impact their everyday professional and personal use of legal information.;;;https://dl.acm.org/doi/10.1145/3326365.3326413;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Graphical Keyword Service for Research Papers with Text-Mining Method;;;['Yejin Jo', 'Eun-Gyeong Kim', 'Yongju Shin'];;;May 2017;;;ICCDA '17: Proceedings of the International Conference on Compute and Data Analysis;;;This paper is for utilization of text mining method to provide visual keywords of the papers and reports. This study presents a visualization approach to secure intuitive understanding rather than abstract, keywords. The statistical examples of few technical papers are shown. The graphical methods in this paper will be helpful tools for researchers, the public who need to access expert literatures. The authors tried to draw graphical methods by using R programming language in this paper. In addition, we expect this work would contribute to the public who want to seek expert papers in easy and intuitive way.;;;https://dl.acm.org/doi/10.1145/3093241.3093242;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Point cloud capture and segmentation of animal images using classification and clustering;;;['Justin Petluk', 'Wendy Osborn'];;;November 2021;;;HANIMOB '21: Proceedings of the 1st ACM SIGSPATIAL International Workshop on Animal Movement Ecology and Human Mobility;;;Measuring characteristics of animals in the wild is not always possible, due to their demeanour and lack of human contact. Remote capture and processing methods, including the segmentation of animal data into relevant body parts, are required. Existing solutions are either costly or too cumbersome to use in the wild. This study explores the use of RGB depth (RGB-D) cameras for data capture of a target animal from a distance. In addition, this study explores the extraction and segmentation of the resulting animal data into point clouds, and the creation of machine learning models for the automated segmentation of this data. Results of this study, including an experimental evaluation, demonstrate the feasibility of utilizing RGB-D cameras for animal data capture, and that classification outperformed clustering for automated animal data segmentation.;;;https://dl.acm.org/doi/10.1145/3486637.3489485;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Semi-Supervised Techniques for Mining Learning Outcomes and Prerequisites;;;['Igor Labutov', 'Yun Huang', 'Peter Brusilovsky', 'Daqing He'];;;August 2017;;;KDD '17: Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining;;;Educational content of today no longer only resides in textbooks and classrooms; more and more learning material is found in a free, accessible form on the Internet. Our long-standing vision is to transform this web of educational content into an adaptive, web-scale "textbook", that can guide its readers to most relevant "pages" according to their learning goal and current knowledge. In this paper, we address one core, long-standing problem towards this goal: identifying outcome and prerequisite concepts within a piece of educational content (e.g., a tutorial). Specifically, we propose a novel approach that leverages textbooks as a source of distant supervision, but learns a model that can generalize to arbitrary documents (such as those on the web). As such, our model can take advantage of any existing textbook, without requiring expert annotation. At the task of predicting outcome and prerequisite concepts, we demonstrate improvements over a number of baselines on six textbooks, especially in the regime of little to no ground-truth labels available. Finally, we demonstrate the utility of a model learned using our approach at the task of identifying prerequisite documents for adaptive content recommendation --- an important step towards our vision of the "web as a textbook".;;;https://dl.acm.org/doi/10.1145/3097983.3098187;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Research on Data Mining in Medical Data Visualization;;;['Hengliang Shi', 'Lei Zhang', 'Lintao Zheng', 'Gang Liu'];;;December 2019;;;ICNCC '19: Proceedings of the 2019 8th International Conference on Networks, Communication and Computing;;;Data mining is an important technology in the field of artificial intelligence. Modern medical and health industry is changing from traditional information representation to isomerization and diversification. The organic combination of the two can excavate intelligent diagnosis and treatment technologies and methods with broad application prospects. This paper mainly summarizes the current classification, regression analysis, clustering, Association rules, features, change and deviation analysis of data mining, the classical algorithms of Web page mining, and the development trend of visualization of medical data mining.;;;https://dl.acm.org/doi/10.1145/3375998.3376041;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Defining Data Literacy Communities by Their Objectives: A Text Mining Analysis;;;['Ahmed Mohamed Fahmy Yousef', 'Johanna Catherine Walker', 'Manuel Leon-Urrutia'];;;June 2021;;;WebSci '21 Companion: Companion Publication of the 13th ACM Web Science Conference 2021;;;Data literacy is a multidimensional concept that attracts the attention of a variety of communities of practice, from different angles. The authors grouped these communities of practice in three categories: education, fields and professions, and citizenship. The meaning of data literacy varies depending on who uses it, and its concept is often conveyed in terms other than data literacy. This paper addresses the problematization of data literacy as a term by examining academic literature around it. To this end, a desk study was carried out to gather sources where the term is used. After an extensive search in the main academic databases and a subsequent PRISMA selection process, automated content analysis was applied to the gathered sources. The findings suggest that the concept of data literacy has a different treatment in different communities of practice. For example, librarians and citizen scientists have a different understanding of the concept of data literacy.;;;https://dl.acm.org/doi/10.1145/3462741.3466663;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Student Performance Prediction and Classification Using Machine Learning Algorithms;;;['Boran Sekeroglu', 'Kamil Dimililer', 'Kubra Tuncal'];;;March 2019;;;ICEIT 2019: Proceedings of the 2019 8th International Conference on Educational and Information Technology;;;For a productive and a good life, education is a necessity and it improves individuals' life with value and excellence. Also, education is considered a vital need for motivating self-assurance as well as providing the things are needed to partake in today's World. Throughout the years, education faced a number of challenges. Different methods of teaching and learning are suggested to increase the learning quality. In today's world, computers and portable devices are employed in every phase of daily life and many materials are available online anytime, anywhere. Technologies like Artificial Intelligence had a surprising evolution in many fields especially in educational teaching and learning processes. Higher education institutions have started to adopt the use of technology into their traditional teaching mechanisms for enhancing learning and teaching. In this paper, two datasets have been considered for the prediction and classification of student performance respectively using five machine learning algorithms. Eighteen experiments have been performed and preliminary results suggest that performances of students might be predictable and classification of these performances can be increased by applying pre-processing to the raw data before implementing machine learning algorithms.;;;https://dl.acm.org/doi/10.1145/3318396.3318419;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Document Enrichment using DBPedia Ontology for Short Text Classification;;;['Jernej Flisar', 'Vili Podgorelec'];;;June 2018;;;WIMS '18: Proceedings of the 8th International Conference on Web Intelligence, Mining and Semantics;;;Every day, millions of short-texts are generated for which effective tools for organization and retrieval are required. Because of the short length of these documents and of their extremely sparse representations, the traditional text classification methods are not effective. We propose a new approach that uses DBpedia Spotlight annotation tools, to identify relevant entities in text and enrich short text documents with concepts derived from those entities, represented in DBpedia ontology. Our experiments show that the proposed document enrichment approach is beneficial for classification of short texts, and is robust with respect to concept drifts and input sources. We report experimental results in three challenging collections, using a variety of classification methods. The results show that the use of DBpedia ontology significantly improves the classification performance of classifiers in short-text classification.;;;https://dl.acm.org/doi/10.1145/3227609.3227649;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Senegalese Road Crash Data Analysis Based On Clustering And Association Rule Mining;;;['Yoro DIA', 'Cheikh Tidiane SECK', 'Mouhamadou Saliou DIALLO', 'Ousmane SALL', 'Mamadou Bousso', 'Edouard Ngor SARR', 'Mamadou Lamine MBOUP'];;;February 2021;;;DSDE '21: 2021 4th International Conference on Data Storage and Data Engineering;;;This paper presents a study on road accident data in Senegal by identifying associations within accident cases. We use unsupervised classification techniques such as clustering and association rule mining. Pre-processing of our data set revealed subgroup structures within the data. To reduce the association rule mining algorithm's search space, we used the k-modes clustering method as the main segmentation task on road accident data. Then, association rule mining helps identify the different circumstances associated with an accident in each group obtained by the k-modes algorithm. The results of the study show that to improve road safety, the authorities in charge of road transportation could orient their prevention policies towards three main aspects: vehicle fleet renewal, respect for the Highway Code, and prohibition of large vehicles circulation, such as trucks used for goods transportation at rush hours.;;;https://dl.acm.org/doi/10.1145/3456146.3456158;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A SURVEY ON SIMILARITY MEASURES AND MACHINE LEARNING ALGORITHMS FOR CLASSIFICATION AND PREDICTION;;;['Sravan kiran Vangipuram', 'Rajesh Appusamy'];;;April 2021;;;DATA'21: International Conference on Data Science, E-learning and Information Systems 2021;;;An important observation which figures out when we look into several applications which are the result of applying data science, machine learning, and deep learning techniques is that most of these techniques are based on the concept of measuring similarity between any two vectors. These vectors may act as representatives for objects being considered. Similarity measurement thus gains a great importance in the design of machine learning or deep learning algorithms and techniques. In similar lines, when we are required to carry a supervised or unsupervised learning task, an algorithm is required to carry the task efficiently. Thus, in this paper, our objective is to outline various similarity measures that have been considered for carrying supervised or unsupervised learning tasks and also to throw light on different machine learning algorithms employed for supervised and unsupervised learning tasks from disease classification and prediction point of view and also interdisciplinary domains such as time series analysis, temporal data mining, medical data mining, and anomaly or intrusion detection.;;;https://dl.acm.org/doi/10.1145/3460620.3460755;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Data mining in IoT: data analysis for a new paradigm on the internet;;;['Peter Wlodarczak', 'Mustafa Ally', 'Jeffrey Soar'];;;August 2017;;;WI '17: Proceedings of the International Conference on Web Intelligence;;;This paper provides an overview on Data Mining (DM) technologies for the Internet of Things (IoT). IoT has become an active area of research, since IoT promises among other to improve quality of live and safety in Smart Cities, to make resource supply and waste management more efficient, and optimize traffic. DM is highly domain specific and depends on what is being mined for. For instance, if IoT is used to optimize traffic in a Smart City to reduce traffic jams and to find parking spaces quicker, different types of data needs to be collected and analysed from an eHealth solution, where IoT is used in a Smart Home to monitor the well being of patients or elderly people. IoT connects things that can collect numeric data from smart sensors, streaming data from cameras or route information on maps. Depending on the type of data, different techniques need to be adopted to analyse them. Also, many IoT applications analyse data from different devices and correlate them to make predictions about possible machine failures in production sites or looming emergency situations in Smart Buildings in a home security application. DM techniques need to handle the heterogeneity of IoT data, the large volumes of data and the speed at which they are produced. This paper explores the state of the art DM techniques for IoT.;;;https://dl.acm.org/doi/10.1145/3106426.3115866;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Data Mining Methods for Solving Classification Problem of Oil Wells;;;['Zayar Aung', 'Mikhaylov Ilya Sergeevich', 'Ye Thu Aung'];;;January 2020;;;BDET 2020: Proceedings of the 2020 2nd International Conference on Big Data Engineering and Technology;;;The purpose of this work is to create a learning algorithm which is based on accumulated historical data on previously drilled wells. Wells will forecast an emergency accompanied by drilling. Such a decision support system will help the engineer time to intervene in the drilling process and prevent high drilling costs simple and repair equipment resulting in an accident.;;;https://dl.acm.org/doi/10.1145/3378904.3378911;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A Combination of Text Mining Techniques for Relevant Literature Search and Extractive Summarization;;;['Thiptanawat Phongwattana', 'Jonathan H. Chan'];;;September 2018;;;NLPIR '18: Proceedings of the 2nd International Conference on Natural Language Processing and Information Retrieval;;;Over the past few years, the amount of research papers published has dramatically increased. Consequently, researchers spend a lot of time reviewing relevant literature in order to better understand their domain of interest and keep up with new developments. After doing literature reviews in the area of text mining, we found many works proposing the means of sentence representation in machine learning for finding sentence similarity. These include average bag of words, weight average word vectors, bag of n-grams, and matrix-vector operations. However, these techniques are limited in word ordering and semantic analysis. This paper proposes a framework that combines two text mining techniques, paragraph vectors and TextRank, for the selection of relevant research paper and extractive summarization, respectively. Our training corpus includes over 20 million research papers. The aim of this work is to build a supplementary research tool that assists researchers in saving time conducting literature reviews. As the result, we can rank all relevant research papers potentially within the corpus, and utilize the outputs in our literature reviews. Moreover, the tool can extract all potential keywords in a single task as well.;;;https://dl.acm.org/doi/10.1145/3278293.3278300;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Crytojacking Classification based on Machine Learning Algorithm;;;['Wan Nur Aaisyah Binti Wan Mansor', 'Azuan Ahmad', 'Wan Shafiuddin Zainudin', 'Madihah Mohd Saudi', 'Mohd Nazri Kama'];;;April 2020;;;ICCBN '20: Proceedings of the 2020 8th International Conference on Communications and Broadband Networking;;;The rise of cryptocurrency has resulted in a number of concerns. A new threat known as cryptojacking" has entered the picture where cryptojacking malware is the trend for future cyber criminals, who infect computers, install cryptocurrency miners, and use stolen information from victim databases to set up wallets for illicit funds transfers. Worst by 2020, researchers estimate there will be 30 billion of IoT devices in the world. Majority of the devices are highly vulnerable to simple attacks based on weak passwords and unpatched vulnerabilities and poorly monitored. Thus it is the best projection that IoT become a perfect target for cryptojacking malwares. There are lacks of study that provide in depth analysis on cryptojacking malware especially in the classification model. As IoT devices requires small processing capability, a lightweight model are required for the cryptojacking malware detection algorithm to maintain its accuracy without sacrificing the performance of other process. As a solution, we propose a new lightweight cryptojacking classifier model based on instruction simplification and machine learning technique that can detect the cryptojacking classification algorithm. This research aims to study the features of existing cryptojacking classification algorithm, to enhanced existing algorithm and to evaluate the enhanced algorithm for cryptojacking malware classification. The output of this research will be significant used in detecting cryptojacking malware attacks that benefits multiple industries including cyber security contractors, oil and gas, water, power and energy industries which align with the National Cyber Security Policy (NCSP) which address the risks to the Critical National Information Infrastructure (CNII).;;;https://dl.acm.org/doi/10.1145/3390525.3390537;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Vulnerability assessment of machine learning based malware classification models;;;['Godwin Raju', 'Pavol Zavarsky', 'Adetokunbo Makanju', 'Yasir Malik'];;;July 2019;;;GECCO '19: Proceedings of the Genetic and Evolutionary Computation Conference Companion;;;The primary focus of the machine learning model is to train a system to achieve self-reliance. However, due to the absence of the inbuilt security functions the learning phase itself is not secured which allows attacker to exploit the security vulnerabilities in the machine learning model. When a malicious adversary manipulates the input data, it exploits vulnerabilities of machine learning algorithms which can compromise the entire system. In this research study, we are conducting a vulnerability assessment of the malware classification model by injecting the datasets with an adversarial example to degrade the quality of classification obtained currently by a trained model. The objective is to find the security gaps that are exploitable in the model. The vulnerability assessment is done by introducing the malware classification model to an AML environment using the Black-Box attack. The simulation provided an insight into the inputs injected into the classifiers and proves the inherent security vulnerability exists in the classification model.;;;https://dl.acm.org/doi/10.1145/3319619.3326897;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Application of Data Mining Classification Algorithms for Breast Cancer Diagnosis;;;['Hajar Saoud', 'Abderrahim Ghadi', 'Mohamed Ghailani', 'Boudhir Anouar Abdelhakim'];;;October 2018;;;SCA '18: Proceedings of the 3rd International Conference on Smart City Applications;;;Breast cancer is one of the diseases that represent a large number of incidence and mortality in the world. Data mining classifications techniques will be effective tools for classifying data of cancer to facilitate decision-making. The objective of this paper is to compare the performance of different machine learning algorithms in the diagnosis of breast cancer, to define exactly if this type of cancer is a benign or malignant tumor. Six machine learning algorithms were evaluated in this research Bayes Network (BN), Support Vector Machine (SVM), k-nearest neighbors algorithm (Knn), Artificial Neural Network (ANN), Decision Tree (C4.5) and Logistic Regression. The simulation of the algorithms is done using the WEKA tool (The Waikato Environment for Knowledge Analysis) on the Wisconsin breast cancer dataset available in UCI machine learning repository.;;;https://dl.acm.org/doi/10.1145/3286606.3286861;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Data mining toolkit for extraction of knowledge from LMS;;;['W. Villegas-Ch', 'S. Luján-Mora', 'Diego Buenaño-Fernandez'];;;December 2017;;;ICETC '17: Proceedings of the 9th International Conference on Education Technology and Computers;;;Today, information technology (IT) is an active part of education. Its main impact is in the administration of learning management systems (LMS). The support provided by IT in LMS has generated greater dexterity in the evaluation of the quality of education. The evaluation process usually includes the use of tools applied to online analytical processing (OLAP). The application of OLAP allows the consultation of large amounts of data. Data mining algorithms can be applied to the data collected to perform a pattern analysis. The potential use of these tools has resulted in their specialization, both in the presentation and in the algorithmic techniques, allowing the possibility of educational data mining (EDM). EDM seeks to enhance or customize education within LMS by classifying groups of students in terms of similar characteristics that require specific resources. The ease of use and extensive information about some of the EDM tools has caused many educational institutions to consider them for their own use. However, these institutions often make errors in data management. Errors in the use of data mean that the improvements in LMS are inadequate. The work described in this paper provides a guide on the use of applied methodology in the process of knowledge extraction (KDD). It also enumerates some of the tools that can be used for each step of the process.;;;https://dl.acm.org/doi/10.1145/3175536.3175553;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A new approach to text classification based on naïve Bayes and modified TF-IDF algorithms;;;['El Barakaz Fatima', 'El Moutaouakkil Abdelmajid'];;;October 2017;;;SCAMS '17: Proceedings of the Mediterranean Symposium on Smart City Application;;;In text mining, classification is a technique of assigning documents to predefined classes. Naïve Bayes algorithm is the basic of text classification technique; it is the most widely used algorithm for diverse text classification applications. This paper proposes a new approach of unstructured text classification using quantitative variable; this variable has a strong correlation with the text attribute. We classify the text attribute using the bags of words to get the keywords of our corpus, and we define classes to which we wish affecting terms, then we apply the naive Bayes classifier. This classifier is not highly efficient in an unstructured text classification case. So we propose a new classifier combining two algorithms principles: term frequency- inverse document frequency (TF-IDF) and k-nearest neighbor (KNN). This classifier is applied on the quantitative variable. The objective is to achieve better classification of an unstructured text with a high level of efficiency. The result of the proposed classifier method was very satisfactory, especially since it enriches the dictionary content each time we use it.;;;https://dl.acm.org/doi/10.1145/3175628.3175643;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Classification of Abstract Images using Machine Learning;;;['Animesh Karnewar', 'Ameeth Kanawaday', 'Chinmay Sawant', 'Yash Gupta'];;;June 2017;;;ICDLT '17: Proceedings of the 2017 International Conference on Deep Learning Technologies;;;Abstract painting uses a visual language of form, color, and line to create a composition that may exist with a degree of independence from visual references in the world. Sometimes, it isn't even about giving the impression of real life without all the little details. This makes the task of classification of the paintings into genres altogether more difficult. In this paper, we describe a systematic method for a machine learning based approach to classifying digital images of abstract art into their most apt artistic styles. To increase the effectiveness of classification, we stack the two classifiers namely Convolutional Neural Network and Deep Neural Network. The hybrid model thus formed outperforms the separate singular models. Furthermore, the task of analysis of color emotions of the artistic image helps to gain further insights of the said classes.;;;https://dl.acm.org/doi/10.1145/3094243.3094259;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Memory-Centric Reconfigurable Accelerator for Classification and Machine Learning Applications;;;['Robert Karam', 'Somnath Paul', 'Ruchir Puri', 'Swarup Bhunia'];;;None;;;ACM Journal on Emerging Technologies in Computing Systems;;;Big Data refers to the growing challenge of turning massive, often unstructured datasets into meaningful, organized, and actionable data. As datasets grow from petabytes to exabytes and beyond, it becomes increasingly difficult to run advanced analytics, especially Machine Learning (ML) applications, in a reasonable time and on a practical power budget using traditional architectures. Previous work has focused on accelerating analytics readily implemented as SQL queries on data-parallel platforms, generally using off-the-shelf CPUs and General Purpose Graphics Processing Units (GPGPUs) for computation or acceleration. However, these systems are general-purpose and still require a vast amount of data transfer between the storage devices and computing elements, thus limiting the system efficiency. As an alternative, this article presents a reconfigurable memory-centric advanced analytics accelerator that operates at the last level of memory and dramatically reduces energy required for data transfer. We functionally validate the framework using an FPGA-based hardware emulation platform and three representative applications: Naïve Bayesian Classification, Convolutional Neural Networks, and k-Means Clustering. Results are compared with implementations on a modern CPU and workstation GPGPU. Finally, the use of in-memory dataset decompression to further reduce data transfer volume is investigated. With these techniques, the system achieves an average energy efficiency improvement of 74× and 212× over GPU and single-threaded CPU, respectively, while dataset compression is shown to improve overall efficiency by an additional 1.8× on average.;;;https://dl.acm.org/doi/10.1145/2997649;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Use Text Mining for Financial Reports Analysis: Long Text to Image Converter;;;['Chia-Hao Chiu', 'Yun-Cheng Tsai'];;;November 2020;;;ICCIP '20: Proceedings of the 6th International Conference on Communication and Information Processing;;;In this study, we propose a novel article analysis method. This method converts the article classification problem into image classification problem by projecting texts into images and then applying CNN models for classification. We call the method the Long Text to Image Converter (LTIC). The features are extract automatically from the generate images, hence there is no need of any explicit step of embedding the words or characters into numeric vector representations. This method saves the time to experiment pre-process. This study uses the financial domain as an example. In companies financial reports, there will describes the company's financial trends. The content has many financial terms used to infer the company's current and future financial position. The results indicated an 80% accuracy rate. The proposed LTIC produce excellent results during practical application. The return on simulated investment is 46%. In addition to tangible returns, the LTIC method reduces the time required for article analysis and is able to provide article classification references in a short period to facilitate the decisions of the researcher.;;;https://dl.acm.org/doi/10.1145/3442555.3442557;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Health Consumer Usage Patterns in Management of CVD using Data Mining Techniques;;;['Devipriyaa Nagappan', 'Jim Warren', 'Patricia Riddle'];;;January 2019;;;ACSW '19: Proceedings of the Australasian Computer Science Week Multiconference;;;The Healthcare system is exposed to the increasing impact of chronic diseases including cardiovascular diseases; it is of much importance to analyze and understand the health trajectories for efficient planning and fair allotment of resources. This work proposes an approach based on mining clinical data to support the exploration of health trajectories related to cardiovascular diseases. As the health data are highly confidential, we aimed to conduct our experiments using a large, synthetic, longitudinal dataset, constituted to represent the CVD risk factors distribution and temporal sequence of events related to heart failure hospitalization and readmission. This research work analyses and represents the temporal events or states of the patient's trajectory with the aim of understanding the patient's journey in the management of the chronic condition and its complications by using data mining techniques. This study focuses on developing an efficient algorithm to find cohesive clusters for handling the temporal events. Clustering health trajectories have been carried out by proposing an improved version of the Ant-based clustering algorithm. Insights from this study can potentially result in evidence that these approaches are useful in understanding and analyzing patient's health trajectories for better management of the chronic condition and its progression.;;;https://dl.acm.org/doi/10.1145/3290688.3290732;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Automatic classification of Aurora-related tweets using machine learning methods;;;['Vyron Christodoulou', 'Rosa Filgueira', 'Emma Bee', 'Elizabeth MacDonald', 'Burcu Kosar'];;;March 2019;;;ICGDA '19: Proceedings of the 2019 2nd International Conference on Geoinformatics and Data Analysis;;;The constant flow of information by social media provides valuable information about all sorts of events at a high temporal and spatial resolution. Over the past few years we have been analyzing in real-time geological hazards/phenomena, such as earthquakes, volcanic eruptions, landslides, floods or the aurora, as part of the GeoSocial project, by geo-locating tweets filtered by keywords in a web-map. However, up to this date only a keyword-based filtering was applied that does not always filter out tweets that are unrelated to hazard-events. Therefore, this work explores five learning-based classification techniques: a Linear SVM and four Deep Neural Networks (DNNs): a Convolutional Neural Network (CNN), a Recurrent Neural Network (RNN), a RNN-Long-short-term memory (RNN-LSTM) and a RNN-Gated Recurrent Unit (GRU) for automatic hazard-event classification based on tweets about Aurora sightings. In addition, for the DNNS we also trained the algorithms using pre-trained word2vec word-embeddings. We finally evaluate the algorithms using two datasets, one from the Aurorasaurus application and one manually labeled in the BGS. We show that DNNs and especially the CNN perform better for both datasets and that there is potential for improvement. Our code is also available online.;;;https://dl.acm.org/doi/10.1145/3318236.3318242;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Big Data Analytics in Association Rule Mining: A Systematic Literature Review;;;['Mahtab Shahin', 'Sijo Arakkal Peious', 'Rahul Sharma', 'Minakshi Kaushik', 'Sadok Ben Yahia', 'Syed Attique Shah', 'Dirk Draheim'];;;January 2021;;;BDET 2021: 2021 the 3rd International Conference on Big Data Engineering and Technology (BDET);;;Due to the rapid impact of IT technology, data across the globe is growing exponentially as compared to the last decade. Therefore, the efficient analysis and application of big data require special technologies. The present study performs a systematic literature review to synthesize recent research on the applicability of big data analytics in association rule mining (ARM). Our research strategy identified 4797 scientific articles, 27 of which were identified as primary papers relevant to our research. We have extracted data from these papers to identify various technologies and algorithms of using big data in association rule mining and identified their limitations in regards to the big data categories (volume, velocity, variety, and veracity).;;;https://dl.acm.org/doi/10.1145/3474944.3474951;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Application of data mining based on machine learning in automobile power prediction;;;['Kexin Zhang'];;;October 2021;;;EITCE '21: Proceedings of the 2021 5th International Conference on Electronic Information Technology and Computer Engineering;;;Automobile power prediction is the key to the automobile industry. Only by reasonably predicting the automobile power can we produce cars that meet the needs of consumers. Compared with traditional methods, machine learning model improves the accuracy of classification in power. Machine learning models include BP neural network, random forest and KNN algorithm. In order to select the optimal vehicle power prediction model, this paper compares the advantages and disadvantages of these three machine learning models through design experiments.;;;https://dl.acm.org/doi/10.1145/3501409.3501532;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Vehicle Image Classification Using Data Mining Techniques;;;['Agnes S. Suguitan', 'Lucille N. Dacaymat'];;;May 2019;;;CSSE '19: Proceedings of the 2nd International Conference on Computer Science and Software Engineering;;;This paper focuses on the application of different data mining techniques to classify images of vehicles into three classes using Weka. The dataset used for this study were collected from Google Image search engine and other dataset websites. In preprocessing the images, filters such as Color Layout, Edge Histogram and Pyramid Histogram of Oriented Gradients were explored to extract the image features from the dataset. Classification techniques such as Multilayer Perceptron, Sequential Minimal Optimization, Logistic Model Trees, Simple Logistic and Random Forest were used. Results of the study showed that the edge histogram features provided much information to the classifiers in order to correctly classify the images. The SMO classifier performs best with the highest accuracy of 82.37%.;;;https://dl.acm.org/doi/10.1145/3339363.3339366;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Application of Data Mining Technology in Financial Fraud Identification;;;['Shunyu Yao'];;;September 2021;;;ICISCAE 2021: 2021 4th International Conference on Information Systems and Computer Aided Education;;;In the era of big data, the identification of financial fraud has changed from the traditional case analysis stage to the data mining stage. The application of data mining technology is helpful in identifying the company's fraud in massive data. In the process of fraud identification, a variety of data mining methods can be used, such as statistical methods, classification, clustering and neural network construction. This paper analyzes the application of several kinds of data mining methods in the field of financial fraud, and finds that due to the different model building methods and sample selection in empirical research, the accuracy of each method has not yet been determined. In the future, with the development of accounting information system, the combination of data mining and text mining will become the inevitable trend of financial fraud identification.;;;https://dl.acm.org/doi/10.1145/3482632.3487540;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Data miners' little helper: data transformation activity cues for cluster analysis on document collections;;;['Tania Cerquitelli', 'Evelina Di Corso', 'Francesco Ventura', 'Silvia Chiusano'];;;June 2017;;;WIMS '17: Proceedings of the 7th International Conference on Web Intelligence, Mining and Semantics;;;In this paper we propose a new self-learning engine to streamline the analytics process, as it enables analysts to mine massive data repositories with minimal user intervention. In the context of cluster analysis on a collection of documents this new system, named SELF-DATA (SELF-learning DAta TrAnsformation), suggests to the analyst how to configure the whole mining process for a given dataset. SELF-DATA relies on an engine exploring different data weighting schemas (e.g., normalized term frequencies) and data transformation methods (e.g., PCA) before applying the cluster analysis, evaluating and comparing solutions through different quality indices (e.g., weighted Silhouette), and presenting the k-top solutions to the analyst. SELF-DATA will also include a knowledge base storing results of experiments on previously processed datasets, and a classification algorithm trained on the knowledge base content to forecast the best configuration for the whole mining process for an unexplored dataset. The first development of SELF-DATA running on Apache Spark has been validated on 5 collections of documents. Experimental results highlight that TF-IDF and logarithmic entropy are effective to measure item relevance with sparse datasets, and the LSI method outperforms PCA with a large dictionary.;;;https://dl.acm.org/doi/10.1145/3102254.3102288;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Snippext: Semi-supervised Opinion Mining with Augmented Data;;;['Zhengjie Miao', 'Yuliang Li', 'Xiaolan Wang', 'Wang-Chiew Tan'];;;April 2020;;;WWW '20: Proceedings of The Web Conference 2020;;;Online services are interested in solutions to opinion mining, which is the problem of extracting aspects, opinions, and sentiments from text. One method to mine opinions is to leverage the recent success of pre-trained language models which can be fine-tuned to obtain high-quality extractions from reviews. However, fine-tuning language models still requires a non-trivial amount of training data.  In this paper, we study the problem of how to significantly reduce the amount of labeled training data required in fine-tuning language models for opinion mining. We describe , an opinion mining system developed over a language model that is fine-tuned through semi-supervised learning with augmented data. A novelty of is its clever use of a two-prong approach to achieve state-of-the-art (SOTA) performance with little labeled training data through: (1) data augmentation to automatically generate more labeled training data from existing ones, and (2) a semi-supervised learning technique to leverage the massive amount of unlabeled data in addition to the (limited amount of) labeled data. We show with extensive experiments that performs comparably and can even exceed previous SOTA results on several opinion mining tasks with only half the training data required. Furthermore, it achieves new SOTA results when all training data are leveraged. By comparison to a baseline pipeline, we found that extracts significantly more fine-grained opinions which enable new opportunities of downstream applications.;;;https://dl.acm.org/doi/10.1145/3366423.3380144;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Special Issue: Text Mining and Information Analysis; Retrieving and Clustering Keywords in Neurosurgery Operation Reports Using Text Mining Techniques;;;['Chun-Chih Liao', 'Furen Xiao', 'Jau-Min Wong', 'I-Jen Chiang', 'Yi-Hsin Tsai', 'Charles Chih-Ho Liu', 'Ke-Chun Huang'];;;June 2018;;;ICMHI '18: Proceedings of the 2nd International Conference on Medical and Health Informatics;;;Background: To develop a more practical and reasonable classification of surgical procedures, we applied text mining techniques to retrieve and categorize keywords in operation reports. Materials and Methods: Based on neurosurgical operation reports performed in a Taiwan medical center between 2009 and 2012, a corpus containing 3,657 documents was built. A total of 9,906 words were extracted. Initially, we applied term frequency-inverse document frequency (TF-IDF) weighting to automatically select pertinent keywords but the results were unsatisfactory. Then, we manually chose 45 keywords that belong to 3 categories: brain, spine and others. All documents were checked in an automated fashion for the presence of these keywords, producing a binary data matrix, which was used to compute the cosine similarity matrix. Then, we applied 6 variants of agglomerative clustering to build the dendrograms. Results: The document frequencies (DFs) of these 45 keywords ranged from 12 to 1,250, with an average of 444±342. The number of distinctive keywords per document ranged from 0-15, with an average of 5.5±2.5. The similarities between DF vectors are higher between keywords in the same category (brain or spine). The shortest link method and the unweighted pair-group method using the centroid (UPGMC) methods performed best on external and internal evaluation, respectively. Conclusion: The distributions of important keywords in neurosurgery operation reports reveal the localized nature of surgical procedures.;;;https://dl.acm.org/doi/10.1145/3239438.3239488;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Analysis and Comparison of Deep Learning Networks for Supporting Sentiment Mining in Text Corpora;;;['Teresa Alcamo', 'Alfredo Cuzzocrea', 'Giosue Lo Bosco', 'Giovanni Pilato', 'Daniele Schicchi'];;;November 2020;;;iiWAS '20: Proceedings of the 22nd International Conference on Information Integration and Web-based Applications &amp; Services;;;In this paper, we tackle the problem of the irony and sarcasm detection for the Italian language to contribute to the enrichment of the sentiment analysis field. We analyze and compare five deep-learning systems. Results show the high suitability of such systems to face the problem by achieving 93% of F1-Score in the best case. Furthermore, we briefly analyze the model architectures in order to choose the best compromise between performances and complexity.;;;https://dl.acm.org/doi/10.1145/3428757.3429144;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Big Data Processing using Machine Learning algorithms: MLlib and Mahout Use Case;;;['Khadija Aziz', 'Dounia Zaidouni', 'Mostafa Bellafkih'];;;October 2018;;;SITA'18: Proceedings of the 12th International Conference on Intelligent Systems: Theories and Applications;;;Machine learning is a field within artificial intelligence that allows machines to learn on their own from existing information to make predictions or/and decisions. There are three main categories of machine learning techniques: Collaborative filtering (for making recommendations), Clustering (for discovering structure in collections of data) and Classification (form of supervised learning). Machine learning helps users to make better decisions, Machine learning algorithms create patterns based on previous information and use them to design predictive models, then, use this models to obtain predictions about future data. A huge amount of data from several sources need methods and techniques to be processed correctly, in order to exploit this data efficiently, machine learning is a great technology for exploiting the needs in big data analysis. This paper describes the implementation of Apache Spark MLlib and Apache Mahout in order to process Big Data using Machine Learning algorithms. Furthermore, we conduct experimental simulations to show the difference between this two Machine Learning frameworks. Subsequently, we discuss the most striking observations that emerge from the comparison of these technologies through several experimental studies.;;;https://dl.acm.org/doi/10.1145/3289402.3289525;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Design and research of archives management system based on Data Mining Technology;;;['Yangyang Dong'];;;February 2022;;;DSDE '22: 2022 the 5th International Conference on Data Storage and Data Engineering;;;In order to enrich the functions of the archives management system, data mining technology is selected as the research tool, and the user service function and text type division function are taken as the key design contents. A new research on the design of archives management system is proposed. Among them, the development of user service function takes the user's personal information and access footprint as the basis, and uses data mining technology to extract highly relevant information as recommendation information. Text type division takes preprocessing, word segmentation and de stop words as the processing core to divide text types in detail. The system test results show that the accuracy of text type classification is 100%, the operation efficiency is significantly improved, and it has great advantages in user experience.;;;https://dl.acm.org/doi/10.1145/3528114.3528135;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Sentiment Polarity Classification using Minimal Feature Vectors and Machine Learning Algorithms;;;['Niwan Wattanakitrungroj', 'Nichapat Pinpo', 'Sasiporn Tongman'];;;June 2021;;;IAIT '21: Proceedings of the 12th International Conference on Advances in Information Technology;;;Recently, social media users can comment as texts to describe their opinions. These texts can be analyzed to classify them into either positive or negative attitude. Feature vectors for representing the texts must be designed and prepared before building a classifier. Generally, texts are represented by vectors of weights or frequencies of terms that appear in the text. The length of the feature vector is equal to the number of terms in the dictionary derived from the possible words in all texts. The large amount of words in dictionary leads to the high dimensional vector for representing text and bring about the long processing time to training and testing the text classification models. This paper, the low-dimensional vectors, V8D, were proposed for representing the texts. The set of positive and negative words including the words of negation which have the significant meanings were considered as information to create these vectors. Four machine learning algorithms to solve the classification problem, i.e., k-Nearest Neighbors, Naïve Bayes classifier, Artificial Neural Networks and Support Vector Machine, were applied to classify the opinion texts. By experimenting on eight data sets with various domains, the proposed V8D vectors were compared with the traditional TF-IDF vector in term of the predictive correctness. The experimental results show that representing text as our V8D vector for opinion text classification can provide the best efficiency in both of space usage and processing time.;;;https://dl.acm.org/doi/10.1145/3468784.3469947;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Uncertainty-Aware Reliable Text Classification;;;['Yibo Hu', 'Latifur Khan'];;;August 2021;;;KDD '21: Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining;;;Deep neural networks have significantly contributed to the success in predictive accuracy for classification tasks. However, they tend to make over-confident predictions in real-world settings, where domain shifting and out-of-distribution (OOD) examples exist. Most research on uncertainty estimation focuses on computer vision because it provides visual validation on uncertainty quality. However, few have been presented in the natural language process domain. Unlike Bayesian methods that indirectly infer uncertainty through weight uncertainties, current evidential uncertainty-based methods explicitly model the uncertainty of class probabilities through subjective opinions. They further consider inherent uncertainty in data with different root causes, vacuity (i.e., uncertainty due to a lack of evidence) and dissonance (i.e., uncertainty due to conflicting evidence). In our paper, we firstly apply evidential uncertainty in OOD detection for text classification tasks. We propose an inexpensive framework that adopts both auxiliary outliers and pseudo off-manifold samples to train the model with prior knowledge of a certain class, which has high vacuity for OOD samples. Extensive empirical experiments demonstrate that our model based on evidential uncertainty outperforms other counterparts for detecting OOD examples. Our approach can be easily deployed to traditional recurrent neural networks and fine-tuned pre-trained transformers.;;;https://dl.acm.org/doi/10.1145/3447548.3467382;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Image-based Candlestick Pattern Classification with Machine Learning;;;['Chenghan Xu'];;;April 2021;;;ICMLT '21: Proceedings of the 2021 6th International Conference on Machine Learning Technologies;;;Financial markets, such as the stock market, bond market and foreign exchange market, are important channels for fund transfer. As a graphical analysis tool, candlestick charts use graphs to display the open, high, low, and close prices in a specific period. In the past, there have been attempts to identify the characteristics of candlesticks based on Gramian Angular Field (GAF) images, but they are not perfect. In this study, we implemented Multilayer Perceptron (MLP), Convolutional Neural Network (CNN), AdaBoost, Random Forest (RF) and XGBoost models, we found that the use of deep learning models is not the best choice for the recognition of candlestick features based on GAF images. Comparing these models, MLP and CNN are better than AdaBoost and RF, but worse than XGBoost. Our results show that for the candlestick pattern classification problem based on GAF images, it is unnecessary to use complex CNNs and traditional machine learning models can also achieve satisfactory results with much less computation resources.;;;https://dl.acm.org/doi/10.1145/3468891.3468896;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Classification and Prediction Based Data Mining algorithms to Predict Email Marketing Campaigns;;;['Redouan Abakouy', 'El Mokhtar En-Naimi', 'Anass El Haddadi'];;;November 2017;;;ICCWCS'17: Proceedings of the 2nd International Conference on Computing and Wireless Communication Systems;;;Nowadays, digital marketing has become an important tool to increase both activities and revenue of each enterprise. Therefore, many enterprises from different fields have integrated big data and data mining utilities, in order to well classify and target the marketing offers according to member's specific and individual needs taking advantage of member's navigational behavior. Personalized Email Marketing is the process of delivering right offer, at the right time to the right person based on the customer's profile. The main objective of Personalized Email Marketing is to identify the needs of a customer and offer products and services that appeal to that particular customer. In this perspective of research, a comparative study concerning several classification algorithms that can be handle this kind of problems, will be discussed in this paper.;;;https://dl.acm.org/doi/10.1145/3167486.3167520;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A Study on the Performance Evaluation of Machine Learning Models for Phoneme Classification;;;['Ali Shariq Imran', 'Abdolreza Sabzi Shahrebabaki', 'Negar Olfati', 'Torbjørn Svendsen'];;;February 2019;;;ICMLC '19: Proceedings of the 2019 11th International Conference on Machine Learning and Computing;;;This paper provides a comparative performance analysis of both shallow and deep machine learning classifiers for speech recognition task using frame-level phoneme classification. Phoneme recognition is still a fundamental and equally crucial initial step toward automatic speech recognition (ASR) systems. Often conventional classifiers perform exceptionally well on domain-specific ASR systems having a limited set of vocabulary and training data in contrast to deep learning approaches. It is thus imperative to evaluate performance of a system using deep artificial networks in terms of correctly recognizing atomic speech units, i.e., phonemes in this case with conventional state-of-the-art machine learning classifiers. Two deep learning models - DNN and LSTM with multiple configuration architectures by varying the number of layers and the number of neurons in each layer on the OLLO speech corpora along with six shallow machine learning classifiers for Filterbank acoustic features are thoroughly studied. Additionally, features with three and ten frames temporal context are computed and compared with no-context features for different models. The classifier's performance is evaluated in terms of precision, recall, and F1 score for 14 consonants and 10 vowels classes for 10 speakers with 4 different dialects. High classification accuracy of 93% and 95% F1 score is obtained with DNN and LSTM networks respectively on context-dependent features for 3-hidden layers containing 1024 nodes each. SVM surprisingly obtained even a higher classification score of 96.13% and a misclassification error of less than 5% for consonants and 4% for vowels.;;;https://dl.acm.org/doi/10.1145/3318299.3318385;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Bayesian text classification and summarization via a class-specified topic model;;;['Feifei Wang', 'Junni L. Zhang', 'Yichao Li', 'Ke Deng', 'Jun S. Liu'];;;None;;;The Journal of Machine Learning Research;;;We propose the class-specified topic model (CSTM) to deal with the tasks of text classification and class-specific text summarization. The model assumes that in addition to a set of latent topics that are shared across classes, there is a set of class-specific latent topics for each class. Each document is a probabilistic mixture of the class-specific topics associated with its class and the shared topics. Each class-specific or shared topic has its own probability distribution over a given dictionary. We develop a Bayesian inference of CSTM in the semisupervised scenario, with the supervised scenario as a special case. We analyze in detail the 20 Newsgroups dataset, a benchmark dataset for text classification, and demonstrate that CSTM has better performance than a two-stage approach based on latent Dirichlet allocation (LDA), several existing supervised extensions of LDA, and an L1 penalized logistic regression. The favorable performance of CSTM is also demonstrated through Monte Carlo simulations and an analysis of the Reuters dataset.;;;https://dl.acm.org/doi/10.5555/3546258.3546347;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Spatio-Temporal Routine Mining on Mobile Phone Data;;;['Tian Qin', 'Wufan Shangguan', 'Guojie Song', 'Jie Tang'];;;None;;;ACM Transactions on Knowledge Discovery from Data;;;Mining human behaviors has always been an important subarea of Data Mining. While it provides empirical evidences to psychological/behavioral studies, it also builds the foundation of various big-data systems, which rely heavily on the prediction of human behaviors. In recent years, the ubiquitous spreading of mobile phones and the massive amount of spatio-temporal data collected from them make it possible to keep track of the daily commute behaviors of mobile subscribers and further conduct routine mining on them. In this article, we propose to model mobile subscribers’ daily commute behaviors by three levels: location trajectory, one-day pattern, and routine pattern. We develop the model Spatio-Temporal Routine Mining Model (STRMM) to characterize the generative process between these three levels. From daily trajectories, the STRMM model unsupervisedly extracts spatio-temporal routine patterns that contain two aspects of information: (1) How people’s typical commute patterns are. (2) How much their commute behaviors vary from day to day. Compared to traditional methods, STRMM takes into account the different degrees of behavioral uncertainty in different timespans of a day, yielding more realistic and intuitive results. To learn model parameters, we adopt Stochastic Expectation Maximization algorithm. Experiments are conducted on two real world datasets, and the empirical results show that the STRMM model can effectively discover hidden routine patterns of human commute behaviors and yields higher accuracy results in trajectory prediction task.;;;https://dl.acm.org/doi/10.1145/3201577;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Few-Sample and Adversarial Representation Learning for Continual Stream Mining;;;['Zhuoyi Wang', 'Yigong Wang', 'Yu Lin', 'Evan Delord', 'Khan Latifur'];;;April 2020;;;WWW '20: Proceedings of The Web Conference 2020;;;Deep Neural Networks (DNNs) have primarily been demonstrated to be useful for closed-world classification problems where the number of categories is fixed. However, DNNs notoriously fail when tasked with label prediction in a non-stationary data stream scenario, which has the continuous emergence of the unknown or novel class (categories not in the training set). For example, new topics continually emerge in social media or e-commerce. To solve this challenge, a DNN should not only be able to detect the novel class effectively but also incrementally learn new concepts from limited samples over time. Literature that addresses both problems simultaneously is limited. In this paper, we focus on improving the generalization of the model on the novel classes, and making the model continually learn from only a few samples from the novel categories. Different from existing approaches that rely on abundant labeled instances to re-train/update the model, we propose a new approach based on Few Sample and Adversarial Representation Learning (FSAR). The key novelty is that we introduce the adversarial confusion term into both the representation learning and few-sample learning process, which reduces the over-confidence of the model on the seen classes, further enhance the generalization of the model to detect and learn new categories with only a few samples. We train the FSAR operated in two stages: first, FSAR learns an intra-class compacted and inter-class separated feature embedding to detect the novel classes; next, we collect a few labeled samples belong to the new categories, utilize episode-training to exploit the intrinsic features for few-sample learning. We evaluated FSAR on different datasets, using extensive experimental results from various simulated stream benchmarks to show that FSAR effectively outperforms current state-of-the-art approaches.;;;https://dl.acm.org/doi/10.1145/3366423.3380153;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Automating the Assessment of Problem-solving Practices Using Log Data and Data Mining Techniques;;;['Karen D. Wang', 'Shima Salehi', 'Max Arseneault', 'Krishnan Nair', 'Carl Wieman'];;;June 2021;;;L@S '21: Proceedings of the Eighth ACM Conference on Learning @ Scale;;;Interactive simulations provide an exciting opportunity to assess and teach students the practices used by scientists and engineers to solve real-world problems. This study examines how the logged interaction data from a simulation-based task could be used to automate the assessment of complex problem-solving practices. A total of 73 college students worked on an interactive circuit puzzle embedded in a science simulation in an interview setting. Their problem-solving processes were videotaped and logged in the backend of the simulation. We extracted different sets of features from the log data and evaluated their effectiveness as predictors of students' problem-solving success and evidence for specific problem-solving practices. Our results indicate that the application of data mining techniques guided by knowledge gained from qualitative observation was instrumental in the discovery of semantically meaningful features from the raw log data. These knowledge-grounded features were significant predictors of students' overall problem-solving success and provided evidence on how well they adopted specific problem-solving practices, including decomposition, data collection, and data recording. The results point to promising directions for how scaffolding/feedback could be provided in educational simulations to enhance student learning in problem-solving skills.;;;https://dl.acm.org/doi/10.1145/3430895.3460127;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Machine learning Android-based malware classification: faculty poster abstract;;;['Micheline Al Harrack'];;;None;;;Journal of Computing Sciences in Colleges;;;Analyzing Android malware to improve classification, clustering and therefore detection continues to increasingly evolve as our interconnected society continues to grow and Android mobile market expands. In this research, I explore two publicly available malware collection datasets and apply a combination of Machine Learning algorithms for classifying and clustering each of them. Some classifiers are applied concurrently, while others exclusively then clusters are being tested on the two different datasets separately. Both sets have the same 215 attributes classified and clustered. The experiment results are presented for inference for best classifiers and clusters by comparing results of the proposed methods on the two datasets sharing the same 215 attributes albeit different in size of malware sample and benign software.;;;https://dl.acm.org/doi/10.5555/3512489.3512512;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Data Mining Technique To Get Characteristics Customers of Bendesa Hotel With K-MEANS Algorithm;;;['I. G. Karang Komala Putra', 'Gede Indrawan', 'I. Made Candiasa'];;;January 2019;;;ICSIM '19: Proceedings of the 2nd International Conference on Software Engineering and Information Management;;;This research aims to find customers based on characteristics of hotel customers who stay since there is still no research provides its technological state of the art. Through collaboration between Computer Science and Tourism, this research contributes on the development of K-Means Algorithm using WEKA application that can be elaborated into: 1) Search for best number of clusters used; 2) Identification of hotel customer characteristics; 3) Measurement of accuracy customer characteristics. This research can be used by hotel management to recognize customer characteristics so that they can develop strategies to get as many customers as possible, especially in Bali Province where Bali tourism is considered as one of the largest foreign exchange earners. K-Means algorithm uses CRISP-DM as a data mining life cycle which consists of 6 phases, the entire sequential phase is adaptive. The next phase in sequence depends on the output from the previous phase. In this research, it was tested on 2 clusters of up to 6 clusters. Using the value of sum of squared errors (SSE) is generated 5 clusters are the best from the other. Data on 5 clusters is used as reference to find characteristics of potential customers who stay in hotels. Through experiments, K-Means algorithm has an accuracy of 72% (108 of 150) tests using sample data compared to characteristics produced by K-Means. In the future, this research could be improved by: 1) collaboration between the K-Means algorithm and other clustering algorithms; and 2) add customer characteristics.;;;https://dl.acm.org/doi/10.1145/3305160.3305184;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Tslearn, a machine learning toolkit for time series data;;;['Romain Tavenard', 'Johann Faouzi', 'Gilles Vandewiele', 'Felix Divo', 'Guillaume Androz', 'Chester Holtz', 'Marie Payne', 'Roman Yurchak', 'Marc Rußwurm', 'Kushal Kolar', 'Eli Woods'];;;None;;;The Journal of Machine Learning Research;;;tslearn is a general-purpose Python machine learning library for time series that offers tools for pre-processing and feature extraction as well as dedicated models for clustering, classification and regression. It follows scikit-learn's Application Programming Interface for transformers and estimators, allowing the use of standard pipelines and model selection tools on top of tslearn objects. It is distributed under the BSD-2-Clause license, and its source code is available at https://github.com/tslearn-team/tslearn.;;;https://dl.acm.org/doi/10.5555/3455716.3455834;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
MI3: Machine-initiated Intelligent Interaction for Interactive Classification and Data Reconstruction;;;['Yu Zhang', 'Bob Coecke', 'Min Chen'];;;None;;;ACM Transactions on Interactive Intelligent Systems;;;In many applications, while machine learning (ML) can be used to derive algorithmic models to aid decision processes, it is often difficult to learn a precise model when the number of similar data points is limited. One example of such applications is data reconstruction from historical visualizations, many of which encode precious data, but their numerical records are lost. On the one hand, there is not enough similar data for training an ML model. On the other hand, manual reconstruction of the data is both tedious and arduous. Hence, a desirable approach is to train an ML model dynamically using interactive classification, and hopefully, after some training, the model can complete the data reconstruction tasks with less human interference. For this approach to be effective, the number of annotated data objects used for training the ML model should be as small as possible, while the number of data objects to be reconstructed automatically should be as large as possible. In this article, we present a novel technique for the machine to initiate intelligent interactions to reduce the user’s interaction cost in interactive classification tasks. The technique of machine-initiated intelligent interaction (MI3) builds on a generic framework featuring active sampling and default labeling. To demonstrate the MI3 approach, we use the well-known cholera map visualization by John Snow as an example, as it features three instances of MI3 pipelines. The experiment has confirmed the merits of the MI3 approach.;;;https://dl.acm.org/doi/10.1145/3412848;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Using Text Mining to Discover Skills Demanded in Software Development Jobs in Thailand;;;['Chamikorn Hiranrat', 'Atichart Harncharnchai'];;;July 2018;;;ICEMT '18: Proceedings of the 2nd International Conference on Education and Multimedia Technology;;;Comprehension of knowledge and skills expected by industry helps universities design appropriate courses and improve employability for graduates. The objective of this study is to identify current technical knowledge and soft skills required by software industry in Thailand. Text mining techniques are applied to analyze the data collected from online job portal websites. The results are summarized and reported for the design of training courses to prepare students readiness for employment.;;;https://dl.acm.org/doi/10.1145/3206129.3239426;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Research of Test Questions Classification Based on Hybrid Frame Mixing Semantic Comprehension and Machine Learning;;;['Rihong Wang', 'Xingmei Cui', 'Chenglong Wang'];;;December 2017;;;ICRAI '17: Proceedings of the 3rd International Conference on Robotics and Artificial Intelligence;;;Text classification primarily from learning these two classifications based on semantic understanding and based on supervised machine to consider. Questions also consist of text, so the questions to achieve automatic classification are the classification text, classification questions help to improve the accuracy of automatic test paper to facilitate question bank management. This paper presented a hybrid model which mixing improved Semantic Comprehension and Machine Learning, and introduced as a word frequency correction index, the dispersion degree and positive and negative correlation coefficient to improve mutual information selection algorithm. Finally, it designed a construction testing training system questions classification module based on the framework, and applied to question classification test. The experiments show that the hybrid framework model improves the efficiency of automatic classification of questions with better classification accuracy.;;;https://dl.acm.org/doi/10.1145/3175603.3175608;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Taming Pretrained Transformers for Extreme Multi-label Text Classification;;;['Wei-Cheng Chang', 'Hsiang-Fu Yu', 'Kai Zhong', 'Yiming Yang', 'Inderjit S. Dhillon'];;;August 2020;;;KDD '20: Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining;;;We consider the extreme multi-label text classification (XMC) problem: given an input text, return the most relevant labels from a large label collection. For example, the input text could be a product description on Amazon.com and the labels could be product categories. XMC is an important yet challenging problem in the NLP community. Recently, deep pretrained transformer models have achieved state-of-the-art performance on many NLP tasks including sentence classification, albeit with small label sets. However, naively applying deep transformer models to the XMC problem leads to sub-optimal performance due to the large output space and the label sparsity issue. In this paper, we propose X-Transformer, the first scalable approach to fine-tuning deep transformer models for the XMC problem. The proposed method achieves new state-of-the-art results on four XMC benchmark datasets. In particular, on a Wiki dataset with around 0.5 million labels, the prec@1 of X-Transformer is 77.28%, a substantial improvement over state-of-the-art XMC approaches Parabel (linear) and AttentionXML (neural), which achieve 68.70% and 76.95% precision@1, respectively. We further apply X-Transformer to a product2query dataset from Amazon and gained 10.7% relative improvement on prec@1 over Parabel.;;;https://dl.acm.org/doi/10.1145/3394486.3403368;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Research of Test Questions Classification Based on Hybrid Frame Mixing Semantic Comprehension and Machine Learning;;;['Rihong Wang', 'Xingmei Cui', 'Chenglong Wang'];;;December 2017;;;ICRAI '17: Proceedings of the 3rd International Conference on Robotics and Artificial Intelligence;;;Text classification primarily from learning these two classifications based on semantic understanding and based on supervised machine to consider. Questions also consist of text, so the questions to achieve automatic classification are the classification text, classification questions help to improve the accuracy of automatic test paper to facilitate question bank management. This paper presented a hybrid model which mixing improved Semantic Comprehension and Machine Learning, and introduced as a word frequency correction index, the dispersion degree and positive and negative correlation coefficient to improve mutual information selection algorithm. Finally, it designed a construction testing training system questions classification module based on the framework, and applied to question classification test. The experiments show that the hybrid framework model improves the efficiency of automatic classification of questions with better classification accuracy.;;;https://dl.acm.org/doi/10.1145/3175603.3175608;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Big Data Framework for Scalable and Efficient Biomedical Literature Mining in the Cloud;;;['Zhengru Shen', 'Xi Wang', 'Marco Spruit'];;;June 2019;;;NLPIR '19: Proceedings of the 2019 3rd International Conference on Natural Language Processing and Information Retrieval;;;The massive size of available biomedical literature requires researchers to utilize novel big data technologies in data storage and analysis. Among them is cloud computing which has become the most popular solution for big data applications in industry. However, many bioinformaticians still rely on expensive and inefficient in-house infrastructure to discover knowledge from biomedical literature. Although some cloud-based solutions were constructed recently, they failed to sufficiently address a few key issues including scalability, flexibility, and reusability. Moreover, no study has taken computational cost into consideration. To fill the gap, we proposed a cloud-based big data framework that enables researchers to perform reproducible and scalable large-scale biomedical literature mining in an efficient and cost-effective way. Additionally, a cloud agnostic platform was constructed and then evaluated on two open access corpora with millions of full-text biomedical articles. The results indicate that our framework supports scalable and efficient large-scale biomedical literature mining.;;;https://dl.acm.org/doi/10.1145/3342827.3342843;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Load Data Mining Based on Deep Learning Method;;;['Ping Zhang', 'Hui Cheng', 'Bo Zou', 'Pan Dai', 'Chengjin Ye'];;;October 2019;;;CSAE '19: Proceedings of the 3rd International Conference on Computer Science and Application Engineering;;;In smart grids and electricity markets, the number of data generated by smart meters increase rapidly. To reduce the communication and storage overhead, data mining algorithms for load must be able to deal with massive and long data with an efficient data compression. On the other hand, load service entities want loads to be clustered in a finer manner for pricing mechanism, demand response or other applications. Thus, some local shapes or high-order features of load profiles should be concerned for a high-accuracy clustering. In this paper, a load data compression and classification method based on deep learning is proposed. It has the following two features: (1) Load data are compressed with Auto-Encoders nonlinearly. It achieves a higher compression ratio and a lower loss than conventional linear methods. (2) Load features are extracted in a layer- wise way and then classified using a probabilistic soft-max regression. Compared with some existing classifiers, the identification accuracy improves a lot. Case studies demonstrates the proposed deep learning method is a feasible tool to handle big data and dig hidden value of load on demand side.;;;https://dl.acm.org/doi/10.1145/3331453.3361279;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Abstract Mining;;;['Ellie Small', 'Javier Cabrera', 'John B. Kostis'];;;September 2020;;;BCB '20: Proceedings of the 11th ACM International Conference on Bioinformatics, Computational Biology and Health Informatics;;;IMPORTANCE: The marked explosion and fragmentation of bibliographic databases that include large parts pertaining to medical subspecialties has created the opportunity to identify new areas of research using the citations at the interface of subspecialty information. Bibliographic databases such as PubMed are useful to researchers when they wish to identify specific citations of their interest. However, they are not useful because of their size for the purpose of identifying new areas of research. OBJECTIVE: To present a method and two computer applications that identify areas for new research by finding abstracts at the interface between subspecialty parts of PubMed. DESIGN: Here we present a new method and computer applications that aim to ameliorate the problem by examining all abstracts that fulfill the general search terms from PubMed. Using text-mining algorithms of the abstracts to extract all non-trivial words, the researcher can repeatedly cluster the publications by commonality of the words in the abstracts to find unusual or unexpected combinations of words that may lead to new research. When single words are not descriptive enough to identify unique and unexpected ideas for potential new research, we allow the extraction of principal phrases from those abstracts instead. Here we define a principal phrase as a phrase that is common by itself, i.e. not common only as part of another common phrase, does not cross punctuation marks, and is informative (e.g. "and this disease" is not an informative phrase). FINDINGS: We present four examples of identifying new research areas by examining PubMed outcomes after searches for "takotsubo", "embolic stroke" excluding "atrial fibrillation", "impedance mismatch", and "aortic and stenosis". New areas of research were identified including comparisons of the clinical picture and pathophysiology of Takotsubo with scorpion envenomation, and the importance of impedance mismatch in pulmonary and renal circulation. CONCLUSION AND RELEVANCE: In conclusion, we have developed a method and two computer applications to mine words and/or principal phrases from the abstracts retrieved from PubMed or other databases to identify new ideas for research.;;;https://dl.acm.org/doi/10.1145/3388440.3412476;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Redescription Model Mining;;;['Felix I. Stamm', 'Martin Becker', 'Markus Strohmaier', 'Florian Lemmerich'];;;August 2021;;;KDD '21: Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining;;;This paper introduces Redescription Model Mining, a novel approach to identify interpretable patterns across two datasets that share only a subset of attributes and have no common instances. In particular, Redescription Model Mining aims to find pairs of describable data subsets -- one for each dataset -- that induce similar exceptional models with respect to a prespecified model class. To achieve this, we combine two previously separate research areas: Exceptional Model Mining and Redescription Mining. For this new problem setting, we develop interestingness measures to select promising patterns, propose efficient algorithms, and demonstrate their potential on synthetic and real-world data. Uncovered patterns can hint at common underlying phenomena that manifest themselves across datasets, enabling the discovery of possible associations between (combinations of) attributes that do not appear in the same dataset.;;;https://dl.acm.org/doi/10.1145/3447548.3467366;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Comparison on Feature Selection Methods for Text Classification;;;['Wenkai Liu', 'Jiongen Xiao', 'Ming Hong'];;;January 2020;;;ICMSS 2020: Proceedings of the 2020 4th International Conference on Management Engineering, Software Engineering and Service Sciences;;;The high-dimensional text data always contains a large quantity of noisy terms which bring negative effects on the performance of text classification. Feature selection is the common solution for dimension reduction in text classification. The choices of feature selection methods for text classification have significant impacts on classification accuracy. According to our literature review, few recent studies of feature selection focus on performance comparisons on feature selection methods. To fill this gap, this paper conducts discussions to compare performances of typical feature selection methods which are commonly involved in previous studies for text classification. Firstly, we introduce and discuss a series of typical feature selection methods in previous studies for text classification in details. Secondly, we conduct comparison experiments on four benchmark datasets to compare the effectiveness of twenty typical feature selection methods in text classification. Finally, we give conclusions on performance of the typical feature selection methods. The result of this paper gives a guideline for selecting appropriate feature selection methods for text classification academic analysis or real-world text classification applications.;;;https://dl.acm.org/doi/10.1145/3380625.3380677;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A Simulation-driven Methodology for IoT Data Mining Based on Edge Computing;;;['Claudio Savaglio', 'Giancarlo Fortino'];;;None;;;ACM Transactions on Internet Technology;;;With the ever-increasing diffusion of smart devices and Internet of Things (IoT) applications, a completely new set of challenges have been added to the Data Mining domain. Edge Mining and Cloud Mining refer to Data Mining tasks aimed at IoT scenarios and performed according to, respectively, Cloud or Edge computing principles. Given the orthogonality and interdependence among the Data Mining task goals (e.g., accuracy, support, precision), the requirements of IoT applications (mainly bandwidth, energy saving, responsiveness, privacy preserving, and security) and the features of Edge/Cloud deployments (de-centralization, reliability, and ease of management), we propose EdgeMiningSim, a simulation-driven methodology inspired by software engineering principles for enabling IoT Data Mining. Such a methodology drives the domain experts in disclosing actionable knowledge, namely descriptive or predictive models for taking effective actions in the constrained and dynamic IoT scenario. A Smart Monitoring application is instantiated as a case study, aiming to exemplify the EdgeMiningSim approach and to show its benefits in effectively facing all those multifaceted aspects that simultaneously impact on IoT Data Mining.;;;https://dl.acm.org/doi/10.1145/3402444;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Correlation Networks for Extreme Multi-label Text Classification;;;['Guangxu Xun', 'Kishlay Jha', 'Jianhui Sun', 'Aidong Zhang'];;;August 2020;;;KDD '20: Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining;;;This paper develops the Correlation Networks (CorNet) architecture for the extreme multi-label text classification (XMTC) task, where the objective is to tag an input text sequence with the most relevant subset of labels from an extremely large label set. XMTC can be found in many real-world applications, such as document tagging and product annotation. Recently, deep learning models have achieved outstanding performances in XMTC tasks. However, these deep XMTC models ignore the useful correlation information among different labels. CorNet addresses this limitation by adding an extra CorNet module at the prediction layer of a deep model, which is able to learn label correlations, enhance raw label predictions with correlation knowledge and output augmented label predictions. We show that CorNet can be easily integrated with deep XMTC models and generalize effectively across different datasets. We further demonstrate that CorNet can bring significant improvements over the existing deep XMTC models in terms of both performance and convergence rate. The models and datasets are available at: https://github.com/XunGuangxu/CorNet.;;;https://dl.acm.org/doi/10.1145/3394486.3403151;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Machine learning based Android malware classification;;;['Yena Lee', 'Yongmin Kim', 'Seungyeon Lee', 'Junyoung Heo', 'Jiman Hong'];;;September 2019;;;RACS '19: Proceedings of the Conference on Research in Adaptive and Convergent Systems;;;As growing Android smart-phones, malware threatens smart-phones is also increasing. There are many types of Android malwares. To detect these Android malwares effectively, first, we need to classify Android malwares. In this paper, we build a database storing Android malwares and their types and characteristics. With the database, we propose a machine learning model to classify the malwares. To evaluate the model, we conducted k-fold cross validation. Through the evaluation, our model showed over 85% accuracy in the malware classification.;;;https://dl.acm.org/doi/10.1145/3338840.3355693;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Analysis and Research of Food Safety Risk Assessment Based on Data Mining;;;['LiJuan Li', 'YuanYing Shen', 'Zhiqiong Yuan', 'Jie Li'];;;August 2018;;;BDET 2018: Proceedings of the 2018 International Conference on Big Data Engineering and Technology;;;With the improvement of living standards, people are increasingly demanding food, food safety problems emerge in an endless stream of emerge in an endless stream of food safety, attracted attention, there was an urgent need to establish a risk assessment system of food safety supervision, the scientific and reasonable decision of export food provides effective theoretical support. This paper proposes a mining food risk assessment and early warning method based on the data, establish scientific risk evaluation system, the risk assessment results, and the evaluation result is multilayer multidimensional association rule mining, early warning information of food inspection project, provide a powerful guarantee for food safety..;;;https://dl.acm.org/doi/10.1145/3297730.3297748;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Measuring and Mitigating Unintended Bias in Text Classification;;;['Lucas Dixon', 'John Li', 'Jeffrey Sorensen', 'Nithum Thain', 'Lucy Vasserman'];;;December 2018;;;AIES '18: Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society;;;We introduce and illustrate a new approach to measuring and mitigating unintended bias in machine learning models. Our definition of unintended bias is parameterized by a test set and a subset of input features. We illustrate how this can be used to evaluate text classifiers using a synthetic test set and a public corpus of comments annotated for toxicity from Wikipedia Talk pages. We also demonstrate how imbalances in training data can lead to unintended bias in the resulting models, and therefore potentially unfair applications. We use a set of common demographic identity terms as the subset of input features on which we measure bias. This technique permits analysis in the common scenario where demographic information on authors and readers is unavailable, so that bias mitigation must focus on the content of the text itself. The mitigation method we introduce is an unsupervised approach based on balancing the training dataset. We demonstrate that this approach reduces the unintended bias without compromising overall model quality.;;;https://dl.acm.org/doi/10.1145/3278721.3278729;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Text classification for predicting multi-level product categories;;;['Hadi Jahanshahi', 'Ozan Ozyegen', 'Mucahit Cevik', 'Beste Bulut', 'Deniz Yigit', 'Fahrettin F. Gonen', 'Ayşe Başar'];;;November 2021;;;CASCON '21: Proceedings of the 31st Annual International Conference on Computer Science and Software Engineering;;;In an online shopping platform, a detailed classification of the products facilitates user navigation. It also helps online retailers keep track of the price fluctuations in a certain industry or special discounts on a specific product category. Moreover, an automated classification system may help to pinpoint incorrect or subjective categories suggested by an operator. In this study, we focus on product title classification of the grocery products. We perform a comprehensive comparison of six different text classification models to establish a strong baseline for this task, which involves testing both traditional and recent machine learning methods. In our experiments, we investigate the generalizability of the trained models to the products of other online retailers, the dynamic masking of infeasible subcategories for pretrained language models, and the benefits of incorporating product titles in multiple languages. Our numerical results indicate that dynamic masking of subcategories is effective in improving prediction accuracy. In addition, we observe that using bilingual product titles is generally beneficial, and neural network-based models perform significantly better than SVM and XGBoost models. Lastly, we investigate the reasons for the misclassified products and propose future research directions to further enhance the prediction models.;;;https://dl.acm.org/doi/10.5555/3507788.3507794;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Automated Machine Learning with Genetic Programming on Real Dataset of Tax Avoidance Classification Problem;;;['Suraya Masrom', 'Rahayu Abdul Rahman', 'Norhayati Baharun', 'Abdullah Sani Abd Rahman'];;;February 2020;;;ICEIT 2020: Proceedings of the 2020 9th International Conference on Educational and Information Technology;;;Dealing with real application datasets often derive a stumbling block for machine learning algorithms to produce good results in solving either prediction or classification problems. Imbalance dataset is the major reason for this problem associated with missing values, small dimension of data size and very skewed data distribution. This paper demonstrates an empirical study that used Automated Machine Learning (AML) based on Genetic Programming (GP) named as AML TPOT. This is a very recent AML developed as an open source Python library and reported as a promising model by a few of researchers who have tested the algorithm. Nevertheless, most of the works on the AML TPOT were conducted on a set of common or benchmark datasets for machine learning testing. In this paper, the focus is on real and deviant dataset, which were collected according to the tax avoidance of the Government-Link Company in Malaysia. Comparison of the AML performances that tested on the dataset with different GP parameters setting is provided. Thus, this paper provides a fundamental knowledge on the experimental design and finding that will be useful for the AML based GP future improvement.;;;https://dl.acm.org/doi/10.1145/3383923.3383942;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Radar Plot Classification Based on Machine Learning;;;['Zhengcheng Liu', 'Yongmei Qi', 'Xiao Dai'];;;October 2021;;;EITCE '21: Proceedings of the 2021 5th International Conference on Electronic Information Technology and Computer Engineering;;;Clutter is the inherent environment of radar signal detection and processing. On the one hand, too many clutter points will start a false track, on the other hand, clutter plots will be incorrectly associated with the track, resulting in track errors. Therefore, how to further distinguish target plots and clutter plots after target detection is an important and difficult problem in radar data processing. Aiming at the clutter data mixed in the plot data output by signal processing, this paper extracts the multi-dimensional feature parameters of radar plot on the radar measured data set, classifies the radar real target and false target by using the traditional support vector machine, fully connected neural network and convolution neural network respectively, and compares the effects of three different classification methods.;;;https://dl.acm.org/doi/10.1145/3501409.3501507;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Data Reduction Workflow Patterns Mining and Optimization based on Ontology;;;['Wen-ning Hao', 'Jun-yue Chen', 'Suo-juan Zhang', 'Zi-xuan Zhang', 'Gang Chen', 'Rui-zhi Kang'];;;December 2018;;;ACAI '18: Proceedings of the 2018 International Conference on Algorithms, Computing and Artificial Intelligence;;;Focusing on massive high-dimensional data reduction, this paper established the ontology model of data reduction, to improve the related theoretical methods of data reduction, and to propose an ontology-based data reduction system architecture. Data reduction workflow model, workflow pattern mining, and workflow optimization and data reduction experiment design based on knowledge base are studied to achieve the accumulation, sharing and reuse of data reduction knowledge and enhance the intelligence level of data reduction process as well as the credibility of reduction results. A mechanism of meta-reduction system framework and its technology is put forward so as to improve the availability, flexibility and applicability of data reduction system.;;;https://dl.acm.org/doi/10.1145/3302425.3302462;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Social Relationship Mining Based on Student Data;;;['Wang Xinzheng', 'Guo Bing', 'Shen Yan', 'Huang FeiHu'];;;December 2020;;;EBIMCS '20: Proceedings of the 2020 3rd International Conference on E-Business, Information Management and Computer Science;;;In recent years, the campus social network mining has been widely concerned by scholars because it is closely related to the physical and mental health development of college students and the university management work. Compared with the typical social network mining tasks, the challenges of campus social network mining mainly lie in the difficulty of data acquisition and unlabeled data. Based on the phenomenon of homogeneity between friends, this paper proposed a social relationship mining method. Firstly, this paper carried out data dimension reduction operation for each student's daily consumption data, and then innovatively carried out the convolution operation for the consumption behavior data after dimension reduction, and finally obtained the characteristics of students' consumption behavior. The Multiple dimensional scaling algorithm is adopted for data dimension reduction, and the convolutional network is an improved Lenet-5 network. Then, the personalized ranking model is developed base on the phenomenon that the distance between friends is less than the distance between non-friends. To solve the problem of unlabeled data, we mined the friends' relationship from the student's library access control system swiping card records, and then taken the mined friends' relationship as the real friends' relationship to train the model. From the experimental results, the social network mining method proposed in this paper performs well.;;;https://dl.acm.org/doi/10.1145/3453187.3453397;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Multi-label Text Classification with Label Correction under Noise;;;['Tingting Yu', 'Tao Li', 'Xiaomeng Wang'];;;October 2021;;;ICCPR '21: Proceedings of the 2021 10th International Conference on Computing and Pattern Recognition;;;Multi-label text classification (MLTC) is a fundamental but difficult problem in text mining, the goal of MLTC is to assign a set of most relevant labels for the given document. While existing supervised training of deep learning models for MLTC usually requires a large number of noise-free labeled samples, which is quite expensive and time-consuming or even impractical in the real-world as label annotations are inevitable error-prone. To handle such a situation, we introduce learning multi-label text classification with noisy labels, and propose an end-to-end method called Multi-label Text Classification with Label Correction under Noise (LCN). LCN contains two modules: a label correction module and a classification module. In the label correction module, a group of prototypes for each class is learnt with the help of label semantic and feature information. These prototypes are then used to calculate the similarity between the extracted deep features to correct the labels of each training sample. In the classification module, the classifier combines the original noisy labels and corrected labels of each sample as supervised information to guide the training procedure. The two modules are combined in a unified framework and trained in an alternative manner. Extensive experimental results on two multi-label text benchmark datasets validate the effectiveness of LCN and show its advantages to the state-of-art methods.;;;https://dl.acm.org/doi/10.1145/3497623.3497650;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Text Mining Based Adaptive Case Management Automation in the Field of Forensic Medicine;;;['Borislav Banchev'];;;June 2017;;;CompSysTech '17: Proceedings of the 18th International Conference on Computer Systems and Technologies;;;In the paper is introduced an algorithm for automated processing of documents, managed in forensic medicine offices. The algorithm is based on series of steps that are executed in a sequence in which many aspects are controlled by the information extracted from the document itself. The resulted software solution is based on adaptive case management. Using text mining techniques and meta modelling, the incoming information is transformed into knowledge that is injected into the adaptive business processes. The proposed mechanism would reduce the total turnaround time, the needed manual work at each step and the confusion for the end user.;;;https://dl.acm.org/doi/10.1145/3134302.3134344;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Evaluation Method of Equipment Combat Effectiveness Based On Big Data Mining;;;['Zhou Liyao', 'Liu Xiaofang', 'Hu Chunyu'];;;January 2020;;;ICCDE '20: Proceedings of 2020 6th International Conference on Computing and Data Engineering;;;In the evaluation of equipment combat effectiveness, it is necessary to comprehensively analyze the data of outfield test and infield test, including a variety of audio-visual, image and other combat test data. These data can be classified, extracted, stored and managed by building data model through big data mining technology. The evaluation method of equipment combat effectiveness based on big data mining is based on massive data, through machine learning, statistical analysis, neural network, database and other methods to analyze and process the data, mining the correlation between test data, evaluation index and evaluation conclusion, and extracting useful information and finding new knowledge from it to realize the evaluation of the combat effectiveness of the tested system.;;;https://dl.acm.org/doi/10.1145/3379247.3379282;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Analysis of Student Academic Performance and Social Media Activities by Using Data Mining Approach;;;['Enda Esyudha Pratama', 'Eva Faja Ripanti'];;;February 2020;;;ICEBA 2020: Proceedings of the 2020 The 6th International Conference on E-Business and Applications;;;This study aims to analysis the relationship of student academic performance to the activity of using social media. The method used in this research is a data mining approach to analysis its connectedness. Data mining techniques used are association and classification. As for the needs of the data used comes from student academic data sourced fromAcademic Information Systemand social media activity data comes from Instagram using Application Programming Interface (API) for get data automatically. Data requirements for academic achievement, i.e. grade-point averagre (GPA), duration of study, and faculty. As for identifying the data of social media activity, i.e.number of post (feed), number of following & follower, date & time post, and caption.The results of the analysis in this study indicate a relationship between academic achievement and the activity of using social media.;;;https://dl.acm.org/doi/10.1145/3387263.3387279;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Binary Classification Model Based on Machine Learning Algorithm for the Short-Circuit Detection in Power System;;;['Qiwei Lu', 'Jinpei Cheng', 'Dianlin Guo', 'Mengmeng Su', 'Xuewei Wu', 'Tao Ru'];;;December 2019;;;ACAI '19: Proceedings of the 2019 2nd International Conference on Algorithms, Computing and Artificial Intelligence;;;Short circuit faults usually occur in the damaged insulation lines or line connections, which will cause serious accidents such as fires and explosions. As the power supply distance increases, accuracy of short-circuit fault detection is insufficient and the process is tedious with the traditional analysis method. In order to solve the problems above, the short-circuit fault detection is classified into the two classification problems while the machine learning method is used. The data of the normal state and short circuit fault state are obtained by the short-circuit simulation experiment. Extract four features from time domain, including the average current and so on. By training support vector machine (SVM) using the different combinations of extraction features above, the model is obtained. The accuracy of classification of the test data set by the model is high. The results show that the short-circuit fault detection method based on machine learning is more accurate and robust than traditional analysis methods.;;;https://dl.acm.org/doi/10.1145/3377713.3377753;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
The Definition, Current Situation and Development Trend of Latent Aspect Rating Analysis in Text Mining;;;['Shaohua Sun', 'Kuisheng Wang', 'Tiantian Zhang'];;;June 2018;;;ICCPR '18: Proceedings of the 2018 International Conference on Computing and Pattern Recognition;;;The field of latent aspect rating analysis has been developed in the last few years. Firstly, we introduce the background and definition of latent aspect rating analysis in text mining. Secondly, we have collected literature on the latent aspect rating analysis of the research in recent years and summarized the development status of this field. Finally, the future development trend and expectation of this field are put forward according to relevant literature. Furthermore, the main contribution of this paper is to describe the field and analyze its development trend according to the author's research work.;;;https://dl.acm.org/doi/10.1145/3232829.3232833;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Highly Efficient Mining of Overlapping Clusters in Signed Weighted Networks;;;['Tuan-Anh Hoang', 'Ee-Peng Lim'];;;November 2017;;;CIKM '17: Proceedings of the 2017 ACM on Conference on Information and Knowledge Management;;;In many practical contexts, networks are weighted as their links are assigned numerical weights representing relationship strengths or intensities of inter-node interaction. Moreover, the links' weight can be positive or negative, depending on the relationship or interaction between the connected nodes. The existing methods for network clustering however are not ideal for handling very large signed weighted networks. In this paper, we present a novel method called LPOCSIN (short for "Linear Programming based Overlapping Clustering on Signed Weighted Networks") for efficient mining of overlapping clusters in signed weighted networks. Different from existing methods that rely on computationally expensive cluster cohesiveness measures, LPOCSIN utilizes a simple yet effective one. Using this measure, we transform the cluster assignment problem into a series of alternating linear programs, and further propose a highly efficient procedure for solving those alternating problems. We evaluate LPOCSIN and other state-of-the-art methods by extensive experiments covering a wide range of synthetic and real networks. The experiments show that LPOCSIN significantly outperforms the other methods in recovering ground-truth clusters while being an order of magnitude faster than the most efficient state-of-the-art method.;;;https://dl.acm.org/doi/10.1145/3132847.3133004;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Machine Learning Predictive Model for the Passive Transparency at the Brazilian Ministry of Mines and Energy;;;['Ingrid Palma', 'Marcelo Ladeira', 'Ana Carla Bittencourt Reis'];;;June 2021;;;DG.O'21: DG.O2021: The 22nd Annual International Conference on Digital Government Research;;;This paper presents a case study based on the CRISP-DM Model and the use of Text Mining tools and techniques to automate the Passive Transparency process at the Brazilian Ministry of Mines and Energy. Thus, a Machine Learning Model is proposed to predict the class of the technical unit responsible for the data/information requested by citizens. Through the application of the algorithm LDA and TF-IDF it was possible to map the topics of the most relevant subjects for society. The stability of the model was tested from the comparative analysis between 5 known classification algorithms (Random Forest, Multinomial NB, Linear SVC, Logistic Regression, XGBoost and Gradient Boosting). XGBoost presented better performance and precision in multiclass learning outcomes.;;;https://dl.acm.org/doi/10.1145/3463677.3463715;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
MotifClass: Weakly Supervised Text Classification with Higher-order Metadata Information;;;['Yu Zhang', 'Shweta Garg', 'Yu Meng', 'Xiusi Chen', 'Jiawei Han'];;;February 2022;;;WSDM '22: Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining;;;We study the problem of weakly supervised text classification, which aims to classify text documents into a set of pre-defined categories with category surface names only and without any annotated training document provided. Most existing classifiers leverage textual information in each document. However, in many domains, documents are accompanied by various types of metadata (e.g., authors, venue, and year of a research paper). These metadata and their combinations may serve as strong category indicators in addition to textual contents. In this paper, we explore the potential of using metadata to help weakly supervised text classification. To be specific, we model the relationships between documents and metadata via a heterogeneous information network. To effectively capture higher-order structures in the network, we use motifs to describe metadata combinations. We propose a novel framework, named MotifClass , which (1) selects category-indicative motif instances, (2) retrieves and generates pseudo-labeled training samples based on category names and indicative motif instances, and (3) trains a text classifier using the pseudo training data. Extensive experiments on real-world datasets demonstrate the superior performance of MotifClass to existing weakly supervised text classification approaches. Further analysis shows the benefit of considering higher-order metadata information in our framework.;;;https://dl.acm.org/doi/10.1145/3488560.3498384;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Knowledge Distillation In Medical Data Mining: A Survey;;;['Hefeng Meng', 'Zhiqiang Lin', 'Fan Yang', 'Yonghui Xu', 'Lizhen Cui'];;;October 2021;;;ICCSE '21: 5th International Conference on Crowd Science and Engineering;;;In recent years, there have always been many problems in the medical field, such as a shortage of professionals and a shortage of medical resources. With the application of machine learning in the medical field, these problems have been alleviated to a certain extent, but these machine learning methods also have shortcomings, such as models are often too large to be deployed on lightweight equipment, and medical data sets are difficult to share, Many researchers have put forward many methods, and knowledge distillation is one of them. As a model compression and acceleration technology, knowledge distillation has been widely used in the medical field. The research of many researchers also shows that the use of knowledge distillation can effectively compress huge and complex models and improve the performance of models. Many studies show that the use of knowledge distillation can effectively solve many problems existing in models in the medical field, Aiming at the various applications of knowledge distillation in the medical field, this paper makes a comprehensive review from the perspectives of knowledge distillation, the problems that knowledge distillation can solve in the medical field and the practical application of knowledge distillation.;;;https://dl.acm.org/doi/10.1145/3503181.3503211;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Word embedding and cognitive linguistic models in text classification tasks;;;['Anna Surkova', 'Sergey Skorynin', 'Igor Chernobaev'];;;October 2019;;;CSIS'2019: Proceedings of the XI International Scientific Conference Communicative Strategies of the Information Society;;;The paper considers two linguistic models, analyzed the possibility of their use for the text data classification as well as their associations in the integrated texts presentation. A cognitive approach for the text classification issues is presented. An algorithm to identify the words basic level using WordNet is considered. A model for text classification based on the pre-trained word embeddings is presented. The model consists of three layers: embedding layer Long-Short Term Memory (LSTM) layer, and softmax layer. The model was trained and evaluated on the 20 Newsgroups dataset. The classification quality was assessed by F- measure, precision and recall. The obtained results analysis is carried out. Both described models show good results, low scores for some texts are explained. The advantages and limitations of the linguistic models are shown. In future works the authors are going to combine proposed models and modify them. Thus, for model based on word embedding there are pretty vast opportunities for extension: from experimenting with different word embeddings and various distance metrics to more complicated architecture of layers and even promising state of the art artificial neural network models, activation functions and their modifications. In addition, there is research area of proper ensemble strategy selection.;;;https://dl.acm.org/doi/10.1145/3373722.3373778;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Combining traditional machine learning and anomaly detection for several imbalanced Android malware dataset's classification;;;['Yiwei Gan', 'Qian Han', 'Yumeng Gao'];;;March 2022;;;ICMLT '22: Proceedings of the 2022 7th International Conference on Machine Learning Technologies;;;As the number of mobile devices has exploded in recent years, so has the amount of advanced Android malware. Among the popular Android malware on the market today, click fraud malware, adware, banking Trojans, spyware, etc. are usually disguised and hidden in the heap of good Android applications. These advanced malwares lurk in the third-party application market trusted by users, and potentially endanger the security of the user's smart device causing privacy or economic loss. Therefore, this paper leverages and combines traditional machine learning and anomaly detection methods to detect specific classes of Android malware in three highly imbalanced Android datasets (entertainment + social app vs. click fraud malware + adware; financial services app vs. banking trojan; communication app vs. spyware). The experiment results show that our proposed combined methods have great performance on the three sub-datasets, achieving the average f1-score over 0.98 on three imbalanced datasets, which performs better than the traditional machine learning algorithm used alone. In addition, we use the combined methods to analyze the correlation between the top features of the dataset, and provide interpretable insights for other researchers focusing on Android malware classification in the coming future.;;;https://dl.acm.org/doi/10.1145/3529399.3529412;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
An efficient approach for dimensionality reduction and classification of high dimensional text documents;;;['Kotte Vinay Kumar', 'R. Srinivasan', 'E. B. Singh'];;;October 2018;;;DATA '18: Proceedings of the First International Conference on Data Science, E-learning and Information Systems;;;Feature representation and dimensionality reduction techniques are two important tasks in text clustering and classification. In this paper, an approach for feature representation and dimensionality reduction of text documents is described. The feature representation and dimensionality reduction approaches that are introduced retain the original distribution of features. Output of feature representation is a hard representation matrix. The hard matrix is used to obtain the low dimensionality document matrix. The input for clustering is the low dimensional matrix. The working of proposed approach is explained using a case study that supports the importance of the approach and advantage of dimensionality reduction. Results prove that the proposed approach has better dimensionality reduction achieved and is also better suited for classification.;;;https://dl.acm.org/doi/10.1145/3279996.3281364;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Research on Flow Classification Model Based on Similarity and Machine Learning Algorithm;;;['Meigen Huang', 'Lingling Wu', 'Xue Yuan'];;;February 2021;;;ICMLC '21: Proceedings of the 2021 13th International Conference on Machine Learning and Computing;;;In recent years, with the rapid development of the Internet, complex and diverse applications and network traffic have been generated. At the same time, network encryption technologies and various new network traffic have emerged, which affects the efficiency of the original traffic classification technology. In order to improve the efficiency of traffic classification and reduce the classification time, this paper proposes a network traffic classification model (Cosine similarity and decision tree classification model, CSDT) based on cosine similarity and decision tree algorithm to identify and classify traffic. First, the cosine similarity algorithm is used to judge the similarity of adjacent network traffic, and the network traffic with higher similarity is labeled with a known classification and forwarded. For network traffic with low similarity, the decision tree algorithm is used to classify the related feature values. This model utilizes the characteristics of high similarity in adjacent data streams, and uses similarity algorithms to preprocess network traffic to reduce classification time. The Moore data set publicly available in the field of network traffic classification is used for training and testing, and the results are compared with various machine learning algorithms on the Weka platform. The experimental results show that the model has a good classification accuracy, which greatly reduces the classification time and improves the classification efficiency of network traffic is improved.;;;https://dl.acm.org/doi/10.1145/3457682.3457687;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
An automated new approach in fast text classification (fastText): A case study for Turkish text classification without pre-processing;;;['Birol Kuyumcu', 'Cuneyt Aksakalli', 'Selman Delil'];;;June 2019;;;NLPIR '19: Proceedings of the 2019 3rd International Conference on Natural Language Processing and Information Retrieval;;;Any Text Classification (TC) problem need pre-processing steps which may affect the classification accuracy. Especially pre-processing steps need substantial effort particularly in agglutinative languages such as Turkish. In this context, a traditional text categorization problem requires pre-processing steps such as tokenization, stop-word removal, lower-case conversion, stemming and feature dimension reduction. Before classification, one or more of these steps are applied to text and then a classifier is trained to evaluate the corresponding precision. Deep neural network classifiers combined with word embedding is one of the solutions to eliminate the pre-processing prerequisites. Another novel approach is fastText word embedding based classifier which was developed by Facebook. In this study, we evaluate a fastText classifier on TTC-3600 Turkish dataset without using any pre-processing steps and present the performance of the algorithm.;;;https://dl.acm.org/doi/10.1145/3342827.3342828;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Research on Media Attention to Quality of Imported Consumer Goods Based on Text Mining – Taking Garments as an Example;;;['Yuan Chen', 'Jiajie Wei'];;;September 2021;;;ICBDT '21: Proceedings of the 4th International Conference on Big Data Technologies;;;With the improvement of residents' consumption level, consumers' demand for all kinds of imported consumer goods has gradually increased, but its quality problem can not be ignored. The quality governance of consumer goods is particularly important, which is a part of social co-governance. It emphasizes the joint participation and responsibility to quality of multiple-subject, such as media, government, enterprises, social groups and the public. In the Internet age, social media is playing an increasingly important role in the reporting of various major event relative to commodity quality. Therefore, the research on the quality attention of imported consumer goods based on text mining to online news can be regarded as a valuable exploration. In this paper, using 3 identified standards —— news authority, news crawling volume and website traffic, we select 2 news platforms, i.e., China Quality News Network as well as Global Textile Network which have the most synthesis advantages to be qualified publishing quality news of imported consumer goods. Then, text mining on online news related to imported garments quality has been conducted by Python through the following efforts: (1) Garments’ quality dictionaries including quality attribution and quality scoring, has been developed by ourselves. (2) This paper verifies the rationality of the dictionary by using a Radial Basis Function (RBF) in Support Vector Machine (SVM) algorithm. The average accuracy on the training data set of the quality attribution dictionary is as high as 93.49%, showing that the selective attribution indexes in the quality attribution dictionary is rational. (3) From the above-mentioned news platforms, all the news relative to garments’ quality until September 10, 2020, has been crawled. There are 10780 crawled news totally, in which 8534 are effective news selected by removing duplicate and other data preprocessing methods. (4) On the basis of Maslow's Hierarchy of Needs, the 33 quality attributions in the dictionary have been divided into 4 categories: Physiological need attribution, Safety attribution, Functional attribution, Cognitive & aesthetic attribution. Text analysis has been made to the media attention about quality of imported consumer goods from the 4 categories , and time series analysis has also been made. (5) The media quality score of quality attribution has been calculated and analysed.)6) A correlation analysis of the media attention and score of each attribute category has been conducted. The results come to the following conclusions: (1) Different platforms basically share the same concern on the attribution quality of imported garments. The top five quality attributions with high media attention are harmful substances, typical mechanical & physical properties, logo, aesthetic, and comfort. The above 5 quality attributions mainly belong to the safety attribution and cognitive & aesthetic attribution. (2) The higher quality score, the higher media attention, and the worse the quality of imported garments. The media attention on the quality of imported garments experienced four stages: the sustained level stage (2001-2003), the slow growth stage(2003-2012), the rapid growth stage (2012-2014)and sustained pullback stage(2014-2019). (3) Media attention has high correlation to the quality of quality score of imported garments. (4) From 2014 to the present, the attributions quality of imported garments from low to high are Safety attribution, Cognitive & aesthetic attribution, Functional attribution, Physiological need attribution, which lead to the media attention to the attributions from high to low are Safety attribution, Cognitive & aesthetic attribution, Functional attribution, Physiological need attribution. (5) During the period of the rapid growth stage (2012-2014), the totality quality of imported garments declined significantly, give rise to the media attention also increased significantly. (6) After 2014, the totality quality of imported garments showed a trend of gradual improvement, and then the media attention of imported clothing quality was also declining. (7) The quality of safety attribution changes the most, but it improves the fastest. According to the analysis of this paper, media attention has a very close relationship with the quality score of imported garments. The more serious the quality problems, the more media attention would be drawn to them. The high media attention quality attributes need more attention of government to strengthen quality supervision. Finally, this paper puts forward some suggestions on the quality governance of imported consumer goods.;;;https://dl.acm.org/doi/10.1145/3490322.3490327;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Research on User Comments of Douban Animation Made in China Based on Text Mining Technology;;;['Siyu Sun', 'Yingjie Gai', 'Yingying Zhou', 'Aiting Xu'];;;December 2019;;;ICIT '19: Proceedings of the 2019 7th International Conference on Information Technology: IoT and Smart City;;;With the advent of the "Internet plus" era, the online film criticism has springing up rapidly. The success of "NeZha" has brought the domestic animation film to an unprecedented high tide and brought a lot of information about the film reviews. Based on Chinese natural language processing technology, this paper takes the Douban movie review of domestic animation series as the research object, uses Python to crawl the movie review data, on the basis of the preprocessing of data cleaning, data normalization, Chinese word segmentation and removal of stop words, etc., carries out machine learning based emotional tendency analysis, and the visual analysis of word cloud and the analysis of sentiment orientation based on machine learning, At last, uses LDA theme model to mine movie reviews in depth. The research shows that: the audience pays more attention to the plot setting, character shaping, picture presentation, production ability, line performance and other aspects of domestic animation series films; Douban users tend to be positive attitude of domestic animation, but there is still a large proportion of negative emotion;the praise and popularity of domestic animated films continue to rise, but the uneven quality of domestic animation films still needs to be improved.;;;https://dl.acm.org/doi/10.1145/3377170.3377232;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Data Mining of Agricultural Software and Suggestions;;;['Zheng-Ming Gao', 'Juan Zhao', 'Yu-Rong Hu'];;;September 2020;;;MLMI '20: Proceedings of the 2020 3rd International Conference on Machine Learning and Machine Intelligence;;;Electric business, also called E-business, or digital business, might be a solution to the so-called Chinese “three agricultural problems”. In order to find the absence of specific agricultural software, we carry out the data scratching of agricultural software regarding agriculture in Mandarin from four most popular web sites and hand phone Android Apps detailers. Data cloud and frequency analysis were carried out and suggestions were proposed for a purpose to lead the farmers to our modern, intelligent and information society.;;;https://dl.acm.org/doi/10.1145/3426826.3426841;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Comparison of Text Mining Feature Extraction Methods Using Moderated vs Non-Moderated Blogs: An Autism Perspective;;;['Abu Saleh Md Tayeen', 'Saleem Masadeh', 'Abderrahmen Mtibaa', 'Satyajayant Misra', 'Moumita Choudhury'];;;November 2019;;;DPH2019: Proceedings of the 9th International Conference on Digital Public Health;;;Online social media is being widely used by social scientists to study human behavior. Researchers have explored different feature extraction (FE) and classification techniques to perform sentiment analysis, topic identification, etc. Most studies tend to evaluate FE and classification methods using only one particular class of datasets---well-defined with little/no noise or with well-defined noise. For instance, when the datasets under study have different noise characteristics, various FE and/or classification methods may fail to identify a given topic. In this paper, we fill this gap by quantitatively comparing multiple FE methods and classifiers using three different datasets (two moderator-controlled blogs and one single-authored personal blogs) related to Autism Spectrum Disorder (ASD). Our result shows that no particular combination of FE and classifier is the best overall, but choosing the right ones can improve accuracy by over 30%.;;;https://dl.acm.org/doi/10.1145/3357729.3357740;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Analysis of Techniques for Data Mining;;;['Keyi Zhu'];;;April 2021;;;ESCC '21: The 2nd European Symposium on Computer and Communications;;;Data mining has been a popular branch of computer science in recent years with great impact in different areas. It is a technique to find the inner connection, the unexpected pattern from a large amount of data and to obtain certain broad conclusions from it. Currently, many data mining techniques are developed and used in order to process data from various aspects and to improve the speed and accuracy of data analysis. Considering that data mining techniques combine knowledge from multiple domains, this article will present an overview of temporal techniques for data mining.;;;https://dl.acm.org/doi/10.1145/3478301.3478308;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A Data Mining Framework for the Analysis of Patient Arrivals into Healthcare Centers;;;['Salam Abdallah', 'Mohsin Malik', 'Gurdal Ertek'];;;December 2017;;;ICIT '17: Proceedings of the 2017 International Conference on Information Technology;;;We present a data mining framework that can be applied for analyzing patient arrivals into healthcare centers. The sequentially applied methods are association mining, text cloud analysis, Pareto analysis, cross-tabular analysis, and regression analysis. We applied our framework using real-world data from a one of the largest public hospitals in the U.A.E., demonstrating its applicability and possible benefits. The dataset used was eventually 110,608 rows in total for the regression models, covering the most utilized 14 hospital units. The dataset is at least 10-fold larger than datasets used in closely-related research. The developed data mining framework can provide the input for a subsequent optimization model, which can be used to optimally assign appointments for patients, based on their arrival patterns.;;;https://dl.acm.org/doi/10.1145/3176653.3176740;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Accelerating Innovation Through Analogy Mining;;;['Tom Hope', 'Joel Chan', 'Aniket Kittur', 'Dafna Shahaf'];;;August 2017;;;KDD '17: Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining;;;The availability of large idea repositories (e.g., the U.S. patent database) could significantly accelerate innovation and discovery by providing people with inspiration from solutions to analogous problems. However, finding useful analogies in these large, messy, real-world repositories remains a persistent challenge for either human or automated methods. Previous approaches include costly hand-created databases that have high relational structure (e.g., predicate calculus representations) but are very sparse. Simpler machine-learning/information-retrieval similarity metrics can scale to large, natural-language datasets, but struggle to account for structural similarity, which is central to analogy. In this paper we explore the viability and value of learning simpler structural representations, specifically, "problem schemas", which specify the purpose of a product and the mechanisms by which it achieves that purpose. Our approach combines crowdsourcing and recurrent neural networks to extract purpose and mechanism vector representations from product descriptions. We demonstrate that these learned vectors allow us to find analogies with higher precision and recall than traditional information-retrieval methods. In an ideation experiment, analogies retrieved by our models significantly increased people's likelihood of generating creative ideas compared to analogies retrieved by traditional methods. Our results suggest a promising approach to enabling computational analogy at scale is to learn and leverage weaker structural representations.;;;https://dl.acm.org/doi/10.1145/3097983.3098038;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Investigating the impact of satisfaction and relational capital on repurchase behavior using a text mining method;;;['Zhepeng Lv', 'Yue Jin', 'Jinghua Huang'];;;June 2021;;;ICCIR '21: Proceedings of the 2021 1st International Conference on Control and Intelligent Robotics;;;Nowadays, sellers concern about how to retain consumers in online context. The present study moves beyond satisfaction and extends the literature by investigating the moderating effect of relational capital. The online shopping platform studied contains reviews and communication texts that are full of descriptive expressions. Those texts are valuable resources to achieve measurements of satisfaction and relational capital in an objective way. Therefore, a text mining method, specifically, the lexicon-based method is employed to extract those constructs. By analyzing 10, 609 transactions and mining related communication conversations and reviews, this study concluded that the extracted satisfaction measurement has a positive effect on repurchase intention with odds ratio of 2.51, and relational capital exerts a moderating effect, with each dimension of relational capital performing distinguished roles.;;;https://dl.acm.org/doi/10.1145/3473714.3473817;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Biogeography-based rule mining for classification;;;['Effat Farhana', 'Steffen Heber'];;;July 2017;;;GECCO '17: Proceedings of the Genetic and Evolutionary Computation Conference;;;Rule-based classification is a popular approach for solving real world classification problems. Once suitable rules have been obtained, rule-based classifiers are easy to deploy and explain. In this paper, we describe an approach that uses biogeography-based optimization (BBO) to compute rule sets that maximize predictive accuracy. BBO is an evolutionary algorithm inspired by the migration patterns of species between the islands of an archipelago. In our implementation, each species corresponds to a classification rule, each island is occupied by multiple species and corresponds to a classifier, and the fitness of an island is computed as the predictive classification accuracy of the corresponding classifier. The archipelago evolves via mutation, selection, and migration of species between islands. Successful islands have a decreased immigration rate and an increased emigration rate. In general, such islands tend to resist invasion and to colonize less successful islands. This results in an evolving set of habitats that corresponds to a population of classifiers. We demonstrate the effectiveness of our approach by comparing it to several traditional and evolutionary based state-of-the-art classifiers.;;;https://dl.acm.org/doi/10.1145/3071178.3071221;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Predict the type of hearing aid of audiology patients using data mining techniques;;;['Sefer Kurnaz', 'Maalim A. H. Aljabery'];;;June 2018;;;ICEMIS '18: Proceedings of the Fourth International Conference on Engineering &amp; MIS 2018;;;Our research transacts with a great various audiology data from National Health System (NHS) facility, including audiograms, structured data such as age, gender, and diagnosis, and a text of specific information about each patient, i.e., clinical reports. This research examines factors related to audiology patients depends on various data by using the mining and analysis of this data. This paper looks for factors affecting the choice between two prevalent hearing aid kinds: BTE (Behind The Ear) or ITE (In The Ear). This choice often done by audiology technicians working in specific clinics for this purpose, based on audiograms results and patient consultation. In many situations, there is an obvious choice, but sometimes the technicians need for the second opinion via an automatic system includes clarification of how to obtain that second opinion. The research deals with diversified specifics and more significant factors for choosing of confirmed hearing aid related to those specifics. We depend on the earlier study data (Bareiss, E. Ray, & Porter, Bruce (1987)). Protos: An Exemplar-Based Learning Apprentice. In the Proceedings of the 4th International Workshop on Machine Learning, 12-23, Irvine, California, which illustrates the database analysis for 180,000 records, for 23,000 patients, by the hearing aid clinic at James Cook University Hospital in Middlesbrough, UK. This data mined to find which factors contribute to the deduction to fit a BTE hearing aid as opposed to an ITE hearing aid. Here we conduct some enhancements on this database and analyze the data depends on medical information to create a new class then we use some intelligent Data Mining (DM) techniques to guess the most correct illness that could be associated with patient's information. Based on the result (according to the patients' diagnosis details), we can obtain right predictions of which type of Hearing Aid (HA) they should use.;;;https://dl.acm.org/doi/10.1145/3234698.3234755;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
The Research of Web Text Classification Based on Wechat Article;;;['Huan Liu', 'Jun Li', 'Yaqin Fan', 'Zekun Song'];;;August 2017;;;ICIE '17: Proceedings of the 6th International Conference on Information Engineering;;;With the rapid development of the network, many document data emerges on the Internet. So automatic text categorization technology becomes extremely important. In this paper, the weighting method based on the weight of HTML semantics and feature items is used to weight the feature items.On the basis of this, LDA model is combined with SVM1, and the performance of LDA good text feature extraction and the strong classification of SVM are used to classify.The experimental results show that the combination of the two can make the text classification performance more superior and shorten the training time greatly.;;;https://dl.acm.org/doi/10.1145/3078564.3078568;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A Survey on Knowledge Enhanced EHR Data Mining;;;['Jiancheng Zhang', 'Xiao Yang', 'Hefeng Meng', 'Zhiqiang Lin', 'Yonghui Xu', 'Lizhen Cui'];;;October 2021;;;ICCSE '21: 5th International Conference on Crowd Science and Engineering;;;EHR contains detailed information about a large number of patients. In the past ten years, EHR-related research has involved various fields, and research in various fields is inseparable from the acquisition of knowledge in EHR. The rapid development of various fields in recent years has brought new challenges to the acquisition of knowledge in EHR. At the same time, the knowledge enhancement technology that has emerged in recent years has effectively improved this problem. Therefore, more and more researches personnel applied knowledge enhancement technology to EHR. In this article, we summarized the literature in this area. We first summarized the knowledge types of EHR, and then made a sub-statement on knowledge extraction and modeling. Next, the correct representation method of knowledge is given, and finally, the specific application in each field is summarized. We hope this article can continue to promote the development of knowledge enhancement technology in EHR.;;;https://dl.acm.org/doi/10.1145/3503181.3503202;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Predicting the existence of exploitation concepts linked to software vulnerabilities using text mining;;;['Konstantinos Charmanas', 'Nikolaos Mittas', 'Lefteris Angelis'];;;November 2021;;;PCI '21: Proceedings of the 25th Pan-Hellenic Conference on Informatics;;;Software vulnerabilities are weaknesses of specific products and versions that may lead in benefiting attackers to exploit such malfunctions, having a further goal to gain access to operating systems, devices and users’ data. As not all vulnerabilities constitute potential threats to such information, this research attempts to explore ways to the identify the ones that are possible to be exploited using only textual descriptions. The practical goal of the experiments is to examine future raw descriptions in order to predict whether the linked product is likely to be exploited or not. The ground truth examined is the existence or absence of references that report exploitation concepts of the related weaknesses. To meet our objectives, in this study, we make use of Natural Language Processing (NLP) techniques, feature evaluation filtering mechanisms and an oversampling method in order to adapt the raw texts into inputs to classification models and detect the most important terms. The results are promising as many constructed models provided an overall accepted accuracy based on the information of the collected dataset.;;;https://dl.acm.org/doi/10.1145/3503823.3503888;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Mining Career Paths from Large Resume Databases: Evidence from IT Professionals;;;['Theodoros Lappas'];;;None;;;ACM Transactions on Knowledge Discovery from Data;;;The emergence of online professional platforms, such as LinkedIn and Indeed, has led to unprecedented volumes of rich resume data that have revolutionized the study of careers. One of the most prevalent problems in this space is the extraction of prototype career paths from a workforce. Previous research has consistently relied on a two-step approach to tackle this problem. The first step computes the pairwise distances between all the career sequences in the database. The second step uses the distance matrix to create clusters, with each cluster representing a different prototype path. As we demonstrate in this work, this approach faces two significant challenges when applied on large resume databases. First, the overwhelming diversity of job titles in the modern workforce prevents the accurate evaluation of distance between career sequences. Second, the clustering step of the standard approach leads to highly heterogeneous clusters, due to its inability to handle categorical sequences and sensitivity to outliers. This leads to non-representative centroids and spurious prototype paths that do not accurately represent the actual groups in the workforce. Our work addresses these two challenges and has practical implications for the numerous researchers and practitioners working on the analysis of career data across domains.;;;https://dl.acm.org/doi/10.1145/3379984;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Metalearning Applied to Multi-label Text Classification;;;['Vânia Batista dos Santos', 'Luiz Henrique de Campos Merschmann'];;;November 2020;;;SBSI '20: Proceedings of the XVI Brazilian Symposium on Information Systems;;;Data Mining and Machine Learning fields have many techniques that can support data analysts in the text classification task. However, finding the most adequate techniques require advanced technical knowledge, exhaustive computational experiments and, consequently, time. To address this issue, researchers have proposed different approaches for selecting such techniques to be employed in classification tasks and the dynamic selection of classifiers is one of them. Therefore, this work proposes an approach that uses metalearning to automate the process of selecting the best classifier for each instance of a given multi-label textual dataset. Experiments were performed with multi-label text datasets and showed that the proposed approach is promising.;;;https://dl.acm.org/doi/10.1145/3411564.3411646;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Data Mining Using Clustering Algorithm as Tool for Poverty Analysis;;;['Janelyn A. Talingdan'];;;February 2019;;;ICSCA '19: Proceedings of the 2019 8th International Conference on Software and Computer Applications;;;Poverty in one place can be reduced or minimized if proper poverty alleviation programs are given to the community. In this study different clustering algorithms were evaluated using silhouette index to get the best clustering algorithm to group the households and analyze the poverty data. The k-means algorithm where k=3 outperformed DBSCAN and k-medoids with a silhouette of 0.308. The algorithm produced three groups or clusters and labelled as non-poor, near poor and poor. The result can help policy-makers formulate and implement poverty reduction policies and programs that are clear, reasonable, realistic, and enforceable.;;;https://dl.acm.org/doi/10.1145/3316615.3316672;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A Machine Learning Approach to Blind Multi-Path Classification for Massive MIMO Systems;;;['Ning Xie', 'Le Ou-Yang', 'Alex X. Liu'];;;None;;;IEEE/ACM Transactions on Networking;;;This paper concerns the problem of the multi-path classification in a multi-user multi-input multi-output (MIMO) system. We propose a machine learning approach to achieve a blind multi-path classification in the uplink (UL) scheme of a multi-user massive MIMO system. Note that the &#x201C;blind&#x201D; term in our approach represents the achievement of the multi-path classification without different pilot sequences on different users, without prior channel state information (CSI) at each user, and without any exploiting the special properties of the received signal. Specifically, our approach consists of two phases. In the first phase, multiple users transmit communication-requests to the base station (BS) for message transmission. The BS only estimates the scaled large-scale path loss of each user, which is determined by the distance between the transmitter and the receiver and is independent of the number of multi-path. Then, the BS compares the difference of the scaled large-scale path loss between any two users. If the difference is sufficiently large, the BS notifies all users to permit their simultaneous message transmissions. However, if the difference is small, the BS notifies each user to slightly adjust their transmission power and then permits their simultaneous message transmissions as well. In the second phase, all users simultaneously transmit their messages using the same radio resource. Then the BS selects one predetermined constellation point from the received pilot symbols as the input of clustering algorithms. According to the clustering results, the BS classifies each multi-path into a specific user. The key intuition of our approach is that the clustering algorithms can generate multiple cluster centroids and each cluster centroid represents the average reception power of each user. Moreover, we use a weighted ensemble clustering algorithm to further improve the performance of our approach. We implemented our approach and conducted extensive performance comparison. Our experimental results show that, when the received signal-to-noise ratio (SNR) is more than 13 dB, our approach with the weighted ensemble clustering algorithm can correctly classify all multi-path to the corresponding user and the output SNR can be improved by 3.2 dB, where we consider three users in an 8PSK system and each user possess 50 multi-path.;;;https://dl.acm.org/doi/10.1109/TNET.2020.3008287;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Mining Frequency of Drug Side Effects over a Large Twitter Dataset Using Apache Spark;;;['Dennis Hsu', 'Melody Moh', 'Teng-Sheng Moh'];;;July 2017;;;ASONAM '17: Proceedings of the 2017 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining 2017;;;Despite clinical trials by pharmaceutical companies as well as current FDA reporting systems, there are still drug side effects that have not been caught. To find a larger sample of reports, a possible way is to mine online social media. With its current widespread use, social media such as Twitter has given rise to massive amounts of data, which can be used as reports for drug side effects. To process these large datasets, Apache Spark has become popular for fast, distributed batch processing. In this work, we have improved on previous pipelines in sentimental analysis-based mining, processing, and extracting tweets with drug-caused side effects. We have also added a new ensemble classifier using a combination of sentiment analysis features to increase the accuracy of identifying drug-caused side effects. In addition, the frequency count for the side effects is also provided. Furthermore, we have also implemented the same pipeline in Apache Spark to improve the speed of processing of tweets by 2.5 times, as well as to support the process of large tweet datasets. As the frequency count of drug side effects opens a wide door for further analysis, we present a preliminary study on this issue, including the side effects of simultaneously using two drugs, and the potential danger of using less-common combination of drugs. We believe the pipeline design and the results present in this work would have great implication on studying drug side effects and on big data analysis in general.;;;https://dl.acm.org/doi/10.1145/3110025.3110110;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
CLEAR: Contrastive-Prototype Learning with Drift Estimation for Resource Constrained Stream Mining;;;['Zhuoyi Wang', 'Yuqiao Chen', 'Chen Zhao', 'Yu Lin', 'Xujiang Zhao', 'Hemeng Tao', 'Yigong Wang', 'Latifur Khan'];;;April 2021;;;WWW '21: Proceedings of the Web Conference 2021;;;Non-stationary data stream mining aims to classify large scale online instances that emerge continuously. The most apparent challenge compared with the offline learning manner is the issue of consecutive emergence of new categories, when tackling non-static categorical distribution. Non-stationary stream settings often appear in real-world applications, e.g., online classification in E-commerce systems that involves the incoming productions, or the summary of news topics on social networks (Twitter). Ideally, a learning model should be able to learn novel concepts from labeled data (in new tasks) and reduce the abrupt degradation of model performance on the old concept (also named catastrophic forgetting problem). In this work, we focus on improving the performance of the stream mining approach under the constrained resources, where both the memory resource of old data and labeled new instances are limited/scarce. We propose a simple yet efficient resource-constrained framework CLEAR to facilitate previous challenges during the one-pass stream mining. Specifically, CLEAR focuses on creating and calibrating the class representation (the prototype) in the embedding space. We first apply the contrastive-prototype learning on large amount of unlabeled data, and generate the discriminative prototype for each class in the embedding space. Next, for updating on new tasks/categories, we propose a drift estimation strategy to calibrate/compensate for the drift of each class representation, which could reduce the knowledge forgetting without storing any previous data. We perform experiments on public datasets (e.g., CUB200, CIFAR100) under stream setting, our approach is consistently and clearly better than many state-of-the-art methods, along with both the memory and annotation restriction.;;;https://dl.acm.org/doi/10.1145/3442381.3449820;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A machine learning approach for medical device classification;;;['Aaron Ceross', 'Jeroen Bergmann'];;;October 2021;;;ICEGOV '21: Proceedings of the 14th International Conference on Theory and Practice of Electronic Governance;;;The growth of medical device innovation over the last decades has necessitated the need for strong regulatory control in order to ensure the safety and performance of such devices. Medical devices are categorised according to the risk posed to the public. However, the legislation describing the classification rules are often dense and difficult to read. In order to facilitate device classification, the medical device regulator in Australia, the Therapeutic Goods Authority (TGA), provides online digital support tool for device classification. In this work, we (i) evaluate the online tool and (ii) make a further a proposal for using machine learning as means to provide more effective results. For the first part of this work, we asses whether the tool increases the readability of the legislative rules by evaluating the Flesch reading ease score of the legislation and the tool. While the online tool provides some degree of simplicity and readability over the legislation, we argue that the TGA can make more use of its data in order to provide more effective services. In the second part, we develop a proof-of-concept machine learning model to classify a device based on its stated purpose. The results of the experiment show a 82% weighted accuracy across four class labels, indicating that a more data-driven approach could be adopted by the authority.;;;https://dl.acm.org/doi/10.1145/3494193.3494232;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Evaluating Citizen Comments in Public Consultations Using Data Mining: Evaluating Citizen Comments in Public Consultations Using Data Mining: Analyzing Legislation Comments for the Greek General Commercial Registry;;;['Eirini Manga', 'Nikitas Karanikolas', 'Catherine Marinagi', 'Christos Skourlas'];;;November 2021;;;PCI '21: Proceedings of the 25th Pan-Hellenic Conference on Informatics;;;None;;;https://dl.acm.org/doi/10.1145/3503823.3503902;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Optimization of Big Data Mining Algorithm Based on Spark Framework: Preparation of Camera-Ready Contributions to SCITEPRESS Proceedings;;;['Yan Zeng', 'Jun Li'];;;January 2022;;;BIC 2022: 2022 2nd International Conference on Bioinformatics and Intelligent Computing;;;Abstract: Frequent itemsets mining is the core of association rule mining data. However, with the continuous increase of data, the traditional Apriori algorithm cannot meet people's daily needs, and the algorithm efficiency is low. This paper proposes the Eclat algorithm based on the Spark framework. In view of the shortcomings of serial algorithm in processing big data, it is modified. Using the vertical structure to avoid repetitive traversal of large amounts of data, while computing based on memory can greatly reduce I/O load and reduce computing time. Combined with the pruning strategy, the calculation of irrelevant itemsets is reduced, and the parallel computing capability of the algorithm is improved. The experimental results show that the efficiency of the Eclat algorithm based on the Spark framework is far better than that of the Eclat algorithm, and it has high efficiency and good scalability when processing massive data.;;;https://dl.acm.org/doi/10.1145/3523286.3524685;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A Three-Step Data-Mining Analysis of Top-Ranked Higher Education Institutions' Communication on Facebook;;;['Álvaro Figueira'];;;October 2018;;;TEEM'18: Proceedings of the Sixth International Conference on Technological Ecosystems for Enhancing Multiculturality;;;Organizations are rushing into social media networks following a worldwide trend to create a social presence in multiple media channels. However, a social media strategy needs to be aligned with and framed in the overall organizational strategic management goals. Higher Educational Institutions (HEI) are not different from other organizations in which concerns these problems. Determining the organizational positioning of an organization current strategy will allow to combine monitoring and benchmarking methods to foster the identification of opportunities and threats, which can serve as inputs for the internal evaluation of social media strategies', for the necessary strategic readjustments and a subsequent efficiency measurement. In order to address these challenges, we propose a three-step automatic data-mining procedure to assess the posting behavior and strategy of HEI, understand the editorial policy behind it, and predict the future HEI engagement. We used a sample of the 5-top ranked educational institutions in 2017. We collected the posts from each HEI official Facebook page during an entire school year. Our method showed high degree of accuracy and is also capable of describing which topics are most common in each university's social media content strategy and relate them to the corresponding response from their publics.;;;https://dl.acm.org/doi/10.1145/3284179.3284342;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Mining Redescriptions with Siren;;;['Esther Galbrun', 'Pauli Miettinen'];;;None;;;ACM Transactions on Knowledge Discovery from Data;;;In many areas of science, scientists need to find distinct common characterizations of the same objects and, vice versa, to identify sets of objects that admit multiple shared descriptions. For example, in biology, an important task is to identify the bioclimatic constraints that allow some species to survive, that is, to describe geographical regions both in terms of the fauna that inhabits them and of their bioclimatic conditions. In data analysis, the task of automatically generating such alternative characterizations is called redescription mining.If a domain expert wants to use redescription mining in his research, merely being able to find redescriptions is not enough. He must also be able to understand the redescriptions found, adjust them to better match his domain knowledge, test alternative hypotheses with them, and guide the mining process toward results he considers interesting. To facilitate these goals, we introduce Siren, an interactive tool for mining and visualizing redescriptions.Siren allows to obtain redescriptions in an anytime fashion through efficient, distributed mining, to examine the results in various linked visualizations, to interact with the results either directly or via the visualizations, and to guide the mining algorithm toward specific redescriptions. In this article, we explain the features of Siren and why they are useful for redescription mining. We also propose two novel redescription mining algorithms that improve the generalizability of the results compared to the existing ones.;;;https://dl.acm.org/doi/10.1145/3007212;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
The Classification of Gene Sequencer Based on Machine Learning;;;['Jie Yang', 'Yong Cao'];;;December 2021;;;EBIMCS '21: Proceedings of the 2021 4th International Conference on E-Business, Information Management and Computer Science;;;Abstract: Biological sequencing plays a very important role in life science, especially with the improvement of sequencing technology and the development of sequencing instruments, and a large number of biological sequencing quality data are produced every day. Because of different sequencers, the quality of sequencing is different. In the process of sequencing quality control, the model of sequencer can be deduced according to the quality of gene sequence. Therefore, in this paper, five sequencers of Illumina HiSeq series, Illumina HiSeq 2000, Illumina HiSeq 2500, Illumina HiSeq 3000, Illumina HiSeq 4000 and Illumina HiSeq XTen, are selected as the classification objects. Firstly, the sequencing quality data of the five sequencers are preprocessed. Then, the classification model is trained by three machine learning algorithms: decision tree, logistic regression and support vector machine. The experimental results show that the accuracy rates of the three machine learning algorithms are 96.67%, 97.50% and 97.50% respectively. These algorithms are very good to solve the problem of using biological sequencing data quality to classify sequencer.;;;https://dl.acm.org/doi/10.1145/3511716.3511730;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Evaluation of Dimensionality Reduction Techniques-Principal Feature Analysis in case of Text Classification Problems;;;['Michael Mammo', 'Tony Lindgren'];;;January 2020;;;ICCDE '20: Proceedings of 2020 6th International Conference on Computing and Data Engineering;;;One of the commonly observed phenomena in text classification problems is sparsity of the generated feature set. So far, different dimensionality reduction techniques have been developed to reduce feature spaces into a convenient size that a learner algorithm can infer. Among these, Principal Component Analysis (PCA) is one of the well-established techniques which is capable of generating an undistorted view of the data. As a result, variants of the algorithm have been developed and applied in several domains, including text mining. However, PCA does not provide backward traceability to the original features once it projected the initial features to a new space. Also, it needs a relatively large computational space since it uses all features when generating the final features. These drawbacks especially pose a problem in text classification problems where high dimensionality and sparsity are common phenomena. This paper presents a modified version PCA, Principal Feature Analysis (PFA), which enables backward traceability by choosing a subset of optimal features in the original space using the same criteria PCA uses, without involving the initial features into final computation. The proposed technique is tested against benchmark corpora and produced a comparable result as PCA while maintaining traceability to the original feature space.;;;https://dl.acm.org/doi/10.1145/3379247.3379274;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Do Words with Certain Part of Speech Tags Improve the Performance of Arabic Text Classification?;;;['Abdulmohsen Al-Thubaity', 'Aali Alqarni', 'Ahmad Alnafessah'];;;April 2018;;;ICISDM '18: Proceedings of the 2nd International Conference on Information System and Data Mining;;;Feature extraction - the process of choosing feature types that can represent and discriminate between dataset topics - is one of the critical steps in text classification and varies with the language of the texts. Different feature types have been proposed for Arabic text classification, ranging from features based on word orthography (single word and character and word N-grams) to features based on linguistic analysis (roots, stems). To the best of our knowledge, little attention has been paid to investigating the performance of Arabic text classification when Part of Speech (POS) tagging information is used to extract features. In this study, we used a corpus comprising 4900 newspaper texts distributed evenly over seven topics to investigate the effect of using POS tag distribution and words that belong to certain POS tags on Arabic text classification, namely nouns, verbs and adjectives. For feature selection, feature representation and text classification we used Chi-squared, Log-Weighted Term Frequency Inverse Document Frequency with Cosine Normalization (LTC) and support vector machine (SVM) respectively. We used four metrics, namely accuracy, precision, recall and F-measure to measure classification performance. Experiment data suggest that the words achieved the best classification performance when the number of features was low; however, the classification performance can be marginally increased when nouns, verbs and adjectives are used as features, given that the number of features is increased.;;;https://dl.acm.org/doi/10.1145/3206098.3206109;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Data Mining in Education: Discussing Knowledge Discovery in Database (KDD) with Cluster Associative Study;;;['Abdulkadir Abdulahi Hasan', 'Huan Fang'];;;May 2021;;;ICAIIS 2021: 2021 2nd International Conference on Artificial Intelligence and Information Systems;;;Data Mining, being an emerging field has ties with ever-increasing knowledge base, contributing to historical data trends and patterns as well as providing evidence to predict future behaviors. With the adoption of data mining techniques and their thorough implications, the knowledge base could be enhanced and a futuristic strategic management tool could be formulated in the form of modern data mining techniques. The technique and terminology used in the paper involves extracting knowledge from large datasets. In this paper, cluster sampling associated with data mining is used to dig out a beneficial way of tackling data mining steps. With these combined data mining efforts, the aim of highlighting the significance of data mining could be amalgamated with data warehouses and the steps that need to involve selecting, transforming, mining, and output evaluation to get beneficial or desired results. Furthermore, a mild emphasize is put on the cluster sampling data mining technique, steps, and its implication to enhance knowledge, explore new terms, and broaden our output scenarios so that there is a better understanding of how to move along the data mining channel. The objective of this study is to explain the basics of data mining and provide a way to further this research over data mining with cluster sampling and Knowledge discovery is data bases (KDD). For the said purpose, two clusters of the population of China are used in this study. One of which includes the percentage of students enrolled in the primary schools; and the other includes percentage of students enrolled in secondary schools in China. The steps of cluster sampling technique are followed to give a better understanding of the data mining approach.;;;https://dl.acm.org/doi/10.1145/3469213.3471319;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Apricot Variety Classification Using Image Processing and Machine Learning Approaches;;;['Seyed Vahid Mirnezami', 'Ali HamidiSepehr', 'Mahdi Ghaebi', 'Seyed Reza Hassan-Beygi'];;;December 2020;;;ICVISP 2020: Proceedings of the 2020 4th International Conference on Vision, Image and Signal Processing;;;Apricot which is a cultivated type of Zerdali (wild apricot) has an important place in human nutrition and its medical properties are essential for human health. The objective of this research was to obtain a model for apricot mass and separate apricot variety with image processing technology using external features of apricot fruit. In this study, five verities of apricot were used. In order to determine the size of the fruits, three mutually perpendicular axes were defined, length, width, and thickness. Measurements show that the effect of variety on all properties was statistically significant at the 1% probability level. Furthermore, there is no significant difference between the estimated dimensions by image processing approach and the actual dimensions. The developed system consists of a digital camera, a light diffusion chamber, a distance adjustment pedestal, and a personal computer. Images taken by the digital camera were stored as (RGB) for further analysis. The images were taken for a number of 49 samples of each cultivar in three directions. A linear equation is recommended to calculate the apricot mass based on the length and the width with R2 = 0.97. In addition, ANFIS model with C-means was the best model for classifying the apricot varieties based on the physical features including length, width, thickness, mass, and projected area of three perpendicular surfaces. The accuracy of the model was 87.7.;;;https://dl.acm.org/doi/10.1145/3448823.3448856;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Data mining techniques and nature-inspired algorithms for query expansion;;;['Ilyes Khennak', 'Habiba Drias'];;;May 2018;;;LOPAL '18: Proceedings of the International Conference on Learning and Optimization Algorithms: Theory and Applications;;;Data mining techniques and nature-inspired algorithms are currently among the most frequently used soft computing techniques for knowledge discovery, optimization, and computational intelligence. In this paper, we propose the application of both data mining techniques and nature-inspired algorithms to overcome the problem of generating the optimum expanded query in web information retrieval. We first use data mining techniques to group similar expansion term candidates into clusters. Next, we use nature-inspired algorithms to extract expansion term candidates from clusters and generate the suitable expanded query. We empirically assess the proposed approach using MEDLINE, the large online medical repository. Numerical experiments show that the proposed approach attains higher effectiveness and efficiency compared to conventional and recently published methods.;;;https://dl.acm.org/doi/10.1145/3230905.3234631;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Linguistic Pattern Mining for Data Analysis in Microblog Texts using Word Embeddings;;;['Danielly Sorato', 'Renato Fileto'];;;May 2019;;;SBSI '19: Proceedings of the XV Brazilian Symposium on Information Systems;;;Microblog posts (e.g. tweets) often contain users opinions and thoughts about events, products, people, organizations, among other possibilities. However, the usage of social media to promote online disinformation and manipulation is not an uncommon occurrence. Analyzing the characteristics of such discourses in social media is essential for understanding and fighting such actions. Extracting recurrent fragments of text, i.e. word sequences, which are semantically similar can lead to the discovery of linguistic patterns used in certain kinds of discourse. Therefore, we aim to use such patterns to encapsulate frequent discourses textually expressed in microblog posts. In this paper, we propose to exploit linguistic patterns in the context of the 2016 United Estates presidential election. Through a technique that we call Short Semantic Pattern (SSP) mining, we were able to extract sequences of words that share a similar meaning in their word embedding representation. In the experiments we investigate the incidence of SSP instances regarding political adversaries and media in tweets posted by Donald Trump, during the presidential election campaign. Experimental results show a high preponderance of some statements of Donald Trump towards their adversaries and expressions that often appeared in such tweets.;;;https://dl.acm.org/doi/10.1145/3330204.3330228;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A survey of text classification models;;;['JinXiong Yang', 'Liang Bai', 'Yanming Guo'];;;October 2020;;;RICAI '20: Proceedings of the 2020 2nd International Conference on Robotics, Intelligent Control and Artificial Intelligence;;;With the rapid development of artificial intelligence, text classification method based on deep learning model has surpassed traditional machine learning method in various aspects. This paper introduces dozens of deep learning models for text classification according to the different network structures of the models. In addition, this paper briefly introduces the evaluation indicators and application scenarios of text classification, summarizes and forecasts the current challenges and future development trend of text classification.;;;https://dl.acm.org/doi/10.1145/3438872.3439101;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Differentiable Pattern Set Mining;;;['Jonas Fischer', 'Jilles Vreeken'];;;August 2021;;;KDD '21: Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining;;;Pattern set mining has been successful in discovering small sets of highly informative and useful patterns from data. To find good models, existing methods heuristically explore the twice-exponential search space over all possible pattern sets in a combinatorial way, by which they are limited to data over at most hundreds of features, as well as likely to get stuck in local minima. Here, we propose a gradient based optimization approach that allows us to efficiently discover high-quality pattern sets from data of millions of rows and hundreds of thousands of features. In particular, we propose a novel type of neural autoencoder called BinaPs, using binary activations and binarizing weights in each forward pass, which are directly interpretable as conjunctive patterns. For training, optimizing a data-sparsity aware reconstruction loss, continuous versions of the weights are learned in small, noisy steps. This formulation provides a link between the discrete search space and continuous optimization, thus allowing for a gradient based strategy to discover sets of high-quality and noise-robust patterns. Through extensive experiments on both synthetic and real world data, we show that BinaPs discovers high quality and noise robust patterns, and unique among all competitors, easily scales to data of supermarket transactions or biological variant calls.;;;https://dl.acm.org/doi/10.1145/3447548.3467348;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Quantitative interactive investment algorithm based on machine learning and data mining;;;['Fangyuan Cheng', 'Junmin Jia'];;;July 2021;;;DSIT 2021: 2021 4th International Conference on Data Science and Information Technology;;;Quantitative investment is a mean to predict the development of securities and conduct transactions by using computer algorithms, but it usually ignores the guiding role of investors' personal preferences in deciding investment plans. Thus, we suggest a quantitative interactive investment algorithm to integrate the rational goals of investment with the individual preference indicators of decision-making investors. The interactive multi-objective solution algorithm creatively combines the decision tree algorithm which mine the investor's individual preference index from the investor's decision data with the second-generation non-dominated sorting genetic algorithm (NSGA-II). This method solves the problem of the lack of personalized choices in current quantitative investment methods by adding decision-makers’ preference indicators.;;;https://dl.acm.org/doi/10.1145/3478905.3478982;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
From Opinion Mining to Improvement Mining : Understanding Product Improvements from User Reviews;;;['Roshni Ramnani', 'Shubhashis Sengupta'];;;December 2021;;;FIRE '21: Proceedings of the 13th Annual Meeting of the Forum for Information Retrieval Evaluation;;;A valuable trove of information exists for product(s) or services online via user opinions like detailed reviews provided by customers on popular e-commerce websites. Users express their individual opinions in the form of overall product/service experiences, which may include explicit positive/negative feedback, preferences, concerns, and suggestions for the future. Such information can be valuable to product/service owners in helping them understand the improvement(s) that must be made to a particular product or service. The primary focus of opinion mining has been on understanding positive and negative aspects within the review effectively. Limited emphasis has been placed on finer topics like user suggestions or conflicting information from users. In this work, we describe a method to extract possible product / service improvements from opinionated text in the form of non-conflicting negative feedback, user tips, recommendations, product usage details, feature suggestions, and specific complaints.;;;https://dl.acm.org/doi/10.1145/3503162.3503166;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Legal Text Processing: Combing two legal ontological approaches through text mining;;;['Michalis Avgerinos Loutsaris', 'Zoi Lachana', 'Charalampos Alexopoulos', 'Yannis Charalabidis'];;;June 2021;;;DG.O'21: DG.O2021: The 22nd Annual International Conference on Digital Government Research;;;The globalization of communication networks and the possibilities offered by the information and communication technologies (ICTs) significantly change the public sector's operation and services. Digital Governance is now integrated into administrations' policies and programs at all levels: local, regional, national, European. At the national level, there is a requirement to provide electronic public services according to citizens' needs while, in the sense of globalization, at the European level, there are many programs (e.g., the Europe 2005 and i2010 program) emphasizing the Digital Governance world (or better Digital Governance community) that indicates rapid changes not only in the sense of the change in the public sector's systems but also in the mentality that the public sector operates. On the other hand, Digital Governance's evolution affects societies intensively, emphasizing the importance of cross-border interaction and information sharing between them. [6]. Concerning the legal informatics domain, this can result in changing governments' operations in many ways [2]. By now, the massive amount of each country's legal information currently remains fragmented across multiple national databases and systems or even better legal databases. Most of these legal databases result from the significant advancements in the “legal informatics” research field that observed since governments have started to promote the development of legal information systems [9]. This research contributes to this purpose by developing an open and automated legal system capable of providing any EU country's legal information based on the existing ontologies.;;;https://dl.acm.org/doi/10.1145/3463677.3463730;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Benchmarking Apache Spark and Hadoop MapReduce on Big Data Classification;;;['Taha Tekdogan', 'Ali Cakmak'];;;August 2021;;;ICCBDC '21: Proceedings of the 2021 5th International Conference on Cloud and Big Data Computing;;;Most of the popular Big Data analytics tools evolved to adapt their working environment to extract valuable information from a vast amount of unstructured data. The ability of data mining techniques to filter this helpful information from Big Data led to the term ‘Big Data Mining’. Shifting the scope of data from small-size, structured, and stable data to huge volume, unstructured, and quickly changing data brings many data management challenges. Different tools cope with these challenges in their own way due to their architectural limitations. There are numerous parameters to take into consideration when choosing the right data management framework based on the task at hand. In this paper, we present a comprehensive benchmark for two widely used Big Data analytics tools, namely Apache Spark and Hadoop MapReduce, on a common data mining task, i.e., classification. We employ several evaluation metrics to compare the performance of the benchmarked frameworks, such as execution time, accuracy, and scalability. These metrics are specialized to measure the performance for classification task. To the best of our knowledge, there is no previous study in the literature that employs all these metrics while taking into consideration task-specific concerns. We show that Spark is 5 times faster than MapReduce on training the model. Nevertheless, the performance of Spark degrades when the input workload gets larger. Scaling the environment by additional clusters significantly improves the performance of Spark. However, similar enhancement is not observed in Hadoop. Machine learning utility of MapReduce tend to have better accuracy scores than that of Spark, like around 2%-3%, even in small-size data sets.;;;https://dl.acm.org/doi/10.1145/3481646.3481649;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Chinese News Text Multi Classification Based on Naive Bayes Algorithm;;;['Fei Wang', 'Xin Deng', 'Lunqing Hou'];;;September 2018;;;ISCSIC '18: Proceedings of the 2nd International Symposium on Computer Science and Intelligent Control;;;With the development of Internet, there are more and more text data appear, the companies face the challenge to organize the content and the users feel confused about what is useful content for them. If the text data can be classified will make a contribution to solve the problem. It has been a long time, text classification work is done by human beings, like editors. So text classification become a hot topic in nature language processing field, especially for Chinese text classification. Sentiment classification just need to classify two classes, but there are more situations where we need to do multi classification. Such as the news editors have to give an article tags manually. There are several ways to solve the text classification problem: (1) Naive Bayes algorithm (2) support vector machine algorithm (3) neural network (4) k nearest neighbors (5) decision tree [1][2][3][4][5]. Naive Bayes applies Bayes' theorem with strong(naive) independence assumptions between the features. This paper proposes to use Naive Bayes to finish a Chinese news text multi classification with nine classes.;;;https://dl.acm.org/doi/10.1145/3284557.3284704;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Using Machine Learning Clustering To Find Large Coverage Holes;;;['Raviv Gal', 'Giora Simchoni', 'Avi Ziv'];;;November 2020;;;MLCAD '20: Proceedings of the 2020 ACM/IEEE Workshop on Machine Learning for CAD;;;Identifying large and important coverage holes is a time-consuming process that requires expertise in the design and its verification environment. This paper describes a novel machine learning-based technique for finding large coverage holes when the coverage events are individually defined. The technique is based on clustering the events according to their names and mapping the clusters into cross-products. Our proposed technique is being used in the verification of high-end servers. It has already improved the quality of coverage analysis and helped identify several environment problems.;;;https://dl.acm.org/doi/10.1145/3380446.3430621;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Research on Data Analysis and Mining Technology Based on Computer Visualization;;;['Li Guo'];;;October 2020;;;CIPAE 2020: Proceedings of the 2020 International Conference on Computers, Information Processing and Advanced Education;;;In the era of mobile Internet, resource interconnection and sharing, group collaboration and cooperation have become the new driving forces for scientific and social development. Visualization and human-computer interaction technology have played an important role in collaborative knowledge dissemination and scientific discovery. In order to fully explore and utilize the value of information resources, data mining technology came into being; the thesis first elaborated on the concept and classification of visual data mining, then discussed some of the main techniques of visual data mining, and finally through a system developed The classic shopping basket analysis problem was discussed with the realization of visual data mining technology.;;;https://dl.acm.org/doi/10.1145/3419635.3419687;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A First Look at the Crypto-Mining Malware Ecosystem: A Decade of Unrestricted Wealth;;;['Sergio Pastrana', 'Guillermo Suarez-Tangil'];;;October 2019;;;IMC '19: Proceedings of the Internet Measurement Conference;;;Illicit crypto-mining leverages resources stolen from victims to mine cryptocurrencies on behalf of criminals. While recent works have analyzed one side of this threat, i.e.: web-browser cryptojacking, only commercial reports have partially covered binary-based crypto-mining malware. In this paper, we conduct the largest measurement of crypto-mining malware to date, analyzing approximately 4.5 million malware samples (1.2 million malicious miners), over a period of twelve years from 2007 to 2019. Our analysis pipeline applies both static and dynamic analysis to extract information from the samples, such as wallet identifiers and mining pools. Together with OSINT data, this information is used to group samples into campaigns. We then analyze publicly-available payments sent to the wallets from mining-pools as a reward for mining, and estimate profits for the different campaigns. All this together is is done in a fully automated fashion, which enables us to leverage measurement-based findings of illicit crypto-mining at scale. Our profit analysis reveals campaigns with multi-million earnings, associating over 4.4% of Monero with illicit mining. We analyze the infrastructure related with the different campaigns, showing that a high proportion of this ecosystem is supported by underground economies such as Pay-Per-Install services. We also uncover novel techniques that allow criminals to run successful campaigns.;;;https://dl.acm.org/doi/10.1145/3355369.3355576;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Machine Learning Techniques for Classification of Spambase Dataset: A Hybrid Approach;;;['Shikha Verma', 'Arun Kumar Gautam'];;;September 2019;;;ISCSIC 2019: Proceedings of the 2019 3rd International Symposium on Computer Science and Intelligent Control;;;Email has become a necessity for this new generation for official communication purposes. As the use of Internet is becoming more and more the risk of being caught into its darker side is so common. The major concern is spam, which is growing exponentially, and the users are becoming victim of it on daily basis. This paper proposes a hybrid machine learning classification model for the spam classification on the spambase dataset. This model uses the four classification algorithms namely Ensemble Classification, Decision Tree, Random Forest and Support Vector Machine (SVM). There are two phases; First phase deals with the classification of spambase dataset in two classes i.e. spam and ham with Decision Tree machine learning algorithm and the second phase comprises of classification improvisation of the output produced by phase one with four machine learning algorithms i.e. Decision Tree, Random Forest, Support Vector Machine (SVM) and Ensemble Learning. The experiment shows a very promising result with improvised accuracy in second phase.;;;https://dl.acm.org/doi/10.1145/3386164.3389089;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Large-Scale Hierarchical Text Classification with Recursively Regularized Deep Graph-CNN;;;['Hao Peng', 'Jianxin Li', 'Yu He', 'Yaopeng Liu', 'Mengjiao Bao', 'Lihong Wang', 'Yangqiu Song', 'Qiang Yang'];;;April 2018;;;WWW '18: Proceedings of the 2018 World Wide Web Conference;;;Text classification to a hierarchical taxonomy of topics is a common and practical problem. Traditional approaches simply use bag-of-words and have achieved good results. However, when there are a lot of labels with different topical granularities, bag-of-words representation may not be enough. Deep learning models have been proven to be effective to automatically learn different levels of representations for image data. It is interesting to study what is the best way to represent texts. In this paper, we propose a graph-CNN based deep learning model to first convert texts to graph-of-words, and then use graph convolution operations to convolve the word graph. Graph-of-words representation of texts has the advantage of capturing non-consecutive and long-distance semantics. CNN models have the advantage of learning different level of semantics. To further leverage the hierarchy of labels, we regularize the deep architecture with the dependency among labels. Our results on both RCV1 and NYTimes datasets show that we can significantly improve large-scale hierarchical text classification over traditional hierarchical text classification and existing deep models.;;;https://dl.acm.org/doi/10.1145/3178876.3186005;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Text Classification of Network Pyramid Scheme based on Topic Model;;;['Pengyu Mu', 'Jingsha He', 'Nafei Zhu'];;;June 2019;;;NLPIR '19: Proceedings of the 2019 3rd International Conference on Natural Language Processing and Information Retrieval;;;At present, the network pyramid scheme has become a major tumor that hinders social development. In order to curb the propagation of the network pyramid scheme and effectively identify the pyramid scheme text in the network, this study proposes a joint topic model, Paragraph Vector Latent Dirichlet Allocation (PV_LDA), based on the characteristics of high-yield, high rebate, hierarchical salary and text topic diversity described in the text. The model uses the paragraph as the minimum processing unit to generate the topic distribution matrix of "high-interest rate" and "hierarchical salary" from the network pyramid scheme text. The Gibbs sampling is used to derive the "pyramid scheme" topic distribution matrix represented by the two features, which is used for classification processing by the classifier. the classification accuracy rate for the network pyramid scheme text can reach 86.25%. The conclusions show that the topic model proposed in this paper can capture the characteristics of the pyramid scheme more reasonably.;;;https://dl.acm.org/doi/10.1145/3342827.3342835;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
The application of data mining techniques and feature selection methods in the risk classification of Egyptian liver cancer patients using clinical and genetic data;;;['Esraa H. Abdelaziz', 'Sanaa M. Kamal', 'Khaled El-Bhanasy', 'Rasha Ismail'];;;April 2019;;;ICSIE '19: Proceedings of the 8th International Conference on Software and Information Engineering;;;Data mining techniques has shown great potential in biomedical and health care fields. The objective of this paper is to apply feature selection methods and data mining techniques to Egyptian liver cancer patients' data to predict their prognosis and extract important features that affect the patient's survivability. Genetic and Clinical data from 1541 patients were analyzed. Three feature selection methods and seven data mining techniques were studied and compared. Wrapper Subset method and Random Forest proved to be the best performing feature selection method and data mining technique respectively. Moreover, important genetic features such as p53 gene exon 6 and 9 mutations proved to have a significant impact on patient's overall prognosis.;;;https://dl.acm.org/doi/10.1145/3328833.3328849;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Generalizing rules by random forest-based learning classifier systems for high-dimensional data mining;;;['Fumito Uwano', 'Koji Dobashi', 'Keiki Takadama', 'Tim Kovacs'];;;July 2018;;;GECCO '18: Proceedings of the Genetic and Evolutionary Computation Conference Companion;;;This paper proposes high-dimensional data mining technique by integrating two data mining methods: Accuracy-based Learning Classifier Systems (XCS) and Random Forests (RF). Concretely the proposed system integrates RF and XCS: RF generates several numbers of decision trees, and XCS generalizes the rules converted from the decision trees. The convert manner is as follows: (1) the branch node of the decision tree becomes the attribute; (2) if the branch node does not exist, the attribute of that becomes # for XCS; and (3) One decision tree becomes one rule at least. Note that # can become any value in the attribute. From the experiments of Multiplexer problems, we derive that: (i) the good performance of the proposed system; and (ii) RF helps XCS to acquire optimal solutions as knowledge by generating appropriately generalized rules.;;;https://dl.acm.org/doi/10.1145/3205651.3208298;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Mining Online Training Log Data;;;['Susan Mehringer', 'Christopher R. Myers', 'Jennifer Houchins', 'Lorna Rivera'];;;July 2019;;;PEARC '19: Proceedings of the Practice and Experience in Advanced Research Computing on Rise of the Machines (learning);;;Online training has been growing in popularity, and offers many advantages for both trainers and learners. Assessing the usage and impact of online material can be difficult, especially if content is made available to anyone and is not part of a course requiring formal enrollment. The Cornell Virtual Workshop (CVW) first offered online training on topics in high-performance computing and computational science in 1994, and ten years ago we began logging usage. We are now performing our first in-depth analysis of those log data to identify patterns in usage, so that we can better understand how users access the material, which types of topics and materials result in the greatest impact, how topic usage changes over time, and what types of presentation format might be preferred. While the CVW is built around a cohesive, sequential narrative for each training topic, we find that many users access our content in a more targeted fashion, suggesting that we rethink how we package our material. We anticipate that ongoing analysis using data science and machine learning methods will enable us to produce more useful training materials, and provide the educational community with valuable information about patterns in online material usage.;;;https://dl.acm.org/doi/10.1145/3332186.3332235;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Predictive Analytics Using Text Classification for Restaurant Inspections;;;['Zhu Wang', 'Booma Sowkarthiga Balasubramani', 'Isabel F. Cruz'];;;November 2017;;;UrbanGIS'17: Proceedings of the 3rd ACM SIGSPATIAL Workshop on Smart Cities and Urban Analytics;;;According to the Center for Disease Control (CDC), there are almost 48 million people affected by foodborne diseases in the U.S. every year, including 3,000 deaths. The most effective way of avoiding food poisoning would be its prevention. However, complete prevention is not possible, therefore Public Health departments perform routine restaurant inspections, combined with the practice of inspecting specific restaurants once a disease outbreak is identified. Following other health applications (e.g., prediction of a flu outbreak using Twitter), we use social media and a predictive analytics approach to identify the need for targeted visits by city inspectors.;;;https://dl.acm.org/doi/10.1145/3152178.3152192;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Malware classification using deep learning methods;;;['Bugra Cakir', 'Erdogan Dogdu'];;;March 2018;;;ACMSE '18: Proceedings of the ACMSE 2018 Conference;;;Malware, short for Malicious Software, is growing continuously in numbers and sophistication as our digital world continuous to grow. It is a very serious problem and many efforts are devoted to malware detection in today's cybersecurity world. Many machine learning algorithms are used for the automatic detection of malware in recent years. Most recently, deep learning is being used with better performance. Deep learning models are shown to work much better in the analysis of long sequences of system calls. In this paper a shallow deep learning-based feature extraction method (word2vec) is used for representing any given malware based on its opcodes. Gradient Boosting algorithm is used for the classification task. Then, k-fold cross-validation is used to validate the model performance without sacrificing a validation split. Evaluation results show up to 96% accuracy with limited sample data.;;;https://dl.acm.org/doi/10.1145/3190645.3190692;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Cloud Computing Resource Load Forecasting Model Based on Data Mining;;;['Xiangqin Li'];;;September 2021;;;ICISCAE 2021: 2021 4th International Conference on Information Systems and Computer Aided Education;;;The changes of cloud computing resources are dynamic and random. It is difficult to obtain ideal prediction results by traditional algorithms. In order to improve the accuracy of cloud computing resource prediction, a cloud computing resource load forecasting model based on data mining technology is proposed. Firstly, data mining technology is used to collect cloud computing resource data, and normalized processing, then the resource data are trained, the improved ant colony algorithm is used to select the optimal parameters of the load model, and finally the cloud computing resources are completed by data clustering. The effectiveness of the load prediction model is determined by simulation experiments. The results show that the data mining-based load forecasting model not only improves the prediction accuracy of cloud computing resources, but also reduces the complexity of resource prediction, improves the prediction efficiency, and provides the cloud computing resource prediction, a new modeling approach.;;;https://dl.acm.org/doi/10.1145/3482632.3484105;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A machine learning approach to flood severity classification and alerting;;;['Prativa Sharma', 'Bandana Kar', 'Jun Wang', 'Doug Bausch'];;;November 2021;;;ARIC '21: Proceedings of the 4th ACM SIGSPATIAL International Workshop on Advances in Resilient and Intelligent Cities;;;With increased big data and computing power, machine learning is predominantly used for classification to object detection and forecasting of phenomena and relationships. Forecasting, mapping and impact assessment of flood events is one such area where machine learning is gaining momentum. While machine learning has been widely used for forecasting of flood extent and depth using rainfall/runoff datasets, impact assessment based on flood severity distribution using machine learning is still a long way from maturity. In this study, we used several machine learning classifiers such as Decision Tree (DT), Random Forest (RF), Gradient Boosting (GB), Support Vector Machine (SVM) and Multinomial Logit (ML) to classify flood severity into four classes: Information, Advisory, Watch and Warning based on the training datasets obtained from the Model of Models. The Model of Models is an ensemble model which integrates flood forecasting models to determine flood severity globally at sub-watershed level based on spatial extent and duration of flooding, risk scores associated with historic flooding events. The severity classes are used to disseminate alerts to stakeholders globally. The initial results reveal that the GB followed by DT and RF classifier performed better for classifying severity based on the performance assessment metrics. While this study has implemented a first version machine learner, future advancements will focus on deploying adaptive learners to increase the forecasting ability of the machine learner with new datasets generated daily.;;;https://dl.acm.org/doi/10.1145/3486626.3493432;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Fine and Coarse Granular Argument Classification before Clustering;;;['Lorik Dumani', 'Tobias Wiesenfeldt', 'Ralf Schenkel'];;;October 2021;;;CIKM '21: Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management;;;Computational argumentation and especially argument mining together with retrieval enjoys increasing popularity. In contrast to standard search engines that focus on finding documents relevant to a query, argument retrieval aims at finding the best supporting and attacking premises given a query claim, e.g., from a predefined collection of arguments. Here, a claim is the central part of an argument representing the standpoint of a speaker with the goal to persuade the audience, and a premise serves as evidence to the claim. In addition to the actual retrieval process, existing work has focused on (1) classifying polarities of arguments into supporting or opposing, (2) classifying arguments by their frames (such as economic or environmental), and (3) clustering similar arguments by their meaning to avoid repetitions in the result list. For experiments, either hand-made argument collections or arguments extracted from debate portals were used. In this paper, we extend existing work on argument clustering, making the following contributions: First, we introduce a novel pipeline for clustering arguments. While previous work classified arguments either by polarity, frame, or meaning, our pipeline incorporates these three, allowing a more systematic presentation of arguments. Second, we introduce a new dataset consisting of 365 argument graphs accompanying more than 11,000 high-quality arguments that, contrary to previous datasets, have been generated, displayed, and verified by journalists and were published in newspapers. A thorough evaluation with this dataset provides a first baseline for future work.;;;https://dl.acm.org/doi/10.1145/3459637.3482431;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
"Keep it Simple, Lazy" -- MetaLazy: A New MetaStrategy for Lazy Text Classification;;;['Luiz Felipe Mendes', 'Marcos Gonçalves', 'Washington Cunha', 'Leonardo Rocha', 'Thierson Couto-Rosa', 'Wellington Martins'];;;October 2020;;;CIKM '20: Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management;;;Recent advances in text-related tasks on the Web, such as text (topic) classification and sentiment analysis, have been made possible by exploiting mostly the "rule of more": more data (massive amounts) more computing power, more complex solutions. We propose a shift in the paradigm to do "more with less" by focusing, at maximum extent, just on the task at hand (e.g., classify a single test instance). Accordingly, we propose MetaLazy, a new supervised lazy text classification meta-strategy that greatly extends the scope of lazy solutions. Lazy classifiers postpone the creation of a classification model until a given test instance for decision making is given. MetaLazy exploits new ideas and solutions, which have in common their lazy nature, producing altogether a solution for text classification, which is simpler, more efficient, and less data demanding than new alternatives. It extends and evolves the lazy creation of the model for the test instance by allowing: (i) to dynamically choose the best classifier for the task; (ii) the exploration of distances in the neighborhood of the test document when learning a classification model, thus diminishing the importance of irrelevant training instances; and (iii) a better representational space for training and test documents by augmenting them, in a lazy fashion, with new co-occurrence based features considering just those observed in the specific test instance. In a sizeable experimental evaluation, considering topics and sentiment analysis datasets and nine baselines, we show that our MetaLazy instantiations are among the top performers in most situations, even when compared to state-of-the-art deep learning classifiers such as Deep Network Transformer Architectures.;;;https://dl.acm.org/doi/10.1145/3340531.3412180;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Mining Hypernyms Semantic Relations from Stack Overflow;;;['László Tóth', 'Balázs Nagy', 'Tibor Gyimóthy', 'László Vidács'];;;June 2020;;;ICSEW'20: Proceedings of the IEEE/ACM 42nd International Conference on Software Engineering Workshops;;;Communication between a software development team and business partners is often a challenging task due to the different context of terms used in the information exchange. The various contexts in which the concepts are defined or used create slightly different semantic fields that can evolve into information and communication silos. Due to the silo effect, the necessary information is often inadequately forwarded to developers resulting in poorly specified software requirements or misinterpreted user feedback. Communication difficulties can be reduced by introducing a mapping between the semantic fields of the parties involved in the communication based on the commonly used terminologies. Our research aims to obtain a suitable semantic database in the form of a semantic network built from the Stack Overflow corpus, which can be considered to encompass the common tacit knowledge of the software development community. Terminologies used in the business world can be assigned to our semantic network, so software developers do not miss features that are not specific to their world but relevant to their clients. We present an initial experiment of mining semantic network from Stack Overflow and provide insights of the newly captured relations compared to WordNet.;;;https://dl.acm.org/doi/10.1145/3387940.3392160;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Mining Abstract XML Data-Types;;;['Dionysis Athanasopoulos', 'Apostolos Zarras'];;;None;;;ACM Transactions on the Web;;;Schema integration has been a long-standing challenge for the data-engineering community that has received steady attention over the past three decades. General-purpose integration approaches construct unified schemas that encompass all schema elements. Schema integration has been revisited in the past decade in service-oriented computing since the input/output data-types of service interfaces are heterogeneous XML schemas. However, service integration differs from the traditional integration problem, since it should generalize schemas (mining abstract data-types) instead of unifying all schema elements. To mine well-formed abstract data-types, the fundamental Liskov Substitution Principle (LSP), which generally holds between abstract data-types and their subtypes, should be followed. However, due to the heterogeneity of service data-types, the strict employment of LSP is not usually feasible. On top of that, XML offers a rich type system, based on which data-types are defined via combining type patterns (e.g., composition, aggregation). The existing integration approaches have not dealt with the challenges of a defining subtyping relation between XML type patterns. To address these challenges, we propose a relaxed version of LSP between XML type patterns and an automated generalization process for mining abstract XML data-types. We evaluate the effectiveness and the efficiency of the process on the schemas of two datasets against two representative state-of-the-art approaches.;;;https://dl.acm.org/doi/10.1145/3267467;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Classification of Multiple Affective Attributes of Customer Reviews: Using Classical Machine Learning and Deep Learning;;;['Jiawen Wang', 'Wai Ming Wang', 'Zonggui Tian', 'Zhi Li'];;;October 2018;;;CSAE '18: Proceedings of the 2nd International Conference on Computer Science and Application Engineering;;;Affective1 engineering is a methodology of designing products by collecting customer affective needs and translating them into product designs. It usually begins with questionnaire surveys to collect customer affective demands and responses. However, this process is expensive, which can only be conducted periodically in a small scale. With the rapid development of e-commerce, a larger number of customer product reviews are available on the Internet. Many studies have been done using opinion mining and sentiment analysis. However, the existing studies focus on the polarity classification from a single perspective (such as positive and negative). The classification of multiple affective attributes receives less attention. In this paper, 3-class classifications of four different affective attributes (i.e. Soft-Hard, Appealing-Unappealing, Handy-Bulky, and Reliable-Shoddy) are performed by using two classical machine learning algorithms (i.e. Softmax regression and Support Vector Machine) and two deep learning methods (i.e. Restricted Boltzmann machines and Deep Belief Network) on an Amazon dataset. The results show that the accuracy of deep learning methods is above 90%, while the accuracy of classical machine learning methods is about 64%. This indicates that deep learning methods are significantly better than classical machine learning methods.;;;https://dl.acm.org/doi/10.1145/3207677.3277953;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Identifying skill sets for bioinformatics graduate students -a text mining approach;;;['Richard Shang', 'Mohammed Ghriga'];;;None;;;Journal of Computing Sciences in Colleges;;;This project proposes a set of skills to serve as a guideline for bioinformatics curriculum design at the graduate level. Bioinformatics, also known as computational biology, is a burgeoning inter-disciplinary field with a demonstrated market need for highly trained experts who can analyze biological data with skills in computation and informatics. Current trends in bioinformatics incorporate machine learning, large data set analytics and artificial intelligence in the diagnosis, treatment and prevention of illness. Students in graduate programs of Bioinformatics typically expect that courses will prepare them for future job markets with employable skills. In an effort to identify the skill sets sought after by employers in Bioinformatics filed, we apply a text mining approach to analyze required qualifications of Bioinformatics jobs posted online. Using the keyword "bioinformatics", we searched on Google Jobs and collected required qualifications of 38 Bioinformatics jobs. All the jobs indicate that a master's degree is required or preferred. Among the job posts, 14 are under the title "Analyst", 13 under "Scientist", and 11 under "Software Engineer".;;;https://dl.acm.org/doi/10.5555/3344051.3344078;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Statistic Solution for Machine Learning to Analyze Heart Disease Data;;;['Abdur Rasool', 'Ran Tao', 'Kaleem Kashif', 'Waqas Khan', 'Promise Agbedanu', 'Neeta Choudhry'];;;February 2020;;;ICMLC '20: Proceedings of the 2020 12th International Conference on Machine Learning and Computing;;;Data crawling, collection and analysis have become a popular pillar for the business intelligence of big data analysis which is the latest hot-topic among the research association. Numerous tools and techniques to solve and analyze the structured and unstructured datasets are developing very quickly. The previous studies show the different approaches in the identification of the strengths and weaknesses of multiple machine learning algorithms. But, most of the approaches demand more expert knowledge base information to understand the concepts of given data. In this paper, we modernize the machine learning methods for the effective prediction of heart disease. This work deliberates the detailed process of implementation of our proposed system. The goal of this work is to find a strong and effective machine learning algorithm for disease prediction for the problem; how can doctors get fast and better results for their diagnosis of heart disease. We design a new system for disease prediction using machine learning prediction algorithms (LR, ANN and SVC) by utilizing an effective approach of ETL, OLAP and data mining. The results showed that the best machine learning algorithm is SVC with 92% accuracy for the risk prediction model. We found that subjects at 56-64 years old have a high risk of heart disease, as well as men, have more heart disease rate than women. This proposed study can be favorable for the medical practitioners in the field of healthcare, supportive practice and precautions to the heart disease patients.;;;https://dl.acm.org/doi/10.1145/3383972.3384061;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Extended PrefixSpan for Efficient Sequential Pattern Mining in a Game-based Learning Environment;;;['Raymond S. Bermudez', 'Ariel M. Sison', 'Ruji P. Medina'];;;January 2020;;;APIT '20: Proceedings of the 2020 2nd Asia Pacific Information Technology Conference;;;This paper proposed an extended version of PrefixSpan as a better sequential pattern mining for a game-based learning environment (GBLE). The extended version of PrefixSpan evolved on integrating time interval constraints, clustering valued actions and extracting the closed sequences. These three concepts were derived after a previous work showed limitations of PrefixSpan in generating sequence patterns that can be used in tutoring services of a GBLE. The extended PrefixSpan underwent two phases of evaluation, performance evaluation and analyzing the quality of generated sequence patterns. The evaluation results showed that the extended versions provided a significant improvement in terms of execution time and the number of generated sequence patterns. Lastly, it shows significant improvement in the quality of sequence patterns generated as shown in better tutoring service it provided after integrating it to the GBLE.;;;https://dl.acm.org/doi/10.1145/3379310.3381044;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Evolutionary mining of relaxed dependencies from big data collections;;;['Loredana Caruccio', 'Vincenzo Deufemia', 'Giuseppe Polese'];;;June 2017;;;WIMS '17: Proceedings of the 7th International Conference on Web Intelligence, Mining and Semantics;;;Many modern application contexts, especially those related to the semantic Web, advocate for automatic techniques capable of extracting relationships between semi-structured data, for several purposes, such as the identification of inconsistencies or patterns of semantically related data, query rewriting, and so forth. One way to represent such relationships is to use relaxed functional dependencies (rfds), since they can embed approximate matching paradigms to compare unstructured data, and admit the possibility of exceptions for them. To this end, thresholds might need to be specified in order to limit the similarity degree in approximate comparisons or the occurrence of exceptions. Thanks to the availability of huge amount of data, including unstructured data available on the Web, nowadays it is possible to automatically discover rfds from data. However, due to the many different combinations of similarity and exception thresholds, the discovery process has an exponential complexity. Thus, it is vital devising proper optimization strategies, in order to make the discovery process feasible. To this end, in this paper, we propose a genetic algorithm to discover rfds from data, also providing an empirical evaluation demonstrating its effectiveness.;;;https://dl.acm.org/doi/10.1145/3102254.3102259;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Evaluating Extreme Learning Machine Models in the Presence of Concept Drift in Streaming Data;;;['Tagrid Alshalali', 'Darsana Josyula'];;;May 2020;;;ICISDM '20: Proceedings of the 2020 the 4th International Conference on Information System and Data Mining;;;This paper discusses concept drift in online streaming data and evaluates the performance of different Extreme Learning Machine (ELM) based techniques on classifying online streaming data in the presence of concept drift. It also compares the performance of a hybrid model called Online Recurrent ELM (OR-ELM) with traditional recurrent neural networks, in terms of training speed and accuracy, on streaming data that has concept drift. The results of our experiments show that OR-ELM has better accuracy and faster training time.;;;https://dl.acm.org/doi/10.1145/3404663.3404682;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Research Hotspots Mining and Visualized Analysis Based on Linking Cluster and K-Core Decomposition;;;['Ying Cai', 'Fang Huang', 'Shuai Wang', 'Hao Zhang', 'Chunxiu Du'];;;May 2018;;;ICDPA 2018: Proceedings of the International Conference on Data Processing and Applications;;;In this paper, we focus on research hotspots mining with knowledge semantic features on discipline topic word networks, which are extracted from scientific and technical documents. For the topic networks, a novel method of combining linking community clustering with k-core decomposition is proposed to mine the hotspot community with knowledge hierarchy structure. And as a post-processing, the hierarchical community identification is implemented by k-core decomposition in order to discover the internal connection with knowledge semantic hierarchy in the research hotspot. Finally, the community density and visualization method is utilized to analyze the core and sub- problem in the research hotspot community. In experiments, the topic networks for a single discipline and interdisciplinary research hotspot are taken as examples of analysis, and the results show the proposed approach can effectively realize the objective of mining and analyzing the discipline research hotspot on the academic topic word network.;;;https://dl.acm.org/doi/10.1145/3224207.3224216;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Sentimental text processing tool for Russian language based on machine learning algorithms;;;['Mohamed A. Hamada', 'Kamila Sultanbek', 'Bauyrzhan Alzhanov', 'Bauyrzhan Tokbanov'];;;June 2019;;;ICEMIS '19: Proceedings of the 5th International Conference on Engineering and MIS;;;Several studies have been published to analyze different approaches to traditional text classification methods. Most of these studies cover the application of certain methods of semantic terminology to textual classification to a certain extent. However, they are not specifically aimed at the classification algorithms for semantic text and their advantages over the traditional text classification. As it is known, Kazakhstan is a multinational country and Russian is a transnational language. Therefore, it was decided to develop a tool for processing the incoming text in different languages. Actually, there are some existing tools that process text in English, but they do not support some foreign languages, especially that are in use in Kazakhstan. The main goal is to analyze some Machine Learning (ML) algorithms and develop a sentimental text processing tool using those algorithms to make a web page for text processing through categorization and sentimental analysis. It was investigated that the best way to implement Machine Learning and Natural Language Processing (NLP) algorithms on Python is to create a web-page using Django framework. The principle of work is to get the text as input, process it with ML algorithms and send result as a «.json» file.;;;https://dl.acm.org/doi/10.1145/3330431.3335204;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Mining Relationships among Online Review Texts and Ratings in Indonesian E-commerce Websites;;;['Cindy Hosea', 'Rofikoh Rokhim'];;;August 2020;;;BDIOT '20: Proceedings of the 2020 4th International Conference on Big Data and Internet of Things;;;As the most growing sector for Indonesia's internet economy during the last five years, e-commerce generates online customer reviews that can be a source for information and giving hints for potential improvements for various stakeholders. Online reviews consist of review text and rating, each of which describes customer's concern and satisfaction in purchasing items online. However, online review text is unstructured, and its relation with rating is hardly observed. This study examines 132,085 online reviews about Xiaomi mobile phones on three major e-commerce websites in Indonesia: Shopee, Bukalapak, and Blibli by text mining and quantitative modeling to correlate reviews with ratings. Online reviews are classified into eight distinct topics, and the relationships between each topic and review rating are analyzed. Multilinear regression is implemented to examine the valence and strength in the relationship between each topic-rating. The result shows that there are more topics with a negative relationship with rating, with several topic differences between the three websites. Further improvements should be focused on the most impactful topics, which are referred to the mobile phone features, such as CPU & hardware, system, and physical appearance. After-sales service is also concerned at Bukalapak and Blibli. These relationships are explained further by the valence expressed by customers in review texts. The implications of this study can be applied for academic purposes, e-commerce companies, customers, sellers, and mobile phone companies.;;;https://dl.acm.org/doi/10.1145/3421537.3421543;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Feature-based Restaurant Customer Reviews Process Model using Data Mining;;;['Anish Kumar Varudharajulu', 'Yongsheng Ma'];;;September 2018;;;ICCBD '18: Proceedings of the 2018 International Conference on Computing and Big Data;;;Mining social media is a popular strategy to revitalize any business. The social media lodges colossal amount of user spawn data which can be used for data mining. The purpose of this research paper is to develop a feature-based software model to analyze customer reviews of an organization using their Facebook page and provide valuable insights for decision making, product quality development, and process improvements. Thus enabling concurrent engineering activities and enhancing collaboration between various departments within the organization. As a sample case study, we have analyzed the customer reviews of a restaurant using the J48 classification algorithm and K-means clustering algorithm to identify areas which need improvement. Results show that customers are giving more importance to features such as the taste, variety of drinks, price, and service, In addition, customers are least bothered about the location, offers, and ambiance of the South Indian restaurant under study.;;;https://dl.acm.org/doi/10.1145/3277104.3277113;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Research on Cold Chain Logistics Risk in E-commerce Using Text Mining Technology;;;['Jingyu Bo'];;;January 2020;;;ICCMB '20: Proceedings of the 2020 the 3rd International Conference on Computers in Management and Business;;;In recent years, with the rapid development of e-commerce and Internet, more and more products transfer to the information-based transformation. Numerous of goods such as fresh products are turning to online sales model. Selling fresh agricultural products on e-commerce platform can not only broaden the sales channels and increase the profits of peasants but also enable people to buy high-quality fresh products. However, at the same time we cannot ignore that due to the relatively slow development of cold supply chain, there are still a lot of problems. For example, untimely and unreasonable transportation will cause fresh products are corrupted and deteriorated in the transportation process every year, which damages the interests of supply chain members. Accurate identification and quantitative analysis of supply chain hazards have great significance in the improvement of transport efficiency of supply chain and reducing the transport cost of supply chain. This paper indicates the methods of literature analysis to collect and summarize the relevant keywords in the theory of supply chain risk and uses text mining technology to collect and analyze supply chain risk in CNKI literatures. It catches those literatures containing keywords about supply chain risk in database, stores the related information in the Excel. Then it calculates the frequency of each keyword appears in the final statistics. Then it removes the supply chain risk factors that have less attention. At last, using the analytic hierarchy process (AHP) to quantitatively analyze and evaluate the risks in the cold supply chain of fresh agricultural products. Finally, the weight of risks in the cold supply chain of fresh agricultural products is calculated.;;;https://dl.acm.org/doi/10.1145/3383845.3383853;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Application of Data Mining in English Linguistics Teaching and Appraisal System;;;['Wei Zhang', 'Xue Wang'];;;October 2020;;;AIAM2020: Proceedings of the 2nd International Conference on Artificial Intelligence and Advanced Manufacture;;;The data mining algorithm based on rough set plays a very important role in dealing with various application-oriented problems. The suitable algorithm can quickly and accurately mine the core of time attribute and simplify the problem. Based on the characteristics of the teaching and appraise system of English linguistics, this paper optimizes the teaching design of English Linguistics in terms of teaching. Under the framework of systemic functional linguistics, this paper makes a follow-up analysis of the appraise resources in English texts, and verifies the feasibility and effectiveness of this method through an example. Some key problems of English linguistics teaching and price system are solved by data mining algorithm.;;;https://dl.acm.org/doi/10.1145/3421766.3421824;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Model-based Clustering of Short Text Streams;;;['Jianhua Yin', 'Daren Chao', 'Zhongkun Liu', 'Wei Zhang', 'Xiaohui Yu', 'Jianyong Wang'];;;July 2018;;;KDD '18: Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining;;;Short text stream clustering has become an increasingly important problem due to the explosive growth of short text in diverse social medias. In this paper, we propose a model-based short text stream clustering algorithm (MStream) which can deal with the concept drift problem and sparsity problem naturally. The MStream algorithm can achieve state-of-the-art performance with only one pass of the stream, and can have even better performance when we allow multiple iterations of each batch. We further propose an improved algorithm of MStream with forgetting rules called MStreamF, which can efficiently delete outdated documents by deleting clusters of outdated batches. Our extensive experimental study shows that MStream and MStreamF can achieve better performance than three baselines on several real datasets.;;;https://dl.acm.org/doi/10.1145/3219819.3220094;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Bayesian Attribute Bagging-Based Extreme Learning Machine for High-Dimensional Classification and Regression;;;['Yulin He', 'Xuan Ye', 'Joshua Zhexue Huang', 'Philippe Fournier-Viger'];;;None;;;ACM Transactions on Intelligent Systems and Technology;;;This article presents a Bayesian attribute bagging-based extreme learning machine (BAB-ELM) to handle high-dimensional classification and regression problems. First, the decision-making degree (DMD) of a condition attribute is calculated based on the Bayesian decision theory, i.e., the conditional probability of the condition attribute given the decision attribute. Second, the condition attribute with the highest DMD is put into the condition attribute group (CAG) corresponding to the specific decision attribute. Third, the bagging attribute groups (BAGs) are used to train an ensemble learning model of extreme learning machines (ELMs). Each base ELM is trained on a BAG which is composed of condition attributes that are randomly selected from the CAGs. Fourth, the information amount ratios of bagging condition attributes to all condition attributes is used as the weights to fuse the predictions of base ELMs in BAB-ELM. Exhaustive experiments have been conducted to compare the feasibility and effectiveness of BAB-ELM with seven other ELM models, i.e., ELM, ensemble-based ELM (EN-ELM), voting-based ELM (V-ELM), ensemble ELM (E-ELM), ensemble ELM based on multi-activation functions (MAF-EELM), bagging ELM, and simple ensemble ELM. Experimental results show that BAB-ELM is convergent with the increase of base ELMs and also can yield higher classification accuracy and lower regression error for high-dimensional classification and regression problems.;;;https://dl.acm.org/doi/10.1145/3495164;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Aggregating Filter Feature Selection Methods to Enhance Multiclass Text Classification;;;['Rhodessa J. Cascaro', 'Bobby D. Gerardo', 'Ruji P. Medina'];;;December 2019;;;ICIT '19: Proceedings of the 2019 7th International Conference on Information Technology: IoT and Smart City;;;Text data usage has increased rapidly and simultaneously resulted in setbacks, such as high dimensionality of text data becoming a prominent problem. Hence, this study aimed to assess the application of filter feature selection techniques on text data. In this study, features were ranked from highest to lowest by the selected filter feature selection methods in each generated feature subset. Thereafter, a new feature subset was obtained using the proposed method. This study yielded that the accuracy of Information Gain is 1.12 percentage points higher in comparison to the accuracy of Chi-square. Moreover, classification accuracy obtained from aggregation exhibits a rise of 0.93 percentage points compared to the accuracy of Information Gain and 2.05 percentage points against Chi-square. Classification accuracy improved when the features are aggregated. On Precision, in comparison to that of the aggregation, results show the differences in percentage points of 1.41 and significant 11.64 for Information Gain and Chi-square respectively. About Recall, there is a 5.54 percentage points improvement on Information Gain and 3.03 percentage points improvement on Chi-square. Then, in F1, the score for aggregation is quite low. It may mean that the classifier has problems with false positives or false negatives. Thus, the classifier needs to be checked using a confusion matrix or check on the dataset, which was not done in the experiment. Dataset imbalance was also not addressed in this study. For future work, the imbalanced class-dataset issue should be addressed. Also, the performance of other filter methods could be compared as well as utilize other classifiers that support multiclass tasks to determine which is suitable for multiclass text classification.;;;https://dl.acm.org/doi/10.1145/3377170.3377209;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Classification of public elementary students' game play patterns in a digital game-based learning system with pedagogical agent;;;['Prometheus Peter L. Lazo', 'Chris Lionel Q. Anareta', 'Jule Brianne T. Duremdes', 'Ellenita R. Red'];;;January 2018;;;ICIET '18: Proceedings of the 6th International Conference on Information and Education Technology;;;This study investigates gameplay attributes that were used to classify student performance in a digital game-based learning system to determine if it will contribute to achieving learning gain. The study was conducted in selected public elementary schools which comprised of 10% of all grade four students in each school visited. Word Infection Version 4, a local-area-network digital game-based learning (DGBL) system with a pedagogical agent, and a pretest and posttest module which served as the tool to collect gameplay logs of students were developed. Also, a dashboard tool was developed to manage, facilitate and administer the game in a distributed network. Usability test results showed strong agreement on its usability, aesthetics and usefulness. Log attributes, gameplay patterns, and performance of elementary students' vocabulary learning were recorded then described using K-means algorithm to determine the different clusters of students' gameplay patterns and performance while using the system. Four clusters were produced to represent the different gameplay styles of the students: gaming, proficient, productive and idle. A model that classified game play patterns of student's performance using Naïve Bayes and J48 algorithms was produced. The accuracy and kappa statistic of the produced models were determined. Higher ratings in accuracy and kappa statistic were yielded by the decision tree algorithm; 52.34% and 0.216 respectively in comparison 42.88% and 0.062 respectively from Naïve Bayes.;;;https://dl.acm.org/doi/10.1145/3178158.3178160;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Information-theoretic classification accuracy: a criterion that guides data-driven combination of ambiguous outcome labels in multi-class classification;;;['Chihao Zhang', 'Yiling Elaine Chen', 'Shihua Zhang', 'Jingyi Jessica Li'];;;None;;;The Journal of Machine Learning Research;;;Outcome labeling ambiguity and subjectivity are ubiquitous in real-world datasets. While practitioners commonly combine ambiguous outcome labels for all data points (instances) in an ad hoc way to improve the accuracy of multi-class classification, there lacks a principled approach to guide the label combination for all data points by any optimality criterion. To address this problem, we propose the information-theoretic classification accuracy (ITCA), a criterion that balances the trade-off between prediction accuracy (how well do predicted labels agree with actual labels) and classification resolution (how many labels are predictable), to guide practitioners on how to combine ambiguous outcome labels. To find the optimal label combination indicated by ITCA, we propose two search strategies: greedy search and breadth-first search. Notably, ITCA and the two search strategies are adaptive to all machine-learning classification algorithms. Coupled with a classification algorithm and a search strategy, ITCA has two uses: improving prediction accuracy and identifying ambiguous labels. We first verify that ITCA achieves high accuracy with both search strategies in finding the correct label combinations on synthetic and real data. Then we demonstrate the effectiveness of ITCA in diverse applications, including medical prognosis, cancer survival prediction, user demographics prediction, and cell type classification. We also provide theoretical insights into ITCA by studying the oracle and the linear discriminant analysis classification algorithms. Python package itca (available at https://github.com/JSB-UCLA/ITCA) implements ITCA and the search strategies.;;;https://dl.acm.org/doi/10.5555/3586589.3586930;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
SynTF: Synthetic and Differentially Private Term Frequency Vectors for Privacy-Preserving Text Mining;;;['Benjamin Weggenmann', 'Florian Kerschbaum'];;;June 2018;;;SIGIR '18: The 41st International ACM SIGIR Conference on Research &amp; Development in Information Retrieval;;;Text mining and information retrieval techniques have been developed to assist us with analyzing, organizing and retrieving documents with the help of computers. In many cases, it is desirable that the authors of such documents remain anonymous: Search logs can reveal sensitive details about a user, critical articles or messages about a company or government might have severe or fatal consequences for a critic, and negative feedback in customer surveys might negatively impact business relations if they are identified. Simply removing personally identifying information from a document is, however, insufficient to protect the writer's identity: Given some reference texts of suspect authors, so-called authorship attribution methods can reidentfy the author from the text itself. One of the most prominent models to represent documents in many common text mining and information retrieval tasks is the vector space model where each document is represented as a vector, typically containing its term frequencies or related quantities. We therefore propose an automated text anonymization approach that produces synthetic term frequency vectors for the input documents that can be used in lieu of the original vectors. We evaluate our method on an exemplary text classification task and demonstrate that it only has a low impact on its accuracy. In contrast, we show that our method strongly affects authorship attribution techniques to the level that they become infeasible with a much stronger decline in accuracy. Other than previous authorship obfuscation methods, our approach is the first that fulfills differential privacy and hence comes with a provable plausible deniability guarantee.;;;https://dl.acm.org/doi/10.1145/3209978.3210008;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Maximally informative k-itemset mining from massively distributed data streams;;;['Mehdi Zitouni', 'Reza Akbarinia', 'Sadok Ben Yahia', 'Florent Masseglia'];;;April 2018;;;SAC '18: Proceedings of the 33rd Annual ACM Symposium on Applied Computing;;;We address the problem of mining maximally informative k-itemsets (miki) in data streams based on joint entropy. We propose PentroS, a highly scalable parallel miki mining algorithm. PentroS renders the mining process of large volumes of incoming data very efficient. It is designed to take into account the continuous aspect of data streams, particularly by reducing the computations of need for updating the miki results after arrival/departure of transactions to/from the sliding window. PentroS has been extensively evaluated using massive real-world data streams. Our experimental results confirm the effectiveness of our proposal which allows excellent throughput with high itemset length.;;;https://dl.acm.org/doi/10.1145/3167132.3167187;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Application analysis of computer web data mining technology in E-commerce;;;['Huiting Ju', 'Hui Wang'];;;October 2021;;;EITCE '21: Proceedings of the 2021 5th International Conference on Electronic Information Technology and Computer Engineering;;;With the development of the Internet, the proportion of e-commerce in people's life is becoming larger and larger. Online shopping has become a major way of shopping and helped people improve their life efficiency. Web data mining technology is a very important technology in e-commerce. The web can deeply mine and analyze the access methods, interest preferences, group characteristics and so on of e-commerce users. These information can help e-commerce push different user groups, and greatly improve the overall promotion effect and benefit of e-commerce. Starting from the web data mining technology, this paper expounds the application process of Web data mining technology used in e-commerce in detail, so as to provide a certain reference for the development of e-commerce.;;;https://dl.acm.org/doi/10.1145/3501409.3501626;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
InFoRM: Individual Fairness on Graph Mining;;;['Jian Kang', 'Jingrui He', 'Ross Maciejewski', 'Hanghang Tong'];;;August 2020;;;KDD '20: Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining;;;Algorithmic bias and fairness in the context of graph mining have largely remained nascent. The sparse literature on fair graph mining has almost exclusively focused on group-based fairness notation. However, the notion of individual fairness, which promises the fairness notion at a much finer granularity, has not been well studied. This paper presents the first principled study of Individual Fairness on gRaph Mining (InFoRM). First, we present a generic definition of individual fairness for graph mining which naturally leads to a quantitative measure of the potential bias in graph mining results. Second, we propose three mutually complementary algorithmic frameworks to mitigate the proposed individual bias measure, namely debiasing the input graph, debiasing the mining model and debiasing the mining results. Each algorithmic framework is formulated from the optimization perspective, using effective and efficient solvers, which are applicable to multiple graph mining tasks. Third, accommodating individual fairness is likely to change the original graph mining results without the fairness consideration. We conduct a thorough analysis to develop an upper bound to characterize the cost (i.e., the difference between the graph mining results with and without the fairness consideration). We perform extensive experimental evaluations on real-world datasets to demonstrate the efficacy and generality of the proposed methods.;;;https://dl.acm.org/doi/10.1145/3394486.3403080;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Sequential Cross-Modal Hashing Learning via Multi-scale Correlation Mining;;;['Zhaoda Ye', 'Yuxin Peng'];;;None;;;ACM Transactions on Multimedia Computing, Communications, and Applications;;;Cross-modal hashing aims to map heterogeneous multimedia data into a common Hamming space through hash function, and achieves fast and flexible cross-modal retrieval. Most existing cross-modal hashing methods learn hash function by mining the correlation among multimedia data, but ignore the important property of multimedia data: Each modality of multimedia data has features of different scales, such as texture, object, and scene features in the image, which can provide complementary information for boosting retrieval task. The correlations among the multi-scale features are more abundant than the correlations between single features of multimedia data, which reveal finer underlying structures of the multimedia data and can be used for effective hashing function learning. Therefore, we propose the Multi-scale Correlation Sequential Cross-modal Hashing (MCSCH) approach, and its main contributions can be summarized as follows: (1) Multi-scale feature guided sequential hashing learning method is proposed to share the information from features of different scales through an RNN-based network and generate the hash codes sequentially. The features of different scales are used to guide the hash codes generation, which can enhance the diversity of the hash codes and weaken the influence of errors in specific features, such as false object features caused by occlusion. (2) Multi-scale correlation mining strategy is proposed to align the features of different scales in different modalities and mine the correlations among aligned features. These correlations reveal the finer underlying structure of multimedia data and can help to boost the hash function learning. (3) Correlation evaluation network evaluates the importance of the correlations to select the worthwhile correlations, and increases the impact of these correlations for hash function learning. Experiments on two widely-used 2-media datasets and a 5-media dataset demonstrate the effectiveness of our proposed MCSCH approach.;;;https://dl.acm.org/doi/10.1145/3356338;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A New System For Audio Mining: Using of MDT+ for automatic prediction of new singers success;;;['Faiz Maazouzi', 'Hafed Zarzour', 'Halima Bahi'];;;December 2018;;;ICSENT 2018: Proceedings of the 7th International Conference on Software Engineering and New Technologies;;;Online music diffusion and distribution is becoming increasingly important and commercial and personal databases are increasing in a considerable way. Nowadays, it's necessary to have tools that allow classifying and reaching these bases by carrying out analyzes through musical contents. The work included in this paper consists of automatic prediction of new singers success. This work lies within the scope of audio mining including of the heterogeneous data. Work can be divided into two parts: in the first part, we treat the audio data to make a classification of the Algerian singers' voices. There exist two categories of the singing voices classification (type and quality), each category has several classes. Within this framework, we proposed to use a vector of characteristics which contains the descriptors of MPEG-7 + the descriptors Not-MPEG-7 and Standard T2 FGMMs "Type 2 Fuzzy Gaussian Mixture Models" for modeling and classification of singing voice. By using the results of the singing voices classification with the statistics of every singer, a new database has been created. The second part of work consists of the data mining to answer our starting question "are our young people's musical tastes poor". In this part, we proposed a new method of data excavation, based on the decision trees called: Multi Decision Tree (MDT+). Finally, we used the MDT+ method to excavate our database.;;;https://dl.acm.org/doi/10.1145/3330089.3330102;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Overlapping Clustering for Textual Data;;;['Atefeh Khazaei', 'Mohammad Ghasemzadeh', 'Dieter Gollmann'];;;February 2018;;;ICSCA '18: Proceedings of the 2018 7th International Conference on Software and Computer Applications;;;Texts have inherent overlapping, therefore for clustering textual data, the overlapping clustering algorithms are more appropriate. In this regard, a major challenge is that they are very slow in clustering big volumes of textual data. Among others, OKM and OSOM are two important overlapping clustering algorithms. In this study, we have implemented and compared the performance of these two algorithms. The experimental results of our study show that OKM clusters have better overlap sizes when these algorithms are used for clustering textual data. Since both of them require much time to complete, none of these two algorithms is suitable for clustering textual data. Therefore we mastermind a fast overlapping version of SOM which is suitable for this purpose.;;;https://dl.acm.org/doi/10.1145/3185089.3185113;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Semi-Unsupervised Lifelong Learning for Sentiment Classification: Less Manual Data Annotation and More Self-Studying;;;['Xianbin Hong', 'Gautam Pal', 'Sheng-Uei Guan', 'Prudence Wong', 'Dawei Liu', 'Ka Lok Man', 'Xin Huang'];;;June 2019;;;HPCCT '19: Proceedings of the 2019 3rd High Performance Computing and Cluster Technologies Conference;;;Lifelong machine learning is a novel machine learning paradigm which can continually accumulate knowledge during learning. The knowledge extracting and reusing abilities enable the lifelong machine learning to solve the related problems. The traditional approaches like Naïve Bayes and some neural network based approaches only aim to achieve the best performance upon a single task. Unlike them, the lifelong machine learning in this paper focus on how to accumulate knowledge during learning and leverage them for the further tasks. Meanwhile, the demand for labeled data for training also be significantly decreased with the knowledge reusing. This paper suggests that the aim of the lifelong learning is to use less labeled data and computational cost to achieve the performance as well as or even better than the supervised learning.;;;https://dl.acm.org/doi/10.1145/3341069.3342992;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Multi-Modal Knowledge Representation Learning via Webly-Supervised Relationships Mining;;;['Fudong Nian', 'Bing-Kun Bao', 'Teng Li', 'Changsheng Xu'];;;October 2017;;;MM '17: Proceedings of the 25th ACM international conference on Multimedia;;;Knowledge representation learning (KRL) encodes enormous structured information with entities and relations into a continuous low-dimensional semantic space. Most conventional methods solely focus on learning knowledge representation from single modality, yet neglect the complementary information from others. The more and more rich available multi-modal data on Internet also drive us to explore a novel approach for KRL in multi-modal way, and overcome the limitations of previous single-modal based methods. This paper proposes a novel multi-modal knowledge representation learning (MM-KRL) framework which attempts to handle knowledge from both textual and visual modal web data. It consists of two stages, i.e., webly-supervised multi-modal relationship mining, and bi-enhanced cross-modal knowledge representation learning. Compared with existing knowledge representation methods, our framework has several advantages: (1) It can effectively mine multi-modal knowledge with structured textual and visual relationships from web automatically. (2) It is able to learn a common knowledge space which is independent to both task and modality by the proposed Bi-enhanced Cross-modal Deep Neural Network (BC-DNN). (3) It has the ability to represent unseen multi-modal relationships by transferring the learned knowledge with isolated seen entities and relations into unseen relationships. We build a large-scale multi-modal relationship dataset (MMR-D) and the experimental results show that our framework achieves excellent performance in zero-shot multi-modal retrieval and visual relationship recognition.;;;https://dl.acm.org/doi/10.1145/3123266.3123443;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Fishing Techniques Classification Based on Beidou Trajectories and Machine Learning;;;['Yao Li', 'Nanyu Chen', 'Luo Chen'];;;April 2020;;;ICGDA '20: Proceedings of the 2020 3rd International Conference on Geoinformatics and Data Analysis;;;Beidou navigation information is widely used in Chinese fisheries. It helps fishermen to locate themselves and hedge. Compared with the data ashore, analysis of satellite data on the ocean is still not enough. Inspired by vehicle trajectory analysis, we want to do some analysis on boat trajectories. Fishing techniques are various, so their trajectories. In this paper, we choose 3 fishing techniques (Trawling, seining and gillnetting). We implement classification with two different algorithms. One of them is ResNet which belongs to image classification with deep learning. The other one is LightGBM which is a kind of decision tree algorithm. The result shows that although deep learning has made great success in daily life images classification, it adds too much redundant pixels and ignore the speed and direction parameters in this task. This leads to a lower precision and more calculations. In contrast, LightGBM can use information effectively and has a higher score with a higher speed. This work shows traditional machine learning algorithm can achieve better result than deep learning algorithm in some circumstance. It will also contribute to establish a smart ocean system.;;;https://dl.acm.org/doi/10.1145/3397056.3397072;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Text mining as a transparency enabler to support decision making in a people management process;;;['José Barroso Júnior', 'Claudia Cappelli', 'Kate Revoredo', 'Vanessa Nunes'];;;May 2018;;;dg.o '18: Proceedings of the 19th Annual International Conference on Digital Government Research: Governance in the Data Age;;;This paper discusses a case study that was performed using mining techniques to analyze data pertinent to a people management process of a Federal University. This process consists in observing documents containing data concerning the organizational environment, the duties required by the position, the course program carried out by the employee, and whether they have direct or indirect correlation. Currently, this correlation evaluation is performed subjectively and there are no instruments that can indicate the degree of similarity between the information. We use text mining techniques to automatically identify correlation through textual representation approaches and syntactic and semantic modeling, which retrieve terms and dimension their respective meanings. To obtain the degree of similarity between the respective documents, the measure of the cosines similarity was used. The results showed that the documents evaluated as correlated by the domain expert presented a degree of similarity consistent with the automatic evaluation. For the uncorrelated cases, it was perceived that the degree of high similarity was influenced by the comprehensiveness of the organizational environment common to all documents. After investigation and identification of the appropriate environment specification, the grades obtained represented the evaluation correctly. The proposed approach contributes to the speed of process judgment, as well as to promote formulations of criticism about the content of political qualifications. In addition, it enhanced processes and information transparency by tracking and publicizing all steps. Lastly, we present a simulation for a course recommendation task, considering position profiles and organizational environment.;;;https://dl.acm.org/doi/10.1145/3209281.3209367;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Minimal learning machine: theoretical results and clustering-based reference point selection;;;['Joonas Hämäläin', 'Alisson S. C. Alencar', 'Tommi Kärkkäinen', 'César L. C. Mattos', 'Amauri H. Souza Júnior', 'João P. P. Gomes'];;;None;;;The Journal of Machine Learning Research;;;The Minimal Learning Machine (MLM) is a nonlinear, supervised approach based on learning linear mapping between distance matrices computed in input and output data spaces, where distances are calculated using a subset of points called reference points. Its simple formulation has attracted several recent works on extensions and applications. In this paper, we aim to address some open questions related to the MLM. First, we detail the theoretical aspects that assure the MLM's interpolation and universal approximation capabilities, which had previously only been empirically verified. Second, we identify the major importance of the task of selecting reference points for the MLM's generalization capability. Several clustering-based methods for reference point selection in regression scenarios are then proposed and analyzed. Based on an extensive empirical evaluation, we conclude that the evaluated methods are both scalable and useful. Specifically, for a small number of reference points, the clustering-based methods outperform the standard random selection of the original MLM formulation.;;;https://dl.acm.org/doi/10.5555/3455716.3455955;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Twitter Data Classification Using Big Data Technologies;;;['Madani Youness', 'Erritali Mohammed', 'Bengourram Jamaa'];;;April 2018;;;ICIEB '18: Proceedings of the 2018 1st International Conference on Internet and e-Business;;;Tweets classification or in general the classification of the social network's data is a recent field of scientific research, where researchers look for new methods to classify users data (tweets, Facebook's post...) into classes (positive, negative, neutral).This type of scientific research called sentiment analysis (SA) or opinion mining and it allows to extract the feelings, opinions or attitudes expressed in a tweet or a facebook post ... In this article, we describe how we can collect and store a large volume of data, which is in the form of tweets, in Hadoop Distributed File System (HDFS), and how we can classify these tweets using different classification methods, making a comparison between the well-known machine learning algorithms and a dictionary based-approach using the AFINN dictionary. The experimental results show that the AFINN dictionary outperforms the well-known machine learning algorithms.;;;https://dl.acm.org/doi/10.1145/3230348.3230368;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A study of leaf classification based on multi machine learning models;;;['Yixuan Zhao'];;;October 2020;;;ICASIT 2020: Proceedings of the 2020 International Conference on Aviation Safety and Information Technology;;;Leaf classification identification is important for identifying new or scarce tree species. In this paper, a traditional machine learning approach is utilized to classify tree leaves exploring the data set of leaf characteristics provided by Kaggle. First, the data is analyzed and pre-processed. Second, different classifiers are chosen to classify the data set and compare the classification results. Finally, the classification results are validated using the test set data, i.e., leaf species prediction is performed for each image. The experimental comparison revealed that the selected Linear Discriminant Analysis model achieved good results on this data set. It provides a reference for leaf species identification and classification or other related studies.;;;https://dl.acm.org/doi/10.1145/3434581.3434636;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Iteratively Divide-and-Conquer Learning for Nonlinear Classification and Ranking;;;['Ou Wu', 'Xue Mao', 'Weiming Hu'];;;None;;;ACM Transactions on Intelligent Systems and Technology;;;Nonlinear classifiers (i.e., kernel support vector machines (SVMs)) are effective for nonlinear data classification. However, nonlinear classifiers are usually prohibitively expensive when dealing with large nonlinear data. Ensembles of linear classifiers have been proposed to address this inefficiency, which is called the ensemble linear classifiers for nonlinear data problem. In this article, a new iterative learning approach is introduced that involves two steps at each iteration: partitioning the data into clusters according to Gaussian mixture models with local consistency and then training basic classifiers (i.e., linear SVMs) for each cluster. The two divide-and-conquer steps are combined into a graphical model. Meanwhile, with training, each classifier is regarded as a task; clustered multitask learning is employed to capture the relatedness among different tasks and avoid overfitting in each task. In addition, two novel extensions are introduced based on the proposed approach. First, the approach is extended for quality-aware web data classification. In this problem, the types of web data vary in terms of information quality. The ignorance of the variations of information quality of web data leads to poor classification models. The proposed approach can effectively integrate quality-aware factors into web data classification. Second, the approach is extended for listwise learning to rank to construct an ensemble of linear ranking models, whereas most existing listwise ranking methods construct a solely linear ranking model. Experimental results on benchmark datasets show that our approach outperforms state-of-the-art algorithms. During prediction for nonlinear classification, it also obtains comparable classification performance to kernel SVMs, with much higher efficiency.;;;https://dl.acm.org/doi/10.1145/3122802;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Machine Learning Approach for Malware Detection Using Random Forest Classifier on Process List Data Structure;;;['Santosh Joshi', 'Himanshu Upadhyay', 'Leonel Lagos', 'Naga Suryamitra Akkipeddi', 'Valerie Guerra'];;;April 2018;;;ICISDM '18: Proceedings of the 2nd International Conference on Information System and Data Mining;;;As computer systems have become an integral part of every organization, it is a big challenge to safeguard the computer systems from malicious activities which compromise not only the systems but also the data stored within. Traditional malware and rootkit detection using antivirus systems are not dynamic enough to capture the complex behavior of malware and its isolated activities. There are many signature-based malware detection techniques have been introduced, but enterprises as well as general users are still facing problems to get protection for their cyber systems against malware. Thus, it emphasizes the necessity of developing an efficient malware detection technique. In this research paper, we design a machine learning approach for malware detection using Random Forest classifier for the process list data extracted from Linux based virtual machine environment.;;;https://dl.acm.org/doi/10.1145/3206098.3206113;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Exploiting Translation Model for Parallel Corpus Mining;;;['Chongman Leong', 'Xuebo Liu', 'Derek F. Wong', 'Lidia S. Chao'];;;None;;;IEEE/ACM Transactions on Audio, Speech and Language Processing;;;Parallel corpus mining (PCM) is beneficial for many corpus-based natural language processing tasks, e.g., machine translation and bilingual dictionary induction, especially in low-resource languages and domains. It relies heavily on cross-lingual representations to model the interdependencies between different languages and determine whether sentences are parallel or not. In this paper, we take the first step towards exploiting the multilingual Transformer translation model to produce expressive sentence representations for PCM. Since the traditional Transformer lacks an immediate sentence representation, we pool the output representation of the encoder as the sentence representation, which is further optimized as a part of the training flow of the translation model. Experiments conducted on the BUCC PCM task show that the proposed method improves mining performance over the existing methods with the assistance of the pre-trained multilingual BERT. To further test the usability of the proposed method, we mine parallel sentences from public resources and find that the mined sentences can indeed enhance low-resource machine translation.;;;https://dl.acm.org/doi/10.1109/TASLP.2021.3105798;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Scholarly data mining: making sense of scientific literature;;;['Horacio Saggion', 'Francesco Ronzano'];;;June 2017;;;JCDL '17: Proceedings of the 17th ACM/IEEE Joint Conference on Digital Libraries;;;During the last decade the amount of scientific information available on-line increased at an unprecedented rate and this situation is unlikely to change. As a consequence, nowadays researchers are overwhelmed by an enormous and continuously growing number of publications to consider when they perform research activities like the exploration of advances in specific topics, peer reviewing, writing and evaluation of proposals. Natural Language Processing technology plays a key role in enabling intelligent access to the content of scientific publications. By mining the contents of scientific papers, for example, rich scientific knowledge bases can be built, thus supporting more effective information discovery and question answering approaches. Moreover, text summarization technology can help condense long papers to their essential contents so as to speed up the selection of scientific articles of interest or to assist in the manual or automatic generation of state of the art reports. Paraphrase and textual entailment techniques can contribute to the identification of relations across different scientific textual sources, thus, for instance, identifying implicit links between publications. This tutorial provides an overview of approaches to the extraction of knowledge from scientific literature, including the in-depth analysis of the structure of the scientific articles, their semantic interpretation, content extraction, summarization, and visualization.;;;https://dl.acm.org/doi/10.5555/3200334.3200406;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Social Media Mining: Prediction of Box Office Revenue;;;['Deepankar Choudhery', 'Carson K. Leung'];;;July 2017;;;IDEAS '17: Proceedings of the 21st International Database Engineering &amp; Applications Symposium;;;In recent years, social media has played a huge role in how we share and communicate our thoughts and opinions. This information can very valuable for companies and governments as it can be used to analyze public mood and opinion which is a very powerful tool. In this paper, we present a system that mines social media content from a platform such as Twitter for predicting future outcomes. Specifically, it uses chatter from Twitter to predict box office revenue of movies by extracting features such as tweets and their sentiments. Then, by using these features, our system constructs a polynomial regression model for predicting box office revenue. Experimental results show the effectiveness of our system in mining social media and predicting box office revenue.;;;https://dl.acm.org/doi/10.1145/3105831.3105854;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Mining Moodle Logs for Grade Prediction: A methodology walk-through;;;['Álvaro Figueira'];;;October 2017;;;TEEM 2017: Proceedings of the 5th International Conference on Technological Ecosystems for Enhancing Multiculturality;;;Research concerning mining data from learning management systems have been consistently been appearing in the literature. However, in many situations there is not a clear path on the data mining procedures that lead to solid conclusions. Therefore, many studies result in ad-hoc conclusions with insufficient generalization capabilities. In this article, we describe a methodology and report our findings in an experiment which one online course which involved more than 150 students. We used the Moodle LMS during the period of one academic semester, collecting all the interactions between the students and the system. These data scales up to more than 33K records of interactions where we applied data mining tools following the procedure for data extraction, cleaning, feature identification and preparation. We then proceeded to the creation of automatic learning models based on decision trees, we assessed the models and validate the results by assessing the accuracy of the predictions using traditional metrics and draw our conclusions on the validity of the process and possible alternatives1.;;;https://dl.acm.org/doi/10.1145/3144826.3145394;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
An Effective Bridge Cracks Classification Method Based on Machine Learning;;;['Xiaoyan Zhang', 'Xiaodong Wang'];;;November 2020;;;EITCE '20: Proceedings of the 2020 4th International Conference on Electronic Information Technology and Computer Engineering;;;Crack is the most common threat to the safety of bridges. Historical data show that the safety accidents caused by cracks account for more than 90% of the total bridge disasters. After a long period of engineering practice and rigorous theoretical analysis, it was found that 0.3 mm is the maximum allowable for bridge cracks. If the width exceeds the limit, the integrity of the bridge will be destroyed, and even a collapse accident will occur. Therefore, it is important to identify cracks in bridge structure effectively and provide information for structural disaster reduction projects in time. With the development of machine learning, bridge crack detection and classification based on deep learning has been paid more attention. This paper designs a bridge crack classification algorithm based on convolution neural network and support vector machine. Firstly, the captured image data are divided into training set and test set. Secondly, they are preprocessing and extracted features by convolution neural network. Lastly, they are classified by SVM. The proposed algorithm can solve the problems of insufficient samples and low classification accuracy, and realizes the effective and accurate classification.;;;https://dl.acm.org/doi/10.1145/3443467.3443855;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Mapping Ordinances and Tweets using Smart City Characteristics to Aid Opinion Mining;;;['Manish Puri', 'Xu Du', 'Aparna S. Varde', 'Gerard de Melo'];;;April 2018;;;WWW '18: Companion Proceedings of the The Web Conference 2018;;;This research focuses on mining ordinances (local laws) and public reactions to them expressed on social media. We place particular emphasis on ordinances and tweets relating to Smart City Characteristics (SCCs), since an important aim of our work is to assess how well a given region heads towards a Smart City. We rely on SCCs as a nexus between a seemingly infinite number of ordinances and tweets to be able to map them, and also to facilitate SCC-based opinion mining later for providing feedback to urban agencies based on public reactions. Common sense knowledge is harnessed in our approach to reflect human judgment in mapping. This paper presents our research in ordinance and tweet mapping with SCCs, including the proposed mapping approach, our initial experiments, related discussion, and future work emerging therein. To the best of our knowledge, ours is among the first works to conduct mining on ordinances and tweets for Smart Cities. This work has a broader impact with a vision to enhance Smart City growth.;;;https://dl.acm.org/doi/10.1145/3184558.3191632;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Philosophy and methodology of clustering in pattern mining: Japanese anthropologist Jiro Kawakita's KJ method;;;['Takashi Iba', 'Ayaka Yoshikawa', 'Konomi Munakata'];;;October 2017;;;PLoP '17: Proceedings of the 24th Conference on Pattern Languages of Programs;;;This paper describes the methodology and philosophy behind a pattern mining process known as "clustering." This holistic approach to pattern language creation is referred to as the "KJ method" by Jiro Kawakita (Kawakita, 1967). Pattern mining is a process used to extract the knowledge of practice (rules of thumb and tips) from individual cases and experiences, with the aim of creating a pattern language. Clustering is carried out to discover and organize the common points from the extracted knowledge. We have used the KJ method as the foundation of our pattern language clustering method. Invented during the 1950s and 60s, the KJ method has been widely applied in Japan, particularly in the areas of industry and education. We seek to deepen the understanding of this method and its underlying intentions by quoting Kawakita's explanations in an English translation. In particular, this paper elaborates on the following factual statements: the method was developed via field science; the method uses a bottom-up approach to generate order from chaos; the method requires that the data be viewed outside of any existing concept or framework; the method prioritizes feelings over reason; and at the conceptual level, the method is consistent with the essence of creativity. We expect this paper to provide readers with a clear understanding of the KJ method with a view to using it effectively in the practice of clustering in pattern mining.;;;https://dl.acm.org/doi/10.5555/3290281.3290296;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A pipeline for mining association rules from large datasets of retailers invoices;;;['Giuseppe Agapito', 'Barbara Calabrese', 'Pietro H. Guzzi', 'Mario Cannataro'];;;January 2019;;;APPIS '19: Proceedings of the 2nd International Conference on Applications of Intelligent Systems;;;The concept of massive data generation nowadays affects several domains such as marketing including electronic invoices (e-invoices) of large retailers, web access log files, healthcare, life sciences and so on. Datasets dimensions grow up, due to the availability of several cheap connected devices, such as mobile devices, RFID and wireless sensors networks, from which to collect data. Often, the collected data need to be gathered into a consistent, integrated and comprehensive form, to be used for knowledge discovery. Without adequately cleaning, transforming and structuring the data before the analysis, it is hard to mine useful knowledge. Thus, users by using data mining can extract knowledge from large invoices documents. In this paper, a pipeline for preprocessing and mining association rules from large retailers commercial documents has been proposed. The preprocessing provides merging, cleaning, formatting and summarization. The methodology can improve the quality of large retailers data by reducing the quantity of irrelevant data, making the remaining data suitable to mine association rules (ARM). Analyzing a real invoices dataset (provided by an Italian retailer) by using the proposed methodology, it was possible to extract 36 significant association rules, highlighting the customers' behavior in the purchase of goods.;;;https://dl.acm.org/doi/10.1145/3309772.3309778;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A Mining Software Repository Extended Cookbook: Lessons learned from a literature review;;;['Daniel Barros', 'Flavio Horita', 'Igor Wiese', 'Kanan Silva'];;;September 2021;;;SBES '21: Proceedings of the XXXV Brazilian Symposium on Software Engineering;;;The main purpose of Mining Software Repositories (MSR) is to discover the latest enhancements and provide an insight into how to make improvements in a software project. In light of it, this paper updates the MSR findings of the original MSR Cookbook, by first conducting a systematic mapping study to elicit and analyze the state-of-the-art, and then proposing an extended version of the Cookbook. This extended Cookbook was built on four high-level themes, which were derived from the analysis of a list of 112 selected studies. Hence, it was used to consolidate the extended Cookbook as a contribution to practice and research in the following areas by: 1) including studies published in all available and relevant publication venues; 2) including and updating recommendations in all four high-level themes, with an increase of 84% in comments in this study when compared with the original MSR Cookbook; 3) summarizing the tools employed for each high-level theme; and 4) providing lessons learned for future studies. Thus, the extended Cookbook examined in this work can support new research projects, as upgraded recommendations and the lessons learned are available with the aid of samples and tools.;;;https://dl.acm.org/doi/10.1145/3474624.3474627;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
NodeAug: Semi-Supervised Node Classification with Data Augmentation;;;['Yiwei Wang', 'Wei Wang', 'Yuxuan Liang', 'Yujun Cai', 'Juncheng Liu', 'Bryan Hooi'];;;August 2020;;;KDD '20: Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining;;;By using Data Augmentation (DA), we present a new method to enhance Graph Convolutional Networks (GCNs), that are the state-of-the-art models for semi-supervised node classification. DA for graph data remains under-explored. Due to the connections built by edges, DA for different nodes influence each other and lead to undesired results, such as uncontrollable DA magnitudes and changes of ground-truth labels. To address this issue, we present the NodeAug (Node-Parallel Augmentation) scheme, that creates a 'parallel universe' for each node to conduct DA, to block the undesired effects from other nodes. NodeAug regularizes the model prediction of every node (including unlabeled) to be invariant with respect to changes induced by Data Augmentation (DA), so as to improve the effectiveness. To augment the input features from different aspects, we propose three DA strategies by modifying both node attributes and the graph structure. In addition, we introduce the subgraph mini-batch training for the efficient implementation of NodeAug. The approach takes the subgraph corresponding to the receptive fields of a batch of nodes as the input per iteration, rather than the whole graph that the prior full-batch training takes. Empirically, NodeAug yields significant gains for strong GCN models on the Cora, Citeseer, Pubmed, and two co-authorship networks, with a more efficient training process thanks to the proposed subgraph mini-batch training approach.;;;https://dl.acm.org/doi/10.1145/3394486.3403063;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Using process mining to analyse self-regulated learning: a systematic analysis of four algorithms;;;['John Saint', 'Yizhou Fan', 'Shaveen Singh', 'Dragan Gasevic', 'Abelardo Pardo'];;;April 2021;;;LAK21: LAK21: 11th International Learning Analytics and Knowledge Conference;;;The conceptualisation of self-regulated learning (SRL) as a process that unfolds over time has influenced the way in which researchers approach analysis. This gave rise to the use of process mining in contemporary SRL research to analyse data about temporal and sequential relations of processes that occur in SRL. However, little attention has been paid to the choice and combinations of process mining algorithms to achieve the nuanced needs of SRL research. We present a study that 1) analysed four process mining algorithms that are most commonly used in the SRL literature – Inductive Miner, Heuristics Miner, Fuzzy Miner, and pMineR; and 2) examined how the metrics produced by the four algorithms complement each. The study looked at micro-level processes that were extracted from trace data collected in an undergraduate course (N=726). The study found that Fuzzy Miner and pMineR offered better insights into SRL than the other two algorithms. The study also found that a combination of metrics produced by several algorithms improved interpretation of temporal and sequential relations between SRL processes. Thus, it is recommended that future studies of SRL combine the use of process mining algorithms and work on new tools and algorithms specifically created for SRL research.;;;https://dl.acm.org/doi/10.1145/3448139.3448171;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Interactive Machine Learning and Explainability in Mobile Classification of Forest-Aesthetics;;;['Simon Flutura', 'Andreas Seiderer', 'Tobias Huber', 'Katharina Weitz', 'Ilhan Aslan', 'Ruben Schlagowski', 'Elisabeth André', 'Joachim Rathmann'];;;September 2020;;;GoodTechs '20: Proceedings of the 6th EAI International Conference on Smart Objects and Technologies for Social Good;;;This paper presents an application that classifies forest's aesthetics using interactive machine learning on mobile devices. Transfer learning is used to be able to build upon deep ANNs (MobileNet) using the limited resources available on smart-phones. We trained and evaluated a model using our application based on a data-set that is plausible to be created by a single user. In order to increase the comprehensibility of our model we explore the potential of incorporating explainable Artificial Intelligence (XAI) into our mobile application. To this end we use deep Taylor decomposition to generate saliency maps that highlight areas of the input that were relevant for the decision of the ANN and conducted a user study to evaluate the usefulness of this approach for end-users.;;;https://dl.acm.org/doi/10.1145/3411170.3411225;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
K-means, HAC and FCM Which Clustering Approach for Arabic Text?;;;['Lahbib Ajallouda', 'Fatima Zahra Fagroud', 'Ahmed Zellou', 'El Habib Benlahmar'];;;September 2020;;;SITA'20: Proceedings of the 13th International Conference on Intelligent Systems: Theories and Applications;;;Today, we are witnessing rapid growth in Web resources that allow Internet users to express and share their ideas, opinions, and judgments on a variety of issues. Several classification approaches have been proposed to classify textual data. But all these approaches require us to label the clusters we want to obtain. Which, in reality, is not available because we do not know in advance the information that can be proposed through these opinions. To overcome this constraint, clustering approaches such as K-mean, HAC or FCM can be exploited. In this paper, we present and compare these approaches. And to show the importance of exploiting clustering algorithms, to classify and analyze textual data in Arabic. By applying them to a real case that has created a great debate in Morocco, which is the case of teachers contracting with academies.;;;https://dl.acm.org/doi/10.1145/3419604.3419779;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Classification and Feature Extraction for Text-based Drug Incident Report;;;['Takanori Yamashita', 'Naoki Nakashima', 'Sachio Hirokawa'];;;March 2018;;;ICBCB 2018: Proceedings of the 2018 6th International Conference on Bioinformatics and Computational Biology;;;Medical institutions have been constructed incident report system, then accumulating incident data. Incident data compose text-based data and some structured attributes. We considered based on the analysis result with clustering for drug incident report. Firstly, we generated a network of documents and words from the text-based data. Secondly, Louvain method was applied to the network and 11 clusters were generated. We confirmed the contents of each cluster from feature words extracted by TF-IDF. Then, we compare clusters of text-based data with structured attributes and grasp the trend of the incident. This proposed method showed the possibility of clinical support toward reduction incident from text-based data.;;;https://dl.acm.org/doi/10.1145/3194480.3194499;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A framework for the analysis of information propagation in social networks combining complex networks and text mining techniques;;;['Carlos Magno G. Barbosa', 'Lucas Gabriel da S. Felix', 'Carolina R. Xavier', 'Vinícius da F. Vieira'];;;October 2019;;;WebMedia '19: Proceedings of the 25th Brazillian Symposium on Multimedia and the Web;;;Online social networks like Twitter, Facebook and WhatsApp are among the greatest innovations of the modern internet. Through these applications, users can consume and be major news broadcasters. These networks are sensitive to real-time events and generate a large amount of data at all times. The ability to extract information from this large amount of data is essential for the survival of companies and the modernization of public policies. With this purpose, this work presents the construction of a framework that combines complex networks and data mining to analyze the content and the propagation of information in social networks, especially in Twitter. As a practical case, the methodology is applied to the analysis of messages posted on twitter related to pension reform in Brazil. As a result, the framework was able to identify the main topics of Internet discussion and the positioning within certain communities regarding the subject. The main feeling surrounding the discussion turned out to be negative and pro-retirement users were more involved in supportive and anti-reform communities.;;;https://dl.acm.org/doi/10.1145/3323503.3360289;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
MATCH: Metadata-Aware Text Classification in A Large Hierarchy;;;['Yu Zhang', 'Zhihong Shen', 'Yuxiao Dong', 'Kuansan Wang', 'Jiawei Han'];;;April 2021;;;WWW '21: Proceedings of the Web Conference 2021;;;Multi-label text classification refers to the problem of assigning each given document its most relevant labels from a label set. Commonly, the metadata of the given documents and the hierarchy of the labels are available in real-world applications. However, most existing studies focus on only modeling the text information, with a few attempts to utilize either metadata or hierarchy signals, but not both of them. In this paper, we bridge the gap by formalizing the problem of metadata-aware text classification in a large label hierarchy (e.g., with tens of thousands of labels). To address this problem, we present the MATCH1 solution—an end-to-end framework that leverages both metadata and hierarchy information. To incorporate metadata, we pre-train the embeddings of text and metadata in the same space and also leverage the fully-connected attentions to capture the interrelations between them. To leverage the label hierarchy, we propose different ways to regularize the parameters and output probability of each child label by its parents. Extensive experiments on two massive text datasets with large-scale label hierarchies demonstrate the effectiveness of MATCH over the state-of-the-art deep learning baselines.;;;https://dl.acm.org/doi/10.1145/3442381.3449979;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Epileptic seizures classification in EEG using PCA based genetic algorithm through machine learning;;;['Md Khurram Monir Rabby', 'A. K. M. Kamrul Islam', 'Saeid Belkasim', 'Marwan U Bikdash'];;;April 2021;;;ACM SE '21: Proceedings of the 2021 ACM Southeast Conference;;;In this research, a Principal Component Analysis (PCA) with Genetic Algorithm based Machine Learning (ML) approach is developed for the binary classification of epileptic seizures from the EEG dataset. The proposed approach utilizes PCA to reduce the number of features for binary classification of epileptic seizures and is applied to the existing machine learning models to evaluate the model performance in comparison to the higher number of features. Here, Genetic Algorithm (GA) is employed to tune the hyperparameters of the machine learning models for identifying the best ML model. The proposed approach is applied to the UCI epileptic seizure recognition dataset, which is originated from the EEG dataset of Bonn University. As a preliminary analysis of the proposed approach, the data analysis result shows a significant reduction in the number of features but has minimal impact on the ML performance parameters in comparison to the existing ML method.;;;https://dl.acm.org/doi/10.1145/3409334.3452065;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Detection and prevention of malicious cryptocurrency mining on internet-connected devices;;;['AbedAlqader Swedan', 'Ahmad N. Khuffash', 'Othman Othman', 'Ahmed Awad'];;;June 2018;;;ICFNDS '18: Proceedings of the 2nd International Conference on Future Networks and Distributed Systems;;;As technology evolves, more and more devices are connected to the Internet. The popularity and increasing significance of cryptocurriences are drawing attention, and crybercriminals are trying to utilize the resources and steal the processing power of these devices. It is highly likely that there are billions of devices that are maliciously mining cryptocurrency for the benefit of a cybercriminal without noticing the damage they may be causing. This paper is proposed because there is a huge need to professionally defend and protect against the misuse of assets in order to avoid losses, both financially and operationally, and how it is possible to mitigate with this rising trend.;;;https://dl.acm.org/doi/10.1145/3231053.3231076;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Machine learning application for malwares classification using visualization technique;;;['Ben Abdel Ouahab Ikram', 'Bouhorma Mohammed', 'Boudhir Anouar Abdelhakim', 'El Aachak Lotfi', 'Bassam Zafar'];;;October 2019;;;SCA '19: Proceedings of the 4th International Conference on Smart City Applications;;;Nowadays attackers work hard to develop efficient cyberthreats and exploit new techniques. So defenders need to use advanced methodologies to combat the latest threats and safely remove them from computers, mobiles and connected devices. Without the intelligent techniques, these devices would be at increased risk of damage from malicious programs. Recently a novel approach of processing malwares was appeared; it passes from malware binaries into malware images. Researchers found similarities in malwares images by extracting specific features. This paper presents malwares classifier using KNN and malware visualization technique. We used a database of 9339 samples of malwares from 25 families. We calculated the GIST descriptor for grayscale malware images. Then a KNN model was trained and evaluated many times to reach a score of 97%, which is very close to results found on literature.;;;https://dl.acm.org/doi/10.1145/3368756.3369098;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Automated classification of text sentiment;;;['Emmanuel Dufourq', 'Bruce A. Bassett'];;;September 2017;;;SAICSIT '17: Proceedings of the South African Institute of Computer Scientists and Information Technologists;;;The ability to identify sentiment in text, referred to as sentiment analysis, is one which is natural to adult humans. This task is, however, not one which a computer can perform by default. Identifying sentiments in an automated, algorithmic manner will be a useful capability for business and research in their search to understand what consumers think about their products or services and to understand human sociology. Here we propose two new Genetic Algorithms (GAs) for the task of automated text sentiment analysis. The GAs learn whether words occurring in a text corpus are either sentiment or amplifier words, and their corresponding magnitude. Sentiment words, such as 'horrible', add linearly to the final sentiment. Amplifier words in contrast, which are typically adjectives/adverbs like 'very', multiply the sentiment of the following word. This increases, decreases or negates the sentiment of the following word. The sentiment of the full text is then the sum of these terms. This approach grows both a sentiment and amplifier dictionary which can be reused for other purposes and fed into other machine learning algorithms. We report the results of multiple experiments conducted on large Amazon data sets. The results reveal that our proposed approach was able to outperform several public and/or commercial sentiment analysis algorithms.;;;https://dl.acm.org/doi/10.1145/3129416.3129420;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Gear Fault Diagnosis and Classification Using Machine Learning Classifier;;;['Sudarsan Sahoo', 'R. A. Laskar', 'J. K. Das', 'S. H. Laskar'];;;March 2019;;;ISMSI '19: Proceedings of the 2019 3rd International Conference on Intelligent Systems, Metaheuristics &amp; Swarm Intelligence;;;In industry the condition monitoring of rotating machinery gear is very important. The defect in gear mesh may cause the failure in machinery and that causes a severe loss in industry. The failure in gear mesh reduces the efficiency and hence decreases the productivity in industrial operation. Therefore the health monitoring of gear mesh is very important. Proper health monitoring of gears can avoid the failure in machinery and can save money in industrial applications. The acoustic emission and vibration are the two widely used measuring parameters which is used for the condition monitoring of gear mesh. In this work the gear fault detection by using the acoustic emission monitoring technique is used. This experimentation is done by using an efficient instrumentation system. The experimental set-up is designed which consists of a gear mesh driving system and a hand-held sound analyzer. To carry out the experiment the measuring signals from the defective and healthy gears are captured and compared. In this work the measuring signal is the acoustic emission from the tested gears. Then for the fault detection, two signal processing techniques are followed. These are statistical analysis and adaptive wavelet transform (AWT) analysis. The comparison in statistical as well as in AWT analysis used to detect the fault present in gears. In AWT analysis the adaptive noise cancellation is used to enhance the signal to noise ratio (SNR). Finally faults in gears are classified using the machine learning classifier. The statistical parameter data are used as the input data for the classifiers to train the system to classify the fault.;;;https://dl.acm.org/doi/10.1145/3325773.3325782;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Improvement of transparency through mining techniques for reclassification of texts: the case of brazilian transparency portal;;;['Gustavo Almeida', 'Kate Revoredo', 'Claudia Cappelli', 'Cristiano Maciel'];;;May 2018;;;dg.o '18: Proceedings of the 19th Annual International Conference on Digital Government Research: Governance in the Data Age;;;Several countries passed transparency laws requiring that governments make data about its fiscal and financial expenditures publicly available in Internet portals. Nevertheless, available data is not always synonymous with transparent data. This is the case of the Transparency Portal of Brazilian Federal Government, since key data is presented as unstructured text hindering the control of purchased items. This article describes the application of text mining techniques with the objective of reclassifying descriptive texts of unit of measurement related to the products and services procured by Federal Government in Brazil. The results of the efficacy of this model are presented, including the production of analysis based on the transformed dataset, identifying probable input errors, suspicious companies and purchasers and factors affecting procurement prices as well as presenting suggestions for future research and improvements for the way the data is inputted and made available;;;https://dl.acm.org/doi/10.1145/3209281.3209332;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Distance Metric Learning Approach for Weather Data Mining;;;['Zhongfeng Niu', 'Yian Zhu', 'Linxiu Jiang'];;;October 2018;;;BDIOT '18: Proceedings of the 2018 2nd International Conference on Big Data and Internet of Things;;;High throughput weather data, which is acquired by remote sensing technology, collected by local weather stations, or gathered by autonomous sensors, is the foundation for modern weather forecast and climate change prediction. Such data set often contains multi-dimensional information on aspects such as temperature, humidity, wind speed/direction, atmospheric pressure, etc., which can be extremely large-scale and convoluted. Therefore, effective and efficient methods for weather data analysis is important and urgently needed. Data mining technologies, which is the computer-aided process that digs useful patterns out of large-scale data sets, is widely acknowledged as a very promising direction in weather data analysis. In this paper, a novel methodology is described, which applies a distance metric learning approach for weather data mining. Such a method is applied to weather data set collected at JFK, MCO and SFO airport in 2016, and shows a very promising advantage in classification accuracy compared with other conventional methods.;;;https://dl.acm.org/doi/10.1145/3289430.3289455;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Data mining classifiers comparison for seismic hazard prediction;;;['Sneha', 'Abdolreza Abhari', 'Chen Ding'];;;April 2018;;;CNS '18: Proceedings of the Communications and Networking Symposium;;;Earthquake and seismic hazards are natural disasters which are very difficult to predict. Researchers are working hard to predict these disasters for minimizing loss of life and property. Proposed research used data mining algorithms on seismic bumps dataset which was obtained from coal mines for the seismic hazard prediction. Data mining is a powerful technique used to discover patterns of data. In this research, performance of five data mining classifiers was compared for better prediction of seismic hazard. For preprocessing of this dataset, discretization and resampling techniques were used. For modelling, five data mining classifiers were implemented and compared by using feature selection technique on the basis of confusion matrix measures like success rate, mean absolute error, kappa statistics, precision, recall and f-measure. This analysis showed that Random Forest algorithm achieved highest success rate by using feature selection technique and provided promising results for seismic hazard prediction.;;;https://dl.acm.org/doi/10.5555/3213200.3213207;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A Machine Learning Based Ensemble Method for Automatic Multiclass Classification of Decisions;;;['Liming Fu', 'Peng Liang', 'Xueying Li', 'Chen Yang'];;;June 2021;;;EASE '21: Proceedings of the 25th International Conference on Evaluation and Assessment in Software Engineering;;;Stakeholders make various types of decisions with respect to requirements, design, management, and so on during the software development life cycle. Nevertheless, these decisions are typically not well documented and classified due to limited human resources, time, and budget. To this end, automatic approaches provide a promising way. In this paper, we aimed at automatically classifying decisions into five types to help stakeholders better document and understand decisions. First, we collected a dataset from the Hibernate developer mailing list. We then experimented and evaluated 270 configurations regarding feature selection, feature extraction techniques, and machine learning classifiers to seek the best configuration for classifying decisions. Especially, we applied an ensemble learning method and constructed ensemble classifiers to compare the performance between ensemble classifiers and base classifiers. Our experiment results show that (1) feature selection can decently improve the classification results; (2) ensemble classifiers can outperform base classifiers provided that ensemble classifiers are well constructed; (3) BoW + 50% features selected by feature selection with an ensemble classifier that combines Naïve Bayes (NB), Logistic Regression (LR), and Support Vector Machine (SVM) achieves the best classification result (with a weighted precision of 0.750, a weighted recall of 0.739, and a weighted F1-score of 0.727) among all the configurations. Our work can benefit various types of stakeholders in software development through providing an automatic approach for effectively classifying decisions into specific types that are relevant to their interests.;;;https://dl.acm.org/doi/10.1145/3463274.3463325;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Research on the design of large data storage structure of database based on Data Mining;;;['Lihua Wang'];;;October 2021;;;AIAM2021: 2021 3rd International Conference on Artificial Intelligence and Advanced Manufacture;;;With the continuous development of China's social economy, the informationization function of power grid companies is becoming increasingly powerful, and its effectiveness is very remarkable. However, in the related business of power system, the performance of database cannot be guaranteed. In the process of power marketing, a large amount of data will be generated. In the process of processing a large amount of data, it is necessary to constantly optimize the database to improve the structure of the database. Data mining is a promising subject frontier of database system and new database application. In this paper, a large data storage structure of database based on data mining is designed. The ETL tool in signaling data warehouse is used to realize the integrated design of signaling data storage and application.;;;https://dl.acm.org/doi/10.1145/3495018.3501223;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Classification of short-texts generated during disasters: a deep neural network based approach;;;['Shamik Kundu', 'Srijith P. K', 'Maunendra Sankar Desarkar'];;;August 2018;;;ASONAM '18: Proceedings of the 2018 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining;;;Micro-blogging sites provide a wealth of resources during disaster events in the form of short texts. Correct classification of these text data into various actionable classes can be of great help in shaping the means to rescue people in disaster-affected places. The process of classification of these text data poses a challenging problem because the texts are usually short and very noisy and finding good features that can distinguish these texts into different classes is time consuming, tedious and often requires a lot of domain knowledge. We propose a deep learning based model to classify tweets into different actionable classes such as resource need and availability, activities of various NGO etc. Our model requires no domain knowledge and can be used in any disaster scenario with little to no modification.;;;https://dl.acm.org/doi/10.5555/3382225.3382396;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
geoGAT: Graph Model Based on Attention Mechanism for Geographic Text Classification;;;['Weipeng Jing', 'Xianyang Song', 'Donglin Di', 'Houbing Song'];;;None;;;ACM Transactions on Asian and Low-Resource Language Information Processing;;;In the area of geographic information processing, there are few researches on geographic text classification. However, the application of this task in Chinese is relatively rare. In our work, we intend to implement a method to extract text containing geographical entities from a large number of network texts. The geographic information in these texts is of great practical significance to transportation, urban and rural planning, disaster relief, and other fields. We use the method of graph convolutional neural network with attention mechanism to achieve this function. Graph attention networks (GAT) is an improvement of graph convolutional neural networks (GCN). Compared with GCN, the advantage of GAT is that the attention mechanism is proposed to weight the sum of the characteristics of adjacent vertices. In addition, We construct a Chinese dataset containing geographical classification from multiple datasets of Chinese text classification. The Macro-F Score of the geoGAT we used reached 95% on the new Chinese dataset.;;;https://dl.acm.org/doi/10.1145/3434239;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Text classification on software requirements specifications using transformer models;;;['Derya Kici', 'Aysun Bozanta', 'Mucahit Cevik', 'Devang Parikh', 'Ayşe Başar'];;;November 2021;;;CASCON '21: Proceedings of the 31st Annual International Conference on Computer Science and Software Engineering;;;Text classification in Software Requirements Specifications (SRS) documents is an essential task for various purposes including automatically extracting requirements and their types as well as identification of duplicate or conflicting information, which all contribute to avoiding potential issues in the later stages of the software development life cycle. While a variety of machine learning approaches have been considered for text classification over SRS documents, many of these fail to provide adequate performance as they often ignore the meaning of software artifacts or integrate domain knowledge for the classification task. Recent advances in deep learning methodology have significantly contributed to Natural Language Processing (NLP) and text classification. One of the main challenges in using deep learning models for various NLP tasks in the software engineering domain is the scarcity of labeled textual data. In addition, even with sufficient data, training from the scratch still requires significant training time and computational resources. Transfer learning is a novel approach that proposes a solution to such reservations by providing pre-trained models that enable fine-tuning with the customized data. In this research, we conduct an empirical analysis on multi-class text classification over SRS documents using different pre-trained transformer models including BERT, DistilBERT, Roberta, AlBERT, and XLNet, and compare their performance. We test the performance of these models using three SRS datasets: DOORS, NFR-PROMISE, and PURE. Our numerical study shows that the transformer models are able to generate highly accurate results to classify all categories except Priority of the requirements. While all models provide a 80% or higher accuracy for other classification tasks, the accuracy of the models to classify the Priority does not exceed 60%.;;;https://dl.acm.org/doi/10.5555/3507788.3507811;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A Survey of Distance Metrics in Clustering Data Mining Techniques;;;['Marina Adriana Mercioni', 'Stefan Holban'];;;June 2019;;;ICGSP '19: Proceedings of the 3rd International Conference on Graphics and Signal Processing;;;Lately, due to the increasing size of databases, several aspects have been studied in detail, such as grouping, searching for the closest neighbor and other identification methods. It has been found that in the multidimensional space, the concept of distance does not offer high performance. In this paper, we study the effect of different types of distances on the group to see the similarities between objects. Among these distances we mention two distances: the Euclidean distance and Manhattan distance, implemented in a system developed to identify the architectural styles of the buildings. The aim of this paper is using cluster analysis to identify distance metrics impact in detection of architectural styles using Data Mining techniques.;;;https://dl.acm.org/doi/10.1145/3338472.3338490;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Object Detection and Classification Using Machine Learning Techniques: A Comparison of Haar Cascades and Neural Networks;;;['Chisulo Mukabe', 'Nalina Suresh', 'Valerians Hashiyana', 'Titus Haiduwa', 'William Sverdlik'];;;August 2021;;;DSMLAI '21': Proceedings of the International Conference on Data Science, Machine Learning and Artificial Intelligence;;;Object recognition and object detection are sub fields of computer vision, the task of giving computers the ability to perceive and respond to the world around them. This is a very useful technology and has many different applications in many different disciplines. Examples of applications include but are not limited to: Use in security by using facial recognition; use in the medical field for classification of cancer types (malignant or benign) or detecting sickle cells in the blood; or it can be used as a research tool to automatically record data (e.g. count the number of trucks that use a particular highway); or used in agriculture or industrialization for quality control; or for entertainment purposes in games that can detect and track a users' movement to control a character in a game. And there are many more examples, in which it can be used. However, just as they are many applications, there are also many methods of implementing these systems, such as Convolutional neural networks, Haar cascades, Scale-Invariant Feature Transformations (SIFT), Histogram of Oriented Gradients (HOG) and several others including combinations of these. Each technique may have different setup procedures and different applications where one may work better than the other. This paper aims to measure and give a comparison of some of these techniques for object detection and tracking, by looking at their training and testing time as well as accuracy. The methods used in this paper was Haar Cascades and Neural Networks. The purpose of this paper is to learn more about these machine learning techniques by comparing the way they work and the way they were implemented, by doing so one can also understand contexts in which to use these systems. The artifacts used in this paper included a robot that can track an object and an application that could classify an image based on a set of objects it was trained on, that is the application can determine what the picture is of based on a set of images it was trained on.;;;https://dl.acm.org/doi/10.1145/3484824.3484895;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Probabilistic Dynamic Non-negative Group Factor Model for Multi-source Text Mining;;;['Chien Lu', 'Jaakko Peltonen', 'Jyrki Nummenmaa', 'Kalervo Järvelin'];;;October 2020;;;CIKM '20: Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management;;;Nonnegative matrix factorization (NMF) is a popular approach to model data, however, most models are unable to flexibly take into account multiple matrices across sources and time or apply only to integer-valued data. We introduce a probabilistic, Gaussian Process-based, more inclusive NMF-based model which jointly analyzes nonnegative data such as text data word content from multiple sources in a temporal dynamic manner. The model collectively models observed matrix data, source-wise latent variables, and their dependencies and temporal evolution with a full-fledged hierarchical approach including flexible nonparametric temporal dynamics. Experiments on simulated data and real data show the model out-performs, comparable models. A case study on social media and news demonstrates the model discovers semantically meaningful topical factors and their evolution;;;https://dl.acm.org/doi/10.1145/3340531.3411956;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Empirical Comparison of Area under ROC curve (AUC) and Mathew Correlation Coefficient (MCC) for Evaluating Machine Learning Algorithms on Imbalanced Datasets for Binary Classification;;;['Chongomweru Halimu', 'Asem Kasem', 'S. H. Shah Newaz'];;;January 2019;;;ICMLSC '19: Proceedings of the 3rd International Conference on Machine Learning and Soft Computing;;;A common challenge encountered when trying to perform classifications and comparing classifiers is selecting a suitable performance metric. This is particularly important when the data has class-imbalance problems. Area under the Receiver Operating Characteristic Curve (AUC) has been commonly used by the machine learning community in such situations, and recently researchers are starting to use Matthew Correlation Coefficient (MCC), especially in biomedical research. However, there is no empirical study that has been conducted to compare the suitability of the two metrics. In this paper, the aim of this study is to provide insights about how AUC and MCC are compared to each other when used with classical machine learning algorithms over a range of imbalanced datasets. In our study, we utilize an earlier-proposed criteria for comparing metrics based on the degree of consistency and degree of Discriminancy to compare AUC against MCC. We carry out experiments using four machine learning algorithms on 54 imbalanced datasets, with imbalance ratios ranging from 1% to 10%. The results demonstrate that both AUC and MCC are statistically consistent with each other; however AUC is more discriminating than MCC. The same observation is noticed when evaluated on 23 balanced datasets. This suggests AUC to be a better measure than MCC in evaluating and comparing classification algorithms.;;;https://dl.acm.org/doi/10.1145/3310986.3311023;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Research of Classification Impact Factors Mining Based on the Contrast Pattern Equivalence Classes;;;['Ji-Cheng Shan', 'Hang Zhang', 'Wei-Ke Liu', 'Qing-Bao Liu'];;;October 2017;;;WCNA 2017: Proceedings of the 2017 International Conference on Wireless Communications, Networking and Applications;;;In the domain of multi-label data and big data, it is hard for most classification methods to generate explainable classify rules, which makes it harder to get impact factors for classification. In this paper, contrast pattern equivalence class was discussed and mined to determine main impact factors for different classes, considering combination of frequent pattern mining and data classification. The rationality and feasibility to determine classification impact factors through contrast pattern equivalence classes mining was theoretically analyzed. Also the mine process and result analysis was shown through an experiment on the real dataset. Experimental results show the validity of the method proposed.;;;https://dl.acm.org/doi/10.1145/3180496.3180621;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Improving support vector machine classification accuracy based on kernel parameters optimization;;;['Lubna B. Mohammed', 'Kaamran Raahemifar'];;;April 2018;;;CNS '18: Proceedings of the Communications and Networking Symposium;;;Support Vector Machine (SVM) learning algorithm is considered as the most popular classification algorithm. It is a supervised learning technique that is mainly based on the conception of decision planes. These decision planes define decision boundaries which are used to separate a set of objects. It is important to extract the main features of the training datasets. These features can be used to define the separation boundaries. The separation boundaries can also be improved by tuning the parameters of the separation hyperplane. In literature, there are different techniques for feature selection and SVM parameters optimization that can be used to improve classification accuracy. There are a wide variety of applications that use SVM classification algorithm, such as text classification, disease diagnosis, gene analysis, and many others. The aim of this paper is to investigate the techniques that can be used to improve the classification accuracy of SVM based on kernel parameters optimization. The datasets are collected from different applications; having different number of classes and different number of features. The analysis and comparison among different kernel parameters were implemented on different datasets to study the effect of the number of features, the number of classes, and kernel parameters on the performance of the classification process.;;;https://dl.acm.org/doi/10.5555/3213200.3213210;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Traffic Sign and Vehicle Classification based on Machine Learning;;;['Malichenko Viktor', 'Han Honggui'];;;December 2020;;;VSIP '20: Proceedings of the 2020 2nd International Conference on Video, Signal and Image Processing;;;In this paper, we offer a machine learning classifier model, later considered as MLCM, for classifying objects such as road signs and vehicles. Showing the influence of vocabulary size on accuracy of SVM using SURF. Based on SURF method used bag-of-words model as feature extractor. Due to its simplifying representation, it accelerates the first stage of our MLCM. We tested and analyzed accuracy of Support Vector Machines, including Linear, Quadratic and Medium Gaussian SVM as flowed step model and automatically use best result for further estimation. Furthermore, we provide a brief introduction of applied methods and experimental results analysis. MLCM introduces combination of SURF method and several SVMs as well as optimized SVM. This technique shows good performance with minimum failures. Thereafter, it will be implemented for real-time video sequences. The achieved goal can be implemented in the use of self-driving of industrial machines with a safe speed.;;;https://dl.acm.org/doi/10.1145/3442705.3442711;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Evaluation of student collaboration on canvas LMS using educational data mining techniques;;;['Urvashi Desai', 'Vijayalakshmi Ramasamy', 'James Kiper'];;;April 2021;;;ACM SE '21: Proceedings of the 2021 ACM Southeast Conference;;;Online discussion forums provide valuable information about students' learning and engagement in course activities. The hidden knowledge in the contents of these discussion posts can be examined by analyzing the social interactions between the participants. This research investigates students' learning and collaborative problem-solving aspects by applying social network analysis (SNA) metrics and sophisticated computational techniques. The data is collected from online course discussion forums on Canvas, a Learning Management System (LMS), in a CS1 course at a medium-sized US University. The research demonstrates that efficient tools are needed to model and evaluate goal-oriented discussion forums constructed from active student collaborations. This research aims to develop a systematic data collection and analysis instrument incorporated into LMSs that enables grading the discussions to improve instructional outcomes, gain insights into and explain educational phenomena. The study also emphasizes important SNA metrics that analyze students' social behavior since a positive correlation was seen between the number of posts made by students and their academic performance in terms of the final grade. The prototype developed (CODA - Canvas Online Discussion Analyzer) helps evaluate students' performance based on the useful knowledge they share while participating in course discussions. The experimental results provided evidence that analysis of structured discussion data offers potential insights about changes in student collaboration patterns over time and students' sense of belongingness for pedagogical benefits. As future work, further analysis will be done by extracting additional students' data, such as their demographic data, majors, and performance in other courses to study cognitive and behavioral aspects from the collaboration networks.;;;https://dl.acm.org/doi/10.1145/3409334.3452042;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Manufacturing Audit Quality Analysis Model Based on Data Mining Technology;;;['Fangyu Sun'];;;December 2021;;;ICASIT 2021: 2021 International Conference on Aviation Safety and Information Technology;;;As our country's economic development enters a new normal, the original manufacturing development model can no longer meet the needs of current economic development, and it is urgent to accelerate the transformation of the manufacturing industry. At present, the country's supply-side structural reforms are deepening, and listed manufacturing companies are the most important backbone in terms of scale and innovation opportunities. Data mining technology is used to study the impact of quality control on corporate performance. Listed companies have a positive impact on the further realization of transformation and upgrading and the improvement of corporate performance. This article aims to study the manufacturing audit quality analysis model based on data mining technology, and adopts the analysis method of the combination of supervisory research and empirical analysis, from the perspective of supervisory research, summarizes the theory of internal audit quality and company performance in the research process, and summarizes predecessors' research results and research ideas. The experimental data in this article shows that the average quality of internal audit information disclosure is 3.1156, indicating that the audit disclosure status of listed companies selected by the Shenzhen Stock Exchange is good, and to a certain extent reflects the quality level of some internal controls.;;;https://dl.acm.org/doi/10.1145/3510858.3510863;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Designing Shapelets for Interpretable Data-Agnostic Classification;;;['Riccardo Guidotti', 'Anna Monreale'];;;July 2021;;;AIES '21: Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society;;;Time series shapelets are discriminatory subsequences which are representative of a class, and their similarity to a time series can be used for successfully tackling the time series classification problem. The literature shows that Artificial Intelligence (AI) systems adopting classification models based on time series shapelets can be interpretable, more accurate, and significantly fast. Thus, in order to design a data-agnostic and interpretable classification approach, in this paper we first extend the notion of shapelets to different types of data, i.e., images, tabular and textual data. Then, based on this extended notion of shapelets we propose an interpretable data-agnostic classification method. Since the shapelets discovery can be time consuming, especially for data types more complex than time series, we exploit a notion of prototypes for finding candidate shapelets, and reducing both the time required to find a solution and the variance of shapelets. A wide experimentation on datasets of different types shows that the data-agnostic prototype-based shapelets returned by the proposed method empower an interpretable classification which is also fast, accurate, and stable. In addition, we show and we prove that shapelets can be at the basis of explainable AI methods.;;;https://dl.acm.org/doi/10.1145/3461702.3462553;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Research on E-commerce Big Data Classification and Mining Algorithm Based on BP Neural Network Technology;;;['Ye Wang'];;;December 2021;;;ICASIT 2021: 2021 International Conference on Aviation Safety and Information Technology;;;With the development of the Internet, with the gradual increase of people's needs, more and more people are engaged in various activities on the Internet, such as online transactions. This article mainly studies the classification and mining algorithm of e-commerce big data based on BP neural network technology. Take user movie rating data as the object of analysis and mining, and use platform functions to complete the whole process of data from preprocessing to data mining to result data storage. According to the requirements of the platform design modules and functions, the construction process from the installation of the cluster dependent tool software, node communication, cluster configuration to the final operation monitoring was completed, and the experimental environment of the e-commerce big data platform was established. According to the real open source movie rating data, according to the BP neural network algorithm, relying on the function of the module, the whole recommendation task from data processing, algorithm mining to the final result generation is completed. Through the comparison of speedup, accuracy, recall and coverage indicators, it can be seen that when the experimental data set is 100K, the recommendation efficiency in the cluster environment is not improved. The results show that the BP neural network improves the efficiency of the e-commerce big data platform and the accuracy of task execution results.;;;https://dl.acm.org/doi/10.1145/3510858.3510892;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Product-review Classification Combining Multiple Clustering Algorithms;;;['Yilun Wei', 'Yingying Lao', 'Yudai Sato', 'Dongli Han'];;;June 2019;;;ICFET '19: Proceedings of the 5th International Conference on Frontiers of Educational Technologies;;;As product reviews accumulate more and more at online shopping sites, customers begin to have an increasing demand for analyzing reviews automatically. In some previous studies, clustering algorithms have been proved to be effective in grouping reviews. However, most of the existing systems are built based on a single clustering algorithm which might make the system fragile. In this paper, we have proposed a method to combine multiple clustering algorithms. Evaluation experiments have shown the effectiveness of our approach.;;;https://dl.acm.org/doi/10.1145/3338188.3338211;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
An Ideology for the Prediction of Critical Haplotype Blocks of Variants in Genes (Cyp2c9 And Vkorc1) for Warfarin (Anticoagulant) Drug Dosage to Treat Heart Patients Efficiently by Using Ml (Machine Learning) and Data Stream Mining Techniques;;;['Hina Saeeda', 'Muhammad Adil Abid'];;;November 2019;;;ICAIP '19: Proceedings of the 2019 3rd International Conference on Advances in Image Processing;;;Now a day's on time treatment of heart diseases is a very critical part of medical diagnoses. So far there are total 50 SNP (Single Nucleotide Polymorphism) diagnosed that are responsible for the heart problems. But it is very hard to study all of the SNP together because of their different base pairs' locations or changes in base pairs positions (variations in genetic code A C G T). These all 50 SNP are present in all individuals with different variations, it is a tough job to calculate all the changes in this SNP set as there are total of (50^50) positions to calculate which is making it a huge data set. For acquiring a data set of all these positions, we will need some good Data Stream Mining (data mining techniques) to find out all the possible locations of all the variants responsible for the heart problems. In this research paper, we are giving a short analysis and introduction to the problem of heart patients drug dosage associated with anticoagulant (Warfarin) and its risks, solution for the challenge of calculating all variants of two genes (CYP2C9 and VKORC1) and advantages of the proposed solution in the future.;;;https://dl.acm.org/doi/10.1145/3373419.3373424;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A Self-Training Subspace Clustering Algorithm under Low-Rank Representation for Cancer Classification on Gene Expression Data;;;['Chun-Qiu Xia', 'Ke Han', 'Yong Qi', 'Yang Zhang', 'Dong-Jun Yu'];;;None;;;IEEE/ACM Transactions on Computational Biology and Bioinformatics;;;Accurate identification of the cancer types is essential to cancer diagnoses and treatments. Since cancer tissue and normal tissue have different gene expression, gene expression data can be used as an efficient feature source for cancer classification. However, accurate cancer classification directly using original gene expression profiles remains challenging due to the intrinsic high-dimension feature and the small size of the data samples. We proposed a new self-training subspace clustering algorithm under low-rank representation, called SSC-LRR, for cancer classification on gene expression data. Low-rank representation LRR is first applied to extract discriminative features from the high-dimensional gene expression data; the self-training subspace clustering SSC method is then used to generate the cancer classification predictions. The SSC-LRR was tested on two separate benchmark datasets in control with four state-of-the-art classification methods. It generated cancer classification predictions with an overall accuracy 89.7 percent and a general correlation 0.920, which are 18.9 and 24.4 percent higher than that of the best control method respectively. In addition, several genes RNF114, HLA-DRB5, USP9Y, and PTPN20 were identified by SSC-LRR as new cancer identifiers that deserve further clinical investigation. Overall, the study demonstrated a new sensitive avenue to recognize cancer classifications from large-scale gene expression data.;;;https://dl.acm.org/doi/10.1109/TCBB.2017.2712607;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
OWSP-Miner: Self-adaptive One-off Weak-gap Strong Pattern Mining;;;['Youxi Wu', 'Xiaohui Wang', 'Yan Li', 'Lei Guo', 'Zhao Li', 'Ji Zhang', 'Xindong Wu'];;;None;;;ACM Transactions on Management Information Systems;;;Gap constraint sequential pattern mining (SPM), as a kind of repetitive SPM, can avoid mining too many useless patterns. However, this method is difficult for users to set a suitable gap without prior knowledge and each character is considered to have the same effects. To tackle these issues, this article addresses a self-adaptive One-off Weak-gap Strong Pattern (OWSP) mining, which has three characteristics. First, it determines the gap constraint adaptively according to the sequence. Second, all characters are divided into two groups: strong and weak characters, and the pattern is composed of strong characters, while weak characters are allowed in the gaps. Third, each character can be used at most once in the process of support (the frequency of pattern) calculation. To handle this problem, this article presents OWSP-Miner, which equips with two key steps: support calculation and candidate pattern generation. A reverse-order filling strategy is employed to calculate the support of a candidate pattern, which reduces the time complexity. OWSP-Miner generates candidate patterns using pattern join strategy, which effectively reduces the candidate patterns. For clarification, time series is employed in the experiments and the results show that OWSP-Miner is not only more efficient but also is easier to mine valuable patterns. In the experiment of stock application, we also employ OWSP-Miner to mine OWSPs and the results show that OWSPs mining is more meaningful in real life. The algorithms and data can be downloaded at https://github.com/wuc567/Pattern-Mining/tree/master/OWSP-Miner.;;;https://dl.acm.org/doi/10.1145/3476247;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
An Extensive Study on Cross-Dataset Bias and Evaluation Metrics Interpretation for Machine Learning Applied to Gastrointestinal Tract Abnormality Classification;;;['Vajira Thambawita', 'Debesh Jha', 'Hugo Lewi Hammer', 'Håvard D. Johansen', 'Dag Johansen', 'Pål Halvorsen', 'Michael A. Riegler'];;;None;;;ACM Transactions on Computing for Healthcare;;;Precise and efficient automated identification of gastrointestinal (GI) tract diseases can help doctors treat more patients and improve the rate of disease detection and identification. Currently, automatic analysis of diseases in the GI tract is a hot topic in both computer science and medical-related journals. Nevertheless, the evaluation of such an automatic analysis is often incomplete or simply wrong. Algorithms are often only tested on small and biased datasets, and cross-dataset evaluations are rarely performed. A clear understanding of evaluation metrics and machine learning models with cross datasets is crucial to bring research in the field to a new quality level. Toward this goal, we present comprehensive evaluations of five distinct machine learning models using global features and deep neural networks that can classify 16 different key types of GI tract conditions, including pathological findings, anatomical landmarks, polyp removal conditions, and normal findings from images captured by common GI tract examination instruments. In our evaluation, we introduce performance hexagons using six performance metrics, such as recall, precision, specificity, accuracy, F1-score, and the Matthews correlation coefficient to demonstrate how to determine the real capabilities of models rather than evaluating them shallowly. Furthermore, we perform cross-dataset evaluations using different datasets for training and testing. With these cross-dataset evaluations, we demonstrate the challenge of actually building a generalizable model that could be used across different hospitals. Our experiments clearly show that more sophisticated performance metrics and evaluation methods need to be applied to get reliable models rather than depending on evaluations of the splits of the same dataset—that is, the performance metrics should always be interpreted together rather than relying on a single metric.;;;https://dl.acm.org/doi/10.1145/3386295;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A Semantic Graph-Based Approach for Mining Common Topics from Multiple Asynchronous Text Streams;;;['Long Chen', 'Joemon M. Jose', 'Haitao Yu', 'Fajie Yuan'];;;April 2017;;;WWW '17: Proceedings of the 26th International Conference on World Wide Web;;;In the age of Web 2.0, a substantial amount of unstructured content are distributed through multiple text streams in an asynchronous fashion, which makes it increasingly difficult to glean and distill useful information. An effective way to explore the information in text streams is topic modelling, which can further facilitate other applications such as search, information browsing, and pattern mining. In this paper, we propose a semantic graph based topic modelling approach for structuring asynchronous text streams. Our model integrates topic mining and time synchronization, two core modules for addressing the problem, into a unified model. Specifically, for handling the lexical gap issues, we use global semantic graphs of each timestamp for capturing the hidden interaction among entities from all the text streams. For dealing with the sources asynchronism problem, local semantic graphs are employed to discover similar topics of different entities that can be potentially separated by time gaps. Our experiment on two real-world datasets shows that the proposed model significantly outperforms the existing ones.;;;https://dl.acm.org/doi/10.1145/3038912.3052630;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Deep Learning Method for Spectral Classification;;;['Tianxu Zhang', 'Yao Ma', 'Hang Lin'];;;November 2020;;;ICAIP '20: Proceedings of the 4th International Conference on Advances in Image Processing;;;Spectral images contain both spatial information and spectral information. The resolution of spectral information is very high, generally reaching nanometer level, but the spatial resolution is relatively low. Spectral image classification is a pixel level classification problem [1]. Specifically, it is to classify each pixel in the image and confirm the category of the pixel.Spectral image classification can be divided into unsupervised classification and supervised classification (including semi supervised classification) [2]. Unsupervised classification in deep learning refers to the classification (clustering) of spectral images without data labels in advance. The main idea is to classify similar pixels into one group according to the characteristic information (spatial information, spectral information and characteristics, etc.) that can represent the characteristics of pixels [3]. Supervised classification refers to the classification of spectral images when there are pre-labeled data as supervisory signals. The main idea is to use the labeled data to learn the intrinsic relationship between pixel feature information and pixel categories, and then use this relationship to classify the unlabeled data to determine the pixel category [4].;;;https://dl.acm.org/doi/10.1145/3441250.3441268;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Using opinion mining techniques on Twitter streaming data regards drug safety issues;;;['Abeer Nafel Alharbi', 'Hessah Alnamlah', 'Liyakathunsia Syed'];;;March 2017;;;ICC '17: Proceedings of the Second International Conference on Internet of things, Data and Cloud Computing;;;In this paper, we propose a four-step guideline to perform twitter mining based on consumer's opinion and adverse drug reaction of certain drugs. Due to advances in technology and increased use of social networks, there has been a tremendous amount of public data which grows from terabytes to petabytes. The accessibility of this enormous amount of data offers vast research opportunities for extracting meaningful opinion data for many applications. Drug consumption is one that could be benefited, from methodical sentiment analysis techniques. In this paper we have focused on social media mining for drug related information. To clean the Twitter streaming data and to increase the accuracy of the results, a spam filter and a preprocessing procedure have been developed, to retrieve relevant information about certain drug. Processing and analysis of data were done on 1579 tweets using R-programming. The results show that Twitter mining with formed word cloud is a very useful technique to get the majority of consumer's opinion about the consumed drug. The obtained results shows that, real time streaming of social networking data could help in early detection and prediction of side effects of the drug for patient safety.;;;https://dl.acm.org/doi/10.1145/3018896.3036386;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Spatial data mining and O-D hotspots discovery in cities based on an O-D hotspots clustering model using vehicles' GPS data: a case study in the morning rush hours in Beijing, China;;;['Xiaoyong Ni', 'Hong Huang', 'Shiwei Zhou', 'Boni Su', 'Yangyang Meng', 'Zhongliang Huang'];;;November 2018;;;Safety and Resilience'18: Proceedings of the 4th ACM SIGSPATIAL International Workshop on Safety and Resilience;;;With the rapid development of cities in recent years, the size of the cities is becoming bigger and bigger and the structure of the cities is becoming more and more complex. The first step to study the urban resilience is hotspots mining and POI analysis. This paper established an O-D hotspots clustering model based on Iterative Self Organizing Data Analysis Techniques Algorithm (hereinafter referred to as ISODATA) to mine the Origin-Destination (hereinafter referred to as O-D) hotspots in the rush hours in cities and study the distribution characteristics of Point of Interests (hereinafter referred to as POIs) in the hotspots area. It is found that the pick-up hotspots tend to be gathered in the residential zones and the drop-off hotspots tend to be gathered in the working zones. Besides, the distribution characteristics of POIs in both pick-up and drop-off hotspots areas and huge railway stations (special drop-off hotspots) areas are quite special. This study provides an in-depth understanding of the structure of the cities and provides an effective guidance in urban zones planning. This study also provides fundamental knowledge for urban resilience design.;;;https://dl.acm.org/doi/10.1145/3284103.3284108;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Three-level binary tree structure for sentiment classification in Arabic text;;;['Hajar Ait Addi', 'Redouane Ezzahir', 'Abdelhak Mahmoudi'];;;March 2020;;;NISS '20: Proceedings of the 3rd International Conference on Networking, Information Systems &amp; Security;;;The advent of web 2.0 platforms allowed users to generate and share textual content. This results in an explosive increase of online personal opinion. Sentiment Analysis, which is a recent field of Natural Language Processing, aims to predict the orientation of sentiment present on this massive textual data. This plays a vital role in many applications, such as recommender systems, customer intelligence, information retrieval and psychological study of crowd. Most existing approaches in sentiment analysis trait only positive, negative and neutral classes, ignoring the class strength (weak or strong positive/negative). In this paper, we propose an innovative approach for multi-class hierarchical sentiment classification in Arabic text based on a three-level binary tree structure. Experimental results show that our approach gives significant improvements over other classification methods.;;;https://dl.acm.org/doi/10.1145/3386723.3387844;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Text Classification Based on Keywords with Different Thresholds;;;['Tu Cam Thi Tran', 'Hiep Xuan Huynh', 'Phuc Quang Tran', 'Dinh Quoc Truong'];;;February 2019;;;ICIIT '19: Proceedings of the 2019 4th International Conference on Intelligent Information Technology;;;Text classification is a supervised learning task for assigning text document to one or more predefined classes/topics. These topics are determined by a set of training documents. In order to construct a classification model, a machine learning algorithm was used. The training model is used to predict a class for new coming document. In this paper, we propose a text classification approach based on automatic keywords extraction with different thresholes. We use 3000 Vietnamese text documents, which belong to ten topics, downloaded from two electronic magazines vnexpress.net and vietnamnet.vn to create ten sets of the keywords. These keywords are used to predict the topic of new text document. The experimental results confirm the feasibility of proposed model.;;;https://dl.acm.org/doi/10.1145/3321454.3321473;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
End-to-end Learning for Short Text Expansion;;;['Jian Tang', 'Yue Wang', 'Kai Zheng', 'Qiaozhu Mei'];;;August 2017;;;KDD '17: Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining;;;Effectively making sense of short texts is a critical task for many real world applications such as search engines, social media services, and recommender systems. The task is particularly challenging as a short text contains very sparse information, often too sparse for a machine learning algorithm to pick up useful signals. A common practice for analyzing short text is to first expand it with external information, which is usually harvested from a large collection of longer texts. In literature, short text expansion has been done with all kinds of heuristics. We propose an end-to-end solution that automatically learns how to expand short text to optimize a given learning task. A novel deep memory network is proposed to automatically find relevant information from a collection of longer documents and reformulate the short text through a gating mechanism. Using short text classification as a demonstrating task, we show that the deep memory network significantly outperforms classical text expansion methods with comprehensive experiments on real world data sets.;;;https://dl.acm.org/doi/10.1145/3097983.3098166;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Deep specification mining;;;['Tien-Duy B. Le', 'David Lo'];;;July 2018;;;ISSTA 2018: Proceedings of the 27th ACM SIGSOFT International Symposium on Software Testing and Analysis;;;Formal specifcations are essential but usually unavailable in software systems. Furthermore, writing these specifcations is costly and requires skills from developers. Recently, many automated techniques have been proposed to mine specifcations in various formats including fnite-state automaton (FSA). However, more works in specifcation mining are needed to further improve the accuracy of the inferred specifcations. In this work, we propose Deep Specifcation Miner (DSM), a new approach that performs deep learning for mining FSA-based specifcations. Our proposed approach uses test case generation to generate a richer set of execution traces for training a Recurrent Neural Network Based Language Model (RNNLM). From these execution traces, we construct a Prefx Tree Acceptor (PTA) and use the learned RNNLM to extract many features. These features are subsequently utilized by clustering algorithms to merge similar automata states in the PTA for constructing a number of FSAs. Then, our approach performs a model selection heuristic to estimate F-measure of FSAs and returns the one with the highest estimated Fmeasure. We execute DSM to mine specifcations of 11 target library classes. Our empirical analysis shows that DSM achieves an average F-measure of 71.97%, outperforming the best performing baseline by 28.22%. We also demonstrate the value of DSM in sandboxing Android apps.;;;https://dl.acm.org/doi/10.1145/3213846.3213876;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Opinion mining using an LVQ neural network;;;['Matthaios Stylianidis', 'Eleni Galiotou', 'Cleo Sgouropoulou', 'Christos Skourlas'];;;September 2017;;;PCI '17: Proceedings of the 21st Pan-Hellenic Conference on Informatics;;;Due to the increased use of social media in the past few years, a large volume of data has been accumulated which contains human sentiments and opinions. The field that deals with the automated extraction of opinions is named opinion mining. In this paper, we evaluate the performance of an LVQ neural network on document level analysis using a benchmark movie review dataset. Document-level opinion mining aims at classifying a text, usually as positive or negative based on its overall sentiment. In order to reduce the dimensions of the reviews' vector representations, we use the feature selection method Information Gain. We use an exhaustive grid search for hyperparameter tuning and two methods for performance evaluation: a nested cross validation and a non-nested 10-fold cross validation. We study the performance of our model for different numbers of selected features by Information-Gain.;;;https://dl.acm.org/doi/10.1145/3139367.3139416;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A new text representation method for clustering based on higher order Markov model;;;['Weifeng Yang', 'Guosheng Han', 'Xiaoqiang Xie'];;;April 2018;;;ICISDM '18: Proceedings of the 2nd International Conference on Information System and Data Mining;;;The ordinal relations in word sequence and character sequence can reflect the latent information about writing style, genre features and topic. Thus, the ordinal relations are important information and should be considered for text clustering. However, the ordinal relations were often neglected in the traditional methods of text clustering. In view of that the ordinal relations can be statistically characterized by the transition probabilities of the higher order Markov model, in this paper, a new method based on higher order Markov model was proposed for text representation. In the new method, all transition probabilities of a higher order Markov model are used as features of text, and the order is identified by maximizing the average Markov-Shannon entropy (MME). The experimental results imply the new text representation method performs better than traditional method.;;;https://dl.acm.org/doi/10.1145/3206098.3206099;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Analyzing the Color Image of Taiwan Town by Using Data Mining;;;['Yu-Wei Su', 'Tzren Ru Chou'];;;February 2019;;;ICSCA '19: Proceedings of the 2019 8th International Conference on Software and Computer Applications;;;Researches have pointed out that the colors have the function of conveying messages and is even easier than words to be memorized. The color image of a city, which means people connect with color through knowledge acquired and their life experiences. It includes landscapes, buildings, food, the city culture, local specialties and so on. Thus, building up the distinctive style of a city is an important part of the city image and its related applications. Nowadays, people mostly use three different applications in order to set up and correct the city color tickets. First, field research; second, residents participate in the comprehensive community development; third, particular projects. In this paper, we use data mining to analyze the connecting between people and the city color image. At the beginning, we select ten cities of Taiwan, which were elected by Taiwan Tourism Bureau as our research object. Secondly, we use Word to vector and Google searching engine to find the relevance between the city and adjectives. For the third step, the highest connection of adjective will be the keyword of Google searching engine to collect the pictures by doing cross-comparison of the results. Last but not least, we capture ten colors from city pictures and result in city color combinations. According to the result of this paper, although it needs to adjust in accordance with local culture, we still can find the regional pictures that correspond with the characteristics and also can obtain the city color combinations, which can be used as a reference of harmonious colors.;;;https://dl.acm.org/doi/10.1145/3316615.3316624;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Mining Expressive Rules in Knowledge Graphs;;;['Naser Ahmadi', 'Viet-Phi Huynh', 'Vamsi Meduri', 'Stefano Ortona', 'Paolo Papotti'];;;None;;;Journal of Data and Information Quality;;;We describe RuDiK, an algorithm and a system for mining declarative rules over RDF knowledge graphs (KGs). RuDiK can discover rules expressing both positive relationships between KG elements, e.g., “if two persons share at least one parent, they are likely to be siblings,” and negative patterns identifying data contradictions, e.g., “if two persons are married, one cannot be the child of the other” or “the birth year for a person cannot be bigger than her graduation year.” While the first kind of rules identify new facts in the KG, the second kind enables the detection of incorrect triples and the generation of (training) negative examples for learning algorithms. High-quality rules are also critical for any reasoning task involving the KGs.Our approach increases the expressive power of the supported rule language w.r.t. the existing systems. RuDiK discovers rules containing (i) comparisons among literal values and (ii) selection conditions with constants. Richer rules increase the accuracy and the coverage over the facts in the KG for the task at hand. This is achieved with aggressive pruning of the search space and with disk-based algorithms, which enable the execution of the system in commodity machines. Also, RuDiK is robust to errors and missing data in the input graph. It discovers approximate rules with a measure of support that is aware of the quality issues. Our experimental evaluation with real-world KGs shows that RuDiK does better than existing solutions in terms of scalability and that it can identify effective rules for different target applications.;;;https://dl.acm.org/doi/10.1145/3371315;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
TLS Encrypted Application Classification Using Machine Learning with Flow Feature Engineering;;;['Onur Barut', 'Rebecca Zhu', 'Yan Luo', 'Tong Zhang'];;;November 2020;;;ICCNS '20: Proceedings of the 2020 10th International Conference on Communication and Network Security;;;Network traffic classification has become increasingly important as the number of devices connected to the Internet is rapidly growing. Proportionally, the amount of encrypted traffic is also increasing, making payload based classification methods obsolete. Consequently, machine learning approaches have become crucial when user privacy is concerned. For this purpose, we propose an accurate, fast, and privacy preserved encrypted traffic classification approach with engineered flow feature extraction and appropriate feature selection. The proposed scheme achieves a 0.92899 macro-average F1 score and a 0.88313 macro-averaged mAP score for the encrypted traffic classification of Audio, Email, Chat, and Video classes derived from the non-vpn2016 dataset. Further experiments on the mixed non-encrypted and encrypted flow dataset with a data augmentation method called Synthetic Minority Over-Sampling Technique are conducted and the results are discussed for TLS-encrypted and mixed flows.;;;https://dl.acm.org/doi/10.1145/3442520.3442529;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Discussion on Information Overlap in Hyperspectral Image Classification Based on Machine Learning;;;['Qingjie Yang', 'Rong Zhang', 'Yi Fang'];;;January 2021;;;ICIGP '21: Proceedings of the 2021 4th International Conference on Image and Graphics Processing;;;Principal component analysis(PCA) and spectral-spatial methods are usually used in hyperspectral images(HSI) classification based on machine learning. These methods have achieved high classification accuracy for several publicly hyperspectral datasets. However, we believe that high accuracy is mainly due to information overlap between the training and test set. In this paper, we have discussed the problem of information overlap caused by PCA and neighborhood region extraction. First, the PCA transformation matrix is fitted on the whole image, which leads to the spectral information overlap between the training and test samples. Second, there are pixels for testing in the neighborhood regions extracted by the training pixels, which cause spatial information overlap. In order to explore the influence of information overlap on classification results, we compare the classification results with or without information overlap using support vector machine (SVM) and convolutional neural network (CNN). Experiments indicate that classification results in above two information overlap cases are less reliable. In fact, in the method based on machine learning, the test set should be completely independent of the training set to ensure the accuracy, reliability and universality of the classification results. Therefore, the discussion on information overlap in HSIs classification method creates a new approach in future research and design for more reliable hyperspectral classification methods.;;;https://dl.acm.org/doi/10.1145/3447587.3447610;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
AutoSmart: An Efficient and Automatic Machine Learning Framework for Temporal Relational Data;;;['Zhipeng Luo', 'Zhixing He', 'Jin Wang', 'Manqing Dong', 'Jianqiang Huang', 'Mingjian Chen', 'Bohang Zheng'];;;August 2021;;;KDD '21: Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining;;;Temporal relational data, perhaps the most commonly used data type in industrial machine learning applications, needs labor-intensive feature engineering and data analyzing for giving precise model predictions. An automatic machine learning framework is needed to ease the manual efforts in fine-tuning the models so that the experts can focus more on other problems that really need humans' engagement such as problem definition, deployment, and business services. However, there are three main challenges for building automatic solutions for temporal relational data: 1) how to effectively and automatically mining useful information from the multiple tables and the relations from them? 2) how to be self-adjustable to control the time and memory consumption within a certain budget? and 3) how to give generic solutions to a wide range of tasks? In this work, we propose our solution that successfully addresses the above issues in an end-to-end automatic way. The proposed framework, AutoSmart, is the winning solution to the KDD Cup 2019 of the AutoML Track, which is one of the largest AutoML competition to date (860 teams with around 4,955 submissions). The framework includes automatic data processing, table merging, feature engineering, and model tuning, with a time and memory controller for efficiently and automatically formulating the models. The proposed framework outperforms the baseline solution significantly on several datasets in various domains.;;;https://dl.acm.org/doi/10.1145/3447548.3467088;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Similarity Association Pattern Mining in Transaction Databases;;;['Phridviraj M.S.B', 'Guru Rao C.V', 'Radhakrishna Vangipuram', 'Aravind Cheruvu'];;;April 2021;;;DATA'21: International Conference on Data Science, E-learning and Information Systems 2021;;;Association pattern mining is a method of finding interesting relationships or patterns between item sets present in each of the transactions of the transactional databases. Current researchers in this area are focusing on the data mining task of finding frequent patterns among the item sets based on the interestingness measures like the support and confidence which is called as Frequent pattern mining. Till date, in existing frequent pattern mining algorithms, an itemset is said to be frequent if the support of the itemset satisfies the minimum support input. In this paper, the objective of our algorithm is to find interesting patterns among the item sets based on a Gaussian similarity for an input reference threshold which is first of its kind in the research literature. This study is limited to outlining naïve approach of mining frequent itemsets which requires validating every itemset to verify if the itemset is frequent or not.;;;https://dl.acm.org/doi/10.1145/3460620.3460752;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Augmented SVM with ordinal partitioning for text classification;;;['Yong Shi', 'Peijia Li', 'Lingfeng Niu'];;;August 2017;;;WI '17: Proceedings of the International Conference on Web Intelligence;;;Ordinal regression has received increasing interest in the past years. It aims to classify patterns by an ordinal scale. With the the explosive growth of data, the method of SVM with ordinal partitioning called SVMOP highlights its advantages due to its convenience of dealing with large scale data. However, the method of SVMOP for ordinal regression has not been exploited much. As we know, the costs should be different when dealing with mislabeled samples and how to use them plays a dominant role in model building. However, L2-loss which could enlarge the cost sensitivity has not been applied into SVM ordinal partition yet. In this paper, we propose the method of SVMOP with L2-loss for ordinal regression. Numerical results show that our approach outperforms the method of SVMOP with L1-loss and other ordianl regression models.;;;https://dl.acm.org/doi/10.1145/3106426.3109428;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Data Integration and Machine Learning: A Natural Synergy;;;['Xin Luna Dong', 'Theodoros Rekatsinas'];;;May 2018;;;SIGMOD '18: Proceedings of the 2018 International Conference on Management of Data;;;There is now more data to analyze than ever before. As data volume and variety have increased, so have the ties between machine learning and data integration become stronger. For machine learning to be effective, one must utilize data from the greatest possible variety of sources; and this is why data integration plays a key role. At the same time machine learning is driving automation in data integration, resulting in overall reduction of integration costs and improved accuracy. This tutorial focuses on three aspects of the synergistic relationship between data integration and machine learning: (1) we survey how state-of-the-art data integration solutions rely on machine learning-based approaches for accurate results and effective human-in-the-loop pipelines, (2) we review how end-to-end machine learning applications rely on data integration to identify accurate, clean, and relevant data for their analytics exercises, and (3) we discuss open research challenges and opportunities that span across data integration and machine learning.;;;https://dl.acm.org/doi/10.1145/3183713.3197387;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Classification and Clustering of arXiv Documents, Sections, and Abstracts, Comparing Encodings of Natural and Mathematical Language;;;['Philipp Scharpf', 'Moritz Schubotz', 'Abdou Youssef', 'Felix Hamborg', 'Norman Meuschke', 'Bela Gipp'];;;August 2020;;;JCDL '20: Proceedings of the ACM/IEEE Joint Conference on Digital Libraries in 2020;;;In this paper, we show how selecting and combining encodings of natural and mathematical language affect classification and clustering of documents with mathematical content. We demonstrate this by using sets of documents, sections, and abstracts from the arXiv preprint server that are labeled by their subject class (mathematics, computer science, physics, etc.) to compare different encodings of text and formulae and evaluate the performance and runtimes of selected classification and clustering algorithms. Our encodings achieve classification accuracies up to 82.8% and cluster purities up to 69.4% (number of clusters equals number of classes), and 99.9% (unspecified number of clusters) respectively. We observe a relatively low correlation between text and math similarity, which indicates the independence of text and formulae and motivates treating them as separate features of a document. The classification and clustering can be employed, e.g., for document search and recommendation. Furthermore, we show that the computer outperforms a human expert when classifying documents. Finally, we evaluate and discuss multi-label classification and formula semantification.;;;https://dl.acm.org/doi/10.1145/3383583.3398529;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Hybrid machine learning methods for demand forecasting: consecutive application of classification and regression methods for the forecasting of periodic and non-continuous demand;;;['Víctor Álvarez-López', 'B. Rosario Campomanes-Álvarez', 'Pelayo Quirós'];;;January 2019;;;APPIS '19: Proceedings of the 2nd International Conference on Applications of Intelligent Systems;;;This paper is focused on demand forecasting, where the orders from each customer are generated periodically but in a non-continuous way, so most of the values for each client and temporal instant are zeros. The application of regression models is compared to hybrid methods, where an initial classification is considered in order to identify the temporal instants in which an order has been predicted, and afterwards, a regression is generated to obtain the predicted amount of such order. This procedure is complemented by an application to real demand data, for selecting the proper methods for both phases, as well as comparing to simple regression models.;;;https://dl.acm.org/doi/10.1145/3309772.3309773;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Compatibility-Aware Web API Recommendation for Mashup Creation via Textual Description Mining;;;['Lianyong Qi', 'Houbing Song', 'Xuyun Zhang', 'Gautam Srivastava', 'Xiaolong Xu', 'Shui Yu'];;;None;;;ACM Transactions on Multimedia Computing, Communications, and Applications;;;With the ever-increasing prosperity of web Application Programming Interface (API) sharing platforms, it is becoming an economic and efficient way for software developers to design their interested mashups through web API re-use. Generally, a software developer can browse, evaluate, and select his or her preferred web APIs from the API's sharing platforms to create various mashups with rich functionality. The big volume of candidate APIs places a heavy burden on software developers’ API selection decisions. This, in turn, calls for the support of intelligent API recommender systems. However, existing API recommender systems often face two challenges. First, they focus more on the functional accuracy of APIs while neglecting the APIs’ actual compatibility. This then creates incompatible mashups. Second, they often require software developers to input a set of keywords that can accurately describe the expected functions of the mashup to be developed. This second challenge tests partial developers who have little background knowledge in the fields. To tackle the above-mentioned challenges, in this article we propose a compatibility-aware and text description-driven web API recommendation approach (named WARtext). WARtext guarantees the compatibility among the recommended APIs by utilizing the APIs’ composition records produced by historical mashup creations. Besides, WARtext entitles a software developer to type a simple text document that describes the expected mashup functions as input. Then through textual description mining, WARtext can precisely capture the developers’ functional requirements and then return a set of APIs with the highest compatibility. Finally, through a real-world mashup dataset ProgrammableWeb, we validate the feasibility of our novel approach.;;;https://dl.acm.org/doi/10.1145/3417293;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Website Defacements Detection Based on Support Vector Machine Classification Method;;;['Siyan Wu', 'Xiaojun Tong', 'Wei Wang', 'Guodong Xin', 'Bailing Wang', 'Qi Zhou'];;;May 2018;;;ICCDE '18: Proceedings of the 2018 International Conference on Computing and Data Engineering;;;Website defacements can inflict significant harm on the website owner through the loss of reputation, the loss of money, or the leakage of information. Due to the complexity and diversity of all kinds of web application systems, especially a lack of necessary security maintenance, website defacements increased year by year. In this paper, we focus on detecting whether the website has been defaced by extracting website features and website embedded trojan features. We use three kinds of classification learning algorithms which include Gradient Boosting Decision Tree (GBDT), Random Forest (RF) and Support Vector Machine (SVM) to do the classification experiments, and experimental results show that Support Vector Machine classifier performed better than two other classifiers. It can achieve an overall accuracy of 95%-96% in detecting website defacements.;;;https://dl.acm.org/doi/10.1145/3219788.3219804;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Towards rapid interactive machine learning: evaluating tradeoffs of classification without representation;;;['Dustin Arendt', 'Emily Saldanha', 'Ryan Wesslen', 'Svitlana Volkova', 'Wenwen Dou'];;;March 2019;;;IUI '19: Proceedings of the 24th International Conference on Intelligent User Interfaces;;;Our contribution is the design and evaluation of an interactive machine learning interface that rapidly provides the user with model feedback after every interaction. To address visual scalability, this interface communicates with the user via a "tip of the iceberg" approach, where the user interacts with a small set of recommended instances for each class. To address computational scalability, we developed an O(n) classification algorithm that incorporates user feedback incrementally, and without consulting the data's underlying representation matrix. Our computational evaluation showed that this algorithm has similar accuracy to several off-the-shelf classification algorithms with small amounts of labeled data. Empirical evaluation revealed that users performed better using our design compared to an equivalent active learning setup.;;;https://dl.acm.org/doi/10.1145/3301275.3302280;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Compressive Sensing Based on Homomorphic Encryption and Attack Classification using Machine Learning Algorithm in WSN Security;;;['Samir Ifzarne', 'Imad Hafidi', 'Nadia Idrissi'];;;March 2020;;;NISS '20: Proceedings of the 3rd International Conference on Networking, Information Systems &amp; Security;;;Data protection is essential for sensitive applications using Wireless Sensor Networks like health monitoring or video surveillance. WSN are deployed generally in harsh environment making them vulnerable for attacks thus it's important to secure data while being transferred from the sensor until the base station. This article is a proposal for a methodology which enable attack detection and classification on WSN. Compressive sensing is used to optimize the size of data exchange and hence optimize energy consumption. Homomorphic encryption allows to reduce encryption complexity by applying arithmetic operations on cypher text. Machine learning is applied to classify the attacks quickly.;;;https://dl.acm.org/doi/10.1145/3386723.3387859;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Distance Based Pattern Driven Mining for Outlier Detection in High Dimensional Big Dataset;;;['Ankit Kumar', 'Abhishek Kumar', 'Ali Kashif Bashir', 'Mamoon Rashid', 'V. D. Ambeth Kumar', 'Rupak Kharel'];;;None;;;ACM Transactions on Management Information Systems;;;Detection of outliers or anomalies is one of the vital issues in pattern-driven data mining. Outlier detection detects the inconsistent behavior of individual objects. It is an important sector in the data mining field with several different applications such as detecting credit card fraud, hacking discovery and discovering criminal activities. It is necessary to develop tools used to uncover the critical information established in the extensive data. This paper investigated a novel method for detecting cluster outliers in a multidimensional dataset, capable of identifying the clusters and outliers for datasets containing noise. The proposed method can detect the groups and outliers left by the clustering process, like instant irregular sets of clusters (C) and outliers (O), to boost the results. The results obtained after applying the algorithm to the dataset improved in terms of several parameters. For the comparative analysis, the accurate average value and the recall value parameters are computed. The accurate average value is 74.05% of the existing COID algorithm, and our proposed algorithm has 77.21%. The average recall value is 81.19% and 89.51% of the existing and proposed algorithm, which shows that the proposed work efficiency is better than the existing COID algorithm.;;;https://dl.acm.org/doi/10.1145/3469891;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Explanation Mining: Post Hoc Interpretability of Latent Factor Models for Recommendation Systems;;;['Georgina Peake', 'Jun Wang'];;;July 2018;;;KDD '18: Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining;;;The widescale use of machine learning algorithms to drive decision-making has highlighted the critical importance of ensuring the interpretability of such models in order to engender trust in their output. The state-of-the-art recommendation systems use black-box latent factor models that provide no explanation of why a recommendation has been made, as they abstract their decision processes to a high-dimensional latent space which is beyond the direct comprehension of humans. We propose a novel approach for extracting explanations from latent factor recommendation systems by training association rules on the output of a matrix factorisation black-box model. By taking advantage of the interpretable structure of association rules, we demonstrate that predictive accuracy of the recommendation model can be maintained whilst yielding explanations with high fidelity to the black-box model on a unique industry dataset. Our approach mitigates the accuracy-interpretability trade-off whilst avoiding the need to sacrifice flexibility or use external data sources. We also contribute to the ill-defined problem of evaluating interpretability.;;;https://dl.acm.org/doi/10.1145/3219819.3220072;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Application of Support Vector Machine Methods in Classification of Customer Communications Data;;;['Huynh Tan Hoi', 'Le Vu Truong'];;;August 2020;;;CCCIS 2020: Proceedings of the 2020 International Conference on Computer Communication and Information Systems;;;The paper used automatic information extraction technique, text classification by SVM (Support vector machine) method, combined with Vietnamese word separation technique and natural language processing. Application results of the research used in extracting information, collecting user feedback from e-commerce websites, social networking sites providing businesses with useful information from contributing users in order to build an effective business strategy. The main contributions of this paper are the following: • Apply the BiGAN, the ability of the model to learn mutually coherent inference and generation networks through the inspections of model samples and reconstructions and confirm the usefulness of the learned representations by obtaining a performance competitive with state-of-the-art on Motorbike Generator task. • Improves learning for BiGAN outperforming several state-of-the-art GAN methods training on motorbike dataset by a few techniques such as preprocessing data, data augmentation and hyperparameter tuning.;;;https://dl.acm.org/doi/10.1145/3418994.3419002;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Lifelong Machine Learning: Outlook and Direction;;;['Xianbin Hong', 'Prudence Wong', 'Dawei Liu', 'Sheng-Uei Guan', 'Ka Lok Man', 'Xin Huang'];;;October 2018;;;ICBDR '18: Proceedings of the 2nd International Conference on Big Data Research;;;The Lifelong machine learning is an advanced machine learning paradigm and also is the key to the stronger AI. In this paper, we review the development history of the lifelong machine learning and evaluate the current stage. The aim, definition and main components of it is introduced. In addition, the bottleneck and possible solution also is discussed and the further development waypoint is proposed.;;;https://dl.acm.org/doi/10.1145/3291801.3291829;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Discriminant Projection Shared Dictionary Learning for Classification of Tumors Using Gene Expression Data;;;['Shaoliang Peng', 'Yaning Yang', 'Wei Liu', 'Fei Li', 'Xiangke Liao'];;;None;;;IEEE/ACM Transactions on Computational Biology and Bioinformatics;;;With a variety of tumor subtypes, personalized treatments need to identify the subtype of a tumor as accurately as possible. The development of DNA microarrays provides an opportunity to predict tumor classification. One strategy is to use gene expression profiling to extend current biological insights into the disease. However, overfitting problems exist in most machine learning methods when classifying tumor gene expression profile data characterized by high dimensional, small samples and nonlinearities. As a new machine learning methods, dictionary learning has become a more effective algorithm for gene expression profile classification. Here, a new method called discriminant projection shared dictionary learning (DPSDL) is proposed for classifying tumor subtypes using LINCS gene expression profile data. The method trains a shared dictionary, embeds Fisher discriminant criteria to obtain a class-specific sub-dictionary and coding coefficients. At the same time, a projection matrix is trained to widen the distance between different classes of samples. Experimental results show that our method performs better classification based on gene expression profile than the other dictionary learning methods and machine learning methods.;;;https://dl.acm.org/doi/10.1109/TCBB.2019.2950209;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Implicit data recommendation based on refined classification and ranking learning;;;['Yuwei Liu'];;;November 2020;;;ICBDR '20: Proceedings of the 4th International Conference on Big Data Research;;;With the exponential growth of data, it becomes more and more difficult to quickly obtain valuable information from massive amounts of data. Clicking and browsing of such non-scoring implicit data has also attracted more and more attention from scholars. Recommendations for implicit data generally use bayesian personalized ranking algorithm (BPR). The algorithm focuses on the difference in preferences between item pairs, and believes that users prefer items that have interacted with items that have never interacted. However, this assumption is still not specific enough for analyzing the relationship between users' items. Therefore, this paper expands the single pairwise sorting algorithm into a more detailed pair-level parallel sorting. First, the non-interactive item set is refined into two categories through the concept of frequent item sets: uncertain feedback and negative feedback. Secondly, the algorithm of fusion of BPR and list sorting is used to relax the assumptions of independence, and two sets are analyzed separately. This also alleviates the sparsity problem of implicit data due to natural imbalance. Finally, a simulation experiment was performed on the public data set. The experimental results show that the refined BPR algorithm has a better improvement than the baseline algorithm.;;;https://dl.acm.org/doi/10.1145/3445945.3445959;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Multi-View Fusion with Extreme Learning Machine for Clustering;;;['Yongshan Zhang', 'Jia Wu', 'Chuan Zhou', 'Zhihua Cai', 'Jian Yang', 'Philip S. Yu'];;;None;;;ACM Transactions on Intelligent Systems and Technology;;;Unlabeled, multi-view data presents a considerable challenge in many real-world data analysis tasks. These data are worth exploring because they often contain complementary information that improves the quality of the analysis results. Clustering with multi-view data is a particularly challenging problem as revealing the complex data structures between many feature spaces demands discriminative features that are specific to the task and, when too few of these features are present, performance suffers. Extreme learning machines (ELMs) are an emerging form of learning model that have shown an outstanding representation ability and superior performance in a range of different learning tasks. Motivated by the promise of this advancement, we have developed a novel multi-view fusion clustering framework based on an ELM, called MVEC. MVEC learns the embeddings from each view of the data via the ELM network, then constructs a single unified embedding according to the correlations and dependencies between each embedding and automatically weighting the contribution of each. This process exposes the underlying clustering structures embedded within multi-view data with a high degree of accuracy. A simple yet efficient solution is also provided to solve the optimization problem within MVEC. Experiments and comparisons on eight different benchmarks from different domains confirm MVEC’s clustering accuracy.;;;https://dl.acm.org/doi/10.1145/3340268;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
NTP-Miner: Nonoverlapping Three-Way Sequential Pattern Mining;;;['Youxi Wu', 'Lanfang Luo', 'Yan Li', 'Lei Guo', 'Philippe Fournier-Viger', 'Xingquan Zhu', 'Xindong Wu'];;;None;;;ACM Transactions on Knowledge Discovery from Data;;;Nonoverlapping sequential pattern mining is an important type of sequential pattern mining (SPM) with gap constraints, which not only can reveal interesting patterns to users but also can effectively reduce the search space using the Apriori (anti-monotonicity) property. However, the existing algorithms do not focus on attributes of interest to users, meaning that existing methods may discover many frequent patterns that are redundant. To solve this problem, this article proposes a task called nonoverlapping three-way sequential pattern (NTP) mining, where attributes are categorized according to three levels of interest: strong, medium, and weak interest. NTP mining can effectively avoid mining redundant patterns since the NTPs are composed of strong and medium interest items. Moreover, NTPs can avoid serious deviations (the occurrence is significantly different from its pattern) since gap constraints cannot match with strong interest patterns. To mine NTPs, an effective algorithm is put forward, called NTP-Miner, which applies two main steps: support (frequency occurrence) calculation and candidate pattern generation. To calculate the support of an NTP, depth-first and backtracking strategies are adopted, which do not require creating a whole Nettree structure, meaning that many redundant nodes and parent–child relationships do not need to be created. Hence, time and space efficiency is improved. To generate candidate patterns while reducing their number, NTP-Miner employs a pattern join strategy and only mines patterns of strong and medium interest. Experimental results on stock market and protein datasets show that NTP-Miner not only is more efficient than other competitive approaches but can also help users find more valuable patterns. More importantly, NTP mining has achieved better performance than other competitive methods in clustering tasks. Algorithms and data are available at:  https://github.com/wuc567/Pattern-Mining/tree/master/NTP-Miner.;;;https://dl.acm.org/doi/10.1145/3480245;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Holy Basil Curl Leaf Disease Classification using Edge Detection and Machine Learning;;;['Pikulkaew Tangtisanon', 'Suttipong Kornrapat'];;;February 2020;;;ICCAE 2020: Proceedings of the 2020 12th International Conference on Computer and Automation Engineering;;;Holy basil (Ocimum basilicum L.) is one of the most vital economic crops that has a significant impact on export earnings. However, the holy basil prices could be dropped due to a curl leaf disease caused by pests. Several previous studies focused on plant leaf disease detection based on the leaf color. Unfortunately, the leaf curl disease sometimes changes a shape of the leaf not the color so it cannot be detected with those schemes. We proposed a novel approach aims to automatically detect a curling leaf on holy basil. This paper presents a Neural Network (NN) model and Logistic Regression (LR) model to automatically detect a curling leaf on holy basil. To be able to detect the infected one not by colors but by its shape, we have applied edge detection algorithms which are Canny and Sobel model. To speed up processing time, images were resized and converted to grayscale before passing them to machine learning models. Moreover, NN and LR were modified with mini-batch technique in order to increase the speed of the processing time. The dataset contains 600 images of holy basil leaves with 300 images of healthy leaves and 300 images of infected leaves. The experimental results indicate that the proposed method effectively detects the curling leaves on holy basil.;;;https://dl.acm.org/doi/10.1145/3384613.3384634;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Classification of News Texts Based on Bayes Algorithm;;;['Qian Wang', 'HongLi Xu', 'YanLing Li'];;;October 2021;;;EITCE '21: Proceedings of the 2021 5th International Conference on Electronic Information Technology and Computer Engineering;;;At present, in order to obtain valuable information from the mixed information in a short time, the text classification in data mining emerges with the time going. we used the naive Bayes algorithm to solve the problem of text classification in data mining. Firstly, we need further preprocessing to reflect this feature of the text, which is TF-ID. Secondly, through the integrated environment anaconda platform of Python, the principle of naive Bayesian classification model is mastered and the whole process of news classification is displayed. Finally, the characteristic extraction with TF-IDF value, the accuracy of Bayesian classifier was significantly improved. The emphasis is on the working principle of naive Bayes model with multinomial as a priori and the improvement on the methodof text feature extraction.: the extraction method of TF-IDF is more reasonable.;;;https://dl.acm.org/doi/10.1145/3501409.3501636;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Web Intelligence Data Clustering by Bare Bone Fireworks Algorithm Combined with K-Means;;;['Eva Tuba', 'Raka Jovanovic', 'Romana Capor Hrosik', 'Adis Alihodzic', 'Milan Tuba'];;;June 2018;;;WIMS '18: Proceedings of the 8th International Conference on Web Intelligence, Mining and Semantics;;;Data mining and clustering are important elements of various applications in different fields. One of the areas were clustering is rather frequently used is web intelligence, which nowadays represents an important research area. Data collected from the web are usually very complex, dynamic, without structure and rather large. Traditional clustering techniques are not efficient enough and need to be improved. In this paper, we propose combination of recent swarm intelligence algorithm, bare bones fireworks algorithm, and k-means for clustering web intelligence data. The proposed method was compared with other approaches from literature. Based on the experimental results, it can be concluded that the proposed method has very promising characteristics in terms of the quality of clustering, as well as the execution time.;;;https://dl.acm.org/doi/10.1145/3227609.3227650;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
NTP-Miner: Nonoverlapping Three-Way Sequential Pattern Mining;;;['Youxi Wu', 'Lanfang Luo', 'Yan Li', 'Lei Guo', 'Philippe Fournier-Viger', 'Xingquan Zhu', 'Xindong Wu'];;;None;;;ACM Transactions on Knowledge Discovery from Data;;;Nonoverlapping sequential pattern mining is an important type of sequential pattern mining (SPM) with gap constraints, which not only can reveal interesting patterns to users but also can effectively reduce the search space using the Apriori (anti-monotonicity) property. However, the existing algorithms do not focus on attributes of interest to users, meaning that existing methods may discover many frequent patterns that are redundant. To solve this problem, this article proposes a task called nonoverlapping three-way sequential pattern (NTP) mining, where attributes are categorized according to three levels of interest: strong, medium, and weak interest. NTP mining can effectively avoid mining redundant patterns since the NTPs are composed of strong and medium interest items. Moreover, NTPs can avoid serious deviations (the occurrence is significantly different from its pattern) since gap constraints cannot match with strong interest patterns. To mine NTPs, an effective algorithm is put forward, called NTP-Miner, which applies two main steps: support (frequency occurrence) calculation and candidate pattern generation. To calculate the support of an NTP, depth-first and backtracking strategies are adopted, which do not require creating a whole Nettree structure, meaning that many redundant nodes and parent–child relationships do not need to be created. Hence, time and space efficiency is improved. To generate candidate patterns while reducing their number, NTP-Miner employs a pattern join strategy and only mines patterns of strong and medium interest. Experimental results on stock market and protein datasets show that NTP-Miner not only is more efficient than other competitive approaches but can also help users find more valuable patterns. More importantly, NTP mining has achieved better performance than other competitive methods in clustering tasks. Algorithms and data are available at:  https://github.com/wuc567/Pattern-Mining/tree/master/NTP-Miner.;;;https://dl.acm.org/doi/10.1145/3480245;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Ecg Classification using Machine Learning Techniques and Smote Oversampling Technique;;;['Zhang Xing Zhong', 'Akotonou J. Michael', 'Zhao Jie Lun', 'Dong Hong Yue'];;;August 2020;;;IPMV '20: Proceedings of the 2020 2nd International Conference on Image Processing and Machine Vision;;;In this paper, automatic classification of Atrial Fibrillation (AF) based on single lead ECG signal was proposed using three different classification algorithm AdaBoost, K-Nearest Neighbors (KNN) and Support Vector Machine (SVM). SMOTE technique was applied as data oversampling techniques. Many features were extracted and Minimum Redundancy Maximum Relevance (MRMR) algorithm was used to select relevant features. 5834 records were selected from the Physionet Challenge 2017 dataset for this experiment. Classification using oversampling technique yields best results for all classifiers involved. AdaBoost on oversampling data yields the best accuracy of 98.8%.;;;https://dl.acm.org/doi/10.1145/3421558.3421560;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Probabilistic Topic Models for Text Data Retrieval and Analysis;;;['ChengXiang Zhai'];;;August 2017;;;SIGIR '17: Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval;;;Text data include all kinds of natural language text such as web pages, news articles, scientific literature, emails, enterprise documents, and social media posts. As text data continues to grow quickly, it is increasingly important to develop intelligent systems to help people manage and make use of vast amounts of text data ("big text data"). As a new family of effective general approaches to text data retrieval and analysis, probabilistic topic models, notably Probabilistic Latent Semantic Analysis (PLSA), Latent Dirichlet Allocations (LDA), and many extensions of them, have been studied actively in the past decade with widespread applications. These topic models are powerful tools for extracting and analyzing latent topics contained in text data; they also provide a general and robust latent semantic representation of text data, thus improving many applications in information retrieval and text mining. Since they are general and robust, they can be applied to text data in any natural language and about any topics. This tutorial will systematically review the major research progress in probabilistic topic models and discuss their applications in text retrieval and text mining. The tutorial will provide (1) an in-depth explanation of the basic concepts, underlying principles, and the two basic topic models (i.e., PLSA and LDA) that have widespread applications, (2) a broad overview of all the major representative topic models (that are usually extensions of PLSA or LDA), and (3) a discussion of major challenges and future research directions. The tutorial should be appealing to anyone who would like to learn about topic models, how and why they work, their widespread applications, and the remaining research challenges to be solved, including especially graduate students, researchers who want to develop new topic models, and practitioners who want to apply topic models to solve many application problems. The attendants are expected to have basic knowledge of probability and statistics.;;;https://dl.acm.org/doi/10.1145/3077136.3082067;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Speeding up the data extraction of machine learning approaches: a distributed framework;;;['Martin Steinhauer', 'Fabio Palomba'];;;November 2020;;;MaLTeSQuE 2020: Proceedings of the 4th ACM SIGSOFT International Workshop on Machine-Learning Techniques for Software-Quality Evaluation;;;In the last decade, mining software repositories (MSR) has become one of the most important sources to feed machine learning models. Especially open-source projects on platforms like GitHub are providing a tremendous amount of data and make them easily accessible. Nevertheless, there is still a lack of standardized pipelines to extract data in an automated and fast way. Even though several frameworks and tools exist which can fulfill specific tasks or parts of the data extraction process, none of them allow neither building an automated mining pipeline nor the possibility for full parallelization. As a consequence, researchers interested in using mining software repositories to feed machine learning models are often forced to re-implement commonly used tasks leading to additional development time and libraries may not be integrated optimally.   This preliminary study aims to demonstrate current limitations of existing tools and Git itself which are threatening the prospects of standardization and parallelization. We also introduce the multi-dimensionality aspects of a Git repository and how they affect the computation time. Finally, as a proof of concept, we define an exemplary pipeline for predicting refactoring operations, assessing its performance. Finally, we discuss the limitations of the pipeline and further optimizations to be done.;;;https://dl.acm.org/doi/10.1145/3416505.3423562;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Recognizing Common Skin Diseases in the Philippines Using Image Processing and Machine Learning Classification;;;['JOEL CASUAYAN DE GOMA', 'MADHAVI DEVARAJ'];;;August 2020;;;ICCBD '20: 2020 the 3rd International Conference on Computing and Big Data;;;Skin disease is prevalent in tropical climates, developing countries, people with poor hygiene, and polluted areas. It is a kind of disease that is visible to human eyes which makes carriers susceptible to shame and may cause people to keep distance from them. Even though it is visible to human eyes, people are unaware of what kind of skin disease they have, and with this, people would go to dermatological clinics to have their skin checked, and to have a diagnosis. In line with this, the proponents created a system that detects and classifies skin diseases, particularly acne vulgaris, atopic dermatitis, keratosis pilaris (Chicken Skin), psoriasis, leprosy, and warts. This research has used different pre-processing and segmentation algorithms to successfully extract features (texture, edge, and color). The extracted features were contained as a feature vector and were used to train the Support Vector Machine classifier and the Artificial Neural Network classifier. For the Support Vector Machine (SVM), the model peaked an average of 93.55% and 93.33% for precision and recall, respectively, and for the Artificial Neural Network (ANN) classifier, it peaked 96.55% for precision and 100% for recall.;;;https://dl.acm.org/doi/10.1145/3418688.3418700;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Identifying Social Network Delusion to Investigate Addiction Ratio using Data Mining;;;['K. S. Thakre', 'Deepali Dawande', 'Vaidehi S. Thakre'];;;January 2020;;;APIT '20: Proceedings of the 2020 2nd Asia Pacific Information Technology Conference;;;Mining social media is the process of defining, analyzing, and extracting applicative patterns and trends from row social media data. Social media are very popular way of expressing opinions and interacting with many individual in the online world. However growing number of social network delusion among various age categories are recently noted. Mental sickness can have a deep influence on person, families, and society as well. Hence, we propose a framework that analyzes Social Network Delusion (SND) and investigates the addiction ratio. This work first defines the framework for analyzing the social network delusion based on mining online social behavior that provides an early stage opportunity to identify SNDs (Social Network Delusion). The proposed system mainly works in three phases. Feature extraction and analysis of the various posts posted by the users on Facebook, Instagram and Twitter is performed by using mining algorithm in the first step. The SND prediction using the extracted features is done in the second phase; Third phase uses the predicted results as an input for investigating the addiction ratio. We investigate the addiction ratio among different genders and age groups for analyzing the prevention strategies against growing number of SND.;;;https://dl.acm.org/doi/10.1145/3379310.3379321;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A Hybrid Machine Learning Approach for Improving Mortality Risk Prediction on Imbalanced Data;;;['Araek Tashkandi', 'Lena Wiese'];;;December 2019;;;iiWAS2019: Proceedings of the 21st International Conference on Information Integration and Web-based Applications &amp; Services;;;The efficiency of Machine Learning (ML) models has widely been acknowledged in the healthcare area. However, the quality of the underlying medical data is a major challenge when applying ML in medical decision making. In particular, the imbalanced class distribution problem causes the ML model to be biased towards the majority class. Furthermore, the accuracy will be biased, too, which produces the Accuracy Paradox. In this paper, we identify an optimal ML model for predicting mortality risk for Intensive Care Units (ICU) patients. We comprehensively assess an approach that leverages the efficiency of ML ensemble learning (in particular, Gradient Boosting Decision Tree) and clustering-based data sampling to handle the imbalanced data problem that this model faces. We comprehensively compare different competitors (in terms of ML models as well as clustering methods) on a big real-world ICU dataset achieving a maximum area under the curve value of 0.956.;;;https://dl.acm.org/doi/10.1145/3366030.3366040;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Breast Tissue Density Classification in Mammograms Based on Supervised Machine Learning Technique;;;['Kanchan Lata Kashyap', 'Manish Kumar Bajpai', 'Pritee Khanna'];;;November 2017;;;Compute '17: Proceedings of the 10th Annual ACM India Compute Conference;;;Breast tissue density is one of the symptoms for breast cancer detection. Fully automatic breast tissue density classification is presented in this work. Present work consists of four steps which include breast region extraction and enhancement of mammograms, segmentation, feature extraction, and breast tissue density classification. Enhancement of mammogram is done by applying fractional order differential based filter. Segmentation of breast tissue segmentation has been done by using clustering based fast fuzzy c-means technique. Further, texture based local binary pattern (LBP) and dominant rotated local binary pattern (DRLBP) features have been computed from the extracted breast tissues to characterize its texture property. Support vector machine with linear kernel functions are used to classify the breast tissue density. Proposed algorithm is validated on the publicly available 322 mammograms of Mini-Mammographic Image Analysis Society (MIAS).;;;https://dl.acm.org/doi/10.1145/3140107.3140131;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Classification of Heart Disease Using Machine Learning Techniques;;;['Perivitta Rajendran', 'Su-Cheng Haw', 'Palaichamy Naveen'];;;September 2021;;;ICDTE '21: Proceedings of the 5th International Conference on Digital Technology in Education;;;The most crucial task in the medical field is diagnosing an illness. If a disease is determined at the early stage then many lives can be saved. The purpose of this paper is to use the medical data to predict cardiovascular heart disease using both supervised and unsupervised learning techniques and to show the effects of feature correlation on the classification model with over four different algorithms namely, Logistic Regression, Naive Bayes, Random Forest and Artificial Neural Networks. For the performance assessment, it incorporates F1-score, precision, Area under curve and recall. Overall, Logistic Regression algorithm tends to perform well for both Hungary and Statlog dataset whereas for Cleveland dataset, Artificial Neural Networks performs better than Logistic Regression in terms of accuracy. In terms of area under curve score, Logistic Regression performance is higher in all the dataset compared to Naive Bayes, Random Forest and Artificial Neural Networks. The results tabulated evidently prove that the designed diagnostic system is capable of predicting the risk level of heart disease effectively when compared to other approaches.;;;https://dl.acm.org/doi/10.1145/3488466.3488482;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Detection and Classification of Embung Land Cover using Support Vector Machine;;;['Ahmad Syarif Hidayat', 'Fatwa Ramdani', 'Fitra Bachtiar'];;;September 2021;;;SIET '21: Proceedings of the 6th International Conference on Sustainable Information Engineering and Technology;;;The agricultural sector is the mainstay sector in the economy of Malang Regency. However, Malang Regency has experienced a decrease in rice harvested area caused by drought. One of the Government's efforts to overcome this is by carrying out embung for agriculture. The use of remote sensing technology is one of the practical tools to monitor the phenomenon of change that occurs continuously and in a large area, in this case, the reservoir. This study aims to determine and analyze the use of SVM classification in satellite imagery to detect embung in Malang Regency. This research uses PlanetScope satellite imagery and Support Vector Machine (SVM) to classify land cover types. This research consists of three main tasks: satellite image preprocessing, satellite image classification, and land cover detection. The results showed that the increase in the number of sample areas in the SVM algorithm impacted the computational time and accuracy of the embung classification. The number of sample areas was small, the computation time was 16 seconds, and the accuracy was 0.5641. While the number of sample areas is large, the computation time is 307 seconds, and the accuracy is 0.7093.;;;https://dl.acm.org/doi/10.1145/3479645.3479673;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Stacked Sparse Autoencoder and Machine Learning Based Anxiety Classification Using EEG Signals;;;['Shikha', 'Manan Agrawal', 'Mohd Ayaan Anwar', 'Divyashikha Sethia'];;;October 2021;;;AIMLSystems '21: Proceedings of the First International Conference on AI-ML Systems;;;Anxiety is an emotion characterized by trepidation, stress, or uneasiness that involves extreme worry or fear over future unwanted events or an actual situation. Careful analysis for anxiety is critical since approximately 2 to 4% of the general population have experienced adequate symptoms indicating an anxiety disorder. This paper aims to classify anxiety levels based on machine learning and deep learning algorithms with improved performance. This work uses the publically available DASPS Database (Database for Anxious States based on a Psychological Stimulation). The dataset consists of EEG recordings from 23 participants during anxiety elicitation through face-to-face psychological stimuli. This work uses RFECV with the classifiers to reduce redundancy between features and improve results. We achieve the highest classification accuracy of 83.93% and 70.25% using Stacked Sparse Autoencoder and Decision Tree for two-class anxiety classification.;;;https://dl.acm.org/doi/10.1145/3486001.3486227;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
RMDL: Random Multimodel Deep Learning for Classification;;;['Kamran Kowsari', 'Mojtaba Heidarysafa', 'Donald E. Brown', 'Kiana Jafari Meimandi', 'Laura E. Barnes'];;;April 2018;;;ICISDM '18: Proceedings of the 2nd International Conference on Information System and Data Mining;;;The continually increasing number of complex datasets each year necessitates ever improving machine learning methods for robust and accurate categorization of these data. This paper introduces Random Multimodel Deep Learning (RMDL): a new ensemble, deep learning approach for classification. Deep learning models have achieved state-of-the-art results across many domains. RMDL solves the problem of finding the best deep learning structure and architecture while simultaneously improving robustness and accuracy through ensembles of deep learning architectures. RDML can accept as input a variety data to include text, video, images, and symbolic. This paper describes RMDL and shows test results for image and text data including MNIST, CIFAR-10, WOS, Reuters, IMDB, and 20newsgroup. These test results show that RDML produces consistently better performance than standard methods over a broad range of data types and classification problems.;;;https://dl.acm.org/doi/10.1145/3206098.3206111;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Subconcept Based One Class Classification Method with Cluster Updating;;;['Zhen Liu', 'Nathalie Japkowicz', 'Ruoyu Wang'];;;February 2020;;;ICMLC '20: Proceedings of the 2020 12th International Conference on Machine Learning and Computing;;;One class classification is an effective way to perform anomaly detection or outlier detection. Previous work has empirically shown that complexity in the background (also known as target) class degrades the performance of one-class classifiers, and one source of data complexity is the presence of subconcepts in that class. Learning over subconcepts individually can mitigate the effects of domain complexity and improve one class classification performance. Unless a clustering could be derived from domain knowledge, the approach used to search for subconcepts is unsupervised clustering. However, in some cases, the examples belonging to some of the clusters may be too scattered, while, in others, clusters may be affected by the small disjunct problem where some clusters comprise only of a few examples that cannot be used to train a robust classifier. To handle these problems, this paper presents a method to update the clusters obtained by the clustering process prior to learning over them. In addition, it introduces the c-Nearest-Cluster (c-NC) method for combining the individual classifiers derived from each subconcept. Our experiments on classical outlier detection datasets and on cyber security datasets show that our method can improve upon the classification performance obtained by the recently proposed subconcept based one class classification method.;;;https://dl.acm.org/doi/10.1145/3383972.3384016;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Data Management in Machine Learning: Challenges, Techniques, and Systems;;;['Arun Kumar', 'Matthias Boehm', 'Jun Yang'];;;May 2017;;;SIGMOD '17: Proceedings of the 2017 ACM International Conference on Management of Data;;;Large-scale data analytics using statistical machine learning (ML), popularly called advanced analytics, underpins many modern data-driven applications. The data management community has been working for over a decade on tackling data management-related challenges that arise in ML workloads, and has built several systems for advanced analytics. This tutorial provides a comprehensive review of such systems and analyzes key data management challenges and techniques. We focus on three complementary lines of work: (1) integrating ML algorithms and languages with existing data systems such as RDBMSs, (2) adapting data management-inspired techniques such as query optimization, partitioning, and compression to new systems that target ML workloads, and (3) combining data management and ML ideas to build systems that improve ML lifecycle-related tasks. Finally, we identify key open data management challenges for future research in this important area.;;;https://dl.acm.org/doi/10.1145/3035918.3054775;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
MFPMiner: Mining Meaningful Frequent Patterns from Spatio-textual Trajectories;;;['Fabio Valdes'];;;None;;;ACM Transactions on Spatial Algorithms and Systems;;;In the second decade of this century, technical progress has led to a worldwide proliferation of devices for tracking the movement behavior of a person, a vehicle, or another kind of entity. One of the consequences of this development is a massive and still growing amount of movement and movement-related data recorded by cellphones, automobiles, vessels, aircraft, and further GPS-enabled entities. As a result, the requirements for managing and analyzing movement records also increase, serving commercial, administrative, or private purposes. Since the development of hardware components cannot keep pace with the data growth, exploring methods of analyzing such trajectory datasets has become a very active and influential research field.For many application scenarios, besides the spatial trajectory of an entity, it is desirable to take additional semantic information into consideration. These descriptions also change with time and may represent, e.g., the course of streets passed by a bus, the sequence of region names traversed by an aircraft, or the points of interest in proximity of the positions of a taxi. Such data may be directly recorded by a sensor (such as the altitude of an aircraft) or computed from the spatial trajectory combined with some underlying information (for example, street names). It is often helpful or even necessary to focus on such semantic information for efficient analyses, as changes usually occur less frequently than it is the case for the spatial trajectory, where data points usually arrive in very close temporal distances. However, any kind of querying requires a deep semantic knowledge of the dataset at hand, particularly for retrieving the set of trajectories that match a certain mobility pattern, that is, a sequence of temporal, spatial, and semantic specifications.In this article, we introduce a framework named MFPMiner1 for retrieving all mobility patterns fulfilling a user-specified frequency threshold from a spatio-textual trajectory dataset. The resulting patterns and their relative frequency can be regarded as a knowledge base of the considered data. They may be directly visualized or applied for a pattern matching query yielding the set of matching trajectories. We demonstrate the functionality of our approach in an application scenario and provide an experimental evaluation of its performance on real and synthetic datasets by comparing it to three competitive methods. The framework has been fully implemented in a DBMS environment and is freely available open source software.;;;https://dl.acm.org/doi/10.1145/3498728;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Text mining to Discover Design Features for Cybersecurity tools: The case of Password Management Systems;;;['Yazan Alshboul', 'Wael Odat'];;;December 2021;;;ICSEB '21: Proceedings of the 2021 5th International Conference on Software and e-Business;;;Username and password are the most common authentication approach used today in cybersecurity. Most people have more than one online account protected by passwords. Managing passwords is one of the daunting tasks for most people. Therefore, users may rely on password management systems PMS to help creating, managing, retrieving, and storing passwords. However, there is still a lack of relying on and using such systems to manage users’ passwords. This study aims to use a text mining approach to investigate the factors that influence users’ behavior to use PMSs which leads to improve their security. This study adopts a text mining approach to uncover the design principles (features) of PMSs extracted from online users’ reviews and feedbacks to improve the adoption of PMSs. Specifically, our study used a topic modeling algorithm to analyze users’ feedback by collecting and analyzing the reviews of nine password management systems. The results indicate the need to address principles and design features related to compatibility, security, usefulness, ease of use, and customer care services.;;;https://dl.acm.org/doi/10.1145/3507485.3507507;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Effects of Image Augmentation and Dual-layer Transfer Machine Learning Architecture on Tumor Classification;;;['Cheng Chen', 'Christine Chen', 'Xuesong Mei', 'Chaoyang Chen', 'Guoxin Ni', 'Stephen Lemos'];;;October 2019;;;ICCPR '19: Proceedings of the 2019 8th International Conference on Computing and Pattern Recognition;;;Breast tumor (BT) is the second most common health problem for women. Traditional diagnosis methods can be very labor-intensive and time-consuming with the risk of making a wrong diagnosis. Computer vision and imaging processing techniques using machine learning (ML) methods are emerging to aide in clinical diagnosis. Some machine learning methods have yielded an accuracy of 85% using a single-layer classifier. In this study Inception-V3, a two-layer classifier of transfer machine learning tool was used for image processing with enhancement technologies and for the classification of breast tumor histopathological types. Results showed that image augmentation with dual-layer transfer machine learning algorithms yielded an accuracy of 95.6% in identification of breast tumor pathologic types, which was higher than previously reported methods in the literature. Different image preprocessing methods, dataset preparing methods, and classifier architectures were also studied to identify the optimal algorithm. Results showed that multiple-layer processing algorithms using color images, instead of black and white images, yielded a better accuracy in histopathological type classification.;;;https://dl.acm.org/doi/10.1145/3373509.3373584;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Mining Latent Semantic Correlation inspired by Quantum Entanglement;;;['Zan Li', 'Yuexian Hou', 'Tingsan Pan', 'Tian Tian', 'Yingjie Gao'];;;December 2021;;;CSAI '21: Proceedings of the 2021 5th International Conference on Computer Science and Artificial Intelligence;;;Text representation learning is the cornerstone of solving downstream problems in Natural Language Processing (NLP). However, mining the potential explanatory factors or semantic associations behind data, rather than simply representing the superficial co-occurrence of words, remains a non-trivial challenge. To this end, we seek inspiration from the Quantum Entanglement (QE) which can effectively provide a complete description for the nature of realities and a globally-determined intrinsic correlation of considered objects, thus proposing a novel representation learning hypothesis called the Latent Semantic Correlation (LSC), namely the implicit internal coherence between the semantic space and its corresponding category space. To construct a multi-granularity representation from sememes to words, phrases, sentences, and higher-level LSC, we implement a QE-inspired Network (QEN) under the constraints of quantum formalism and propose the Local Semantic Measurement (LSM) and Extraction (LSE) for effectively capturing probability distribution information from the entangled state of a bipartite quantum system, which has a clear geometrical motivation but also supports a well-founded probabilistic interpretation. Experimental results conducted on several benchmarking classification tasks prove the validity of the LSC hypothesis and the superiority of QEN.;;;https://dl.acm.org/doi/10.1145/3507548.3507598;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A User-Centered Concept Mining System for Query and Document Understanding at Tencent;;;['Bang Liu', 'Weidong Guo', 'Di Niu', 'Chaoyue Wang', 'Shunnan Xu', 'Jinghong Lin', 'Kunfeng Lai', 'Yu Xu'];;;July 2019;;;KDD '19: Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining;;;Concepts embody the knowledge of the world and facilitate the cognitive processes of human beings. Mining concepts from web documents and constructing the corresponding taxonomy are core research problems in text understanding and support many downstream tasks such as query analysis, knowledge base construction, recommendation, and search. However, we argue that most prior studies extract formal and overly general concepts from Wikipedia or static web pages, which are not representing the user perspective. In this paper, we describe our experience of implementing and deploying ConcepT in Tencent QQ Browser. It discovers user-centered concepts at the right granularity conforming to user interests, by mining a large amount of user queries and interactive search click logs. The extracted concepts have the proper granularity, are consistent with user language styles and are dynamically updated. We further present our techniques to tag documents with user-centered concepts and to construct a topic-concept-instance taxonomy, which has helped to improve search as well as news feeds recommendation in Tencent QQ Browser. We performed extensive offline evaluation to demonstrate that our approach could extract concepts of higher quality compared to several other existing methods. Our system has been deployed in Tencent QQ Browser. Results from online A/B testing involving a large number of real users suggest that the Impression Efficiency of feeds users increased by 6.01% after incorporating the user-centered concepts into the recommendation framework of Tencent QQ Browser.;;;https://dl.acm.org/doi/10.1145/3292500.3330727;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Towards investigation of iterative strategy for data mining of short-term traffic flow with Recurrent Neural Networks;;;['Armando Fandango', 'R. Paul Wiegand'];;;April 2018;;;ICISDM '18: Proceedings of the 2nd International Conference on Information System and Data Mining;;;The smart cities of modern nations rely on the smooth flow of transportation that depends on the predictions of the traffic flow patterns. Since last few years, deep learning based methods have emerged to show better results for short-term traffic ow prediction. For multi-step-ahead prediction, researchers applying statistical methods have used the iterative strategies for preparing input data and building forecast models. In studies applying recurrent neural networks (RNN), the iterative strategies are not used. Hence, we investigate the usage of an iterative strategy for building the RNN models for short-term traffic flow forecasting.;;;https://dl.acm.org/doi/10.1145/3206098.3206112;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Effects of Part-of-Speech on Thai Sentence Classification to Wh-Question Categories using Machine Learning Approach;;;['Saranlita Chotirat', 'Phayung Meesad'];;;July 2020;;;IAIT '20: Proceedings of the 11th International Conference on Advances in Information Technology;;;In the last decade, question classification is a strong signal for answer selection and help to find the structure of question sentences from sentences. For this paper, we evaluated the proposed pre-processing method for classifying the simple sentence to wh-question categories ("What", "When", "Who", "Where", and "How") on Thai texts by considering Part-of-Speech tagging (POS). The performances are evaluated using classification accuracy obtained from traditional classification models including Naïve Bayes, Logistic Regression, Support Vector Machine, K-Nearest Neighbors, and neural networks which employs Long Short-Term Memory (LSTM) and Convolutional Neural Network (CNN). We compared traditional models and neural networks; the experimental results showed that the result of the neural networks models better than the traditional model. The accuracy of the proposed model using the LSTM model with pre-trained word embedding is improved with an average F1 of 79.60%.;;;https://dl.acm.org/doi/10.1145/3406601.3406648;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A parallel island model for biogeography-based classification rule mining in julia;;;['Samuel Ebert', 'Effat Farhana', 'Steffen Heber'];;;July 2018;;;GECCO '18: Proceedings of the Genetic and Evolutionary Computation Conference Companion;;;In this paper, we present a distributed island model implementation of biogeography-based optimization for classification rule mining (island BBO-RM). Island BBO-RM is an evolutionary algorithm for rule mining that uses Pittsburgh style classification rule encoding, which represents an entire ruleset (classifier) as a single chromosome. Our algorithm relies on biogeography-based optimization (BBO), an optimization technique that is inspired by species migration pattern between habitats. Biogeography-based optimization has been reported to perform well in various applications ranging from function optimization to image classification. A major limitation of evolutionary rule mining algorithms is their high computational cost and running time. To address this challenge, we have applied a distributed island model to parallelize the rule extraction phase via BBO. We have explored several different migration topologies and data windowing techniques. Our algorithm is implemented in Julia, a dynamic programming language designed for high-performance and parallel computation. Our results show that our distributed implementation is able to achieve considerable speedups when compared to a serial implementation. Without data windowing, we obtain speedups up to a factor of nine without a loss of classification accuracy. With data windowing, we obtain speedups up to a factor of 30 with a small loss of accuracy in some cases.;;;https://dl.acm.org/doi/10.1145/3205651.3208262;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
ClassiNet -- Predicting Missing Features for Short-Text Classification;;;['Danushka Bollegala', 'Vincent Atanasov', 'Takanori Maehara', 'Ken-Ichi Kawarabayashi'];;;None;;;ACM Transactions on Knowledge Discovery from Data;;;Short and sparse texts such as tweets, search engine snippets, product reviews, and chat messages are abundant on the Web. Classifying such short-texts into a pre-defined set of categories is a common problem that arises in various contexts, such as sentiment classification, spam detection, and information recommendation. The fundamental problem in short-text classification is feature sparseness -- the lack of feature overlap between a trained model and a test instance to be classified. We propose ClassiNet -- a network of classifiers trained for predicting missing features in a given instance, to overcome the feature sparseness problem. Using a set of unlabeled training instances, we first learn binary classifiers as feature predictors for predicting whether a particular feature occurs in a given instance. Next, each feature predictor is represented as a vertex vi in the ClassiNet, where a one-to-one correspondence exists between feature predictors and vertices. The weight of the directed edge eij connecting a vertex vi to a vertex vj represents the conditional probability that given vi exists in an instance, vj also exists in the same instance.We show that ClassiNets generalize word co-occurrence graphs by considering implicit co-occurrences between features. We extract numerous features from the trained ClassiNet to overcome feature sparseness. In particular, for a given instance x, we find similar features from ClassiNet that did not appear in x, and append those features in the representation of x. Moreover, we propose a method based on graph propagation to find features that are indirectly related to a given short-text. We evaluate ClassiNets on several benchmark datasets for short-text classification. Our experimental results show that by using ClassiNet, we can statistically significantly improve the accuracy in short-text classification tasks, without having to use any external resources such as thesauri for finding related features.;;;https://dl.acm.org/doi/10.1145/3201578;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A Machine Learning Approach to Violin Bow Technique Classification: a Comparison Between IMU and MOCAP systems;;;['David Dalmazzo', 'Simone Tassani', 'Rafael Ramírez'];;;September 2018;;;iWOAR '18: Proceedings of the 5th International Workshop on Sensor-based Activity Recognition and Interaction;;;Motion Capture (MOCAP) Systems have been used to analyze body motion and postures in biomedicine, sports, rehabilitation, and music. With the aim to compare the precision of low-cost devices for motion tracking (e.g. Myo) with the precision of MOCAP systems in the context of music performance, we recorded MOCAP and Myo data of a top professional violinist executing four fundamental bowing techniques (i.e. Détaché, Martelé, Spiccato and Ricochet). Using the recorded data we applied machine learning techniques to train models to classify the four bowing techniques. Despite intrinsic differences between the MOCAP and low-cost data, the Myo-based classifier resulted in slightly higher accuracy than the MOCAP-based classifier. This result shows that it is possible to develop music-gesture learning applications based on low-cost technology which can be used in home environments for self-learning practitioners.;;;https://dl.acm.org/doi/10.1145/3266157.3266216;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Mining personal media thresholds for opinion dynamics and social influence;;;['Casey Doyle', 'Alex Meandzija', 'Gyorgy Korniss', 'Boleslaw Szymanski', 'Derrik Asher', 'Elizabeth Bowman'];;;August 2018;;;ASONAM '18: Proceedings of the 2018 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining;;;To study the detailed effects of social media consumption on personal opinion dynamics, we gather self reported survey data on the volume of different media types an individual must consume before forming or changing their opinion on a subject. We then use frequent pattern mining to analyze the data for common groupings of responses with respect to various media types, sources, and contexts. We show that in general individuals tend to perceive their behavior to be consistent across many variations in these parameters, while further detail shows various common parameter groupings that indicate response changes as well as small groups of individuals that tend to be consistently more easily swayed than the average participant.;;;https://dl.acm.org/doi/10.5555/3382225.3382478;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Joint Mobility Pattern Mining with Urban Region Partitions;;;['Jing Lian', 'Yang Li', 'Weixi Gu', 'Shao-Lun Huang', 'Lin Zhang'];;;November 2018;;;MobiQuitous '18: Proceedings of the 15th EAI International Conference on Mobile and Ubiquitous Systems: Computing, Networking and Services;;;Mobility pattern mining answers the fundamental question of where people are likely to go from a given location. It plays an important role in city planning, public transport management and location-based mobile applications. Among these applications, many concern the mobility pattern over contiguous spatial regions as a whole. Traditional ways of mobility pattern mining either result in trip clusters with overlapped origin and destination regions, or require an extra step to partition the city into discrete regions, which may not be optimal for mobility pattern extraction. In this paper, we present a region-aware mobility pattern mining framework to jointly extract trip clusters while maintaining non-overlapping partitions of trip origins and destinations. We developed kernelized ACE, a novel extension to a classic algorithm in statistics to compute the optimal mobility clusters under spatial constraints. Experimental results using Beijing taxi trip data show that our approach outperforms other methods with only ~ 0.3% spatial overlap and 86.43% origin-destination correlation. Our case studies on New York City's and Beijing's taxi datasets also yield insightful findings that reveal city-scale mobility patterns and propose potential improvement for public transportation.;;;https://dl.acm.org/doi/10.1145/3286978.3287004;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
An ensemble outlier detection method for multiclass classification problem in data mining;;;['Dalton Ndirangu', 'Waweru Mwangi', 'Lawrence Nderu'];;;July 2018;;;DSIT '18: Proceedings of the 2018 International Conference on Data Science and Information Technology;;;We proposed to develop a heterogeneous ensemble method that boost the performance of random forest classifier. The proposed method utilized the boosting capability of adaboost algorithm and the feature selection and bagging capability of random subspace algorithm. Both algorithms used random forest as the base classifier and were combined using voting methodology. We preprocessed the dataset by removing both redundant features and the detected outliers associated with dataset features. We addressed the multiclass problem of the dataset by decomposing the dataset into binary classes using the technique of 1 against 1 enhanced by pairwise coupling. Since supervised algorithms are designed to be biased with majority class, we overcome that challenge by generating synthetic instances using synthetic minority over sampling technique. The proposed SMOTE_Voted outlier ensemble method outperformed Random Forest, KNN, NaiveBayes, C4.5 and Support Vector machine outlier detection methods. We conclude that ensemble technique improves performance of outlier detection for multiclass problem.;;;https://dl.acm.org/doi/10.1145/3239283.3239303;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Automated Classification of Class Role-Stereotypes via Machine Learning;;;['Arif Nurwidyantoro', 'Truong Ho-Quang', 'Michel R. V. Chaudron'];;;April 2019;;;EASE '19: Proceedings of the 23rd International Conference on Evaluation and Assessment in Software Engineering;;;Role stereotypes indicate generic roles that classes play in the design of software systems (e.g. controller, information holder, or interfacer). Knowledge about the role-stereotypes can help in various tasks in software development and maintenance, such as program understanding, program summarization, and quality assurance. This paper presents an automated machine learning-based approach for classifying the role-stereotype of classes in Java. We analyse the performance of this approach against a manually labelled ground truth for a sizable open source project (of 770+ Java classes) for the Android platform. Moreover, we compare our approach to an existing rule-based classification approach. The contributions of this paper include an analysis of which machine learning algorithms and which features provide the best classification performance. This analysis shows that the Random Forest algorithm yields the best classification performance. We find however, that the performance of the ML-classifier varies a lot for classifying different role-stereotypes. In particular its performs degrades for rare role-types. Our ML-classifier improves over the existing rule-based classification method in that the ML-approach classifies all classes, while rule-based approaches leave a significant number of classes unclassified.;;;https://dl.acm.org/doi/10.1145/3319008.3319016;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Machine learning classification methods in hyperspectral data processing for agricultural applications;;;['Jonáš Hruška', 'Telmo Adão', 'Luís Pádua', 'Pedro Marques', 'António Cunha', 'Emanuel Peres', 'António Sousa', 'Raul Morais', 'Joaquim J. Sousa'];;;April 2018;;;ICGDA '18: Proceedings of the International Conference on Geoinformatics and Data Analysis;;;In agricultural applications hyperspectral imaging is used in cases where differences in spectral reflectance of the examined objects are small. However, the large amount of data generated by hyperspectral sensors requires advance processing methods. Machine learning approaches may play an important role in this task. They are known for decades, but they need high volume of data to compute accurate results. Until recently, the availability of hyperspectral data was a big drawback. It was first used in satellites, later in manned aircrafts and data availability from those platforms was limited because of logistics complexity and high price. Nowadays, hyperspectral sensors are available for unmanned aerial vehicles, which enabled to reach a high volume of data, thus overcoming these issues. This way, the aim of this paper is to present the status of the usage of machine learning approaches in the hyperspectral data processing, with a focus on agriculture applications. Nevertheless, there are not many studies available applying machine learning approach to hyperspectral data for agricultural applications. This apparent limitation was in fact the inspiration for making this survey. Preliminary results using UAV-based data are presented, showing the suitability of machine learning techniques in remote sensed data.;;;https://dl.acm.org/doi/10.1145/3220228.3220242;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Learning One-class Support Vector Machine by Using Artificial Bee Colony Algorithm and Its Application for Disease Classification;;;['Ming-Huwi Horng', 'Yu-Lun Hong', 'Yung-Nien Sun', 'Zhe-Yuan Zhan', 'Chen-Yu Hong'];;;July 2019;;;IECC '19: Proceedings of the 1st International Electronics Communication Conference;;;The one-classification support vector (OCSVM) is a variant of SVM which only uses the positive class sample set in training stage. It has been widely used in the applications of disease diagnose, handwritten signature verification, remote sensing and document classification. However, there are many parameters needed to regulate. The mistake of parameter setting makes OCSVM it to be not effectiveness. Therefore, in this paper we proposed a learning algorithm based on the artificial bee colony algorithm to select the parameters. The construction algorithm of OSCVM is called the artificial bee colony based OSCVM (ABC-OCSVM) algorithm. Experimental results of two medical datasets of UCI data repository showed that our proposed ABC-OCSVM method outperforms the conventional LIBSVM package.;;;https://dl.acm.org/doi/10.1145/3343147.3343152;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Automating developer chat mining;;;['Shengyi Pan', 'Lingfeng Bao', 'Xiaoxue Ren', 'Xin Xia', 'David Lo', 'Shanping Li'];;;November 2021;;;ASE '21: Proceedings of the 36th IEEE/ACM International Conference on Automated Software Engineering;;;Online chatrooms are gaining popularity as a communication channel between widely distributed developers of Open Source Software (OSS) projects. Most discussion threads in chatrooms follow a Q&A format, with some developers (askers) raising an initial question and others (respondents) joining in to provide answers. These discussion threads are embedded with rich information that can satisfy the diverse needs of various OSS stakeholders. However, retrieving information from threads is challenging as it requires a thread-level analysis to understand the context. Moreover, the chat data is transient and unstructured, consisting of entangled informal conversations. In this paper, we address this challenge by identifying the information types available in developer chats and further introducing an automated mining technique. Through manual examination of chat data from three chatrooms on Gitter, using card sorting, we build a thread-level taxonomy with nine information categories and create a labeled dataset with 2,959 threads. We propose a classification approach (named F2Chat) to structure the vast amount of threads based on the information type automatically, helping stakeholders quickly acquire their desired information. F2Chat effectively combines handcrafted non-textual features with deep textual features extracted by neural models. Specifically, it has two stages with the first one leveraging the siamese architecture to pretrain the textual feature encoder, and the second one facilitating an in-depth fusion of two types of features. Evaluation results suggest that our approach achieves an average F1-score of 0.628, which improves the baseline by 57%. Experiments also verify the effectiveness of our identified non-textual features under both intra-project and cross-project validations.;;;https://dl.acm.org/doi/10.1109/ASE51524.2021.9678923;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Scalable and efficient data analytics and mining with lemonade;;;['Walter dos Santos', 'Gustavo P. Avelar', 'Manoel Horta Ribeiro', 'Dorgival Guedes', 'Wagner Meira'];;;None;;;Proceedings of the VLDB Endowment;;;Professionals outside of the area of Computer Science have an increasing need to analyze large bodies of data. This analysis often demands high level of security and has to be done in the cloud. However, current data analysis tools that demand little proficiency in systems programming struggle to deliver solutions which are scalable and safe. In this context we present Lemonade, a platform which focuses on creating data analysis and mining flows in the cloud, with authentication, authorization and accounting (AAA) guarantees. Lemonade provides an interface for the visual construction of flows, and encapsulates storage and data processing environment details, providing higher-level abstractions for data source access and algorithms. We illustrate its usage through a demo, where a data processing flow builds a classification model for detecting fake-news, also extracting some insights along the way.;;;https://dl.acm.org/doi/10.14778/3229863.3236262;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Mining ordinal data under human response uncertainty;;;['Sergej Sizov'];;;August 2017;;;WI '17: Proceedings of the International Conference on Web Intelligence;;;Analysis and interpretation of collective feedback on ordinal scales is an important issue for several disciplines, including social sciences, recommender systems research, marketing, political science, and many others. A "reasonable" model is expected to provide an "explanation" of collective user behaviour. Many existing data mining approaches employ for this purpose probabilistic models, based on distributions and mixtures from a certain parametric family. In real life, users meet their decisions with considerable uncertainty. Its assessment and use in probabilistic models for better interpretation of collective feedback is the key concern of this paper. In doing so, we introduce approaches for gathering individual uncertainty, and discuss their viability and limitations. Consequently, we enrich state of the art response mining models (especially focused on discovery of latent user groups) with uncertainty knowledge, and demonstrate resulting advantages in systematic experiments with real users.;;;https://dl.acm.org/doi/10.1145/3106426.3106448;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
The Research of Semantic Kernel in SVM for Chinese Text Classification;;;['Mai Fanjin', 'Huang Ling', 'Tan Jing', 'Wang Xinzheng'];;;July 2017;;;ICIIP '17: Proceedings of the 2nd International Conference on Intelligent Information Processing;;;The study of semantic kernel function is an important branch of kernel function research in recent years. However, there are few studies on the use of semantic kernel function in support vector machine for Chinese text classification. This paper constructs a domain-related weight matrix based on statistical features and a semantic kernel function based on the combination of "HowNet" and "Synonyms", and how to make full use of semantic relations in Chinese text to improve classification performance. The semantic kernel function is embedded in the support vector machine classifier for Chinese text classification experiment. The test results show that the accuracy, recall rate and F1 value of the support vector machine (SVM) of the semantic kernel function are higher than that of a single ontology or statistic-based semantic kernel function.;;;https://dl.acm.org/doi/10.1145/3144789.3144801;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Academic Diagnosis in College English Teaching Supported By Data Mining;;;['Qiaoe Ni', 'Weiwei Zeng'];;;September 2021;;;ICISCAE 2021: 2021 4th International Conference on Information Systems and Computer Aided Education;;;With the rapid development of big data era, there are more and more research and application of data-based mining and analysis technology in education. This paper discusses how to use data mining technology to integrate learning data into college English classroom, and to track and analyze students’ learning situation dynamically through data mining in student-centered college English teaching. According to the constructed academic diagnosis model, accurately diagnose learning problems, accurately locate all kinds of learning groups in the classroom, correctly locate learning needs, realize the push of personalized learning resources, and promote the improvement of learning effect. Through classified and hierarchical teaching intervention, we can guide learners to cultivate their interest in learning and improve teachers' grasp of the classroom and the efficiency of teaching. Create a positive and effective learning community.;;;https://dl.acm.org/doi/10.1145/3482632.3483075;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Performance Evaluation and Application of Computation Based Low-cost Homogeneous Machine Learning Model Algorithm for Image Classification;;;['W. H. Huang'];;;May 2020;;;ICBDM 2020: Proceedings of the 2020 International Conference on Big Data in Management;;;The image classification machine learning model was trained with the intention to predict the category of the input image. While multiple state-of-the-art ensemble model method- ologies are openly available, this paper evaluates the performance of a low-cost, simple algorithm that would integrate seamlessly into modern production-grade cloud-based applications. The homogeneous models, trained with the full instead of subsets of data, contains varying hyper-parameters and neural layers from one another. These models' inferences will be processed by the new algorithm, which is loosely based on conditional probability theories. The final output will be evaluated.;;;https://dl.acm.org/doi/10.1145/3437075.3437095;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Classification Performance Analysis in Medical Science: Using Kidney Disease Data;;;['R. A. Jeewantha', 'Malka N. Halgamuge', 'Azeem Mohammad', 'Gullu Ekici'];;;October 2017;;;ICBDR '17: Proceedings of the 1st International Conference on Big Data Research;;;Health-care practices face data storage problems in the growing world. Huge data storage demands have caused undeniable data storage problems leaving health practitioners exclaimed. Without delay, accumulated data becomes too difficult to analyzed and handled by traditional approaches. A solution to this problem is urgently needed. One possible answer to this problem is Data mining that delivers the technology and procedure to convert these embankments of ordinary data into meaningful evidences for futuristic planning and decision-making. Data mining is a tool that not only solves the problem of piled up data; nonetheless it similarly turns it into meaningful data themes based on reoccurrences of trends in the data. The healthcare trade is mostly an "information and document rich industry," and manual handling is not feasible in practical life. These huge volumes of data have been key to the arena of data-mining to generate associations among the attributes and extract expedient information. Recent research shows that combating Kidney diseases is a complex assignment that involves considerable knowledge and experience for annual testing and screening. In developed nations, Kidney diseases have become a silent killer, that makes key factors of disease burden in third world nations. Various data mining procedures are available for forecasting diseases such as clustering, classification, association rules, regression, and summarizations. The key objective of this study is to analyze datasets collected from 400 patients grounded on 25 different attributes attended for treatment for Chronic Kidney Disease (CKD), after using classification methods to forecast class precisely. Our analysis illustrates that Multilayer Perceptron is the most suitable classification method that outperforms the highest classification accuracy by 99.75% (0.0085 error) with only 5% of fluctuation among algorithm measures. Introspectively, the computational time, Multilayer Perception can be time-consuming comparatively, when it comes to deal with billions of data. Nonetheless, for the field of bioinformatics and medical science accuracy, the key objective is to deal with sensitive data because, a single error can lead to a disastrous confidentiality breech. Hence, our results show that Multilayer Perception classification method is the most accurate and suitable classification algorithm that could be used in the field of bioinformatics and medical science, for further data analysis and predictions. This paper will be useful for many medical institutions and work-related bioinformatics in pursuance to understand the prediction accuracies of data patterns in related work.;;;https://dl.acm.org/doi/10.1145/3152723.3152724;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Mining Moodle Data to Detect the Inactive and Low-performance Students during the Moodle Course;;;['Mushtaq Hussain', 'Sadiq Hussain', 'Wu Zhang', 'Wenhao Zhu', 'Paraskevi Theodorou', 'Syed Muhammad Raza Abidi'];;;October 2018;;;ICBDR '18: Proceedings of the 2nd International Conference on Big Data Research;;;In web-based learning systems such as massive open online course (MOOC) and modular object-oriented developmental learning environment (Moodle), monitoring the student's activities as well as predict the low-performance students is an important task because it enables the instructors to award the students when their activities level drops from normal activities levels as well as having lower grades. We used several machine learning (ML) classification and clustering techniques to extract the pattern from student data during completing the Moodle course; which enables the instructor to detect the low-performance student in advance before the examination. The experimental result shows that the fuzzy unordered rule induction algorithm (FURIA) classification technique achieves high accuracy in detecting inactive students as well as predicts the different categories of the student during the Moodle course. The K-means clustering is also able to group the inactive and active users and poorly performed users. The result demonstrates that our proposed system will be easily integrated to Moodle system to send alert to inactive and low- performance students while completing the course and build efficient education environment for the students.;;;https://dl.acm.org/doi/10.1145/3291801.3291828;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A Novel Classification Model SA-MPCNN for Power Equipment Defect Text;;;['Xiuxia Tian', 'Can Li', 'Bo Zhao'];;;None;;;ACM Transactions on Asian and Low-Resource Language Information Processing;;;The text classification of power equipment defect is of great significance to equipment health condition evaluation and power equipment maintenance decisions. Most of the existing classification methods do not sufficiently consider the semantic relation between words in the same sentence and cannot extract deep semantic features. To tackle those problems, this article proposes a novel classification method by combining the self-attention mechanism and multi-channel pyramid convolution neural networks. We utilize the bidirectional gated recurrent unit to model the text sequence and, on this basis, improve self-attention layer to dot multiplication on the forward and backward features to obtain the global attention score. Thereby, effective features are enhanced, invalid features are weakened, and important text representation vectors are obtained. To solve the problem that the shallow network structure cannot extract deep semantic features, we design a multi-channel pyramid convolution network, which first extracts deep text features from the channels of different windows and then fuses the text features of each channel. By comparing with the state-of-the-art methods, the model in this article has better performance in text classification of power equipment defects.;;;https://dl.acm.org/doi/10.1145/3464380;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Application and Research of Deep Mining of Health Medical Big Data Based on Internet of Things;;;['Youshen Chi'];;;October 2021;;;AIAM2021: 2021 3rd International Conference on Artificial Intelligence and Advanced Manufacture;;;Traditional data mining algorithms are mostly difficult to handle large data sets, but need to manage big data and discover hidden knowledge. Therefore, the combination of data mining algorithms and IoT technology is the development trend of data processing in the future, but because of the difficulty, not all algorithms can be implemented on the cloud platform, so the research results are not enough. The core idea of cloud computing is architecture. All data mining algorithm improvement strategies need to be designed according to the characteristics of the architecture, and each part must implement specific functions. It is difficult or impossible to implement an algorithm that cannot be decomposed into the above form in the architecture. With the widespread application of IoT technology, a large number of unstructured, distributed and even data mining requirements in mobile devices pose serious challenges to existing data mining technologies. How to use cloud computing technology to achieve large-scale distributed data collection, transmission and mining has become an important research direction. This paper investigates some health care big data, combines the Internet of Things cloud data platform, and introduces the traditional association rules algorithm and its interest level in mining technology. On this basis, the improved algorithm is improved and compared with other traditional algorithms. Establish a simulation platform to implement algorithms and mine training data. It proves that the improved algorithm has lower spatial complexity and faster processing rate in data mining, and analyzes the data mining technology in health medical data.;;;https://dl.acm.org/doi/10.1145/3495018.3495462;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Automatic detection of emotions in Twitter data: a scalable decision tree classification method;;;['Jaishree Ranganathan', 'Nikhil Hedge', 'Allen S. Irudayaraj', 'Angelina A. Tzacheva'];;;July 2018;;;RevOpiD '18: Proceedings of the Workshop on Opinion Mining, Summarization and Diversification;;;Social media data is one of the promising datasets to mine meaningful insights with applications in business and social science. Emotion mining has significant importance in the field of psychology, cognitive science, and linguistics etc. Recently, textual emotion mining has gained attraction in modern science applications. In this paper, we propose an approach which builds a corpus of tweets and related fields where each tweet is classified with respective emotion based on lexicon, and emoticons. Also, we have developed decision tree classifier, decision forest, and rule-based classifier for automatic classification of emotion based on the labeled corpus. The method is implemented in Apache Spark for scalability and BigData accommodation. Results show higher classification accuracy than previous works.;;;https://dl.acm.org/doi/10.1145/3301020.3303751;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
RHPTree—Risk Hierarchical Pattern Tree for Scalable Long Pattern Mining;;;['Danlu Liu', 'Yu Li', 'William Baskett', 'Dan Lin', 'Chi-Ren Shyu'];;;None;;;ACM Transactions on Knowledge Discovery from Data;;;Risk patterns are crucial in biomedical research and have served as an important factor in precision health and disease prevention. Despite recent development in parallel and high-performance computing, existing risk pattern mining methods still struggle with problems caused by large-scale datasets, such as redundant candidate generation, inability to discover long significant patterns, and prolonged post pattern filtering. In this article, we propose a novel dynamic tree structure, Risk Hierarchical Pattern Tree (RHPTree), and a top-down search method, RHPSearch, which are capable of efficiently analyzing a large volume of data and overcoming the limitations of previous works. The dynamic nature of the RHPTree avoids costly tree reconstruction for the iterative search process and dataset updates. We also introduce two specialized search methods, the extended target search (RHPSearch-TS) and the parallel search approach (RHPSearch-SD), to further speed up the retrieval of certain items of interest. Experiments on both UCI machine learning datasets and sampled datasets of the Simons Foundation Autism Research Initiative (SFARI)—Simon’s Simplex Collection (SSC) datasets demonstrate that our method is not only faster but also more effective in identifying comprehensive long risk patterns than existing works. Moreover, the proposed new tree structure is generic and applicable to other pattern mining problems.;;;https://dl.acm.org/doi/10.1145/3488380;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Exploiting Deep Neural Networks for Intention Mining;;;['Anam Habib', 'Nosheen Jelani', 'Asad Masood Khattak', 'Saima Akbar', 'Muhammad Zubair Asghar'];;;February 2020;;;ICSCA '20: Proceedings of the 2020 9th International Conference on Software and Computer Applications;;;In the current era of digital media, people are greatly interested to express themselves on online interaction which produces a huge amount of data. The user generated content may contain user's emotions, opinions, daily events and specially their intent or motive behind their communication. Intention identification/mining of user's reviews, that is whether a user review contains intent or not, from social media network, is an emerging area and is in great demand in various fields like online advertising, improving customer services and decision making. Until now, a lot of work has been performed by researchers on user intention identification using machine learning approaches. However, it is demanded to focus on deep neural network methods. In this research work, we have conducted experimentation on intention dataset using a deep learning method namely CNN+BILSTM. The results exhibit that the proposed model efficiently performed identification of intention sentences in user generated text with a 90% accuracy.;;;https://dl.acm.org/doi/10.1145/3384544.3384607;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Improving classification performance of support vector machines via guided custom kernel search;;;['Kumar Ayush', 'Abhishek Sinha'];;;July 2019;;;GECCO '19: Proceedings of the Genetic and Evolutionary Computation Conference Companion;;;Support Vector Machines (SVMs) deliver state-of-the-art performance in real-world applications and are established as one of the standard tools for machine learning and data mining. A key problem of these methods is how to choose an optimal kernel function. The real-world applications have also emphasized the need to adapt the kernel to the characteristics of heterogeneous data in order to boost the classification accuracy. Therefore, our goal is to automatically search a task specific kernel function. We use reinforcement learning based search mechanisms to discover custom kernel functions and verify the effectiveness of our approach by conducting an empirical evaluation with the discovered kernel function on MNIST classification. Our experiments show that the discovered kernel function shows significantly better classification performance than well-known classic kernels. Our solution will be very effective for resource constrained systems with low memory footprint which rely on traditional machine learning algorithms like SVMs for classification tasks.;;;https://dl.acm.org/doi/10.1145/3319619.3321923;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Automation of Android applications functional testing using machine learning activities classification;;;['Ariel Rosenfeld', 'Odaya Kardashov', 'Orel Zang'];;;May 2018;;;MOBILESoft '18: Proceedings of the 5th International Conference on Mobile Software Engineering and Systems;;;Following the ever-growing demand for mobile applications, researchers are constantly developing new test automation solutions for mobile developers. However, researchers have yet to produce an automated functional testing approach, resulting in many developers relying on a resource consuming manual testing. In this paper, we present a novel approach for the automation of functional testing in mobile software by leveraging machine learning techniques and reusing generic test scenarios. Our approach aims at relieving some of the manual functional testing burden by automatically classifying each of the application's screens to a set of common screen behaviors for which generic test scripts can be instantiated and reused. We empirically demonstrate the potential benefits of our approach in two experiments: First, using 26 randomly selected Android applications, we show that our approach can successfully instantiate and reuse generic functional tests and discover functional bugs. Second, in a human study with two experienced human mobile testers, we show that our approach can automatically cover a large portion of the human testers' work suggesting a significant potential relief in the manual testing efforts.;;;https://dl.acm.org/doi/10.1145/3197231.3197241;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A Unified Framework for Frequent Sequence Mining with Subsequence Constraints;;;['Kaustubh Beedkar', 'Rainer Gemulla', 'Wim Martens'];;;None;;;ACM Transactions on Database Systems;;;Frequent sequence mining methods often make use of constraints to control which subsequences should be mined. A variety of such subsequence constraints has been studied in the literature, including length, gap, span, regular-expression, and hierarchy constraints. In this article, we show that many subsequence constraints—including and beyond those considered in the literature—can be unified in a single framework. A unified treatment allows researchers to study jointly many types of subsequence constraints (instead of each one individually) and helps to improve usability of pattern mining systems for practitioners. In more detail, we propose a set of simple and intuitive “pattern expressions” to describe subsequence constraints and explore algorithms for efficiently mining frequent subsequences under such general constraints. Our algorithms translate pattern expressions to succinct finite-state transducers, which we use as computational model, and simulate these transducers in a way suitable for frequent sequence mining. Our experimental study on real-world datasets indicates that our algorithms—although more general—are efficient and, when used for sequence mining with prior constraints studied in literature, competitive to (and in some cases superior to) state-of-the-art specialized methods.;;;https://dl.acm.org/doi/10.1145/3321486;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A novel malware analysis for malware detection and classification using machine learning algorithms;;;['Kamalakanta Sethi', 'Shankar Kumar Chaudhary', 'Bata Krishan Tripathy', 'Padmalochan Bera'];;;October 2017;;;SIN '17: Proceedings of the 10th International Conference on Security of Information and Networks;;;Nowadays, Malware has become a serious threat to the digitization of the world due to the emergence of various new and complex malware every day. Due to this, the traditional signature-based methods for detection of malware effectively becomes an obsolete method. The efficiency of the machine learning model in context to the detection of malware files has been proved by different researches and studies. In this paper, a framework has been developed to detect and classify different files (e.g exe, pdf, php, etc.) as benign and malicious using two level classifier namely, Macro (for detection of malware) and Micro (for classification of malware files as a Trojan, Spyware, Adware, etc.). Cuckoo Sandbox is used for generating static and dynamic analysis report by executing files in the virtual environment. In addition, a novel model is developed for extracting features based on static, behavioral and network analysis using analysis report generated by the Cuckoo Sandbox. Weka Framework is used to develop machine learning models by using training datasets. The experimental results using proposed framework shows high detection rate with an accuracy of 100% using J48 Decision tree model, 99% using SMO (Sequential Minimal Optimization) and 97% using Random Forest tree. It also shows effective classification rate with accuracy 100% using J48 Decision tree, 91% using SMO and 66% using Random Forest tree. These results are used for detecting and classifying unknown files as benign or malicious.;;;https://dl.acm.org/doi/10.1145/3136825.3136883;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Imbalanced Data Classification Based on Hybrid Methods;;;['Nai-Nan Zhang', 'Shao-Zhen Ye', 'Ting-Ying Chien'];;;October 2018;;;ICBDR '18: Proceedings of the 2nd International Conference on Big Data Research;;;Imbalanced data are ubiquitous in real-world datasets. This study investigate imbalanced data distribution for binary classification, i.e., where the number of majority class instances is significantly greater than the number of minority class instances. It is assumed that traditional machine learning algorithms attempt to minimize empirical risk factors, and, as a result, the classification accuracy of the minority is often sacrificed. However, people are often interested in the minority. Various data-level methods, such as over- and under-sampling, and algorithm-level methods, such as ensemble, cost-sensitive, and one-class learning, have been proposed to improve classifier performance with an imbalanced data distribution. Based on such methods, this study proposed a hybrid approach to deal with imbalanced data problem that comprises data preprocessing, clustering, data balancing, model building, and ensemble.;;;https://dl.acm.org/doi/10.1145/3291801.3291812;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Ontology-based workflow pattern mining: application to bioinformatics expertise acquisition;;;['Ahmed Halioui', 'Tomas Martin', 'Petko Valtchev', 'Abdoulaye Baniré Diallo'];;;April 2017;;;SAC '17: Proceedings of the Symposium on Applied Computing;;;Workflow platforms enable the construction of solutions to complex problems as step-wise processes made of components including methods, tools, data formats, parameters, etc. Successful workflow solutions require a mastering of the different components paving the way to automated acquisition of problem solving expertise. Thus, process mining could be applied to discover workflow patterns. Due to the combinatorics of component instances in rich domains such as bioinformatics, generalized patterns could be a relevant way of abstraction. Here, we propose an approach for mining workflow patterns, defined on the top of a domain ontology which categorizes workflow elements and their interactions. While original workflows are doubly-labelled DAGs, the underlying problem is transformed into a mining of generalized sequential patterns with links between their items. The proposed mining method traverses the ensuing pattern space using five refinement primitives that exploit the is-a links from the ontology. To assess the prediction power of the approach, we applied the generated patterns as templates in a recommendation platform to complete partial workflows under construction. The analyses of recommendations vs. actual content of a real-world dataset reveals that non trivial patterns can be found and further used to provide plausible recommendations with high accuracies (fMeasure >75+).;;;https://dl.acm.org/doi/10.1145/3019612.3019866;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Indoor Seat Occupancy Classification with Wi-Fi Channel State Information and Machine Learning Methods;;;['Yichuan Zhang', 'Jiefeng Li', 'Hang Wang'];;;October 2021;;;SSIP '21: Proceedings of the 2021 4th International Conference on Sensors, Signal and Image Processing;;;Keeping a distance by monitoring the seat occupancy is an essential way to prevent the spread of virus inside a room. However, most current human sensing methods need customized devices, so a cheaper way of indoor seat occupancy classification is in need. Recent researches indicate that Wi-Fi channel state information (CSI) can be utilized for indoor human sensing without wearable sensors. This paper proposes a multi-person seat occupancy classification method based on machine learning and Wi-Fi CSI received by commercial network interface card. We designed an experimental scenario of 5 seats and 2 individuals, and use commercial Wi-Fi devices to build a multi-input multi-output (MIMO) system indoors to acquire an adequate dataset. Then a pipeline consists of phase calibration, linear interpolation, outlier removal and threshold de-noising was applied to preprocess the raw CSI amplitude and phase data. After sliding window feature extraction, convolutional neural network (CNN) and some conventional machine learning methods, such as naive Bayes (NB), decision tree (DT), support vector machine (SVM) and K-nearest neighbors (KNN), are used to classify seat occupancy, among which CNN performs the best, with a classification accuracy of 95%.;;;https://dl.acm.org/doi/10.1145/3502814.3502826;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
MSURU: Large Scale E-commerce Image Classification with Weakly Supervised Search Data;;;['Yina Tang', 'Fedor Borisyuk', 'Siddarth Malreddy', 'Yixuan Li', 'Yiqun Liu', 'Sergey Kirshner'];;;July 2019;;;KDD '19: Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining;;;In this paper we present a deployed image recognition system used in a large scale commerce search engine, which we call MSURU. It is designed to process product images uploaded daily to Facebook Marketplace. Social commerce is a growing area within Facebook and understanding visual representations of product content is important for search and recommendation applications on Marketplace. In this paper, we present techniques we used to develop efficient large-scale image classifiers using weakly supervised search log data. We perform extensive evaluation of presented techniques, explain practical experience of developing large-scale classification systems and discuss challenges we faced. Our system, MSURU out-performed current state of the art system developed at Facebook [23] by 16% in e-commerce domain. MSURU is deployed to production with significant improvements in search success rate and active interactions on Facebook Marketplace.;;;https://dl.acm.org/doi/10.1145/3292500.3330696;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Mobile App Classification Method Using Machine Learning Based User Emotion Recognition;;;['Taewon Kwak', 'Moonhyun Kim'];;;August 2018;;;ICICM '18: Proceedings of the 8th International Conference on Information Communication and Management;;;In this paper, we propose a convolutional neural network based application method which shows superior performance in image classification. Recently, various requirements such as emotional UI, rather than the existing Touch UI method, have been presented in the mobile UI field, and a methodology for this is presented. First, it recognizes human facial expressions through Convolutional Neural Networks (CNN).Based on the second recognized facial expression, a multi-layer perceptron (MLP) Learning. This enables the application to be executed only by the user's face when the mobile application is restarted. In order to implement and experiment on this, we implemented and experimented with the Google inception model structure to enhance the performance of face recognition in the first CNN - based facial recognition step. In the second application classification step, We implemented a method using multidimensional data for recognition. As a result, CNN - based facial expression recognition achieved about 98% accuracy, and based on this, the application classification to be studied in this paper was able to obtain a maximum of 97.9% accuracy;;;https://dl.acm.org/doi/10.1145/3268891.3268909;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Relative evolutionary hierarchical analysis for gene expression data classification;;;['Marcin Czajkowski', 'Marek Kretowski'];;;July 2019;;;GECCO '19: Proceedings of the Genetic and Evolutionary Computation Conference;;;Relative Expression Analysis (RXA) focuses on finding interactions among a small group of genes and studies the relative ordering of their expression rather than their raw values. Algorithms based on that idea play an important role in biomarker discovery and gene expression data classification. We propose a new evolutionary approach and a paradigm shift for RXA applications in data mining as we redefine the inter-gene relations using the concept of a cluster of co-expressed genes. The global hierarchical classification allows finding various sub-groups of genes, unifies the main variants of RXA algorithms and explores a much larger solution space compared to current solutions based on exhaustive search. Finally, the multi-objective fitness function, which includes accuracy, discriminative power of genes and clusters consistency, as well as specialized variants of genetic operators improve evolutionary convergence and reduce model underfitting. Importantly, patterns in predictive structures are kept comprehensible and may have direct applicability. Experiments carried out on 8 cancer-related gene expression datasets show that the proposed approach allows finding interesting patterns and significantly improves the accuracy of predictions.;;;https://dl.acm.org/doi/10.1145/3321707.3321862;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Mining Algorithm Roadmap in Scientific Publications;;;['Hanwen Zha', 'Wenhu Chen', 'Keqian Li', 'Xifeng Yan'];;;July 2019;;;KDD '19: Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining;;;The number of scientific publications is ever increasing. The long time to digest a scientific paper posts great challenges on the number of papers people can read, which impedes a quick grasp of major activities in new research areas especially for intelligence analysts and novice researchers. To accelerate such a process, we first define a new problem called mining algorithm roadmap in scientific publications, and then propose a new weakly supervised method to build the roadmap. The algorithm roadmap describes evolutionary relation between different algorithms, and sketches the undergoing research and the dynamics of the area. It is a tool for analysts and researchers to locate the successors and families of algorithms when analyzing and surveying a research field. We first propose abbreviated words as candidates for algorithms and then use tables as weak supervision to extract these candidates and labels. Next we propose a new method called Cross-sentence Attention NeTwork for cOmparative Relation (CANTOR) to extract comparative algorithms from text. Finally, we derive order for individual algorithm pairs with time and frequency to construct the algorithm roadmap. Through comprehensive experiments, our proposed algorithm shows its superiority over the baseline methods on the proposed task.;;;https://dl.acm.org/doi/10.1145/3292500.3330913;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Hybrid model of correlation based filter feature selection and machine learning classifiers applied on smart meter data set;;;['Sinayobye Janvier Omar', 'Kiwanuka N. Fred', 'Kaawaase Kyanda Swaib', 'Musabe Richard'];;;May 2019;;;SEiA '19: Proceedings of the 2nd Symposium on Software Engineering in Africa;;;Feature selection is referred to the process of obtaining a subset from an original feature set according to certain feature selection criterion, which selects the relevant features of the dataset. It plays a role in compressing the data processing scale, where the redundant and irrelevant features are removed. Feature selection techniques show that more information is not always good in machine learning applications. Apply different algorithms for the data at hand and with baseline classification performance values we can select a final feature selection algorithm. In this paper, we propose a hybrid classification model, which has correlation based filter feature selection algorithm and Machine learning as classifiers. The objective of this study is to select relevant features and analyze the outperform machine learning algorithms in order to train our model, predict and compare their classification performance. In this method, features are ordered according to their Absolute correlation value with respect to the class attribute. Then top K Features are selected from ordered list of features to form a reduced dataset. This proposed classifier model is applied to our smart meter datasets. To measure the performance of these selected features; seven benchmark classifier are used; Random Forest (RF), Logistic Regression (LR), k-Nearest Neighbor (kNN), Naïve Bayes (NB), Decision Tree (DT), Linear Discriminant Analysis (LDA) and Support Vector Machine (SVM). This paper then analyzes the performance of all classifiers with feature selection in term of accuracy, sensitivity, F-Measure, Specificity, Precision, and MCC. From our experiment, we found that Random Forest classifier performed higher than other used classifiers.;;;https://dl.acm.org/doi/10.1109/SEiA.2019.00009;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Process Mining to Unleash Variability Management: Discovering Configuration Workflows Using Logs;;;['Ángel Jesús Varela-Vaca', 'José A. Galindo', 'Belén Ramos-Gutiérrez', 'María Teresa Gómez-López', 'David Benavides'];;;September 2019;;;SPLC '19: Proceedings of the 23rd International Systems and Software Product Line Conference - Volume A;;;Variability models are used to build configurators. Configurators are programs that guide users through the configuration process to reach a desired configuration that fulfils user requirements. The same variability model can be used to design different configurators employing different techniques. One of the elements that can change in a configurator is the configuration workflow, i.e., the order and sequence in which the different configuration elements are presented to the configuration stakeholders. When developing a configurator, a challenge is to decide the configuration workflow that better suites stakeholders according to previous configurations. For example, when configuring a Linux distribution, the configuration process start by choosing the network or the graphic card, and then other packages with respect to a given sequence. In this paper, we present COnfiguration workfLOw proceSS mIning (COLOSSI), an automated technique that given a set of logs of previous configurations and a variability model can automatically assist to determine the configuration workflow that better fits the configuration logs generated by user activities. The technique is based on process discovery, commonly used in the process mining area, with an adaptation to configuration contexts. Our proposal is validated using existing data from an ERP configuration environment showing its feasibility. Furthermore, we open the door to new applications of process mining techniques in different areas of software product line engineering.;;;https://dl.acm.org/doi/10.1145/3336294.3336303;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Comparative Analysis of Machine Learning Techniques using Customer Feedback Reviews of Oil and Gas Companies;;;['Layth Nabeel AlRawi', 'Osama Ibraheem Ashour Ashour'];;;November 2020;;;ICSIE '20: Proceedings of the 9th International Conference on Software and Information Engineering;;;Sentiment analysis is the process of computationally identifying and categorizing opinions from a piece of text to determine whether the writer's attitude towards a practical topic, products or services is positive, negative or neutral. In this study, Machine Learning techniques are used to perform sentiment analysis on Oil and Gas customer feedback data. We present a comparison of different classification algorithms used for opinion mining, including Support Vector Machine (SVM), Naïve Bayes (NB), Instance Based Learning (IB3), Random Forest (RF), Partial Decision trees (PART), and Logit Boost (LB). Many studies have been performed on sentiment analysis in different sectors, but research into Oil and Gas customer feedback has been limited. Therefore, we have targeted a pathless sector, namely the Petroleum sector, where companies express their opinions towards specific products or services. Waikato Environment for Knowledge Analysis (WEKA) is used for experimental results. The WEKA environment is open source software entailing a collection of machine learning algorithms to solve data mining problems. The main aim of this study is to evaluate the efficiency of the above mentioned classifiers in terms of Precision, Recall, F-Measure and Accuracy. The findings of the comparison analysis indicate that the Naïve-Bayes classifier gives the best Accuracy of all classifiers. A small dataset could be considered as a limitation to our study due to the difficulty of gaining more datasets at the time of the research. However, this research will play a vital role for researchers in making decisions about the algorithm that they are going to use to solve their data mining problems.;;;https://dl.acm.org/doi/10.1145/3436829.3436871;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Mining World Indicators for Analyzing and Modeling the Development of Countries;;;['Hong Huang', 'Mingyuan Chi', 'Yu Song', 'Hai Jin'];;;None;;;ACM/IMS Transactions on Data Science;;;The world indicators released by the World Bank or other organizations usually give the basic public knowledge about the world. However, separate and static index lacks the complex interplay among different indicators and thus cannot help us have an overall understanding of the world. To this end, we study the world indicators from a different angle. Firstly, we discover that there exist correlations between indicators either from a static view or from a dynamic view. Moreover, taking the trade and diplomatic relationships into consideration, we construct a multi-relational network to depict the interactions between different countries, and propose a Multiple Relations to Vector (MR2vec) model to study world indicators from a network perspective. The experimental results show the changes of world indicators are predictable with the proposed model, and our proposed MR2vec has wide adaptability in predicting multi-relation networks.;;;https://dl.acm.org/doi/10.1145/3488059;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Sentiment Analysis of Twitter Data Using Machine Learning Techniques and Scikit-learn;;;['Shihab Elbagir', 'Jing Yang'];;;December 2018;;;ACAI '18: Proceedings of the 2018 International Conference on Algorithms, Computing and Artificial Intelligence;;;Sentiment analysis of Twitter data is an area that has experienced significant growth in recent years. The ability to identify sentiment from tweets using machine learning techniques has attracted researchers because of the simple efficiency of machine learning techniques. This paper tackles the use of machine learning algorithms and Scikit-learn in sentiment analysis of Twitter data. To do this, we perform analyses on Twitter datasets made publicly available by NLTK Corpora and create an efficient feature by using a feature extraction technique. We train and test various machine learning classifiers such as MultinomialNB, BernoulliNB, LogisticRegression, SGD classifier, SVC, LinearSVC, and NuSVC. Experimental results demonstrate that BernoulliNB, LogisticRegression, and SGD classifier reached accuracy as high as 75%.;;;https://dl.acm.org/doi/10.1145/3302425.3302492;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Mining Software Entities in Scientific Literature: Document-level NER for an Extremely Imbalance and Large-scale Task;;;['Patrice Lopez', 'Caifan Du', 'Johanna Cohoon', 'Karthik Ram', 'James Howison'];;;October 2021;;;CIKM '21: Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management;;;We present a comprehensive information extraction system dedicated to software entities in scientific literature. This task combines the complexity of automatic reading of scientific documents (PDF processing, document structuring, styled/rich text, scaling) with challenges specific to mining software entities: high heterogeneity and extreme sparsity of mentions, document-level cross-references, disambiguation of noisy software mentions and poor portability of Machine Learning approaches between highly specialized domains. While NER is a key component to recognize new and unseen software, considering this task as a simple NER application fails to address most of these issues. In this paper, we propose a multi-model Machine Learning approach where raw documents are ingested by a cascade of document structuring processes applied not to text, but to layout token elements. The cascading process further enriches the relevant structures of the document with a Deep Learning software mention recognizer adapted to the high sparsity of mentions. The Machine Learning cascade culminates with entity disambiguation to alleviate false positives and to provide software entity linking. A bibliographical reference resolution is integrated to the process for attaching references cited alongside the software mentions. Based on the first gold-standard annotated dataset developed for software mentions, this work establishes a new reference end-to-end performance for this task. Experiments with the CORD-19 publications have further demonstrated that our system provides practically usable performance and is scalable to the whole scientific corpus, enabling novel applications for crediting research software and for better understanding the impact of software in science.;;;https://dl.acm.org/doi/10.1145/3459637.3481936;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Text Classification Based on Enriched Vector Space Model;;;['Tsvetanka Georgieva-Trifonova'];;;June 2017;;;CompSysTech '17: Proceedings of the 18th International Conference on Computer Systems and Technologies;;;As one of the challenges to text classification can be indicated applying a model with the following characteristics: acceptable computational complexity of the model construction; dimension reduction of the vector space without significant decreasing of the classification performance. The present research aims to find a possible solution to mentioned problems. This paper proposes a model obtained by enrichment of the vector space model with the association relationships between words extracted from their co-occurrence in the text documents. For this purpose, the lift measure of association rules between word pairs is calculated. Experiments are conducted on Reuters-21578 dataset by using SVM classifier. The results confirm that applying the model improves the binominal and polynomial classification performance in comparison to the vector space model with respect to the F-measure even after word filtering, leading to a significant dimension reduction.;;;https://dl.acm.org/doi/10.1145/3134302.3134343;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
COVID-19 classification using thermal images: thermal images capability for identifying COVID-19 using traditional machine learning classifiers;;;['Martha Rebeca Canales-Fiscal', 'Rocío Ortiz López', 'Regina Barzilay', 'Víctor Treviño', 'Servando Cardona-Huerta', 'Luis Javier Ramírez-Treviño', 'Adam Yala', 'José Tamez-Peña'];;;August 2021;;;BCB '21: Proceedings of the 12th ACM Conference on Bioinformatics, Computational Biology, and Health Informatics;;;Medical images have been proposed as a diagnostic tool for SARS-COV-2. The image modality more investigated on this subject is computed tomography (CT), however it has some disadvantages: it uses ionizing radiation, requires unique installations along with a complicated process limiting the number of possible tests per equipment, and the economic costs can be prohibitively high for screening a large population. For these reasons, the aim of this study is to investigate thermal images as an alternative modality for diagnosis of COVID-19. The methodology used in this study consisted of using radiomics and moment features extracted from six images obtained from thermal video clips in which optical flow and super resolution were used, these features were classified using traditional machine learning methods. Accuracies were in the range of 0.433 - 0.524. These first results conducted on thermal images suggest that the use of this type of image modality is unlikely to be favorable for COVID-19 detection.;;;https://dl.acm.org/doi/10.1145/3459930.3469558;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Report on the 2nd ACM SIGIR/SIGKDD Africa school on machine learning for data mining and search;;;['Tanya Berger-Wolf', 'Ben Carterette', 'Tamer Elsayed', 'Maria Keet', 'Fabrizio Sebastiani', 'Hussein Suleman'];;;June 2020;;;ACM SIGIR Forum;;;We report on the organization and activities of the 2nd ACM SIGIR/SIGKDD Africa School on Machine Learning for Data Mining and Search, which took place at the University of Cape Town in South Africa January 27--31, 2020.;;;https://dl.acm.org/doi/10.1145/3451964.3451968;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A unified framework of density-based clustering for semi-supervised classification;;;['Jadson Castro Gertrudes', 'Arthur Zimek', 'Jörg Sander', 'Ricardo J. G. B. Campello'];;;July 2018;;;SSDBM '18: Proceedings of the 30th International Conference on Scientific and Statistical Database Management;;;Semi-supervised classification is drawing increasing attention in the era of big data, as the gap between the abundance of cheap, automatically collected unlabeled data and the scarcity of labeled data that are laborious and expensive to obtain is dramatically increasing. In this paper, we introduce a unified framework for semi-supervised classification based on building-blocks from density-based clustering. This framework is not only efficient and effective, but it is also statistically sound. Experimental results on a large collection of datasets show the advantages of the proposed framework.;;;https://dl.acm.org/doi/10.1145/3221269.3223037;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Decision Support Method for Product Replacement in Coin-Less Vending Machine Using Data Mining Techniques and Product Segmentation;;;['Peeraya Wasutanachai', 'Kun-Ming Yu', 'Yi-Hui Chiang', 'Wen Ouyang', 'Yen-Chiu Chen'];;;June 2019;;;DSDE 2019: Proceedings of the 2019 2nd International Conference on Data Storage and Data Engineering;;;In this research paper, we introduce a novel model for product segmentation based on data collected from coin-less vending machines called SFM (Steadiness, Frequency and Monetary) in order to track customer behavior through each segments of products and provide vending machine owner the more reasonably way to change the items on the vending machine. We adopted two well-known algorithms from data mining techniques which are association rules mining and K-means clustering. Apriori together with k-means were used in our proposed methodology. After performing the method, we tried our theory on the machines. The results from the real-word experiment showed that there were only 25% of new products that were in low value segment after applied our method while there were 67% before the usage.;;;https://dl.acm.org/doi/10.1145/3354153.3354161;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Auditing Data Provenance in Text-Generation Models;;;['Congzheng Song', 'Vitaly Shmatikov'];;;July 2019;;;KDD '19: Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining;;;To help enforce data-protection regulations such as GDPR and detect unauthorized uses of personal data, we develop a new model auditing technique that helps users check if their data was used to train a machine learning model. We focus on auditing deep-learning models that generate natural-language text, including word prediction and dialog generation. These models are at the core of popular online services and are often trained on personal data such as users' messages, searches, chats, and comments. We design and evaluate a black-box auditing method that can detect, with very few queries to a model, if a particular user's texts were used to train it (among thousands of other users). We empirically show that our method can successfully audit well-generalized models that are not overfitted to the training data. We also analyze how text-generation models memorize word sequences and explain why this memorization makes them amenable to auditing.;;;https://dl.acm.org/doi/10.1145/3292500.3330885;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
An Unsupervised Approach for Sentiment Analysis on Social Media Short Text Classification in Roman Urdu;;;['Toqir A. Rana', 'Kiran Shahzadi', 'Tauseef Rana', 'Ahsan Arshad', 'Mohammad Tubishat'];;;None;;;ACM Transactions on Asian and Low-Resource Language Information Processing;;;During the last two decades, sentiment analysis, also known as opinion mining, has become one of the most explored research areas in Natural Language Processing (NLP) and data mining. Sentiment analysis focuses on the sentiments or opinions of consumers expressed over social media or different web sites. Due to exposure on the Internet, sentiment analysis has attracted vast numbers of researchers over the globe. A large amount of research has been conducted in English, Chinese, and other languages used worldwide. However, Roman Urdu has been neglected despite being the third most used language for communication in the world, covering millions of users around the globe. Although some techniques have been proposed for sentiment analysis in Roman Urdu, these techniques are limited to a specific domain or developed incorrectly due to the unavailability of language resources available for Roman Urdu. Therefore, in this article, we are proposing an unsupervised approach for sentiment analysis in Roman Urdu. First, the proposed model normalizes the text to overcome spelling variations of different words. After normalizing text, we have used Roman Urdu and English opinion lexicons to correctly identify users’ opinions from the text. We have also incorporated negation terms and stemming to assign polarities to each extracted opinion. Furthermore, our model assigns a score to each sentence on the basis of the polarities of extracted opinions and classifies each sentence as positive, negative, or neutral. In order to verify our approach, we have conducted experiments on two publicly available datasets for Roman Urdu and compared our approach with the existing model. Results have demonstrated that our approach outperforms existing models for sentiment analysis tasks in Roman Urdu. Furthermore, our approach does not suffer from domain dependency.;;;https://dl.acm.org/doi/10.1145/3474119;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Radio Frequency-based Techniques of Drone Detection and Classification using Machine Learning;;;['Mariam M. Alaboudi', 'Manar Abu Talib', 'Qassim Nasir'];;;November 2020;;;ICRAI '20: Proceedings of the 6th International Conference on Robotics and Artificial Intelligence;;;This research paper provides a comprehensive survey review on drone detection using Radio Frequency (RF)-based techniques along with machine learning and localization algorithms. RF signals proved its effectiveness in detecting drones, however, due to the lack of a published survey, this research paper reviews the newly emerged RF-based techniques by addressing the implemented methods and discussing the results obtained in terms of the testing environment, range of detection and accuracy of the system. In this survey review, thirty conference and journal papers have been collected, however only selected papers have been discussed depending on the contribution and limited space of the paper. Finally, this survey also discusses the challenges encountered in drone detection using RF due to its great impact on the efficiency of the system.;;;https://dl.acm.org/doi/10.1145/3449301.3449348;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A data mining approach for predicting main-engine rotational speed from vessel-data measurements;;;['Dimitrios Kaklis', 'George Giannakopoulos', 'Iraklis Varlamis', 'Constantine D. Spyropoulos', 'Takis J. Varelas'];;;June 2019;;;IDEAS '19: Proceedings of the 23rd International Database Applications &amp; Engineering Symposium;;;In this work we face the challenge of estimating a ship's main-engine rotational speed from vessel data series, in the context of sea vessel route optimization. To this end, we study the value of different vessel data types as predictors of the engine rotational speed. As a result, we utilize speed data under a time-series view and examine how extracting locally-aware prediction models affects the learning performance. We apply two different approaches: the first utilizes clustering as a pre-processing step to the creation of many local models; the second builds upon splines to predict the target value. Given the above, we show that clustering can improve performance and demonstrate how the number of clusters affects the outcome. We also show that splines perform in a promising manner, but do not clearly outperform other methods. On the other hand, we show that spline regression combined with a Delaunay partitioning offers most competitive results.;;;https://dl.acm.org/doi/10.1145/3331076.3331123;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Improving Multiclass Classification of Cybersecurity Breaches in Railway Infrastructure using Imbalanced Learning;;;['Aleksandr N. Nebaba', 'Ilias K. Savvas', 'Maria A. Butakova', 'Andrey V. Chernov', 'Petr S. Shevchuk'];;;November 2021;;;ESSE '21: Proceedings of the 2021 European Symposium on Software Engineering;;;Machine learning approaches and algorithms are spreading in wide areas in research and technology. Cybersecurity breaches are the common anomalies for networked and distributed infrastructures which are monitored, registered, and described carefully. However, the description of each security breaches episode and its classification is still a difficult problem, especially in highly complex telecommunication infrastructure. Railway information infrastructure usually has a large scale and large diversity of possible security breaches. Today's situation shows the registering of the security breaches has a mature and stable character, but the problem of their automated classification is not solved completely. Many studies on security breaches multiclass classification show inadequate accuracy of classification. We investigated the origins of this problem and suggested the possible roots consist in disbalance the datasets used for machine learning multiclass classification. Thus, we proposed an approach to improve the accuracy of the classification and verified our approach on the really collected datasets with cybersecurity breaches in railway telecommunication infrastructure. We analyzed the results of applying three imbalanced learning methodologies, namely random oversampling, synthetic minority oversampling technique, and the last one with Tomek links. We have implemented three machine learning algorithms, namely Naïve Bayes, K-means, and support vector machine, on disbalances and balanced data to estimate imbalance learning methodologies with comparing results. The proposed approach demonstrated the increase of the accuracy for multiclass classification in the range from 30 to 41%, depending on the imbalanced learning technique.;;;https://dl.acm.org/doi/10.1145/3501774.3501789;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Evaluating User Satisfaction with Typography Designs via Mining Touch Interaction Data in Mobile Reading;;;['Junxiang Wang', 'Jianwei Yin', 'Shuiguang Deng', 'Ying Li', 'Calton Pu', 'Yan Tang', 'Zhiling Luo'];;;April 2018;;;CHI '18: Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems;;;Previous work has demonstrated that typography design has a great influence on users' reading experience. However, current typography design guidelines are mainly for general purpose, while the individual needs are nearly ignored. To achieve personalized typography designs, an important and necessary step is accurately evaluating user satisfaction with the typography designs. Current evaluation approaches, e.g., asking for users' opinions directly, however, interrupt the reading and affect users' judgments. In this paper, we propose a novel method to address this challenge by mining users' implicit feedbacks, e.g., touch interaction data. We conduct two mobile reading studies in Chinese to collect the touch interaction data from 91 participants. We propose various features based on our three hypotheses to capture meaningful patterns in the touch behaviors. The experiment results show the effectiveness of our evaluation models with higher accuracy on comparing with the baseline under three text difficulty levels, respectively.;;;https://dl.acm.org/doi/10.1145/3173574.3173687;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Predicting the Survivors of the Titanic Kaggle, Machine Learning From Disaster;;;['Nadine Farag', 'Ghada Hassan'];;;May 2018;;;ICSIE '18: Proceedings of the 7th International Conference on Software and Information Engineering;;;April 14th, 1912 was very unfortunate for the most powerful ship ever built at that time, the Titanic. Grievously, 1503 out of 2203 passengers perished the sinking, but the rationale behind survival still remains a question mark. In efforts to study the Titanic passengers; Kaggle, a popular data science website, assembled information about each passenger back in the days of the Titanic into a dataset, and made it available for a competition titled: "Titanic: Machine Learning from Disaster." This research aims to use machine learning techniques on the Titanic data to analyze the data for classification and to predict the survival of the Titanic passengers by using data-mining algorithms; specifically Decision Trees and Naïve Bayes. The prediction and efficiency of these algorithms depend greatly on data analysis and the model. The paper presents an implementation which combines the benefits of feature selection and machine learning to accurately select and distinguish characteristics of passengers' age, class, cabin, and port of embarkation then consequently infer an authentic model for an accurate prediction. The data-set is described and the implementation details and prediction results are presented then compared to other results. The Decision Tree algorithm has accurately predicted 90.01% of the survival of passengers, while the Gaussian Naïve Bayes witnessed 92.52% accuracy in prediction.;;;https://dl.acm.org/doi/10.1145/3220267.3220282;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Using Contextual Text Mining Algorithm to Analysis Yearly Trend for Population Ageing and Declining Fertility with Government Science and Technology Projects in Taiwan;;;['C. Y. Chuang', 'M. C. Huang', 'Y. Y. Lin', 'Y. H. Hsiao', 'T. C. Wang'];;;October 2021;;;CSSE '21: Proceedings of the 4th International Conference on Computer Science and Software Engineering;;;None;;;https://dl.acm.org/doi/10.1145/3494885.3494919;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A Comparative Analysis with the Hybrid Algorithm Approach for Sentimental Analysis through Machine Learning;;;['Ravleen Singh', 'Ganpat Joshi', 'Paras Kothari'];;;August 2021;;;DSMLAI '21': Proceedings of the International Conference on Data Science, Machine Learning and Artificial Intelligence;;;This research work focuses on the latest studies that have used Machine learning to find a solution to sentiment analysis problems related to sentiment polarisation. In preprocessing steps, the Models applied to stop words and Bag of words to collect datasets. Even with the widespread usage and acceptance of some approaches, a superior technique for categorising the polarisation of text documents is tough to make out. Machine learning has lately evoked attention as a method for sentiment investigation. The present work proposes a machine learning-based hybrid algorithm that incorporates N-gram technique as feature extraction. It combines a Decision tree classifier and Random forest Classifier techniques as a classification for sentiment analysis. Naïve bayse, linear classifier and support vector machine approaches are perform in the perspective of sentiment classification. Finally, a comparative study with the different supervised algorithms implemented on the product reviews dataset. The performance of the model evaluated on the confusion matrix. In the comparative analysis of classification techniques, the combined technique has shown better results than previously used supervised techniques of naïve bayse, linear classifier and support vector machine.;;;https://dl.acm.org/doi/10.1145/3484824.3484904;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Simulation Analysis of Standardized Management Measures for Private College Students Based on Data Mining;;;['Lijun Fan'];;;September 2021;;;ICISCAE 2021: 2021 4th International Conference on Information Systems and Computer Aided Education;;;With the continuous expansion of college enrollment and the flexible diversification of educational methods, most universities are facing the contradiction between the sharp increase in the number of students and the increasing shortage of teaching resources, which brings unprecedented challenges to the management of universities. With the networking of computers, the rapid development of database technology and the wide application of database management system, DM (data mining) technology has been widely used in university information management. In the era of rapid development of Internet and Internet of Things, the pace of education informatization construction is accelerating, and the construction of "Internet+Education" and "Smart Campus" is deepening. Students' studies, life and network behaviors are recorded as electronic data by information systems and electronic devices. This article aims to apply DM technology to the standardized management of private college students, establish a database that collects useful information, analyze the status of students in school, and provide management personnel with a basis for decision-making.;;;https://dl.acm.org/doi/10.1145/3482632.3482658;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
On the behavior of the infinite restricted boltzmann machine for clustering;;;['Nikolas A. Huhnstock', 'Alexander Karlsson', 'Maria Riveiro', 'H. Joe Steinhauer'];;;April 2018;;;SAC '18: Proceedings of the 33rd Annual ACM Symposium on Applied Computing;;;Clustering is a core problem within a wide range of research disciplines ranging from machine learning and data mining to classical statistics. A group of clustering approaches so-called nonparametric methods, aims to cluster a set of entities into a beforehand unspecified and unknown number of clusters, making potentially expensive pre-analysis of data obsolete. In this paper, the recently, by Cote and Larochelle introduced infinite Restricted Boltzmann Machine that has the ability to self-regulate its number of hidden parameters is adapted to the problem of clustering by the introduction of two basic cluster membership assumptions. A descriptive study of the influence of several regularization and sparsity settings on the clustering behavior is presented and results are discussed. The results show that sparsity is a key adaption when using the iRBM for clustering that improves both the clustering performances as well as the number of identified clusters.;;;https://dl.acm.org/doi/10.1145/3167132.3167183;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
DL-Learner Structured Machine Learning on Semantic Web Data;;;['Lorenz Bühmann', 'Jens Lehmann', 'Patrick Westphal', 'Simon Bin'];;;April 2018;;;WWW '18: Companion Proceedings of the The Web Conference 2018;;;The following paper is an extended summary of the journal paper "DL-Learner A framework for inductive learning on the Semantic Web". In this system paper, we describe the DL-Learner framework. It is beneficial in various data and schema analytic tasks with applications in different standard machine learning scenarios, e.g. life sciences, as well as Semantic Web specific applications such as ontology learning and enrichment. Since its creation in 2007, it has become the main OWL and RDF-based software framework for supervised structured machine learning and includes several algorithm implementations, usage examples and has applications building on top of the framework.;;;https://dl.acm.org/doi/10.1145/3184558.3186235;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Genetic programming based feature construction for classification with incomplete data;;;['Cao Truong Tran', 'Mengjie Zhang', 'Peter Andreae', 'Bing Xue'];;;July 2017;;;GECCO '17: Proceedings of the Genetic and Evolutionary Computation Conference;;;Missing values are an unavoidable problem in many real-world datasets. Dealing with incomplete data is an crucial requirement for classification because inadequate treatment of missing values often causes large classification error. Feature construction has been successfully applied to improve classification with complete data, but it has been seldom applied to incomplete data. Genetic programming-based multiple feature construction (GPMFC) is a current encouraging feature construction method which uses genetic programming to evolve new multiple features from original features for classification tasks. GPMFC can improve the accuracy and reduce the complexity of many decision trees and rule-based classifiers; however, it cannot directly work with incomplete data. This paper proposes IGPMFC which is extended from GPMFC to tackle with incomplete data. IGPMFC uses genetic programming with interval functions to directly evolve multiple features for classification with incomplete data. Experimental results reveal that not only IGPMFC can substantially improve the accuracy, but also can reduce the complexity of learnt classifiers facing with incomplete data.;;;https://dl.acm.org/doi/10.1145/3071178.3071183;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Taking Advantage of Multitask Learning for Fair Classification;;;['Luca Oneto', 'Michele Doninini', 'Amon Elders', 'Massimiliano Pontil'];;;January 2019;;;AIES '19: Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society;;;A central goal of algorithmic fairness is to reduce bias in automated decision making. An unavoidable tension exists between accuracy gains obtained by using sensitive information as part of a statistical model, and any commitment to protect these characteristics. Often, due to biases present in the data, using the sensitive information in the functional form of a classifier improves classification accuracy. In this paper we show how it is possible to get the best of both worlds: optimize model accuracy and fairness without explicitly using the sensitive feature in the functional form of the model, thereby treating different individuals equally. Our method is based on two key ideas. On the one hand, we propose to use Multitask Learning (MTL), enhanced with fairness constraints, to jointly learn group specific classifiers that leverage information between sensitive groups. On the other hand, since learning group specific models might not be permitted, we propose to first predict the sensitive features by any learning method and then to use the predicted sensitive feature to train MTL with fairness constraints. This enables us to tackle fairness with a three-pronged approach, that is, by increasing accuracy on each group, enforcing measures of fairness during training, and protecting sensitive information during testing. Experimental results on two real datasets support our proposal, showing substantial improvements in both accuracy and fairness.;;;https://dl.acm.org/doi/10.1145/3306618.3314255;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
On accelerating ultra-large-scale mining;;;['Ganesha Upadhyaya', 'Hridesh Rajan'];;;May 2017;;;ICSE-NIER '17: Proceedings of the 39th International Conference on Software Engineering: New Ideas and Emerging Results Track;;;Ultra-large-scale mining has been shown to be useful for a number of software engineering tasks e.g. mining specifications, defect prediction. We propose a new research direction for accelerating ultra-large-scale mining that goes beyond parallelization. Our key idea is to analyze the interaction pattern between the mining task and the artifact to cluster artifacts such that running the mining task on one candidate artifact from each cluster is sufficient to produce results for other artifacts in the same cluster. Our artifact clustering criteria go beyond syntactic, semantic, and functional similarities to mining-task-specific similarity, where the interaction pattern between the mining task and the artifact is used for clustering. Our preliminary evaluation demonstrates that our technique significantly reduces the overall mining time.;;;https://dl.acm.org/doi/10.1109/ICSE-NIER.2017.11;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Unsupervised context switch for classification tasks on data streams with recurrent concepts;;;['Denis M. dos Reis', 'André G. Maletzke', 'Gustavo E. A. P. A. Batista'];;;April 2018;;;SAC '18: Proceedings of the 33rd Annual ACM Symposium on Applied Computing;;;In this paper, we propose a novel approach to deal with concept drifts in data streams. We assume we can collect labeled data for different concepts in the training phase; however, in the test phase, no labels are available. Our approach consists of the storage of a limited number of classification models and the unsupervised identification of the most suitable one depending on the current concept. Several real-world classification problems with extreme label latency can use this setting. One example is the identification of insects species using wing-beat data gathered by sensors in field conditions. Flying insects have their wing-beat frequency indirectly affected by temperature, among other factors. In this work, we show that we can dynamically identify which is the most appropriate classification model, among other models from data with different temperature conditions, without any temperature information. We then expand the use of the method to other data sets and obtain accurate results.;;;https://dl.acm.org/doi/10.1145/3167132.3167189;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
An FPGA-Based Hardware Accelerator for K-Nearest Neighbor Classification for Machine Learning on Mobile Devices;;;['Mokhles A. Mohsin', 'Darshika G. Perera'];;;June 2018;;;HEART '18: Proceedings of the 9th International Symposium on Highly-Efficient Accelerators and Reconfigurable Technologies;;;Machine learning has become one of the cornerstones of information technology. Many machine learning algorithms have found their way into mobile devices, which have stringent requirements. Also, machine learning algorithms, such as classification and clustering, are becoming complex, requiring high processing power, thus affecting the speedup. In this paper, we introduce unique, novel, and efficient hardware architecture to accelerate the K-nearest neighbor classifier on mobile devices, considering constraints associated with these devices. We evaluate the efficiency of our hardware architecture, in terms of speedup, space, and accuracy. Our design is generic, parameterized, and scalable. Our hardware design achieves 127 times speedup compared to its software counterpart, and can also achieve 100% classification accuracy.;;;https://dl.acm.org/doi/10.1145/3241793.3241810;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Data mining Contribution to Intrusion Detection Systems Improvement;;;['Abdelkader khobzaoui', 'Mohamed Benhamouda', 'Mahmoud Fahsi'];;;June 2020;;;ICIST '20: Proceedings of the 10th International Conference on Information Systems and Technologies;;;Intrusion detection has become one of the most prominent components in computer security field. In order to improve intrusion detection systems performances, Data mining techniques have been massively used. Actually, the massive integration of data mining technique in intrusion detection has quickly emerged due to the fact that intrusion detection task is a classification problem by nature and Data mining provides tools to discover consistent and useful patterns of system features that describe program and user behavior, and use the set of relevant system features to build classifiers able to recognize abnormal or suspicious activities. In this paper, we will stress the role of the data mining in intrusion detection systems development and promotion.;;;https://dl.acm.org/doi/10.1145/3447568.3448514;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Histological classification of non-small cell lung cancer with RNA-seq data using machine learning models;;;['Robert B. Eshun', 'Md Khurram Monir Rabby', 'A. K. M. Kamrul Islam', 'Marwan U. Bikdash'];;;August 2021;;;BCB '21: Proceedings of the 12th ACM Conference on Bioinformatics, Computational Biology, and Health Informatics;;;This study develops an automated model using the supervised learning framework(s) for the classification of the histological subtypes of non-small cell lung cancer (NSCLC). The machine learning (ML) approach is performed on gene expression profiles for the diagnosis of lung cancer that is the primary cause of cancer deaths worldwide. The performance of five classical Machine Learning (ML) estimators and four ensemble ML classifiers are evaluated on an RNA-Sequence dataset of 127 cases of NSCLC. The Decision Tree (DT) and Bagging models show promising classification accuracy up to 100% and area under curves (AUCs) is more than 0.97. The implemented ensemble methods collectively exhibit good performance in terms of AUCs (0.68 -- 1.00). The findings are comparable to the high precision ML models and the results provide an insight into the supervised models that can achieve higher diagnosis accuracy on RNA-Seq-based gene expression profiles of NSCLC subtypes.;;;https://dl.acm.org/doi/10.1145/3459930.3471168;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Facilitating and Managing Machine Learning and Data Analysis Tasks in Big Data Environments using Web and Microservice Technologies;;;['Shadi Shahoud', 'Sonja Gunnarsdottir', 'Hatem Khalloof', 'Clemens Duepmeier', 'Veit Hagenmeyer'];;;November 2019;;;MEDES '19: Proceedings of the 11th International Conference on Management of Digital EcoSystems;;;Driven by the great advance of machine learning in a wide range of application areas, the need for developing machine learning frameworks effectively as well as easily usable by novices increased dramatically. Furthermore, building machine learning models in the context of big data environments still represents a great challenge. In the present paper, we tackle these challenges by introducing a new generic framework for efficiently facilitating the training, testing, managing, storing, and retrieving of machine learning models in the context of big data. The framework makes use of a powerful big data software stack and a microservice architecture for a fully manageable and highly scalable solution. A highly configurable user interface is introduced giving the user the ability to easily train, test, and manage machine learning models. Moreover, it automatically indexes models and allows flexible exploration of them in the visual interface. The performance of the new framework is evaluated on state-of-the-arts machine learning algorithms: it is shown that storing and retrieving machine learning models as well as a respective acceptable low overhead demonstrate an efficient approach to facilitate machine learning in big data environments.;;;https://dl.acm.org/doi/10.1145/3297662.3365807;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Novel Machine Learning for Big Data Analytics in Intelligent Support Information Management Systems;;;['Zhihan Lv', 'Ranran Lou', 'Hailin Feng', 'Dongliang Chen', 'Haibin Lv'];;;None;;;ACM Transactions on Management Information Systems;;;Two-dimensional1 arrays of bi-component structures made of cobalt and permalloy elliptical dots with thickness of 25 nm, length 1 mm and width of 225 nm, have been prepared by a self-aligned shadow deposition technique. Brillouin light scattering has been exploited to study the frequency dependence of thermally excited magnetic eigenmodes on the intensity of the external magnetic field, applied along the easy axis of the elements.Scientific information technology has been developed rapidly. Here, the purposes are to make people's lives more convenient and ensure information management and classification. The machine learning algorithm is improved to obtain the optimized Light Gradient Boosting Machine (LightGBM) algorithm. Then, an Android-based intelligent support information management system is designed based on LightGBM for the big data analysis and classification management of information in the intelligent support information management system. The system is designed with modules of employee registration and login, company announcement notice, attendance and attendance management, self-service, and daily tools with the company as the subject. Furthermore, the performance of the constructed information management system is analyzed through simulations. Results demonstrate that the training time of the optimized LightGBM algorithm can stabilize at about 100s, and the test time can stabilize at 0.68s. Besides, its accuracy rate can reach 89.24%, which is at least 3.6% higher than other machine learning algorithms. Moreover, the acceleration efficiency analysis of each algorithm suggests that the optimized LightGBM algorithm is suitable for processing large amounts of data; its acceleration effect is more apparent, and its acceleration ratio is higher than other algorithms. Hence, the constructed intelligent support information management system can reach a high accuracy while ensuring the error, with apparent acceleration effect. Therefore, this model can provide an experimental reference for information classification and management in various fields.;;;https://dl.acm.org/doi/10.1145/3469890;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A Case Study of HealthCare Platform using Big Data Analytics and Machine Learning;;;['M. D. Samiul Islam', 'Daizong Liu', 'Kewei Wang', 'Pan Zhou', 'Li Yu', 'Dapeng Wu'];;;June 2019;;;HPCCT '19: Proceedings of the 2019 3rd High Performance Computing and Cluster Technologies Conference;;;The medical services in Bangladesh are shortage nowadays; people are suffering from getting the correct treatment from the hospital. With the low proportion of the doctors and the low per capita salary in Bangladesh, patients need to spend more money to get the appropriate treatments. Therefore, it is necessary to apply modern information technologies by which the scaffold between the patients and specialists can be reduced, and the patients can take proper treatment at a lower cost. Fortunately, we can solve this critical problem by utilizing interaction among electrical devices. With the big data collected from these devices, machine learning is a powerful tool for the data analytics because of its high accuracy, lower computational costs, and lower power consumption. This research is based on a case of study by the incorporation of the database, mobile application, web application and develops a novel platform through which the patients and the doctors can interact. In addition, the platform helps to store the patients' health data to make the final prediction using machine learning methods to get the proper healthcare treatment with the help of the machines and the doctors. The experiment result shows the high accuracy over 95% of the disease detection using machine learning methods, with the cost 90% lower than the local hospital in Bangladesh, which provides the strong support to implement of our platform in the remote area of the country.;;;https://dl.acm.org/doi/10.1145/3341069.3342980;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Event modeling and mining: a long journey toward explainable events;;;['Xinhong Chen', 'Qing Li'];;;None;;;The VLDB Journal — The International Journal on Very Large Data Bases;;;AbstractRecently, research on event management has redrawn much attention and made great progress. As the core tasks of event management, event modeling and mining are essential for accessing and utilizing events effectively. In this survey, we provide a detailed review of event modeling and event mining. Based on a general definition, different characteristics of events are described, along with the associated challenges. Then, we define four forms of events in order to better classify currently available but somewhat confusing event types; we also compare different event representation and relationship analysis techniques used for different forms of events. Finally, we discuss several pending issues and application-specific challenges which also shed light on future research directions.;;;https://dl.acm.org/doi/10.1007/s00778-019-00545-0;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
500+ times faster than deep learning: a case study exploring faster methods for text mining stackoverflow;;;['Suvodeep Majumder', 'Nikhila Balaji', 'Katie Brey', 'Wei Fu', 'Tim Menzies'];;;May 2018;;;MSR '18: Proceedings of the 15th International Conference on Mining Software Repositories;;;Deep learning methods are useful for high-dimensional data and are becoming widely used in many areas of software engineering. Deep learners utilizes extensive computational power and can take a long time to train- making it difficult to widely validate and repeat and improve their results. Further, they are not the best solution in all domains. For example, recent results show that for finding related Stack Overflow posts, a tuned SVM performs similarly to a deep learner, but is significantly faster to train. This paper extends that recent result by clustering the dataset, then tuning every learners within each cluster. This approach is over 500 times faster than deep learning (and over 900 times faster if we use all the cores on a standard laptop computer). Significantly, this faster approach generates classifiers nearly as good (within 2% F1 Score) as the much slower deep learning method. Hence we recommend this faster methods since it is much easier to reproduce and utilizes far fewer CPU resources. More generally, we recommend that before researchers release research results, that they compare their supposedly sophisticated methods against simpler alternatives (e.g applying simpler learners to build local models).;;;https://dl.acm.org/doi/10.1145/3196398.3196424;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Deep learning benchmarks and datasets for social media image classification for disaster response;;;['Firoj Alam', 'Ferda Ofli', 'Muhammad Imran', 'Tanvirul Alam', 'Umair Qazi'];;;December 2020;;;ASONAM '20: Proceedings of the 12th IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining;;;During a disaster event, images shared on social media helps crisis managers gain situational awareness and assess incurred damages, among other response tasks. Recent advances in computer vision and deep neural networks have enabled the development of models for real-time image classification for a number of tasks, including detecting crisis incidents, filtering irrelevant images, classifying images into specific humanitarian categories, and assessing the severity of damage. Despite several efforts, past works mainly suffer from limited resources (i.e., labeled images) available to train more robust deep learning models. In this study, we propose new datasets for disaster type detection, and informativeness classification, and damage severity assessment. Moreover, we relabel existing publicly available datasets for new tasks. We identify exact- and near-duplicates to form non-overlapping data splits, and finally consolidate them to create larger datasets. In our extensive experiments, we benchmark several state-of-the-art deep learning models and achieve promising results. We release our datasets and models publicly, aiming to provide proper baselines as well as to spur further research in the crisis informatics community.;;;https://dl.acm.org/doi/10.1109/ASONAM49781.2020.9381294;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
DeepXML: A Deep Extreme Multi-Label Learning Framework Applied to Short Text Documents;;;['Kunal Dahiya', 'Deepak Saini', 'Anshul Mittal', 'Ankush Shaw', 'Kushal Dave', 'Akshay Soni', 'Himanshu Jain', 'Sumeet Agarwal', 'Manik Varma'];;;March 2021;;;WSDM '21: Proceedings of the 14th ACM International Conference on Web Search and Data Mining;;;Scalability and accuracy are well recognized challenges in deep extreme multi-label learning where the objective is to train architectures for automatically annotating a data point with the most relevant subset of labels from an extremely large label set. This paper develops the DeepXML framework that addresses these challenges by decomposing the deep extreme multi-label task into four simpler sub-tasks each of which can be trained accurately and efficiently. Choosing different components for the four sub-tasks allows DeepXML to generate a family of algorithms with varying trade-offs between accuracy and scalability. In particular, DeepXML yields the Astec algorithm that could be 2-12% more accurate and 5-30x faster to train than leading deep extreme classifiers on publically available short text datasets. Astec could also efficiently train on Bing short text datasets containing up to 62 million labels while making predictions for billions of users and data points per day on commodity hardware. This allowed Astec to be deployed on the Bing search engine for a number of short text applications ranging from matching user queries to advertiser bid phrases to showing personalized ads where it yielded significant gains in click-through-rates, coverage, revenue and other online metrics over state-of-the-art techniques currently in production. DeepXML's code is available at https://github.com/Extreme-classification/deepxml.;;;https://dl.acm.org/doi/10.1145/3437963.3441810;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Mining Frequent Itemsets Using Improved Apriori on Spark;;;['Fei Gao', 'Ashutosh Khandelwal', 'Jiangjiang Liu'];;;April 2019;;;ICISDM '19: Proceedings of the 2019 3rd International Conference on Information System and Data Mining;;;Finding the frequent itemset is one of the most investigated extents of data mining. The Apriori algorithm is the most established algorithm for frequent itemset mining, but it has issues regarding scanning frequent databases and generating a large amount of candidate sets. To solve these issues, an Improved Apriori algorithm was proposed. We examined the data structure, implementation, and algorithmic features that mainly focus on frequent itemset mining. We are representing an Improved Apriori algorithm on Spark in which simple and scalable implementation is done to achieve a faster process with lower support thresholds. We examined the improved Apriori algorithm on Extended Bakery Dataset and Retail Dataset. The results show execution time was reduced by 40% and 57% compared with the original Apriori algorithm.;;;https://dl.acm.org/doi/10.1145/3325917.3325925;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Data Preprocessing for Learning, Analyzing and Detecting Scene Text Video based on Rotational Gradient;;;['Manasa Devi Devi Mortha', 'Seetha Maddala', 'Vishwanadha Raju'];;;April 2021;;;DATA'21: International Conference on Data Science, E-learning and Information Systems 2021;;;Challenging annotated video datasets are in huge demand for the researchers and embedded industrials to learn and build an artificial intelligence for detecting, localizing and classifying the objects of interest aimed at various applications under pattern recognition and computer vision domain. It is very significant to produce those annotated sets to the respective communal. This paper focuses on text as annotated data in video for detection, localization, tracking and classification to solve several optical character recognition (OCR) based problems. Text is very essential in understanding the nature of the video because of diverse applications which are in renowned today like video retrieval and searching, driverless cars, industrial goods automation, geocoding and many more. Hence, it is important to understand how to create, prepare and load datasets to make ready for the machine to learn and understand. First, we have applied bilateral filter to preserve the edge information. Then, rotational gradient approach is proposed to detect the text in variable viewpoints. Later, the combination of morphology and contours has applied to generate blobs with bounding box around the detected regions by eradicating quasi text areas. The simulation results have shown better performance than traditional techniques with better detection rate on ICDAR Robust Reading Competition on Text in Video 2013-15 datasets.;;;https://dl.acm.org/doi/10.1145/3460620.3460621;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Data Mining to Characterize Seasonal Patterns of Apis mellifera Honey Bee Colonies;;;['Felipe Anderson O. Maciel', 'Antonio Rafael Braga', 'Rhaniel M. Xavier', 'Ticiana L. Coelho da Silva', 'Breno M. Freitas', 'Danielo G. Gomes'];;;June 2018;;;SBSI '18: Proceedings of the XIV Brazilian Symposium on Information Systems;;;Among the agricultural crops used for human consumption, 75% depends on pollination. As the principal pollinating agent, bees are essential for the food production for humans and the ecosystems sustainability. However, a combination of habitat destruction, climate change and exposure to pesticides and pathogens has led to a significant decrease in bee population. Here we propose a method to recognize status patterns of Apis mellifera colonies through the application of data mining techniques. Using a real dataset from the HiveTool.net containing Apis mellifera temperature, humidity and weight data, we identified 3 status patterns in the observed hive. Our results suggest that the recognized patterns are consistent with a honey bee colony life cycle. Based on the found patterns, we propose a high accuracy classification model capable of automatically identifying colony status for new samples.;;;https://dl.acm.org/doi/10.1145/3229345.3229386;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Discovering software vulnerabilities using data-flow analysis and machine learning;;;['Jorrit Kronjee', 'Arjen Hommersom', 'Harald Vranken'];;;August 2018;;;ARES '18: Proceedings of the 13th International Conference on Availability, Reliability and Security;;;We present a novel method for static analysis in which we combine data-flow analysis with machine learning to detect SQL injection (SQLi) and Cross-Site Scripting (XSS) vulnerabilities in PHP applications. We assembled a dataset from the National Vulnerability Database and the SAMATE project, containing vulnerable PHP code samples and their patched versions in which the vulnerability is solved. We extracted features from the code samples by applying data-flow analysis techniques, including reaching definitions analysis, taint analysis, and reaching constants analysis. We used these features in machine learning to train various probabilistic classifiers. To demonstrate the effectiveness of our approach, we built a tool called WIRECAML, and compared our tool to other tools for vulnerability detection in PHP code. Our tool performed best for detecting both SQLi and XSS vulnerabilities. We also tried our approach on a number of open-source software applications, and found a previously unknown vulnerability in a photo-sharing web application.;;;https://dl.acm.org/doi/10.1145/3230833.3230856;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Analysis of Various Diabetic Prediction Methods of Machine Learning;;;['Ankur Goyal', 'Kailash Kumar'];;;August 2021;;;DSMLAI '21': Proceedings of the International Conference on Data Science, Machine Learning and Artificial Intelligence;;;The method that can derive valuable information from rough data is data mining. Prediction analysis is a data mining technique that predicts future possibilities from current knowledge. A range of statistical techniques (including machine learning, predictive modelling and data mining) are included in predictive analytics and statistics (both historical and current) to estimate, predict, and predict future results. There are different steps in the prediction analysis that include pre-processing, extraction of features and classification. This paper is focused on the use of machine learning techniques for diabetic prediction. In this paper, different techniques for diabetic prediction are reviewed based on machine learning.;;;https://dl.acm.org/doi/10.1145/3484824.3484898;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
HGAT: Heterogeneous Graph Attention Networks for Semi-supervised Short Text Classification;;;['Tianchi Yang', 'Linmei Hu', 'Chuan Shi', 'Houye Ji', 'Xiaoli Li', 'Liqiang Nie'];;;None;;;ACM Transactions on Information Systems;;;Short text classification has been widely explored in news tagging to provide more efficient search strategies and more effective search results for information retrieval. However, most existing studies, concentrating on long text classification, deliver unsatisfactory performance on short texts due to the sparsity issue and the insufficiency of labeled data. In this article, we propose a novel heterogeneous graph neural network-based method for semi-supervised short text classification, leveraging full advantage of limited labeled data and large unlabeled data through information propagation along the graph. Specifically, we first present a flexible heterogeneous information network (HIN) framework for modeling short texts, which can integrate any type of additional information and meanwhile capture their relations to address the semantic sparsity. Then, we propose Heterogeneous Graph Attention networks (HGAT) to embed the HIN for short text classification based on a dual-level attention mechanism, including node-level and type-level attentions. To efficiently classify new coming texts that do not previously exist in the HIN, we extend our model HGAT for inductive learning, avoiding re-training the model on the evolving HIN. Extensive experiments on single-/multi-label classification demonstrates that our proposed model HGAT significantly outperforms state-of-the-art methods across the benchmark datasets under both transductive and inductive learning.;;;https://dl.acm.org/doi/10.1145/3450352;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Multiple imputation and genetic programming for classification with incomplete data;;;['Cao Truong Tran', 'Mengjie Zhang', 'Peter Andreae', 'Bing Xue'];;;July 2017;;;GECCO '17: Proceedings of the Genetic and Evolutionary Computation Conference;;;Many industrial and research datasets suffer from an unavoidable issue of missing values. One of the most common approaches to solving classification with incomplete data is to use an imputation method to fill missing values with plausible values before applying classification algorithms. Multiple imputation is a powerful approach to estimating missing values, but it is very expensive to use multiple imputation to estimate missing values for a single instance that needs to be classified. Genetic programming (GP) has been widely used to construct classifiers for complete data, but it seldom has been used for incomplete data. This paper proposes an approach to combining multiple imputation and GP to evolve classifiers for incomplete data. The proposed method uses multiple imputation to provide a high quality training data. It also searches for common patterns of missing values, and uses GP to build a classifier for each pattern of missing values. Therefore, the proposed method generates a set of classifiers that can be used to directly classify any new incomplete instance without requiring imputation. Experimental results show that the proposed method not only can be faster than other common methods for classification with incomplete data but also can achieve better classification accuracy.;;;https://dl.acm.org/doi/10.1145/3071178.3071181;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Employing Auto-Annotated Data for Government Document Classification;;;['Yajun Song', 'Zeyuan Li', 'Jie He', 'Zesong Li', 'Xin Fang', 'Dagang Chen'];;;March 2019;;;ICIAI '19: Proceedings of the 2019 3rd International Conference on Innovation in Artificial Intelligence;;;In China, the government documents are documents with legal effect and of standard forms formulated in the process of government administration. With the continuous development of e-government in China, government database size increases hugely. To fully utilize the potential of the database, many applications based on natural language processing (NLP) are developed. Classification is a fundamental task for many NLP applications such as automatic document archive, intelligent search, and personalized recommendation. Presently, in China, the government document classification method which based on issuing departments has very low accuracy. Traditional text classifiers based on machine learning or deep learning models rely heavily on human-labeled training data. While there are no open data sets on the government documents, we propose a method to automatically constructing large-scale annotated data set for government document classification based on the information retrieval method. Experiment results show that the supervised classification model trained on our automatically constructed data set outperforms the baseline method 15% on F1-score.;;;https://dl.acm.org/doi/10.1145/3319921.3319970;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Supervised machine learning for service providers' classification using multiple criteria in a network architecture environment;;;['Imane Haddar', 'Brahim Raouyane', 'Mostafa Bellafkih'];;;October 2018;;;SITA'18: Proceedings of the 12th International Conference on Intelligent Systems: Theories and Applications;;;The service selection in a Next Generation Network field remains a challenging problem for service providers, as they have to satisfy customers and keep their earnings. Given the growing number of telecom service providers, the customer is in a dilemma to choose the right service with a fair price. To do so, we propose in this paper a supervised learning algorithm since it is a classification problem. Based on requirements specified in the contract called Service Level Agreement (SLA) in IP Multimedia Service (IMS) network, we ended up choosing the decision trees algorithm for several reasons that we will explore later in this work. This method will assist users in selecting the right service for a better management of contracts between the involved entities.;;;https://dl.acm.org/doi/10.1145/3289402.3289532;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Role of Discourse Information in Urdu Sentiment Classification: A Rule-based Method and Machine-learning Technique;;;['Dr. Muhammad Awais', 'Dr. Muhammad Shoaib'];;;None;;;ACM Transactions on Asian and Low-Resource Language Information Processing;;;In computational linguistics, sentiment analysis refers to the classification of opinions in a positive class or a negative class. There exist a lot of different methods for sentiment analysis of the English language, but the literature lacks the availability of methods and techniques for Urdu, which is the largely spoken language in the South Asian sub-continent and the national language of Pakistan. The currently available techniques, such as adjective count method known as Bag of Words (BoW), is not sufficient for classification of complex sentiment written in the Urdu language. Also, the performance of available machine-learning techniques (with legacy features), for classification of Urdu sentiments, are not comparable with the achieved accuracy of other languages. In the case of the English language, the discourse information (sub-sentence-level information) boosts the performance of both the BoW method and machine-learning techniques, but there are very few works available that have tested the context-level information for the sentiment analysis of the Urdu language. This research aims to extract the discourse information from the Urdu sentiments and utilise the discourse information to improve the performance and reduce the error rate of existing techniques for Urdu Sentiment classification. The proposed solution extracts the discourse information, suggests a new set of features for machine-learning techniques, and introduces a set of rules to extend the capabilities of the BoW model. The results show that the task has been enhanced significantly and the performance metrics such as recall, precision, and accuracy are increased by 31.25%, 8.46%, and 21.6%, respectively. In future, the proposed technique can be extended to sentiments with more than two sub-opinions, such as for blogs, reviews, and TV talk shows.;;;https://dl.acm.org/doi/10.1145/3300050;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Employing Auto-Annotated Data for Government Document Classification;;;['Yajun Song', 'Zeyuan Li', 'Jie He', 'Zesong Li', 'Xin Fang', 'Dagang Chen'];;;March 2019;;;ICIAI '19: Proceedings of the 2019 3rd International Conference on Innovation in Artificial Intelligence;;;In China, the government documents are documents with legal effect and of standard forms formulated in the process of government administration. With the continuous development of e-government in China, government database size increases hugely. To fully utilize the potential of the database, many applications based on natural language processing (NLP) are developed. Classification is a fundamental task for many NLP applications such as automatic document archive, intelligent search, and personalized recommendation. Presently, in China, the government document classification method which based on issuing departments has very low accuracy. Traditional text classifiers based on machine learning or deep learning models rely heavily on human-labeled training data. While there are no open data sets on the government documents, we propose a method to automatically constructing large-scale annotated data set for government document classification based on the information retrieval method. Experiment results show that the supervised classification model trained on our automatically constructed data set outperforms the baseline method 15% on F1-score.;;;https://dl.acm.org/doi/10.1145/3319921.3319970;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Linear support vector machine to classify the vibrational modes for complex chemical systems;;;['Triet Huynh Minh Le', 'Tung Thanh Tran', 'Lam Kim Huynh'];;;February 2018;;;ICMLSC '18: Proceedings of the 2nd International Conference on Machine Learning and Soft Computing;;;Classification of vibrational modes into hindered internal rotation (HIR) and harmonic oscillation modes is important to obtain correct thermodynamic data for a chemical species for a wide range of temperatures. In this study, we propose a multivariate linear support vector machine (SVM) model to solve this challenging binary classification problem. The results of the proposed model were found to be similar to those of logistic regression and 2-5% better than those of the rule-based method. Moreover, the number of features found by linear SVM was also fewer than that of logistic regression (five versus six), which makes it easier to be interpreted by chemists. The detailed explanation of such differences is also presented. The three models were implemented in the GUI of the Multi-Species Multi-Channel Software Suite (Duong et al., Int. J. Chem. Kinet, 2015, 564) to facilitate the determination of HIR modes as well as the calculation of thermodynamic properties for a chemical species of interest.;;;https://dl.acm.org/doi/10.1145/3184066.3184087;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Discovering knowledge from student interactions: clustering vs classification;;;['Sheila Lucero Sánchez López', 'Rebeca P. Díaz Redondo', 'Ana Fernández Vilas'];;;October 2017;;;TEEM 2017: Proceedings of the 5th International Conference on Technological Ecosystems for Enhancing Multiculturality;;;Currently, we live in a technological environment that gives us the possibility to carry out many actions with our own style, times and preferences. We are free to interact with technology and the education is no exception, the use of educational platforms has increased considerably in recent years. The main objective of this work is to know how students interact. We analyse the interaction of university students in a blended course comparing two methods: clustering and classification.;;;https://dl.acm.org/doi/10.1145/3144826.3145390;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Mining assumptions for software components using machine learning;;;['Khouloud Gaaloul', 'Claudio Menghi', 'Shiva Nejati', 'Lionel C. Briand', 'David Wolfe'];;;November 2020;;;ESEC/FSE 2020: Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering;;;Software verification approaches aim to check a software component under analysis for all possible environments. In reality, however, components are expected to operate within a larger system and are required to satisfy their requirements only when their inputs are constrained by environment assumptions. In this paper, we propose EPIcuRus, an approach to automatically synthesize environment assumptions for a component under analysis (i.e., conditions on the component inputs under which the component is guaranteed to satisfy its requirements). EPIcuRus combines search-based testing, machine learning and model checking. The core of EPIcuRus is a decision tree algorithm that infers environment assumptions from a set of test results including test cases and their verdicts. The test cases are generated using search-based testing, and the assumptions inferred by decision trees are validated through model checking. In order to improve the efficiency and effectiveness of the assumption generation process, we propose a novel test case generation technique, namely Important Features Boundary Test (IFBT), that guides the test generation based on the feedback produced by machine learning. We evaluated EPIcuRus by assessing its effectiveness in computing assumptions on a set of study subjects that include 18 requirements of four industrial models. We show that, for each of the 18 requirements, EPIcuRus was able to compute an assumption to ensure the satisfaction of that requirement, and further, ≈78% of these assumptions were computed in one hour.;;;https://dl.acm.org/doi/10.1145/3368089.3409737;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Early-Stage Diabetes Prediction using Data Mining Algorithms;;;['Md Moniruzzaman', 'A. G. M. Zaman', 'Rifah Tasnia', 'Sutopa Biswas', 'Mehnur Khanam'];;;March 2022;;;ICCA '22: Proceedings of the 2nd International Conference on Computing Advancements;;;Diabetes is a very common disease nowadays. If not treated early diabetes can pose a profoundly serious health threat. Much research has been conducted to find out the optimal solution for diabetes detection by applying different data mining algorithms, where the dataset consists of different medicinal attributes. In this study, our aim is to examine whether diabetes can be detected at early-stage by applying different data mining algorithms to the non-medicinal dataset; as well as to investigate whether data normalization techniques can improve the classifiers accuracy. Naive Bayes, K-Nearest Neighbor (KNN), Support Vector Machines (SVM), Decision Tree, Random Forest, and Gradient Boosting Classifier (GBC) algorithms are applied to the Early Stage Diabetes Risk Prediction Dataset in conjunction with Decimal Point Scaling, Z-Score Normalization, Pareto Scaling, Variable Stability Scaling, Min-Max normalization, Max normalization, Maximum Absolute Scaling, Mean Centered Scaling, Soft-max normalization, Power Transformer, Median and Median Absolute Deviation Normalization, Robust Scaling and Log Scaling normalization methods. In this experiment, we discovered that early-stage diabetes detection is possible without any medical diagnosis data. The result shows that GBC performs better compared to other classification algorithms in combination with data normalization and achieved an impressive 99.038% prediction accuracy.;;;https://dl.acm.org/doi/10.1145/3542954.3542990;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Supervised machine learning for service providers' classification using multiple criteria in a network architecture environment;;;['Imane Haddar', 'Brahim Raouyane', 'Mostafa Bellafkih'];;;October 2018;;;SITA'18: Proceedings of the 12th International Conference on Intelligent Systems: Theories and Applications;;;The service selection in a Next Generation Network field remains a challenging problem for service providers, as they have to satisfy customers and keep their earnings. Given the growing number of telecom service providers, the customer is in a dilemma to choose the right service with a fair price. To do so, we propose in this paper a supervised learning algorithm since it is a classification problem. Based on requirements specified in the contract called Service Level Agreement (SLA) in IP Multimedia Service (IMS) network, we ended up choosing the decision trees algorithm for several reasons that we will explore later in this work. This method will assist users in selecting the right service for a better management of contracts between the involved entities.;;;https://dl.acm.org/doi/10.1145/3289402.3289532;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Mining cross product line rules with multi-objective search and machine learning;;;['Safdar Aqeel Safdar', 'Hong Lu', 'Tao Yue', 'Shaukat Ali'];;;July 2017;;;GECCO '17: Proceedings of the Genetic and Evolutionary Computation Conference;;;Nowadays, an increasing number of systems are being developed by integrating products (belonging to different product lines) that communicate with each other through information networks. Cost-effectively supporting Product Line Engineering (PLE) and in particular enabling automation of configuration in PLE is a challenge. Capturing rules is the key for enabling automation of configuration. Product configuration has a direct impact on runtime interactions of communicating products. Such products might be within or across product lines and there usually don't exist explicitly specified rules constraining configurable parameter values of such products. Manually specifying such rules is tedious, time-consuming, and requires expert's knowledge of the domain and the product lines. To address this challenge, we propose an approach named as SBRM that combines multi-objective search with machine learning to mine rules. To evaluate the proposed approach, we performed a real case study of two communicating Video Conferencing Systems belonging to two different product lines. Results show that SBRM performed significantly better than Random Search in terms of fitness values, Hyper-Volume, and machine learning quality measurements. When comparing with rules mined with real data, SBRM performed significantly better in terms of Failed Precision (18%), Failed Recall (72%), and Failed F-measure (59%).;;;https://dl.acm.org/doi/10.1145/3071178.3071261;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Design and Implementation of Tax Collection and Management Index Early Warning System Based on Data Mining;;;['Jie Mao'];;;December 2021;;;ICASIT 2021: 2021 International Conference on Aviation Safety and Information Technology;;;With the continuous improvement of tax information level of tax authorities, tax authorities have formed a large number of tax business management data in their daily business. However, at present, only a simple historical query is provided for these historical data, which is far from the expected advanced applications such as analysis and prediction and decision support. This paper designs and implements a set of early warning system of tax collection and management indicators by using database technology, constructs indicators according to taxpayers' declaration data, and uses data warehouse technology, attribute-oriented summary method and association rule algorithm for data mining to provide data support for tax early warning. Setting up the corresponding early warning value system can reduce the risk of tax evasion, improve the quality of tax monitoring, and then improve the efficiency of law enforcement and management level.;;;https://dl.acm.org/doi/10.1145/3510858.3511348;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
MeLL: Large-scale Extensible User Intent Classification for Dialogue Systems with Meta Lifelong Learning;;;['Chengyu Wang', 'Haojie Pan', 'Yuan Liu', 'Kehan Chen', 'Minghui Qiu', 'Wei Zhou', 'Jun Huang', 'Haiqing Chen', 'Wei Lin', 'Deng Cai'];;;August 2021;;;KDD '21: Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining;;;User intent detection is vital for understanding their demands in dialogue systems. Although the User Intent Classification (UIC) task has been widely studied, for large-scale industrial applications, the task is still challenging. This is because user inputs in distinct domains may have different text distributions and target intent sets. When the underlying application evolves, new UIC tasks continuously emerge in a large quantity. Hence, it is crucial to develop a framework for large-scale extensible UIC that continuously fits new tasks and avoids catastrophic forgetting with an acceptable parameter growth rate. In this paper, we introduce the Meta Lifelong Learning (MeLL) framework to address this task. In MeLL, a BERT-based text encoder is employed to learn robust text representations across tasks, which is slowly updated for lifelong learning. We design global and local memory networks to capture the cross-task prototype representations of different classes, treated as the meta-learner quickly adapted to different tasks. Additionally, the Least Recently Used replacement policy is applied to manage the global memory such that the model size does not explode through time. Finally, each UIC task has its own task-specific output layer, with the attentive summarization of various features. We have conducted extensive experiments on both open-source and real industry datasets. Results show that MeLL improves the performance compared with strong baselines and also reduces the number of total parameters. We have also deployed MeLL on a real-world e-commerce dialogue system AliMe and observed significant improvements in terms of both F1 and the resources usage.;;;https://dl.acm.org/doi/10.1145/3447548.3467107;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Quantum Fair Machine Learning;;;['Elija Perrier'];;;July 2021;;;AIES '21: Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society;;;In this paper, we inaugurate the field of quantum fair machine learning. We undertake a comparative analysis of differences and similarities between classical and quantum fair machine learning algorithms, specifying how the unique features of quantum computation alter measures, metrics and remediation strategies when quantum algorithms are subject to fairness constraints. We present the first results in quantum fair machine learning by demonstrating the use of Grover's search algorithm to satisfy statistical parity constraints imposed on quantum algorithms. We provide lower-bounds on iterations needed to achieve such statistical parity within ε-tolerance. We extend canonical Lipschitz-conditioned individual fairness criteria to the quantum setting using quantum metrics. We examine the consequences for typical measures of fairness in machine learning context when quantum information processing and quantum data are involved. Finally, we propose open questions and research programmes for this new field of interest to researchers in computer science, ethics and quantum computation.;;;https://dl.acm.org/doi/10.1145/3461702.3462611;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Wikipedia-Based Relatedness Measurements for Multilingual Short Text Clustering;;;['Tatsuya Nakamura', 'Masumi Shirakawa', 'Takahiro Hara', 'Shojiro Nishio'];;;None;;;ACM Transactions on Asian and Low-Resource Language Information Processing;;;Throughout the world, people can post information about their local area in their own languages using social networking services. Multilingual short text clustering is an important task to organize such information, and it can be applied to various applications, such as event detection and summarization. However, measuring the relatedness between short texts written in various languages is a challenging problem. In addition to handling multiple languages, the semantic gaps among all languages must be considered. In this article, we propose two Wikipedia-based semantic relatedness measurement methods for multilingual short text clustering. The proposed methods solve the semantic gap problem by incorporating the inter-language links of Wikipedia into Extended Naive Bayes (ENB), a probabilistic method that can be applied to measure semantic relatedness among monolingual short texts. The proposed methods represent a multilingual short text as a vector of the English version of Wikipedia articles (entities). By transferring texts to a unified vector space, the relatedness between texts in different languages with similar meanings can be increased. We also propose an approach that can improve clustering performance and reduce the processing time by eliminating language-specific entities in the unified vector space. Experimental results on multilingual Twitter message clustering revealed that the proposed methods outperformed cross-lingual explicit semantic analysis, a previously proposed method to measure relatedness between texts in different languages. Moreover, the proposed methods were comparable to ENB applied to texts translated into English using a proprietary translation service. The proposed methods enabled relatedness measurements for multilingual short text clustering without requiring machine translation processes.;;;https://dl.acm.org/doi/10.1145/3276473;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Context-aware Outstanding Fact Mining from Knowledge Graphs;;;['Yueji Yang', 'Yuchen Li', 'Panagiotis Karras', 'Anthony K. H. Tung'];;;August 2021;;;KDD '21: Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining;;;An Outstanding Fact (OF) is an attribute that makes a target entity stand out from its peers. The mining of OFs has important applications, especially in Computational Journalism, such as news promotion, fact-checking, and news story finding. However, existing approaches to OF mining: (i) disregard the context in which the target entity appears, hence may report facts irrelevant to that context; and (ii) require relational data, which are often unavailable or incomplete in many application domains. In this paper, we introduce the novel problem of mining Context-aware Outstanding Facts (COFs) for a target entity under a given context specified by a context entity. We propose FMiner, a context-aware mining framework that leverages knowledge graphs (KGs) for COF mining. FMiner generates COFs in two steps. First, it discovers top-k relevant relationships between the target and the context entity from a KG. We propose novel optimizations and pruning techniques to expedite this operation, as this process is very expensive on large KGs due to its exponential complexity. Second, for each derived relationship, we find the attributes of the target entity that distinguish it from peer entities that have the same relationship with the context entity, yielding the top-l COFs. As such, the mining process is modeled as a top-(k,l) search problem. Context-awareness is ensured by relying on the relevant relationships with the context entity to derive peer entities for COF extraction. Consequently, FMiner can effectively navigate the search to obtain context-aware OFs by incorporating a context entity. We conduct extensive experiments, including a user study, to validate the efficiency and the effectiveness of FMiner.;;;https://dl.acm.org/doi/10.1145/3447548.3467272;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Classification of APIs by hierarchical clustering;;;['Johannes Härtel', 'Hakan Aksu', 'Ralf Lämmel'];;;May 2018;;;ICPC '18: Proceedings of the 26th Conference on Program Comprehension;;;APIs can be classified according to the programming domains (e.g., GUIs, databases, collections, or security) that they address. Such classification is vital in searching repositories (e.g., the Maven Central Repository for Java) and for understanding the technology stack used in software projects. We apply hierarchical clustering to a curated suite of Java APIs to compare the computed API clusters with preexisting API classifications. Clustering entails various parameters (e.g., the choice of IDF versus LSI versus LDA). We describe the corresponding variability in terms of a feature model. We exercise all possible configurations to determine the maximum correlation with respect to two baselines: i) a smaller suite of APIs manually classified in previous research; ii) a larger suite of APIs from the Maven Central Repository, thereby taking advantage of crowd-sourced classification while relying on a threshold-based approach for identifying important APIs and versions thereof, subject to an API dependency analysis on GitHub. We discuss the configurations found in this way and we examine the influence of particular features on the correlation between computed clusters and baselines. To this end, we also leverage interactive exploration of the parameter space and the resulting dendrograms. In this manner, we can also identify issues with the use of classifiers (e.g., missing classifiers) in the baselines and limitations of the clustering approach.;;;https://dl.acm.org/doi/10.1145/3196321.3196344;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Modeling and Mining Domain Shared Knowledge for Sentiment Analysis;;;['Guang-You Zhou', 'Jimmy Xiangji Huang'];;;None;;;ACM Transactions on Information Systems;;;Sentiment classification aims to automatically predict sentiment polarity (e.g., positive or negative) of user generated sentiment data (e.g., reviews, blogs). In real applications, these user-generated sentiment data can span so many different domains that it is difficult to label the training data for all of them. Therefore, we study the problem of sentiment classification adaptation task in this article. That is, a system is trained to label reviews from one source domain but is meant to be used on the target domain. One of the biggest challenges for sentiment classification adaptation task is how to deal with the problem when two data distributions between the source domain and target domain are significantly different from one another. However, our observation is that there might exist some domain shared knowledge among certain input dimensions of different domains. In this article, we present a novel method for modeling and mining the domain shared knowledge from different sentiment review domains via a joint non-negative matrix factorization–based framework. In this proposed framework, we attempt to learn the domain shared knowledge and the domain-specific information from different sentiment review domains with several various regularization constraints. The advantage of the proposed method can promote the correspondence under the topic space between the source domain and the target domain, which can significantly reduce the data distribution gap across two domains. We conduct extensive experiments on two real-world balanced data sets from Amazon product reviews for sentence-level and document-level binary sentiment classification. Experimental results show that our proposed approach significantly outperforms several strong baselines and achieves an accuracy that is competitive with the most well-known methods for sentiment classification adaptation.;;;https://dl.acm.org/doi/10.1145/3091995;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Mining Patterns of Drug-Disease Association from Biomedical Texts;;;['Wen-Juan Hou', 'Bo-Syun Lee', 'Hung-Chi Chen'];;;January 2018;;;ICBBB '18: Proceedings of the 2018 8th International Conference on Bioscience, Biochemistry and Bioinformatics;;;Drug repurposing aims to identify new indications for approved drugs, and it can promisingly reduce time and drug development costs. The goal of the paper, drug-disease relation extraction automatically from biomedical texts, is fundamental to the study of drug repurposing since lots of clinical case studies published in an unstructured textual form. To analyze the number of verbs and nouns pertinent to diseases and medications in the training data, two models with different drug-disease orders are established, and some rules are proposed at this phase. The first model is for the sentences with the order that the disease name precedes the drug name. The second model is for the reverse order to the first model. These verbs and nouns are then classified into categories of "pure association," "pure no association" and "neutrals." Among them, some neutrals are further verified by the Chi-square test method. As a result, the associations between diseases and medications are identified, which are called patterns later. Finally, the patterns are used in the test data to extract the disease and drug pairs. The best experimental results show the precision value of 100%, recall value of 89.0%, and F-score value of 94.2%.;;;https://dl.acm.org/doi/10.1145/3180382.3180401;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Mining Features Associated with Effective Tweets;;;['Jian Xu', 'Nitesh V. Chawla'];;;July 2017;;;ASONAM '17: Proceedings of the 2017 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining 2017;;;What tweet features are associated with higher effectiveness in tweets? Through the mining of 122 million engagements of 2.5 million original tweets, we present a systematic review of tweet time, entities, composition, and user account features. We show that the relationship between various features and tweeting effectiveness is non-linear; for example, tweets that use a few hashtags have higher effectiveness than using no or too many hashtags. This research closely relates to various industrial applications that are based on tweet features, including the analysis of advertising campaigns, the prediction of user engagement, the extraction of signals for automated trading, etc.;;;https://dl.acm.org/doi/10.1145/3110025.3110126;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Performance Evaluation of Extreme Learning Machines Classification Algorithm for Medical Datasets;;;['Oyekale Abel Alade', 'Roselina Sallehuddin', 'Nor Haizan Mohamed Radzi'];;;August 2021;;;BECB 2021: 2021 International Symposium on Biomedical Engineering and Computational Biology;;;The choice of efficient algorithms is a critical issue in the classification of medical datasets. This requires the consideration of a number of measures to ensure reliable results. In this study, the robustness of Extreme Learning Machine (ELM) and some state-of-arts classifiers were investigated on six (6) different (complete and incomplete) medical datasets. Multiple imputation technique with 5-fold-iteration was used to address the issue of missing data points in datasets with holes. The technique regenerated the missing values 100% in all the datasets. The performance of ELM was compared with Support Vector Machine (SVM), k-Nearest Neighbour (KNN) and Classification and Regression Tree (CART) on the complete and imputed datasets. The evaluations were based on classification accuracy, computational time and stability of the algorithms. ELM has 83.33% overall best accuracy, and 100% best computational time of the simulations. However, the stability of ELM is subject to further improvement, which is an area of further research.;;;https://dl.acm.org/doi/10.1145/3502060.3502156;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Imputation Techniques and Recursive Feature Elimination in Machine Learning Applied to Type II Diabetes Classification;;;['Vincent Peter Catimbang Magboo', 'Ma. Sheila Abad Magboo'];;;December 2021;;;AICCC '21: Proceedings of the 2021 4th Artificial Intelligence and Cloud Computing Conference;;;Type II diabetes is a chronic metabolic disease secondary to elevated blood glucose levels. Complications of this disease include heart attack, stroke, blindness, renal failure, lower limb amputation and mortality. Due to its rising prevalence and consequent mortality, it is important to identify at an early stage those patients at high risk of developing diabetes. We applied 8 machine learning techniques namely: support vector machine, logistic regression, k-nearest neighbor, naïve Bayes, decision tree, random forest, AdaBoost and XGBoost in predicting diabetes using a publicly available diabetes dataset. In our study, Naïve Bayes with median imputation and recursive feature elimination obtained the highest performance with an accuracy rate of 81.0%. Although the results are very promising, one major limitation in this study is the small number of samples in the dataset. Early accurate detection can help patients to proactively monitor their lifestyle habits mitigating the risks of complications of uncontrolled diabetes.;;;https://dl.acm.org/doi/10.1145/3508259.3508288;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Web Mining in e-Procurement: A Case Study in Indonesia;;;['Julius Dimas Trisaktyo Nugroho', 'Rahmad Mahendra', 'Indra Budi'];;;January 2021;;;APIT '21: Proceedings of the 2021 3rd Asia Pacific Information Technology Conference;;;E-procurement is an electronic procurement system that became a key factor required to manage financial aspect of a country with appropriate controls and protected by legal policies. The Presidential Regulation in Indonesia expect all government institutions to run the e-procurement process following the procurement principles, namely effective, efficient, transparent, open, competitive, fair and accountable. However in the implementation of e-tendering, which is part of e-procurement, found there are practices that not in accordance with the procurement principles. In this study, an in-depth analysis conducted to evaluate the tender activities of the ministry in Indonesia. We apply data mining process towards the national procurement portal to analyze tender data and find the hidden pattern that would be useful to support the decision-making process. This study combines several techniques, e.g. web mining and statistical analysis approach. Our finding includes correlation patterns among a number of values existing in e-procurement portal.;;;https://dl.acm.org/doi/10.1145/3449365.3449382;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Automated Intention Mining with Comparatively Fine-tuning BERT;;;['Xuan Sun', 'Luqun Li', 'Francesco Mercaldo', 'Yichen Yang', 'Antonella Santone', 'Fabio Martinelli'];;;December 2021;;;NLPIR '21: Proceedings of the 2021 5th International Conference on Natural Language Processing and Information Retrieval;;;In the field of software engineering, intention mining is an interesting but challenging task, where the goal is to have a good understanding of user generated texts so as to capture their requirements that are useful for software maintenance and evolution. Recently, BERT and its variants have achieved state-of-the-art performance among various natural language processing tasks such as machine translation, machine reading comprehension and natural language inference. However, few studies try to investigate the efficacy of pre-trained language models in the task. In this paper, we present a new baseline with fine-tuned BERT model. Our method achieves state-of-the-art results on three benchmark data sets, outscoring baselines by a substantial margin. We also further investigate the efficacy of the pre-trained BERT model with shallower network depths through a simple strategy for layer selection.;;;https://dl.acm.org/doi/10.1145/3508230.3508254;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Cross-Modality Transfer Learning for Image-Text Information Management;;;['Shuteng Niu', 'Yushan Jiang', 'Bowen Chen', 'Jian Wang', 'Yongxin Liu', 'Houbing Song'];;;None;;;ACM Transactions on Management Information Systems;;;In the past decades, information from all kinds of data has been on a rapid increase. With state-of-the-art performance, machine learning algorithms have been beneficial for information management. However, insufficient supervised training data is still an adversity in many real-world applications. Therefore, transfer learning (TF) was proposed to address this issue. This article studies a not well investigated but important TL problem termed cross-modality transfer learning (CMTL). This topic is closely related to distant domain transfer learning (DDTL) and negative transfer. In general, conventional TL disciplines assume that the source domain and the target domain are in the same modality. DDTL aims to make efficient transfers even when the domains or the tasks are entirely different. As an extension of DDTL, CMTL aims to make efficient transfers between two different data modalities, such as from image to text. As the main focus of this study, we aim to improve the performance of image classification by transferring knowledge from text data. Previously, a few CMTL algorithms were proposed to deal with image classification problems. However, most existing algorithms are very task specific, and they are unstable on convergence. There are four main contributions in this study. First, we propose a novel heterogeneous CMTL algorithm, which requires only a tiny set of unlabeled target data and labeled source data with associate text tags. Second, we introduce a latent semantic information extraction method to connect the information learned from the image data and the text data. Third, the proposed method can effectively handle the information transfer across different modalities (text-image). Fourth, we examined our algorithm on a public dataset, Office-31. It has achieved up to 5% higher classification accuracy than “non-transfer” algorithms and up to 9% higher than existing CMTL algorithms.;;;https://dl.acm.org/doi/10.1145/3464324;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Efficient Big Data Clustering;;;['Michele Ianni', 'Elio Masciari', 'Giuseppe M. Mazzeo', 'Carlo Zaniolo'];;;June 2018;;;IDEAS '18: Proceedings of the 22nd International Database Engineering &amp; Applications Symposium;;;The need to support advanced analytics on Big Data is driving data scientist' interest toward massively parallel distributed systems and software platforms, such as Map-Reduce and Spark, that make possible their scalable utilization. However, when complex data mining algorithms are required, their fully scalable deployment on such platforms faces a number of technical challenges that grow with the complexity of the algorithms involved. Thus algorithms, that were originally designed for a sequential nature, must often be redesigned in order to effectively use the distributed computational resources. In this paper, we explore these problems, and then propose a solution which has proven to be very effective on the complex hierarchical clustering algorithm CLUBS+. By using four stages of successive refinements, CLUBS+ delivers high-quality clusters of data grouped around their centroids, working in a totally unsupervised fashion. Experimental results confirm the accuracy and scalability of CLUBS+.;;;https://dl.acm.org/doi/10.1145/3216122.3216154;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Multi-Feature Sparse Representation Classification Method Based on Clustering;;;['Zeli Wang', 'Weizhen Sun', 'Jielong Guo', 'Xiaoliang Tang', 'Chao Li', 'Xian Wei'];;;July 2019;;;AICS 2019: Proceedings of the 2019 International Conference on Artificial Intelligence and Computer Science;;;In complex environments, the point cloud data obtained by LiDAR Often have shadows and occlusion, which greatly reduces the accuracy and the robustness of target classification. To solve this problem, this paper proposes a robust LiDAR point cloud recognition method, called Multi-Feature Sparse Representation Classification based on Clustering (MFSRCC). Firstly, all training data are used to generate a 3D-SIFT multi-feature dictionary. Secondly, the data are reconstructed on the basis of a complete dictionary. Finally, the sparse coefficients are clustered by K-means, and hence the classifier is constructed according to the principle of minimum cluster center value. The experimental results performed on Large-Scale Point Cloud Classification benchmark show that the proposed method can significantly improve the recognition rate of LiDAR point cloud objects, and it has strong robustness to interference information.;;;https://dl.acm.org/doi/10.1145/3349341.3349506;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Mining social web service repositories for social relationships to aid service discovery;;;['Alejandro Corbellini', 'Daniela Godoy', 'Cristian Mateos', 'Alejandro Zunino', 'Ignacio Lizarralde'];;;May 2017;;;MSR '17: Proceedings of the 14th International Conference on Mining Software Repositories;;;The Service Oriented Computing (SOC) paradigm promotes building new applications by discovering and then invoking services, i.e., software components accessible through the Internet. Discovering services means inspecting registries where textual descriptions of services functional capabilities are stored. To automate this, existing approaches index descriptions and associate users' queries to relevant services. However, the massive adoption of Web-exposed API development practices, specially in large service ecosystems such as the IoT, is leading to ever-growing registries which challenge the accuracy and speed of such approaches. The recent notion of Social Web Services (SWS), where registries not only store service information but also social-like relationships between users and services opens the door to new discovery schemes. We investigate an approach to discover SWSs that operates on graphs with user-service relationships and employs lightweight topological metrics to assess service similarity. Then, "socially" similar services, which are determined exploiting explicit relationships and mining implicit relationships in the graph, are clustered via exemplar-based clustering to ultimately aid discovery. Experiments performed with the ProgrammableWeb.com registry, which is at present the largest SWS repository with over 15k services and 140k user-service relationships, show that pure topology-based clustering may represent a promising complement to content-based approaches, which in fact are more time-consuming due to text processing operations.;;;https://dl.acm.org/doi/10.1109/MSR.2017.16;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Research on Higher Education Intelligent Decision System Based on Data Mining;;;['Shufeng Zhang', 'Lantao You'];;;September 2021;;;ICISCAE 2021: 2021 4th International Conference on Information Systems and Computer Aided Education;;;The paper elaborated on the application process of data mining in college management decision support system: establishment of data mining goals, selection of data sources, data preparation, processing and evaluation models, verification models, implementation and maintenance models, especially for the key data preparations were analysed in depth. According to the specific characteristics of college management data, the data cleaning method has been usefully explored and tried. Finally, combined with the data conversion service (DTS) in SQL Server 2010, the establishment of the SQL Server data warehouse is explained, and data mining is carried out on this basis. According to this, the design and implementation process of establishing a university management decision support system is introduced. Practice shows that the current system is well adapted to the pace of development of college management informationization, and improves college management decision-making ability and level.;;;https://dl.acm.org/doi/10.1145/3482632.3487530;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Evolution of Decision Tree Classifiers in Open Ended Educational Data Mining;;;['Tapani Toivonen', 'Ilkka Jormanainen'];;;October 2019;;;TEEM'19: Proceedings of the Seventh International Conference on Technological Ecosystems for Enhancing Multiculturality;;;Educational Data Mining (EDM) aims to produce new knowledge from educational settings to support educators, learners and other stakeholders. EDM aims to facilitate the understanding of the educational context by utilizing different methods of statistics and machine learning. Like wise to the current trends in data mining, also EDM approaches have shifted from black box tools and algorithms to more open-ended tools and algorithms where the EDM end-users can adjust multiple parameters, view visualizations, and even adjust the predictive models. Multiple studies have shown that the EDM end-users benefit from the white box approaches and tools. We introduce the concept of Augmented Intelligence (AUI) method in EDM. AUI method is applied in an iterative process where a white box machine learning algorithm generates a predictive model, which is adjustable by the EDM end-user. The adjustable predictive model affects to the perception of the end-user and the adjusting affects to the output of the predictive model. When applied in cycles, the AUI method generates new knowledge from the educational context. To study AUI method, a potential EDM end-user generated multiple adjustable decision tree models and we observed the evolution of the models. The study indicates that, over time, the models generalize better and the AUI method helps to avoid the issue of overfitting. Moreover, the study indicates that the cyclic nature of the AUI method facilitates deeper knowledge generation from the dataset, if the context is known by the end-user.;;;https://dl.acm.org/doi/10.1145/3362789.3362880;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Transfer learning for malware multi-classification;;;['Mohamad Al Kadri', 'Mohamed Nassar', 'Haidar Safa'];;;June 2019;;;IDEAS '19: Proceedings of the 23rd International Database Applications &amp; Engineering Symposium;;;In this paper, we build on top of the MalConv neural networks learning architecture which was initially designed for malware/benign classification. We evaluate the transfer learning of MalConv for malware multi-class classification by extending its contribution in several directions: (1) We assess MalConv performance on a multi-classification problem using a new dataset composed of solely malware samples belonging to different malware families, (2) we evaluate MalConv on the raw bytes data as well as on the opcodes extracted from the reversed assembly samples and compare the results, (3) we validate the MalConv findings about regularization, and (4) we study MalConv performance when using a medium size dataset and limited computational resources and GPU. The obtained results show that MalConv performs equally well for multi-classification and its performance on raw byte sequences is comparable to opcodes sequences. DeCov regularization is shown to improve the accuracy results better than other regularization techniques.;;;https://dl.acm.org/doi/10.1145/3331076.3331111;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Self-tuning techniques for large scale cluster analysis on textual data collections;;;['Evelina Di Corso', 'Tania Cerquitelli', 'Francesco Ventura'];;;April 2017;;;SAC '17: Proceedings of the Symposium on Applied Computing;;;This paper proposes PASTA (PArameter-free Solutions for Textual Analysis), a large scale engine providing strategies to automatically tune the algorithm parameters for the whole text clustering process. A data weighting strategy (e.g., TF-IDF) and a transformation method of input data (e.g., LSI) is explored before performing the cluster analysis to reduce sparseness, and make the overall analysis problem more effectively tractable. PASTA includes auto-selection strategies to off-load the end-user from parameter tuning and achieve a good quality of the clustering results. PASTA's current implementation runs on Apache Spark, a state-of-the-art distributed computing framework. As a case study, PASTA has been validated on three collections of Wikipedia documents. The experimental results show the effectiveness and the efficiency of the proposed solution in analyzing collections of documents without tuning algorithm parameters and in discovering cohesive and well-separated groups of documents.;;;https://dl.acm.org/doi/10.1145/3019612.3019661;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Exploring Active Learning for Student Behavior Classification;;;['Cristina E. Dumdumaya', 'Yance Vance M. Paredes', 'Ma. Mercedes T. Rodrigo'];;;March 2019;;;ICIET 2019: Proceedings of the 2019 7th International Conference on Information and Education Technology;;;Selection of high-quality ground truth data is a critical step for machine learning. Conventionally, a human-centered strategy is utilized to label the data. While this technique provides accurate annotations of task-specific behaviors, it is difficult, costly and error-prone. One method explored to solve these problems is active learning, a model-centered approach that minimizes human involvement. In this work, we conduct an experiment to compare the performance of active learning and passive learning strategies in selecting ground truth data for a classification task to detect the incidence of task persistent behavior from students' interaction logs. Our findings suggest that active learning tends to be more effective and efficient than passive learning in achieving a certain level of performance. However, the overall performance comparison shows that passive selection for ground truth data is as effective as the active learning approach for applications with relatively small sample size.;;;https://dl.acm.org/doi/10.1145/3323771.3323807;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Improve performance of extreme learning machine in classification of patchouli varieties with imbalanced class;;;['Candra Dewi', 'Wayan Firdaus Mahmudy', 'Rio Arifando', 'Yoke Kusuma Arbawa', 'Beryl Labique Ahmadie'];;;November 2020;;;SIET '20: Proceedings of the 5th International Conference on Sustainable Information Engineering and Technology;;;Patchouli has various varieties with almost the same physical characteristics. This often makes it difficult to recognize varieties with a high PA (Patchouli Alcohol) content. In this study an improvisation was introduced in the identification of patchouli varieties using leaf images using Extreme Learning Machine (ELM). However, problems occur in ELM if the data used is not balanced where the training process can not able to recognize data in the minority class well. Therefore, this study conducted a process to balance the composition of the data using the Synthetic Minority Over-sampling Technique (SMOTE) method. The test results of 93 data on the imbalanced composition with a comparison of 70% of training data and 30% of test data obtained an average accuracy of 93.57%. After implementing SMOTE in the Tetraploid, Patchoulina and Sidikalang classes where the amount of data in each class becomes 58 data, an average accuracy of 96.00% is achieved. This shows the existence of an increase in the process of identification with ELM when new data generation with SMOTE is carried out to balance the composition of the data.;;;https://dl.acm.org/doi/10.1145/3427423.3427424;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Mining Implicit Relevance Feedback from User Behavior for Web Question Answering;;;['Linjun Shou', 'Shining Bo', 'Feixiang Cheng', 'Ming Gong', 'Jian Pei', 'Daxin Jiang'];;;August 2020;;;KDD '20: Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining;;;Training and refreshing a web-scale Question Answering (QA) system for a multi-lingual commercial search engine often requires a huge amount of training examples. One principled idea is to mine implicit relevance feedback from user behavior recorded in search engine logs. All previous works on mining implicit relevance feedback target at relevance of web documents rather than passages. Due to several unique characteristics of QA tasks, the existing user behavior models for web documents cannot be applied to infer passage relevance. In this paper, we make the first study to explore the correlation between user behavior and passage relevance, and propose a novel approach for mining training data for Web QA. We conduct extensive experiments on four test datasets and the results show our approach significantly improves the accuracy of passage ranking without extra human labeled data. In practice, this work has proved effective to substantially reduce the human labeling cost for the QA service in a global commercial search engine, especially for languages with low resources. Our techniques have been deployed in multi-language services.;;;https://dl.acm.org/doi/10.1145/3394486.3403343;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Mining of DSLs and generator templates from reference applications;;;['Wolf Rost'];;;October 2020;;;MODELS '20: Proceedings of the 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems: Companion Proceedings;;;Domain-Specific Languages (DSLs) found application in different domains. The development of Model-Driven Development (MDD) components is facilitated by a wealth of frameworks like EMF, Xtext, and Xtend. However, the development of the necessary IDE components still can take up to several weeks or even months until it can be used in a production environment. The first step during the development of such an MDD infrastructure is to analyse a set of reference applications to deduce the DSL used by the domain experts and the templates used in the generator. The analysis requires technical expertise and is usually performed by MDD infrastructure developers, who have to adhere to a close communication with domain experts and are exposed to high cognitive load and time-consuming tasks. The objective of this PhD project is to reduce the initial effort during the creation of new MDD infrastructure facilities for either a new domain or newly discovered platforms within a known domain. This should be made possible by the (semi-)automatic analysis of multiple codebases using Code Clone Detection (CCD) tools in a defined process flow. Code clones represent schematically redundant and generic code fragments which were found in the provided codebase. In the process, the key steps include (i) choosing appropriate reference applications (ii) distinguishing the codebase by clustering the files, (iii) reviewing the quality of the clusters, (iv) analysing the cluster by tailored CCD, and (v) transforming of the code clones, depending on the code clone type, to extract a DSL and the corresponding generator templates.;;;https://dl.acm.org/doi/10.1145/3417990.3419492;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Discovering, selecting and exploiting feature sequence records of study participants for the classification of epidemiological data on hepatic steatosis;;;['Tommy Hielscher', 'Henry Völzke', 'Panagiotis Papapetrou', 'Myra Spiliopoulou'];;;April 2018;;;SAC '18: Proceedings of the 33rd Annual ACM Symposium on Applied Computing;;;In longitudinal epidemiological studies, participants undergo repeated medical examinations and are thus represented by a potentially large number of short examination outcome sequences. Some of those sequences may contain important information in various forms, such as patterns, with respect to the disease under study, while others may be on features of little relevance to the outcome. In this work, we propose a framework for Discovery, Selection and Exploitation (DiSelEx) of longitudinal epidemiological data, aiming to identify informative patterns among these sequences. DiSelEx combines sequence clustering with supervised learning to identify sequence groups that contribute to class separation. Newly derived and old features are evaluated and selected according to their redundancy and informativeness regarding the target variable. The selected feature set is then used to learn a classification model on the study data. We evaluate DiSelEx on cohort participants for the disorder "hepatic steatosis" and report on the impact on predictive performance when using sequential data in comparison to utilizing only the basic classifier.1;;;https://dl.acm.org/doi/10.1145/3167132.3167162;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Mining and Leveraging Background Knowledge for Improving Named Entity Linking;;;['Albert Weichselbraun', 'Philipp Kuntschik', 'Adrian M.P. Braşoveanu'];;;June 2018;;;WIMS '18: Proceedings of the 8th International Conference on Web Intelligence, Mining and Semantics;;;Knowledge-rich Information Extraction (IE) methods aspire towards combining classical IE with background knowledge obtained from third-party resources. Linked Open Data repositories that encode billions of machine readable facts from sources such as Wikipedia play a pivotal role in this development. The recent growth of Linked Data adoption for Information Extraction tasks has shed light on many data quality issues in these data sources that seriously challenge their usefulness such as completeness, timeliness and semantic correctness. Information Extraction methods are, therefore, faced with problems such as name variance and type confusability. If multiple linked data sources are used in parallel, additional concerns regarding link stability and entity mappings emerge. This paper develops methods for integrating Linked Data into Named Entity Linking methods and addresses challenges in regard to mining knowledge from Linked Data, mitigating data quality issues, and adapting algorithms to leverage this knowledge. Finally, we apply these methods to Recognyze, a graph-based Named Entity Linking (NEL) system, and provide a comprehensive evaluation which compares its performance to other well-known NEL systems, demonstrating the impact of the suggested methods on its own entity linking performance.;;;https://dl.acm.org/doi/10.1145/3227609.3227670;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Swarm Search Methods in Weka for Data Mining;;;['Simon Fong', 'Robert P. Biuk-Aghai', 'Richard C. Millham'];;;February 2018;;;ICMLC '18: Proceedings of the 2018 10th International Conference on Machine Learning and Computing;;;Building a good prediction from high-dimensional data model in data mining is a challenging endeavor. One key step in data pre-processing is feature selection (FS) which is about finding the right feature subset for effective supervised learning. FS has two parts: feature evaluators and search methods to find the appropriate features in the search space. In this paper we introduce a collection of search methods that implement metaheuristics search which is also known as swarm search (SS). SS has the advantage over conventional search such as local search, that SS has the facility to explore global optima by a group of autonomous search agents. We have recently added nine new methods to the Weka machine learning workbench. The objective of these nine swarm search methods is to supplement the existing search methods in Weka for providing efficient and effective FS in data mining. We have carried out two experiments using synthetic data and medical data. The results show that in general SS has certain advantages over the conventional search methods. The SS methods can be found in the Weka Package Manager as open source code. Researchers and Weka users are encouraged to enhance data mining performance using these free swarm search programs.;;;https://dl.acm.org/doi/10.1145/3195106.3195167;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Research on the Effect of Blended Learning Mode Based on Text Data Analysis;;;['Lin Tan', 'Yali Chen', 'Li Lai', 'Runhan Yang'];;;November 2019;;;WAIE 2019: Proceedings of the International Workshop on Artificial Intelligence and Education;;;Blended Learning mode is developing towards more and more scientific direction under the promotion of information technology. Aiming at freshmen's learning situation, this study designs a Blended Learning mode with four communication patterns and effective teaching cycle as the main ideas. It mainly uses data mining technology to analyze the communication records of online group, and it is concluded that the students in the pilot class in the Blended Learning mode have a better learning initiative. It also proved the feasibility of text data analysis method in teaching research. Through the comparison of homework grade and final examination results with the control classes, the advantages of Blended Learning mode are further demonstrated.;;;https://dl.acm.org/doi/10.1145/3397453.3397460;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
From data points to data curves: a new approach on big data curves clustering;;;['Konstantinos F. Xylogiannopoulos'];;;August 2018;;;ASONAM '18: Proceedings of the 2018 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining;;;In the new era of IoT, enormous real-values datasets are produced daily. Time series created by smart devices, financial data, weather analysis, medical applications, traffic control etc. become more and more important in human day life. Analyzing and clustering these time series or in general any kind of curve could be critical. In the current paper, a new methodology (BD2C) is presented, which applies text mining and pattern detection techniques in order to cluster curves according to their shape. Several experiments have been conducted on artificial and real datasets in order to present the accuracy, efficiency and rapid discovery of the best possible clustering that the proposed methodology can achieve.;;;https://dl.acm.org/doi/10.5555/3382225.3382412;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Machine Learning Techniques for Automated Software Fault Detection via Dynamic Execution Data: Empirical Evaluation Study;;;['Rafig Almaghairbe', 'Marc Roper', 'Tahani Almabruk'];;;September 2020;;;ICEMIS'20: Proceedings of the 6th International Conference on Engineering &amp; MIS 2020;;;The biggest obstacle of automated software testing is the construction of test oracles. Today, it is possible to generate enormous amount of test cases for an arbitrary system that reach a remarkably high level of coverage, but the effectiveness of test cases is limited by the availability of test oracles that can distinguish failing executions. Previous work by the authors has explored the use of unsupervised and semi-supervised learning techniques to develop test oracles so that the correctness of software outputs and behaviours on new test cases can be predicated [1], [2], [10], and experimental results demonstrate the promise of this approach. In this paper, we present an evaluation study for test oracles based on machine-learning approaches via dynamic execution data (firstly, input/output pairs and secondly, amalgamations of input/output pairs and execution traces) by comparing their effectiveness with existing techniques from the specification mining domain (the data invariant detector Daikon [5]). The two approaches are evaluated on a range of mid-sized systems and compared in terms of their fault detection ability and false positive rate. The empirical study also discuss the major limitations and the most important properties related to the application of machine learning techniques as test oracles in practice. The study also gives a road map for further research direction in order to tackle some of discussed limitations such as accuracy and scalability. The results show that in most cases semi-supervised learning techniques performed far better as an automated test classifier than Daikon (especially in the case that input/output pairs were augmented with their execution traces). However, there is one system for which our strategy struggles and Daikon performed far better. Furthermore, unsupervised learning techniques performed on a par when compared with Daikon in several cases particularly when input/output pairs were used together with execution traces.;;;https://dl.acm.org/doi/10.1145/3410352.3410747;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Active Learning for Spam Email Classification;;;['Zheng Chen', 'Ruiwen Tao', 'Xiaoyang Wu', 'Zhimin Wei', 'Xiao Luo'];;;December 2019;;;ACAI '19: Proceedings of the 2019 2nd International Conference on Algorithms, Computing and Artificial Intelligence;;;Deep learning has yielded state-of-the-art performance on text classification tasks. In this paper, a new neural network based on Long-Short-Term-Memory model is applied to classify spam emails. Using deep learning method to classify spam emails requires large amounts of labeled data. To solve this problem, active learning method is used to reduce labeling cost and increase model adaptability. In this paper, it is found that the new model performs better than standard CNNs and RNNs on email classification task, and active learning methods can match state-of-the-art performance with just 10% of the labeled data.;;;https://dl.acm.org/doi/10.1145/3377713.3377789;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Mining online learner profile through learning behavior analysis;;;['Bing Wu', 'Jun Xiao'];;;October 2018;;;ICETC '18: Proceedings of the 10th International Conference on Education Technology and Computers;;;User profile is an effective model to describe the user's interests and preferences. In the learning field, learner profile should meet the demand of learning and teaching such as learning patterns recognition or performance prediction. Analysis of user's behaviors is the common way to build user profile. Statistics show that online learning activities are incontinuous and diverse. By taking a closer look at the learning activity data, we found back accessing behavior is a frequent activity and reveals the truth of learners' intention. In this study, we make use of Shanghai Open University's learning platform as the data source for our research, adopt machine learning method to find the hidden patterns of learning activities and build the online learner profile. Statistics show that 15.68% of the accessing activities are back accessing. We found three learning patterns with different amount of back accessing behaviors and learning paths. Meanwhile, they relate to many factors including demographics, major type and area where learners join in learning. Through learner profile, we can predict learner's learning pattern which we found in this study. In the conclusion of our study, we suggest that learning path should be taken into consideration of learning engagement.;;;https://dl.acm.org/doi/10.1145/3290511.3290560;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Pile Foundation Detection Data Analysis and Classification Method;;;['Luo Zhong', 'Bingqing Wu', 'Ruiqi Luo', 'Shujun Zhang', 'Zhaoyu Dong', 'Ye Lu'];;;April 2019;;;ICDMML 2019: Proceedings of the 2019 International Conference on Data Mining and Machine Learning;;;In this paper, by combing the collected testing data of pile bearing capacity from 78 reinforced concrete cast-in-place bored piles. The distribution characteristics of the pile bearing capacity are analyzed in detail. Based on this, the n-σ criteria are introduced and a more practical data processing method for bearing capacity of foundation piles is proposed. Using this method, the data of pile bearing capacity detected was analyzed and processed. Then the data was divided into "strong data", "good data" and "weak data". In addition, we verified the validity of this method to determine the detected data quality of pile bearing capacity through engineering examples. The verification shows that the data quality has a significant influence on the calculation results of the reliability index and the resistance coefficient.;;;https://dl.acm.org/doi/10.1145/3335656.3335678;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Big data execution time based on Spark Machine Learning Libraries;;;['Anna Karen Gárate-Escamilla', 'Amir Hajjam El Hassani', 'Emmanuel Andres'];;;August 2019;;;ICCBDC '19: Proceedings of the 2019 3rd International Conference on Cloud and Big Data Computing;;;The paper focuses on exploring the time consumption of supervised and unsupervised models of Apache Spark framework in massive datasets. Big Data analytics has been relevant in the industry due to the need to convert information into knowledge. Among the challenge of big data is the creation of strategies to improve the execution costs of running machine learning models to make a prediction. Apache Spark is a powerful in-memory platform that offers an extensive machine learning library for regression, classification, clustering, and rule extraction. This investigation, from a computation cost perspective, performs different experiments using real datasets. The main contribution of the paper is to compare the execution time of different machine learning models, such as random forests, decision tree, logistic regression, linear support vector machine, and kNN. The present work expects to combine the areas of big data and machine learning, comparing the results with different configurations and the use of the optimization methods, cache and persist. The evaluation experiments show that logistic regression performed the shortest execution time of the Spark MLlib models.;;;https://dl.acm.org/doi/10.1145/3358505.3358519;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
An automated ensemble learning framework using genetic programming for image classification;;;['Ying Bi', 'Bing Xue', 'Mengjie Zhang'];;;July 2019;;;GECCO '19: Proceedings of the Genetic and Evolutionary Computation Conference;;;An ensemble consists of multiple learners and can achieve a better generalisation performance than a single learner. Genetic programming (GP) has been applied to construct ensembles using different strategies such as bagging and boosting. However, no GP-based ensemble methods focus on dealing with image classification, which is a challenging task in computer vision and machine learning. This paper proposes an automated ensemble learning framework using GP (EGP) for image classification. The new method integrates feature learning, classification function selection, classifier training, and combination into a single program tree. To achieve this, a novel program structure, a new function set and a new terminal set are developed in EGP. The performance of EGP is examined on nine different image classification data sets of varying difficulty and compared with a large number of commonly used methods including recently published methods. The results demonstrate that EGP achieves better performance than most competitive methods. Further analysis reveals that EGP evolves good ensembles simultaneously balancing diversity and accuracy. To the best of our knowledge, this study is the first work using GP to automatically generate ensembles for image classification.;;;https://dl.acm.org/doi/10.1145/3321707.3321750;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
(1+ε)-class classification: an anomaly detection method for highly imbalanced or incomplete data sets;;;['Maxim Borisyak', 'Artem Ryzhikov', 'Andrey Ustyuzhanin', 'Denis Derkach', 'Fedor Ratnikov', 'Olga Mineeva'];;;None;;;The Journal of Machine Learning Research;;;Anomaly detection is not an easy problem since distribution of anomalous samples is unknown a priori. We explore a novel method that gives a trade-off possibility between oneclass and two-class approaches, and leads to a better performance on anomaly detection problems with small or non-representative anomalous samples. The method is evaluated using several data sets and compared to a set of conventional one-class and two-class approaches.;;;https://dl.acm.org/doi/10.5555/3455716.3455788;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Graph-based Semi-supervised Learning for Text Classification;;;['Natalie Widmann', 'Suzan Verberne'];;;October 2017;;;ICTIR '17: Proceedings of the ACM SIGIR International Conference on Theory of Information Retrieval;;;In this paper, we propose a graph-based representation of document collections in which both documents and features are represented by nodes. The nodes are connected with weights based on word order, context similarity and word frequency. Graph-based representations can overcome the limitations of bag-of-words based representations that suffer from sparseness for collections with short documents. In a series of experiments, we evaluate multiple types of graph-based text features in the context of semi-supervised text classification, and investigate the effect of the number of labeled documents in the collection. We find that graph-based semi-supervised learning outperforms bag-of-words semi-supervised learning but not bag-of-words supervised learning in 20-class text categorization. A large asset of graph-based representations is that they are flexible in the types of nodes and relations that are included.;;;https://dl.acm.org/doi/10.1145/3121050.3121055;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
The Efficient Mining of Skyline Patterns from a Volunteer Computing Network;;;['Jimmy Ming-Tai Wu', 'Qian Teng', 'Gautam Srivastava', 'Matin Pirouz', 'Jerry Chun-Wei Lin'];;;None;;;ACM Transactions on Internet Technology;;;In the ever-growing world, the concepts of High-utility Itemset Mining (HUIM) as well as Frequent Itemset Mining (FIM) are fundamental works in knowledge discovery. Several algorithms have been designed successfully. However, these algorithms only used one factor to estimate an itemset. In the past, skyline pattern mining by considering both aspects of frequency and utility has been extensively discussed. In most cases, however, people tend to focus on purchase quantities of itemsets rather than frequencies. In this article, we propose a new knowledge called skyline quantity-utility pattern (SQUP) to provide better estimations in the decision-making process by considering quantity and utility together. Two algorithms, respectively, called SQU-Miner and SKYQUP are presented to efficiently mine the set of SQUPs. Moreover, the usage of volunteer computing is proposed to show the potential in real supermarket applications. Two new efficient utility-max structures are also mentioned for the reduction of the candidate itemsets, respectively, utilized in SQU-Miner and SKYQUP. These two new utility-max structures are used to store the upper-bound of utility for itemsets under the quantity constraint instead of frequency constraint, and the second proposed utility-max structure moreover applies a recursive updated process to further obtain strict upper-bound of utility. Our in-depth experimental results prove that SKYQUP has stronger performance when a comparison is made to SQU-Miner in terms of memory usage, runtime, and the number of candidates.;;;https://dl.acm.org/doi/10.1145/3423557;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Multi-Relational Classification via Bayesian Ranked Non-Linear Embeddings;;;['Ahmed Rashed', 'Josif Grabocka', 'Lars Schmidt-Thieme'];;;July 2019;;;KDD '19: Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining;;;The task of classifying multi-relational data spans a wide range of domains such as document classification in citation networks, classification of emails, and protein labeling in proteins interaction graphs. Current state-of-the-art classification models rely on learning per-entity latent representations by mining the whole structure of the relations' graph, however, they still face two major problems. Firstly, it is very challenging to generate expressive latent representations in sparse multi-relational settings with implicit feedback relations as there is very little information per-entity. Secondly, for entities with structured properties such as titles and abstracts (text) in documents, models have to be modified ad-hoc. In this paper, we aim to overcome these two main drawbacks by proposing a flexible nonlinear latent embedding model (BRNLE) for the classification of multi-relational data. The proposed model can be applied to entities with structured properties such as text by utilizing the numerical vector representations of those properties. To address the sparsity problem of implicit feedback relations, the model is optimized via a sparsely-regularized multi-relational pair-wise Bayesian personalized ranking loss (BPR). Experiments on four different real-world datasets show that the proposed model significantly outperforms state-of-the-art models for multi-relational classification.;;;https://dl.acm.org/doi/10.1145/3292500.3330863;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Automatic Feature Learning for MOOC Forum Thread Classification;;;['Lin Feng', 'Huimin Lu', 'Shenglan Liu', 'Guochao Liu', 'Sen Luo'];;;April 2018;;;ICBDC '18: Proceedings of the 3rd International Conference on Big Data and Computing;;;Discussion thread classification plays an important role for Massive Open Online Courses (MOOCs) forum. Most existing methods in this filed focus on extracting text features (e.g. key words) from the content of discussions using NLP methods. However, diversity of languages used in MOOC forums results in poor expansibility of these methods. To tackle this problem, in this paper, we artificially design 23 language independent features related to structure, popularity and underlying social network of thread. Furthermore, a hybrid model which combine Gradient Boosting Decision Tree (GBDT) with Linear Regression (LR) (GBDT + LR) is employed to reduce the traditional cost of feature learning for discussion threads classification manually. Experiments are carried out on the datasets contributed by Coursera with nearly 100, 000 discussion threads of 60 courses taught in 4 different languages. Results demonstrate that our method can significantly improve the performance of discussion threads classification. It is worth drawing that the average AUC of our model is 0.832, outperforming baseline by 15%.;;;https://dl.acm.org/doi/10.1145/3220199.3220201;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
MiningBreastCancer: Selection of Candidate Gene Associated with Breast Cancer via Comparison between Data Mining of TCGA and Text Mining of PubMed;;;['Chou-Cheng Chen', 'Yao-Lung Kuo', 'Chi-Hui Chiang'];;;December 2020;;;ACM ICEA '20: Proceedings of the 2020 ACM International Conference on Intelligent Computing and its Emerging Applications;;;In 2016, 12,676 new cases of breast cancer were diagnosed among Taiwan women. In 2018 the standardized death rate of breast cancer was 12.5 per 100,000 persons. Previous studies have integrated data and text mining to yield fusion genes, identify genetic factors for breast cancer and select single-gene feature sets for colon cancer discrimination. However, our study is the first to select significantly different expression between breast normal tissue and cancer using TCGA data and biostatistics, excluding know genes using abstracts from PubMed and natural language processing. The top twenty genes for research potential from the selection of Mining-BreastCancer are EML3, ABCB9, GRASP, KANK3, GPR146, ZNF623, CCDC9, ADCY4, DLL1, ADAM33, GRRP1, LRRN4CL, C14orf180, ABCD4, ABCC6P1, PEAR1, FAM43A, C20orf160, KIF21A and PP-FIA3. Few studies for these genes exist, but they hold significantly different expressions between breast cancer and normal tissue, each pathologic tumor and lymph node, or between each pathologic metastasis. These results show that MiningBreastCancer can help scientists select genes for research potential. MiningBreastCancer is available through http://bio.yungyun.com.tw/MiningBreastCancer.aspx.;;;https://dl.acm.org/doi/10.1145/3440943.3444718;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
MiningBreastCancer: Selection of Candidate Gene Associated with Breast Cancer via Comparison between Data Mining of TCGA and Text Mining of PubMed;;;['Chou-Cheng Chen', 'Yao-Lung Kuo', 'Chi-Hui Chiang'];;;December 2020;;;ACM ICEA '20: Proceedings of the 2020 ACM International Conference on Intelligent Computing and its Emerging Applications;;;In 2016, 12,676 new cases of breast cancer were diagnosed among Taiwan women. In 2018 the standardized death rate of breast cancer was 12.5 per 100,000 persons. Previous studies have integrated data and text mining to yield fusion genes, identify genetic factors for breast cancer and select single-gene feature sets for colon cancer discrimination. However, our study is the first to select significantly different expression between breast normal tissue and cancer using TCGA data and biostatistics, excluding know genes using abstracts from PubMed and natural language processing. The top twenty genes for research potential from the selection of Mining-BreastCancer are EML3, ABCB9, GRASP, KANK3, GPR146, ZNF623, CCDC9, ADCY4, DLL1, ADAM33, GRRP1, LRRN4CL, C14orf180, ABCD4, ABCC6P1, PEAR1, FAM43A, C20orf160, KIF21A and PP-FIA3. Few studies for these genes exist, but they hold significantly different expressions between breast cancer and normal tissue, each pathologic tumor and lymph node, or between each pathologic metastasis. These results show that MiningBreastCancer can help scientists select genes for research potential. MiningBreastCancer is available through http://bio.yungyun.com.tw/MiningBreastCancer.aspx.;;;https://dl.acm.org/doi/10.1145/3440943.3444718;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Actor-based incremental tree data processing for large-scale machine learning applications;;;['Kouhei Sakurai', 'Taiki Shimizu'];;;October 2019;;;AGERE 2019: Proceedings of the 9th ACM SIGPLAN International Workshop on Programming Based on Actors, Agents, and Decentralized Control;;;A number of online machine learning techniques based on tree model have been studied in order to cope with today's requirements of quickly processing large scale data-sets. We present a design pattern for incremental tree data processing as gradually constructing on-demand tree-model on memory. Our approach adopts the actor model as making use of multi-cores and distributed computers without largely rewriting code for algorithms. The pattern basically defines a node in the tree as an actor which is the unit of asynchronous processes and each data instance flows between actor nodes as a message. We study concrete two machine learning algorithms, VFDT for decision tree's top-down growth and BIRCH for hierarchical clustering's bottom up growth. For supporting VFDT, we propose an extension mechanism of replicating root nodes so that it can address bottleneck as starting of inputs. For supporting BIRCH, we split processes of recursive construction into asynchronous steps with correcting target node by traversing extra horizontal links between sibling nodes. We carried out machine learning tasks with our implementation on top of Akka Java, and we confirmed reasonable performance for the tasks with large scale data-sets.;;;https://dl.acm.org/doi/10.1145/3358499.3361220;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Dynamically Adjusting Diversity in Ensembles for the Classification of Data Streams with Concept Drift;;;['Juan I. G. Hidalgo', 'Silas G. T. C. Santos', 'Roberto S. M. Barros'];;;None;;;ACM Transactions on Knowledge Discovery from Data;;;A data stream can be defined as a system that continually generates a lot of data over time. Today, processing data streams requires new demands and challenging tasks in the data mining and machine learning areas. Concept Drift is a problem commonly characterized as changes in the distribution of the data within a data stream. The implementation of new methods for dealing with data streams where concept drifts occur requires algorithms that can adapt to several scenarios to improve its performance in the different experimental situations where they are tested. This research proposes a strategy for dynamic parameter adjustment in the presence of concept drifts. Parameter Estimation Procedure (PEP) is a general method proposed for dynamically adjusting parameters which is applied to the diversity parameter (λ) of several classification ensembles commonly used in the area. To this end, the proposed estimation method (PEP) was used to create Boosting-like Online Learning Ensemble with Parameter Estimation (BOLE-PE), Online AdaBoost-based M1 with Parameter Estimation (OABM1-PE), and Oza and Russell’s Online Bagging with Parameter Estimation (OzaBag-PE), based on the existing ensembles BOLE, OABM1, and OzaBag, respectively. To validate them, experiments were performed with artificial and real-world datasets using Hoeffding Tree (HT) as base classifier. The accuracy results were statistically evaluated using a variation of the Friedman test and the Nemenyi post-hoc test. The experimental results showed that the application of the dynamic estimation in the diversity parameter (λ) produced good results in most scenarios, i.e., the modified methods have improved accuracy in the experiments with both artificial and real-world datasets.;;;https://dl.acm.org/doi/10.1145/3466616;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Frontmatter: mining Android user interfaces at scale;;;['Konstantin Kuznetsov', 'Chen Fu', 'Song Gao', 'David N. Jansen', 'Lijun Zhang', 'Andreas Zeller'];;;August 2021;;;ESEC/FSE 2021: Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering;;;We introduce Frontmatter: the largest open-access dataset containing user interface models of about 160,000 Android apps. Frontmatter opens the door for comprehensive mining of mobile user interfaces, jumpstarting empirical research at a large scale, addressing questions such as "How many travel apps require registration?", "Which apps do not follow accessibility guidelines?", "Does the user interface correspond to the description?", and many more. The Frontmatter UI analysis tool and the Frontmatter dataset are available under an open-source license.;;;https://dl.acm.org/doi/10.1145/3468264.3473125;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Adaptive-Step Graph Meta-Learner for Few-Shot Graph Classification;;;['Ning Ma', 'Jiajun Bu', 'Jieyu Yang', 'Zhen Zhang', 'Chengwei Yao', 'Zhi Yu', 'Sheng Zhou', 'Xifeng Yan'];;;October 2020;;;CIKM '20: Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management;;;Graph classification aims to extract accurate information from graph-structured data for classification and is becoming more and more important in the graph learning community. Although Graph Neural Networks (GNNs) have been successfully applied to graph classification tasks, most of them overlook the scarcity of labeled graph data in many applications. For example, in bioinformatics, obtaining protein graph labels usually needs laborious experiments. Recently, few-shot learning has been explored to alleviate this problem with only a few labeled graph samples of test classes. The shared sub-structures between training classes and test classes are essential in the few-shot graph classification. Existing methods assume that the test classes belong to the same set of super-classes clustered from training classes. However, according to our observations, the label spaces of training classes and test classes usually do not overlap in a real-world scenario. As a result, the existing methods don't well capture the local structures of unseen test classes. To overcome the limitation, in this paper, we propose a direct method to capture the sub-structures with a well initialized meta-learner within a few adaptation steps. More specifically, (1) we propose a novel framework consisting of a graph meta-learner, which uses GNNs based modules for fast adaptation on graph data, and a step controller for the robustness and generalization of meta-learner; (2) we provide quantitative analysis for the framework and give a graph-dependent upper bound of the generalization error based on our framework; (3) the extensive experiments on real-world datasets demonstrate that our framework gets state-of-the-art results on several few-shot graph classification tasks compared to baselines.;;;https://dl.acm.org/doi/10.1145/3340531.3411951;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Probabilistic Feature Selection and Classification Vector Machine;;;['Bingbing Jiang', 'Chang Li', 'Maarten De Rijke', 'Xin Yao', 'Huanhuan Chen'];;;None;;;ACM Transactions on Knowledge Discovery from Data;;;Sparse Bayesian learning is a state-of-the-art supervised learning algorithm that can choose a subset of relevant samples from the input data and make reliable probabilistic predictions. However, in the presence of high-dimensional data with irrelevant features, traditional sparse Bayesian classifiers suffer from performance degradation and low efficiency due to the incapability of eliminating irrelevant features. To tackle this problem, we propose a novel sparse Bayesian embedded feature selection algorithm that adopts truncated Gaussian distributions as both sample and feature priors. The proposed algorithm, called probabilistic feature selection and classification vector machine (PFCVMLP) is able to simultaneously select relevant features and samples for classification tasks. In order to derive the analytical solutions, Laplace approximation is applied to compute approximate posteriors and marginal likelihoods. Finally, parameters and hyperparameters are optimized by the type-II maximum likelihood method. Experiments on three datasets validate the performance of PFCVMLP along two dimensions: classification performance and effectiveness for feature selection. Finally, we analyze the generalization performance and derive a generalization error bound for PFCVMLP. By tightening the bound, the importance of feature selection is demonstrated.;;;https://dl.acm.org/doi/10.1145/3309541;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Scalable Machine Learning on High-Dimensional Vectors: From Data Series to Deep Network Embeddings;;;['Karima Echihabi', 'Kostas Zoumpatianos', 'Themis Palpanas'];;;June 2020;;;WIMS 2020: Proceedings of the 10th International Conference on Web Intelligence, Mining and Semantics;;;There is an increasingly pressing need, by several applications in diverse domains, for developing techniques able to analyze very large collections of static and streaming sequences (a.k.a. data series), predominantly in real-time. Examples of such applications come from Internet of Things installations, neuroscience, astrophysics, and a multitude of other scientific and application domains that need to apply machine learning techniques for knowledge extraction. It is not unusual for these applications, for which similarity search is a core operation, to involve numbers of data series in the order of hundreds of millions to billions, which are seldom analyzed in their full detail due to their sheer size. Such application requirements have driven the development of novel similarity search methods that can facilitate scalable analytics in this context. At the same time, a host of other methods have been developed for similarity search of high-dimensional vectors in general. All these methods are now becoming increasingly important, because of the growing popularity and size of sequence collections, as well as the growing use of high-dimensional vector representations of a large variety of objects (such as text, multimedia, images, audio and video recordings, graphs, database tables, and others) thanks to deep network embeddings. In this work, we review recent efforts in designing techniques for indexing and analyzing massive collections of data series, and argue that they are the methods of choice even for general high-dimensional vectors. Finally, we discuss the challenges and open research problems in this area.;;;https://dl.acm.org/doi/10.1145/3405962.3405989;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A Lightweight Deep Learning Approach to Mosquito Classification from Wingbeat Sounds;;;['Myat Su Yin', 'Peter Haddawy', 'Borvorntat Nirandmongkol', 'Tup Kongthaworn', 'Chanaporn Chaisumritchoke', 'Akara Supratak', 'Chaitawat Sa-ngamuang', 'Patchara Sriwichai'];;;September 2021;;;GoodIT '21: Proceedings of the Conference on Information Technology for Social Good;;;Diseases transmitted by mosquito vectors such as malaria, dengue, and Zika virus are amongst the largest healthcare concerns across the globe today. To tackle such life-threatening diseases, it is vital to evaluate the risk of transmission. Of critical importance in this task is the estimation of vector species populations in an area of interest. Traditional approaches to estimating vector populations involve physically collecting vector samples in traps and manually classifying species, which is highly labor intensive. A promising alternative approach is to classify mosquito species based on the audio signal from their wingbeats. Various traditional machine learning and deep learning models have been developed for such automated acoustic mosquito species classification. But they require data preprocessing and significant computation, limiting their suitability to be deployed on low-cost sensor devices. This paper presents two lightweight deep learning models for mosquito species and sex classification from wingbeat audio signals which are suitable to be deployed on small IoT sensor devices. One model is a 1D CNN and the other combines the 1D CNN with an LSTM model. The models operate directly on a low-sample-rate raw audio signal and thus require no signal preprocessing. Both models achieve a classification accuracy of over 93% on a dataset of recordings of males and females of five species. In addition, we explore the relation between model size and classification accuracy. Through model tuning, we are able to reduce the sizes of both models by approx. 60% while losing only 3% in classification accuracy.;;;https://dl.acm.org/doi/10.1145/3462203.3475908;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Efficient Document Filtering Using Vector Space Topic Expansion and Pattern-Mining: The Case of Event Detection in Microposts;;;['Julia Proskurnia', 'Ruslan Mavlyutov', 'Carlos Castillo', 'Karl Aberer', 'Philippe Cudré-Mauroux'];;;November 2017;;;CIKM '17: Proceedings of the 2017 ACM on Conference on Information and Knowledge Management;;;Automatically extracting information from social media is challenging given that social content is often noisy, ambiguous, and inconsistent. However, as many stories break on social channels first before being picked up by mainstream media, developing methods to better handle social content is of utmost importance. In this paper, we propose a robust and effective approach to automatically identify microposts related to a specific topic defined by a small sample of reference documents. Our framework extracts clusters of semantically similar microposts that overlap with the reference documents, by extracting combinations of key features that define those clusters through frequent pattern mining. This allows us to construct compact and interpretable representations of the topic, dramatically decreasing the computational burden compared to classical clustering and k-NN-based machine learning techniques and producing highly-competitive results even with small training sets (less than 1'000 training objects). Our method is efficient and scales gracefully with large sets of incoming microposts. We experimentally validate our approach on a large corpus of over 60M microposts, showing that it significantly outperforms state-of-the-art techniques.;;;https://dl.acm.org/doi/10.1145/3132847.3133016;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Mining software defects: should we consider affected releases?;;;['Suraj Yatish', 'Jirayus Jiarpakdee', 'Patanamon Thongtanunam', 'Chakkrit Tantithamthavorn'];;;May 2019;;;ICSE '19: Proceedings of the 41st International Conference on Software Engineering;;;With the rise of the Mining Software Repositories (MSR) field, defect datasets extracted from software repositories play a foundational role in many empirical studies related to software quality. At the core of defect data preparation is the identification of post-release defects. Prior studies leverage many heuristics (e.g., keywords and issue IDs) to identify post-release defects. However, such the heuristic approach is based on several assumptions, which pose common threats to the validity of many studies. In this paper, we set out to investigate the nature of the difference of defect datasets generated by the heuristic approach and the realistic approach that leverages the earliest affected release that is realistically estimated by a software development team for a given defect. In addition, we investigate the impact of defect identification approaches on the predictive accuracy and the ranking of defective modules that are produced by defect models. Through a case study of defect datasets of 32 releases, we find that that the heuristic approach has a large impact on both defect count datasets and binary defect datasets. Surprisingly, we find that the heuristic approach has a minimal impact on defect count models, suggesting that future work should not be too concerned about defect count models that are constructed using heuristic defect datasets. On the other hand, using defect datasets generated by the realistic approach lead to an improvement in the predictive accuracy of defect classification models.;;;https://dl.acm.org/doi/10.1109/ICSE.2019.00075;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Laconic Image Classification: Human vs. Machine Performance;;;['Javier Carrasco', 'Aidan Hogan', 'Jorge Pérez'];;;October 2020;;;CIKM '20: Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management;;;We propose laconic classification as a novel way to understand and compare the performance of diverse image classifiers. The goal in this setting is to minimise the amount of information (aka. entropy) required in individual test images to maintain correct classification. Given a classifier and a test image, we compute an approximate minimal-entropy positive image for which the classifier provides a correct classification, becoming incorrect upon any further reduction. The notion of entropy offers a unifying metric that allows to combine and compare the effects of various types of reductions (e.g., crop, colour reduction, resolution reduction) on classification performance, in turn generalising similar methods explored in previous works. Proposing two complementary frameworks for computing the minimal-entropy positive images of both human and machine classifiers, in experiments over the ILSVRC test-set, we find that machine classifiers are more sensitive entropy-wise to reduced resolution (versus cropping or reduced colour for machines, as well as reduced resolution for humans), supporting recent results suggesting a texture bias in the ILSVRC-trained models used. We also find, in the evaluated setting, that humans classify the minimal-entropy positive images of machine models with higher precision than machines classify those of humans.;;;https://dl.acm.org/doi/10.1145/3340531.3411984;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Clustering of Functionally Related Genes Using Machine Learning Techniques;;;['Yujing Xue', 'Lang Cao'];;;February 2021;;;ICCDA '21: Proceedings of the 2021 5th International Conference on Compute and Data Analysis;;;The clustering of functionally related genes has been an important task for biologists. With the recent progress of machine learning technology, researchers now have more powerful weapons to identify the structures within a large amount of DNA sequencing data. That allows the research on genes to be conducted in an efficient and scalable way. This paper studies the clustering of functionally related genes and their impact on the development and prognosis of lung cancer with machine learning technologies. The patient data derived from 218 patients are analyzed. We focus on two extreme cases, one case includes patients who survived less than 1 year, and the other case includes patients who survived longer than 5 years. We will investigate how different clustering methods can assist in the visualization of the DNA sequence data of such patients, and how such methods can help us identify the underlying patterns of the DNA sequence data.;;;https://dl.acm.org/doi/10.1145/3456529.3456538;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Aspect-Based Opinion Mining of Students' Reviews on Online Courses;;;['Zenun Kastrati', 'Blend Arifaj', 'Arianit Lubishtani', 'Fitim Gashi', 'Engjëll Nishliu'];;;April 2020;;;ICCAI '20: Proceedings of the 2020 6th International Conference on Computing and Artificial Intelligence;;;It is critical for higher education institutions to work on improvement of their teaching and learning strategy by examining feedback of students. Analyzing these feedbacks typically requires manual interventions which are not only labor intensive but prone to errors as well. Therefore, automatic models and techniques are needed to handle textual feedback efficiently. To this end, we propose a model for aspect-based opinion mining of comments of students that are posted in online learning platforms. The model aims to predict some of the key aspects related to an online course from students' reviews and then assess the attitude of students toward these commented aspects. The proposed model is tested on a large-scale real-world dataset which is collected for this purpose. The dataset consists of more than 21 thousand manually annotated students' reviews that are collected from Coursera. Conventional machine learning algorithms and deep learning techniques are used for prediction of the aspect categories and the aspect sentiment classification as well. The obtained results with respect to precision, recall, and F1 score are very promising.;;;https://dl.acm.org/doi/10.1145/3404555.3404633;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Mining Bad Credit Card Accounts from OLAP and OLTP;;;['Sheikh Rabiul Islam', 'William Eberle', 'Sheikh Khaled Ghafoor'];;;May 2017;;;ICCDA '17: Proceedings of the International Conference on Compute and Data Analysis;;;Credit card companies classify accounts as a good or bad based on historical data where a bad account may default on payments in the near future. If an account is classified as a bad account, then further action can be taken to investigate the actual nature of the account and take preventive actions. In addition, marking an account as "good" when it is actually bad, could lead to loss of revenue - and marking an account as "bad" when it is actually good, could lead to loss of business. However, detecting bad credit card accounts in real time from Online Transaction Processing (OLTP) data is challenging due to the volume of data needed to be processed to compute the risk factor. We propose an approach which precomputes and maintains the risk probability of an account based on historical transactions data from offline data or data from a data warehouse. Furthermore, using the most recent OLTP transactional data, risk probability is calculated for the latest transaction and combined with the previously computed risk probability from the data warehouse. If accumulated risk probability crosses a predefined threshold, then the account is treated as a bad account and is flagged for manual verification.;;;https://dl.acm.org/doi/10.1145/3093241.3093279;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Graph Embeddings for Linked Data Clustering;;;['Siham Eddamiri', 'Elmoukhtar Zemmouri', 'Asmaa Benghabrit'];;;November 2018;;;iiWAS2018: Proceedings of the 20th International Conference on Information Integration and Web-based Applications &amp; Services;;;The availability and accessibility of large RDF data in the Linked Open Data cloud encourage the machine learning community to develop approaches and techniques to extract useful knowledge from such type of data. Moreover, Data Clustering is identified as a crucial task for many web-based applications. In this paper, we present an approach that uses neural language models for RDF data clustering. We, first, generate sequences of entities extracted from several graph substructures using Doc2vec and Word2vec combined with TF-IDF. Then we apply K-Means to cluster generated vectors. Our experiments on real datasets show good results when applying TF-IDF with Doc2vec for vector representation of RDF data.;;;https://dl.acm.org/doi/10.1145/3282373.3282401;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
The Classification of Spoiler Comments in Thai Discussion Forums;;;['Rangsipan Marukatat'];;;December 2020;;;NLPIR '20: Proceedings of the 4th International Conference on Natural Language Processing and Information Retrieval;;;Classifying comments about movies into spoiler or non-spoiler is a challenging application of text mining. This research proposes using intrinsic and extrinsic attributes for the classification task. Intrinsic attributes consist of words in a bag-of-words model and spoiler cues extracted from the comments, whereas extrinsic ones are genre information gathered from external sources. First, a few methods to select predictive words from the bag of words were compared. Ensemble attribute selector was found to achieve the best results. Then, the classification was done by support vector machine (SVM) and Naïve Bayes. The accuracies on unseen data were around 85--89% when using only bags of selected words, and close to 91% when using all the proposed attributes.;;;https://dl.acm.org/doi/10.1145/3443279.3443298;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Review highlights: opinion mining on reviews: a hybrid model for rule selection in aspect extraction;;;['Amit Kushwaha', 'Shubham Chaudhary'];;;October 2017;;;IML '17: Proceedings of the 1st International Conference on Internet of Things and Machine Learning;;;This paper proposes a methodology to extract key insights from user generated reviews. This work is based on Aspect Based Sentiment Analysis (ABSA) which predicts the sentiment of aspects mentioned in the text documents. The extracted aspects are fine-grained for the presentation form known as Review Highlights. The syntactic approach for extraction process suffers from the overlapping chunking rules which result in noise extraction. We introduce a hybrid technique which combines machine learning and rule based model. A multi-label classifier identifies the effective rules which efficiently parse aspects and opinions from texts. This selection of rules reduce the amount of noise in extraction tasks. This is a novel attempt to learn syntactic rule fitness from a corpus using machine learning for accurate aspect extraction. As the model learns the syntactic rule prediction from the corpus, it makes the extraction method domain independent. It also allows studying the quality of syntactic rules in a different corpus.;;;https://dl.acm.org/doi/10.1145/3109761.3158385;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Mining Twitter messages for software evolution;;;['Emitza Guzman', 'Mohamed Ibrahim', 'Martin Glinz'];;;May 2017;;;ICSE-C '17: Proceedings of the 39th International Conference on Software Engineering Companion;;;Twitter is a widely used social network. Previous research showed that users engage in Twitter to communicate about software applications via short messages, referred to as tweets, and that some of these tweets are relevant for software evolution. However, a manual analysis is impractical due to the large number of tweets - in the range of thousands per day for popular apps. In this work we present ALERTme, an approach to automatically classify, group and rank tweets about software applications. We apply machine learning techniques for automatically classifying tweets requesting improvements, topic modeling for grouping semantically related tweets and a weighted function for ranking tweets according to their relevance for software evolution. We ran our approach on 68,108 tweets from three different software applications and compared the results against practitioners' assessments. Our results are promising and could help incorporate short, informal user feedback with social components into the software evolution process.;;;https://dl.acm.org/doi/10.1109/ICSE-C.2017.65;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Detection of Cyber-Aggressive Comments on Social Media Networks: A Machine Learning and Text mining approach;;;['Risul Islam Rasel', 'Nasrin Sultana', 'Sharna Akhter', 'Phayung Meesad'];;;September 2018;;;NLPIR '18: Proceedings of the 2nd International Conference on Natural Language Processing and Information Retrieval;;;The spread of aggressive tweets, status and comments on social network are increasing gradually. People are using social media networks as a virtual platform to troll, objurgate, blaspheme and revile one another. These activities are spreading animosity in race-to-race, religion to religion etc. So, these comments should be identified and blocked on social networks. This work focuses on extracting comments from social networks and analyzes those comments whether they convey any blaspheme or revile in meaning. Comments are classified into three distinct classes; offensive, hate speech and neither. Document similarity analyses are done to identify the correlations among the documents. A well defined text pre-processing analysis is done to create an optimized word vector to train the classification model. Finally, the proposed model categorizes the comments into their respective classes with more than 93% accuracy.;;;https://dl.acm.org/doi/10.1145/3278293.3278303;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Enhancing classification performance of convolutional neural networks for prostate cancer detection on magnetic resonance images: a study with the semantic learning machine;;;['Paulo Lapa', 'Ivo Gonçalves', 'Leonardo Rundo', 'Mauro Castelli'];;;July 2019;;;GECCO '19: Proceedings of the Genetic and Evolutionary Computation Conference Companion;;;Prostate cancer (PCa) is the most common oncological disease in Western men. Even though a significant effort has been carried out by the scientific community, accurate and reliable automated PCa detection methods are still a compelling issue. In this clinical scenario, high-resolution multiparametric Magnetic Resonance Imaging (MRI) is becoming the most used modality, also enabling quantitative studies. Recently, deep learning techniques have achieved outstanding results in prostate MRI analysis tasks, in particular with regard to image classification. This paper studies the feasibility of using the Semantic Learning Machine (SLM) neuroevolution algorithm to replace the fully-connected architecture commonly used in the last layers of Convolutional Neural Networks (CNNs). The experimental phase considered the PROSTATEx dataset composed of multispectral MRI sequences. The achieved results show that, on the same non-contrast-enhanced MRI series, SLM outperforms with statistical significance a state-of-the-art CNN trained with backpropagation. The SLM performance is achieved without pre-training the underlying CNN with backpropagation. Furthermore, on average the SLM training time is approximately 14 times faster than the backpropagation-based approach.;;;https://dl.acm.org/doi/10.1145/3319619.3322035;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Improving Multimodal Data Labeling with Deep Active Learning for Post Classification in Social Networks;;;['Dmitry Krylov', 'Semen Poliakov', 'Natalia Khanzhina', 'Alexey Zabashta', 'Andrey Filchenkov', 'Aleksandr Farseev'];;;October 2021;;;MULL'21: Multimedia Understanding with Less Labeling on Multimedia Understanding with Less Labeling;;;Automatic user post classification is an important task in the field of social network analysis. Being effectively solved, post classification could be used for thematic user feed composition or inappropriate content identification. Commonly addressed by applying various Machine Learning approaches, the task often involves manual processes related to ground truth sourcing, which is known to be a hardly-scalable and increasingly expensive procedure. At the same time, Active Learning for automatic user post classification is a promising way to bridge such a gap, as it does not require massive ground truth availability aligning our research with the real world settings. In this work, we put our focus on leveraging textual and visual data modalities for the application of user post classification and investigate how batch size and batch normalization disabling techniques could affect active deep neural network learning process. We solve the problem of automatic user post classification by employing our novel multimodal neural network architecture with multi-head tunable loss function components. We show that the proposed approach, coupled with Active Learning, allows for the achievement of a significant classification performance boost in terms of crowd assessing resources as compared to the passive learning approaches.;;;https://dl.acm.org/doi/10.1145/3476098.3485055;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Active Learning and Visual Analytics for Stance Classification with ALVA;;;['Kostiantyn Kucher', 'Carita Paradis', 'Magnus Sahlgren', 'Andreas Kerren'];;;None;;;ACM Transactions on Interactive Intelligent Systems;;;The automatic detection and classification of stance (e.g., certainty or agreement) in text data using natural language processing and machine-learning methods creates an opportunity to gain insight into the speakers’ attitudes toward their own and other people’s utterances. However, identifying stance in text presents many challenges related to training data collection and classifier training. To facilitate the entire process of training a stance classifier, we propose a visual analytics approach, called ALVA, for text data annotation and visualization. ALVA’s interplay with the stance classifier follows an active learning strategy to select suitable candidate utterances for manual annotaion. Our approach supports annotation process management and provides the annotators with a clean user interface for labeling utterances with multiple stance categories. ALVA also contains a visualization method to help analysts of the annotation and training process gain a better understanding of the categories used by the annotators. The visualization uses a novel visual representation, called CatCombos, which groups individual annotation items by the combination of stance categories. Additionally, our system makes a visualization of a vector space model available that is itself based on utterances. ALVA is already being used by our domain experts in linguistics and computational linguistics to improve the understanding of stance phenomena and to build a stance classifier for applications such as social media monitoring.;;;https://dl.acm.org/doi/10.1145/3132169;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Opinion Mining for Software Development: A Systematic Literature Review;;;['Bin Lin', 'Nathan Cassee', 'Alexander Serebrenik', 'Gabriele Bavota', 'Nicole Novielli', 'Michele Lanza'];;;None;;;ACM Transactions on Software Engineering and Methodology;;;Opinion mining, sometimes referred to as sentiment analysis, has gained increasing attention in software engineering (SE) studies. SE researchers have applied opinion mining techniques in various contexts, such as identifying developers’ emotions expressed in code comments and extracting users’ critics toward mobile apps. Given the large amount of relevant studies available, it can take considerable time for researchers and developers to figure out which approaches they can adopt in their own studies and what perils these approaches entail.We conducted a systematic literature review involving 185 papers. More specifically, we present (1) well-defined categories of opinion mining-related software development activities, (2) available opinion mining approaches, whether they are evaluated when adopted in other studies, and how their performance is compared, (3) available datasets for performance evaluation and tool customization, and (4) concerns or limitations SE researchers might need to take into account when applying/customizing these opinion mining techniques. The results of our study serve as references to choose suitable opinion mining tools for software development activities and provide critical insights for the further development of opinion mining techniques in the SE domain.;;;https://dl.acm.org/doi/10.1145/3490388;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A Comparative Study of Unsupervised Classification Algorithms in Multi-Sized Data Sets;;;['Syed Quddus', 'Adil Bagirov'];;;December 2019;;;AICCC '19: Proceedings of the 2019 2nd Artificial Intelligence and Cloud Computing Conference;;;The ability to mine and extract useful information automatically, from large data sets, is a common concern for organizations, for the last few decades. Over the internet, data is vastly increasing gradually and consequently the capacity to collect and store very large data is significantly increasing. Existing clustering algorithms are not always efficient and accurate in solving clustering problems for large data sets. However, the development of accurate and fast data classification algorithms for very large scale data sets is still a challenge. In this paper, we present an overview of various algorithms and approaches which are recently being used for Clustering of large data and E-document. In this paper, a comparative study of the performance of various algorithms: the global kmeans algorithm (GKM), the multi-start modified global kmeans algorithm (MS-MGKM), the multi-start kmeans algorithm (MS-KM), the difference of convex clustering algorithm (DCA), the clustering algorithm based on the difference of convex representation of the cluster function and non-smooth optimization (DC-L2), is carried out using C++.;;;https://dl.acm.org/doi/10.1145/3375959.3375979;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Strong agile metrics: mining log data to determine predictive power of software metrics for continuous delivery teams;;;['Hennie Huijgens', 'Robert Lamping', 'Dick Stevens', 'Hartger Rothengatter', 'Georgios Gousios', 'Daniele Romano'];;;August 2017;;;ESEC/FSE 2017: Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering;;;ING Bank, a large Netherlands-based internationally operating bank, implemented a fully automated continuous delivery pipe-line for its software engineering activities in more than 300 teams, that perform more than 2500 deployments to production each month on more than 750 different applications. Our objective is to examine how strong metrics for agile (Scrum) DevOps teams can be set in an iterative fashion. We perform an exploratory case study that focuses on the classification based on predictive power of software metrics, in which we analyze log data derived from two initial sources within this pipeline. We analyzed a subset of 16 metrics from 59 squads. We identified two lagging metrics and assessed four leading metrics to be strong.;;;https://dl.acm.org/doi/10.1145/3106237.3117779;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Incident prediction through logging management and machine learning;;;['J. El Abdelkhalki', 'M. Ben Ahmed', 'A. Slimani'];;;October 2019;;;SCA '19: Proceedings of the 4th International Conference on Smart City Applications;;;Analyzing the log file for software or device provides a focal point for making incremental improvements; it is the performed step to start the incident analysis. Although, log messages format or contents may not always be fully documented, and described in many different formats. It makes the log analysis task more difficult, affects the correction deadline of incidents and therefore involves a high financial risk. In this paper, we survey the log file analysis and the existing systems elaborated to resolve current issue. Then, we propose a methodology to support the log analysis in the complex environment. The KN-K-Nearest-Neighbor (KNN) classification method was chosed to be used online by weka to predict the error. Therefore, a program was developed in python to extract, clean and format the log file before comparing the different algorithms of the classifiation method KNN, J48 and Bayes - NaiveBayes in the context of dataset.API was used in order to process Weka. Finally, we illustrate our proposal in the Tivoli Storage Manager (TSM) file log and provide a description of the results obtained.;;;https://dl.acm.org/doi/10.1145/3368756.3369069;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Social Networks and Railway Passenger Capacity: An Empirical Study Based on Text Mining and Deep Learning;;;['Chao Wang', 'Xuyan Pan', 'Yibo Wang'];;;November 2018;;;Safety and Resilience'18: Proceedings of the 4th ACM SIGSPATIAL International Workshop on Safety and Resilience;;;Railway passenger transport is essential to modern transportation in China. The prediction of railway passenger capacity is of vital importance for ensuring the safety of railway transportation. This paper introduces social network text data into the prediction of railway passenger capacity. In the process of analyzing social network text data, text mining methods are used to analyze the text data, and the information related to railway passenger flow is extracted from the text and added to the prediction model. Meanwhile, in order to obtain better prediction results, this paper applies deep learning method on the data. The combination of text mining and deep learning method has greatly improved the accuracy of our prediction model. Experimental results show that a good accuracy rate has been achieved.;;;https://dl.acm.org/doi/10.1145/3284103.3284125;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Debugging crashes using continuous contrast set mining;;;['Rebecca Qian', 'Yang Yu', 'Wonhee Park', 'Vijayaraghavan Murali', 'Stephen Fink', 'Satish Chandra'];;;June 2020;;;ICSE-SEIP '20: Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering: Software Engineering in Practice;;;Facebook operates a family of services used by over two billion people daily on a huge variety of mobile devices. Many devices are configured to upload crash reports should the app crash for any reason. Engineers monitor and triage millions of crash reports logged each day to check for bugs, regressions, and any other quality problems. Debugging groups of crashes is a manually intensive process that requires deep domain expertise and close inspection of traces and code, often under time constraints. We use contrast set mining, a form of discriminative pattern mining, to learn what distinguishes one group of crashes from another. Prior works focus on discretization to apply contrast mining to continuous data. We propose the first direct application of contrast learning to continuous data, without the need for discretization. We also define a weighted anomaly score that unifies continuous and categorical contrast sets while mitigating bias, as well as uncertainty measures that communicate confidence to developers. We demonstrate the value of our novel statistical improvements by applying it on a challenging dataset from Facebook production logs, where we achieve 40x speedup over baseline approaches using discretization.;;;https://dl.acm.org/doi/10.1145/3377813.3381369;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Spatial data mining of public transport incidents reported in social media;;;['Kamil Raczycki', 'Marcin Szymański', 'Yahor Yeliseyenka', 'Piotr Szymański', 'Tomasz Kajdanowicz'];;;November 2021;;;IWCTS '21: Proceedings of the 14th ACM SIGSPATIAL International Workshop on Computational Transportation Science;;;Public transport agencies use social media as an essential tool for communicating mobility incidents to passengers. However, while the short term, day-to-day information about transport phenomena is usually posted in social media with low latency, its availability is short term as the content is rarely made an aggregated form. Social media communication of transport phenomena usually lacks GIS annotations as most social media platforms do not allow attaching non-POI GPS coordinates to posts. As a result, the analysis of transport phenomena information is minimal. We collected three years of social media posts of a polish public transport company with user comments. Through exploration, we infer a six-class transport information typology. We successfully build an information type classifier for social media posts, detect stop names in posts, and relate them to GPS coordinates, obtaining a spatial understanding of long-term aggregated phenomena. We show that our approach enables citizen science and use it to analyze the impact of three years of infrastructure incidents on passenger mobility, and the sentiment and reaction scale towards each of the events. All these results are achieved for Polish, an under-resourced language when it comes to spatial language understanding, especially in social media contexts. To improve the situation, we released two of our annotated data sets: social media posts with incident type labels and matched stop names and social media comments with the annotated sentiment. We also opensource the experimental codebase.;;;https://dl.acm.org/doi/10.1145/3486629.3490696;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Scalable Mining of High-Utility Sequential Patterns With Three-Tier MapReduce Model;;;['Jerry Chun-Wei Lin', 'Youcef Djenouri', 'Gautam Srivastava', 'Yuanfa Li', 'Philip S. Yu'];;;None;;;ACM Transactions on Knowledge Discovery from Data;;;High-utility sequential pattern mining (HUSPM) is a hot research topic in recent decades since it combines both sequential and utility properties to reveal more information and knowledge rather than the traditional frequent itemset mining or sequential pattern mining. Several works of HUSPM have been presented but most of them are based on main memory to speed up mining performance. However, this assumption is not realistic and not suitable in large-scale environments since in real industry, the size of the collected data is very huge and it is impossible to fit the data into the main memory of a single machine. In this article, we first develop a parallel and distributed three-stage MapReduce model for mining high-utility sequential patterns based on large-scale databases. Two properties are then developed to hold the correctness and completeness of the discovered patterns in the developed framework. In addition, two data structures called sidset and utility-linked list are utilized in the developed framework to accelerate the computation for mining the required patterns. From the results, we can observe that the designed model has good performance in large-scale datasets in terms of runtime, memory, efficiency of the number of distributed nodes, and scalability compared to the serial HUSP-Span approach.;;;https://dl.acm.org/doi/10.1145/3487046;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
New Multi-View Classification Method with Uncertain Data;;;['Bo Liu', 'Haowen Zhong', 'Yanshan Xiao'];;;None;;;ACM Transactions on Knowledge Discovery from Data;;;Multi-view classification aims at designing a multi-view learning strategy to train a classifier from multi-view data, which are easily collected in practice. Most of the existing works focus on multi-view classification by assuming the multi-view data are collected with precise information. However, we always collect the uncertain multi-view data due to the collection process is corrupted with noise in real-life application. In this case, this article proposes a novel approach, called uncertain multi-view learning with support vector machine (UMV-SVM) to cope with the problem of multi-view learning with uncertain data. The method first enforces the agreement among all the views to seek complementary information of multi-view data and takes the uncertainty of the multi-view data into consideration by modeling reachability area of the noise. Then it proposes an iterative framework to solve the proposed UMV-SVM model such that we can obtain the multi-view classifier for prediction. Extensive experiments on real-life datasets have shown that the proposed UMV-SVM can achieve a better performance for uncertain multi-view classification in comparison to the state-of-the-art multi-view classification methods.;;;https://dl.acm.org/doi/10.1145/3458282;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Identifying Cognitive Attributes Using Deep Learning Classification Techniques;;;['Shuai Zhao', 'Xiaoting Huang'];;;November 2019;;;WAIE 2019: Proceedings of the International Workshop on Artificial Intelligence and Education;;;Cognitive diagnosis is very useful to teachers and students, but its application is limited at present. This is largely because identifying the cognitive attributes of items currently is labor intensive and time-consuming. In this study, we used text classification techniques to automatically identify cognitive attributes. Specifically, two popular deep learning classification models, long-short term memory and bi-directional long-short term memory, were employed in conjunction with word embeddings. As the baseline, support vector machine with feature selection using information gain was also adopted. Experiments based on a sample of 805 third grade math items showed that both the deep learning models performed better than support vector machine, and bi-directional long-short term memory achieved the best performance, yielding the accuracy of 82% and the F1 measure of 80%. Our result indicated that text classification methods, especially deep learning models, have great potential in identifying cognitive attributes efficiently, and in turn, make cognitive diagnostic more feasible to practitioners.;;;https://dl.acm.org/doi/10.1145/3397453.3397458;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Multi-task Learning for Animal Species and Group Category Classification;;;['Donghyeon Kim', 'Younglo Lee', 'Hanseok Ko'];;;December 2019;;;ICIT '19: Proceedings of the 2019 7th International Conference on Information Technology: IoT and Smart City;;;Accurate animal sound classification is an important task in automated animal monitoring system. Such monitoring system is essential for preventing epidemics caused by animal disease. Based on such needs, there has been a variety of efforts to develop an accurate system performing animal sound classification in deep learning framework. Although many research issues and methods to address the issues were introduced, no one has yet to address overcoming the machine learning barriers induced by a single objective function. As learnable parameters only consider a single penalty at the output prediction for training, they cannot capture other characteristics contained in the dataset to extract more generalized prediction. This paper proposes a deep learning based multi-task learning framework for animal sound classification. Both animal species and group classification are performed in an end-to-end learning process. Experimental results show that the proposed multi-task method outperforms single-task method in our recorded animal sound dataset.;;;https://dl.acm.org/doi/10.1145/3377170.3377259;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Junction density based clustering algorithm for data with arbitrary shapes;;;['Ruijia Li', 'Zhiling Cai', 'Hong Wu'];;;February 2022;;;ICMLC '22: Proceedings of the 2022 14th International Conference on Machine Learning and Computing;;;Density-based clustering algorithms can deal with arbitrary shaped clusters in data. However, most of these algorithms face difficulties in handling large scale data, since they usually need to compute the distance between each pair of data points for density estimation. To alleviate this problem, we define a new type of density called junction density to measure the density of the junction region of two groups generated by K-means. Since the junction density is only computed for neighboring groups, the computation burden is small. Based on the junction density, we propose a new clustering method to merge the groups instead of directly clustering the data points. Specifically, it mines initial clusters in the groups then assigns the remaining groups to corresponding initial clusters. The experiments on several arbitrary shaped datasets demonstrate the efficiency and effectiveness of the proposed method.;;;https://dl.acm.org/doi/10.1145/3529836.3529860;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A Survey of Opinion Mining in Arabic: A Comprehensive System Perspective Covering Challenges and Advances in Tools, Resources, Models, Applications, and Visualizations;;;['Gilbert Badaro', 'Ramy Baly', 'Hazem Hajj', 'Wassim El-Hajj', 'Khaled Bashir Shaban', 'Nizar Habash', 'Ahmad Al-Sallab', 'Ali Hamdi'];;;None;;;ACM Transactions on Asian and Low-Resource Language Information Processing;;;Opinion-mining or sentiment analysis continues to gain interest in industry and academics. While there has been significant progress in developing models for sentiment analysis, the field remains an active area of research for many languages across the world, and in particular for the Arabic language, which is the fifth most-spoken language and has become the fourth most-used language on the Internet. With the flurry of research activity in Arabic opinion mining, several researchers have provided surveys to capture advances in the field. While these surveys capture a wealth of important progress in the field, the fast pace of advances in machine learning and natural language processing (NLP) necessitates a continuous need for a more up-to-date literature survey. The aim of this article is to provide a comprehensive literature survey for state-of-the-art advances in Arabic opinion mining. The survey goes beyond surveying previous works that were primarily focused on classification models. Instead, this article provides a comprehensive system perspective by covering advances in different aspects of an opinion-mining system, including advances in NLP software tools, lexical sentiment and corpora resources, classification models, and applications of opinion mining. It also presents future directions for opinion mining in Arabic. The survey also covers latest advances in the field, including deep learning advances in Arabic Opinion Mining. The article provides state-of-the-art information to help new or established researchers in the field as well as industry developers who aim to deploy an operational complete opinion-mining system. Key insights are captured at the end of each section for particular aspects of the opinion-mining system giving the reader a choice of focusing on particular aspects of interest.;;;https://dl.acm.org/doi/10.1145/3295662;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Combining clustering and classification algorithms for automatic bot detection: a case study on posts about COVID-19;;;['Diego Bezerra Lira', 'Fernando Xavier', 'Luciano Antonio Digiampietri'];;;June 2021;;;SBSI '21: Proceedings of the XVII Brazilian Symposium on Information Systems;;;In the last decade, there has been a great insertion of bots in several social media. Among the potentially harmful effects of these software agents, there are: the spread of computer viruses and different internet scams, and the spread of fake news, with emphasis on political-electoral and public health-related news. This work presents a new approach for bots’ detection on Twitter, combining the use of feature selection, clustering, and classification algorithms. The proposed approach was compared with more conventional ones (for example, without the use of clustering) and the premise used in this work proved to be true: the use of clustering, together with the features selection, allowed the production of better classification models in order to identify not only the bots who have an activity profile considered non-human (extremely active on Twitter) but also other bots whose profiles are more similar to humans’ ones. The best results of automatic detection of bots reached an overall accuracy of 96.8% and F1 score equal to 0.622. As an additional advantage, these values were achieved by decision-tree models, which can be considered explainable artificial intelligence models.;;;https://dl.acm.org/doi/10.1145/3466933.3466970;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Mining Approximate Acyclic Schemes from Relations;;;['Batya Kenig', 'Pranay Mundra', 'Guna Prasaad', 'Babak Salimi', 'Dan Suciu'];;;June 2020;;;SIGMOD '20: Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data;;;Acyclic schemes have numerous applications in databases and in machine learning, such as improved design, more efficient storage, and increased performance for queries and machine learning algorithms. Multivalued dependencies (MVDs) are the building blocks of acyclic schemes. The discovery from data of both MVDs and acyclic schemes is more challenging than other forms of data dependencies, such as Functional Dependencies, because these dependencies do not hold on subsets of data, and because they are very sensitive to noise in the data; for example a single wrong or missing tuple may invalidate the schema. In this paper we present Maimon, a system for discovering approximate acyclic schemes and MVDs from data. We give a principled definition of approximation, by using notions from information theory, then describe the two components of Maimon: mining for approximate MVDs, then reconstructing acyclic schemes from approximate MVDs. We conduct an experimental evaluation of Maimon on 20 real-world datasets, and show that it can scale up to 1M rows, and up to 30 columns.;;;https://dl.acm.org/doi/10.1145/3318464.3380573;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Secure Naïve Bayes Classification Protocol over Encrypted Data Using Fully Homomorphic Encryption;;;['Yoshiko Yasumura', 'Yu Ishimaki', 'Hayato Yamana'];;;December 2019;;;iiWAS2019: Proceedings of the 21st International Conference on Information Integration and Web-based Applications &amp; Services;;;Machine learning classification has a wide range of applications. In the big data era, a client may want to outsource classification tasks to reduce the computational burden at the client. Meanwhile, an entity may want to provide a classification model and classification services to such clients. However, applications such as medical diagnosis require sensitive data that both parties may not want to reveal. Fully homomorphic encryption (FHE) enables secure computation over encrypted data without decryption. By applying FHE, classification can be outsourced to a cloud without revealing any data. However, existing studies on classification over FHE do not achieve the scenario of outsourcing classification to a cloud while preserving the privacy of the classification model, client's data and result. In this work, we apply FHE to a naïve Bayes classifier and, to the best of our knowledge, propose the first concrete secure classification protocol that satisfies the above scenario.;;;https://dl.acm.org/doi/10.1145/3366030.3366056;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Concept-based classification of software defect reports;;;['Sangameshwar Patil'];;;May 2017;;;MSR '17: Proceedings of the 14th International Conference on Mining Software Repositories;;;Automatic identification of the defect type from the textual description of a software defect can significantly speedup as well as improve the software defect management life-cycle. This has been recognized in the research community and multiple solutions based on supervised learning approach have been proposed in the recent literature. However, these approaches need significant amount of labeled training data for use in real-life projects. In this paper, we propose to use Explicit Semantic Analysis (ESA) to carry out concept-based classification of software defect reports. We compute the "semantic similarity" between the defect type labels and the defect report in a concept space spanned by Wikipedia articles and then, assign the defect type which has the highest similarity with the defect report. This approach helps us to circumvent the problem of dependence on labeled training data. Experimental results show that using concept-based classification is a promising approach for software defect classification to avoid the expensive process of creating labeled training data and yet get accuracy comparable to the traditional supervised learning approaches. To the best of our knowledge, this is the first use of Wikipedia and ESA for software defect classification problem.;;;https://dl.acm.org/doi/10.1109/MSR.2017.20;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Deep Learning for Extreme Multi-label Text Classification;;;['Jingzhou Liu', 'Wei-Cheng Chang', 'Yuexin Wu', 'Yiming Yang'];;;August 2017;;;SIGIR '17: Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval;;;Extreme multi-label text classification (XMTC) refers to the problem of assigning to each document its most relevant subset of class labels from an extremely large label collection, where the number of labels could reach hundreds of thousands or millions. The huge label space raises research challenges such as data sparsity and scalability. Significant progress has been made in recent years by the development of new machine learning methods, such as tree induction with large-margin partitions of the instance spaces and label-vector embedding in the target space. However, deep learning has not been explored for XMTC, despite its big successes in other related areas. This paper presents the first attempt at applying deep learning to XMTC, with a family of new Convolutional Neural Network (CNN) models which are tailored for multi-label classification in particular. With a comparative evaluation of 7 state-of-the-art methods on 6 benchmark datasets where the number of labels is up to 670,000, we show that the proposed CNN approach successfully scaled to the largest datasets, and consistently produced the best or the second best results on all the datasets. On the Wikipedia dataset with over 2 million documents and 500,000 labels in particular, it outperformed the second best method by 11.7%~15.3% in precision@K and by 11.5%~11.7% in NDCG@K for K = 1,3,5.;;;https://dl.acm.org/doi/10.1145/3077136.3080834;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Emerging applications of machine learning in modern data management;;;['Amin Kamali', 'Calisto Zuzarte', 'Verena Kantere'];;;November 2021;;;CASCON '21: Proceedings of the 31st Annual International Conference on Computer Science and Software Engineering;;;In recent years, the applications of machine learning (ML) have proliferated in most aspects of traditional computer science. Data management discipline is no exception in this regard. Rule-based modules are being replaced by ML-based counterparts that effectively 'mine the rules' from experience. Approaches that rely on crude statistics are rapidly being outdated by the ones that 'learn' the functional dependencies, correlations, and skewness from the underlying data. These learning-based methods have an upper hand on many different fronts. On one hand, they promise to reduce the cost of development and maintenance of the highly complex classical modules. On the other hand, they avoid the 'one solution fits all' approach by effectively tailoring the behavior to fit the requirements of individual system instances. This workshop brought together leaders of cutting-edge research projects in the area and audience from academia and industry, to discuss some examples of using machine learning for modernizing different aspects of data management. The discussed examples covered four different areas: Query Optimization, Data Partitioning, Database Knobs Tuning, and Data Caching.;;;https://dl.acm.org/doi/10.5555/3507788.3507841;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Machine Learning at Microsoft with ML.NET;;;['Zeeshan Ahmed', 'Saeed Amizadeh', 'Mikhail Bilenko', 'Rogan Carr', 'Wei-Sheng Chin', 'Yael Dekel', 'Xavier Dupre', 'Vadim Eksarevskiy', 'Senja Filipi', 'Tom Finley', 'Abhishek Goswami', 'Monte Hoover', 'Scott Inglis', 'Matteo Interlandi', 'Najeeb Kazmi', 'Gleb Krivosheev', 'Pete Luferenko', 'Ivan Matantsev', 'Sergiy Matusevych', 'Shahab Moradi', 'Gani Nazirov', 'Justin Ormont', 'Gal Oshri', 'Artidoro Pagnoni', 'Jignesh Parmar', 'Prabhat Roy', 'Mohammad Zeeshan Siddiqui', 'Markus Weimer', 'Shauheen Zahirazami', 'Yiwen Zhu'];;;July 2019;;;KDD '19: Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining;;;Machine Learning is transitioning from an art and science into a technology available to every developer. In the near future, every application on every platform will incorporate trained models to encode data-based decisions that would be impossible for developers to author. This presents a significant engineering challenge, since currently data science and modeling are largely decoupled from standard software development processes. This separation makes incorporating machine learning capabilities inside applications unnecessarily costly and difficult, and furthermore discourage developers from embracing ML in first place. In this paper we present ML.NET, a framework developed at Microsoft over the last decade in response to the challenge of making it easy to ship machine learning models in large software applications. We present its architecture, and illuminate the application demands that shaped it. Specifically, we introduce DataView, the core data abstraction of ML.NET which allows it to capture full predictive pipelines efficiently and consistently across training and inference lifecycles. We close the paper with a surprisingly favorable performance study of ML.NET compared to more recent entrants, and a discussion of some lessons learned.;;;https://dl.acm.org/doi/10.1145/3292500.3330667;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Towards Model-based Pricing for Machine Learning in a Data Marketplace;;;['Lingjiao Chen', 'Paraschos Koutris', 'Arun Kumar'];;;June 2019;;;SIGMOD '19: Proceedings of the 2019 International Conference on Management of Data;;;Data analytics using machine learning (ML) has become ubiquitous in science, business intelligence, journalism and many other domains. While a lot of work focuses on reducing the training cost, inference runtime and storage cost of ML models, little work studies how to reduce the cost of data acquisition, which potentially leads to a loss of sellers' revenue and buyers' affordability and efficiency. In this paper, we propose a model-based pricing (MBP) framework, which instead of pricing the data, directly prices ML model instances. We first formally describe the desired properties of the MBP framework, with a focus on avoiding arbitrage. Next, we show a concrete realization of the MBP framework via a noise injection approach, which provably satisfies the desired formal properties. Based on the proposed framework, we then provide algorithmic solutions on how the seller can assign prices to models under different market scenarios (such as to maximize revenue). Finally, we conduct extensive experiments, which validate that the MBP framework can provide high revenue to the seller, high affordability to the buyer, and also operate on low runtime cost.;;;https://dl.acm.org/doi/10.1145/3299869.3300078;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A Sentiment Analysis Model for Faculty Comment Evaluation Using Ensemble Machine Learning Algorithms;;;['Jay-ar P. Lalata', 'Bobby Gerardo', 'Ruji Medina'];;;June 2019;;;BDE 2019: Proceedings of the 2019 International Conference on Big Data Engineering;;;Teacher evaluation is the systematic procedure done in educational institutions to review the performance of the teachers in a classroom. It aims to provide constructive feedback for teacher's professional growth which benefits students in their education. Students' feedback in the evaluation typically include textual comments which are unstructured but are rich with adequate information and insight about teacher's mastery of the course, teaching style, course content and learning experiences of the students. In this study, sentiment analysis or opinion mining was used to analyze the students' comments. An ensemble approach integrating five individual machine algorithms namely Naive Bayes, Logistic Regression, Support Vector Machine, Decision Tree and Random Forest algorithms were applied to classify the comments based on Majority Voting Principle. The experimental result shows that the ensemble classification system outperforms these individual classifiers with 90.32% accuracy. It helps to improve machine learning results producing better predictions compared to a single model.;;;https://dl.acm.org/doi/10.1145/3341620.3341638;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Opinion Mining in Facebook Regional Discussion Groups: A Case Study to Identify Health, Education and Security Posts in Discussion Groups;;;['Leonardo Augusto Sápiras', 'Rodrigo Antônio Weber'];;;May 2019;;;SBSI '19: Proceedings of the XV Brazilian Symposium on Information Systems;;;This paper presents the results a case study that apply opinion mining about health, security and education, using as source discussions in Facebook regional groups. The method used is quite different from other researches because it propose an approach to identify regional posts. Five different supervisioned learning algorithms was applied during the classification step. The results show that region's posts can be identified with this new approach.;;;https://dl.acm.org/doi/10.1145/3330204.3330221;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Let's shine together!: a comparative study between learning analytics and educational data mining;;;['Guanliang Chen', 'Vitor Rolim', 'Rafael Ferreira Mello', 'Dragan Gašević'];;;March 2020;;;LAK '20: Proceedings of the Tenth International Conference on Learning Analytics &amp; Knowledge;;;Learning Analytics and Knowledge (LAK) and Educational Data Mining (EDM) are two of the most popular venues for researchers and practitioners to report and disseminate discoveries in data-intensive research on technology-enhanced education. After the development of about a decade, it is time to scrutinize and compare these two venues. By doing this, we expected to inform relevant stakeholders of a better understanding of the past development of LAK and EDM and provide suggestions for their future development. Specifically, we conducted an extensive comparison analysis between LAK and EDM from four perspectives, including (i) the topics investigated; (ii) community development; (iii) community diversity; and (iv) research impact. Furthermore, we applied one of the most widely-used language modeling techniques (Word2Vec) to capture words used frequently by researchers to describe future works that can be pursued by building upon suggestions made in the published papers to shed light on potential directions for future research.;;;https://dl.acm.org/doi/10.1145/3375462.3375500;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Understanding and Visualizing Data Iteration in Machine Learning;;;['Fred Hohman', 'Kanit Wongsuphasawat', 'Mary Beth Kery', 'Kayur Patel'];;;April 2020;;;CHI '20: Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems;;;Successful machine learning (ML) applications require iterations on both modeling and the underlying data. While prior visualization tools for ML primarily focus on modeling, our interviews with 23 ML practitioners reveal that they improve model performance frequently by iterating on their data (e.g., collecting new data, adding labels) rather than their models. We also identify common types of data iterations and associated analysis tasks and challenges. To help attribute data iterations to model performance, we design a collection of interactive visualizations and integrate them into a prototype, Chameleon, that lets users compare data features, training/testing splits, and performance across data versions. We present two case studies where developers apply \system to their own evolving datasets on production ML projects. Our interface helps them verify data collection efforts, find failure cases stretching across data versions, capture data processing changes that impacted performance, and identify opportunities for future data iterations.;;;https://dl.acm.org/doi/10.1145/3313831.3376177;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Machine Learning for Detecting Data Exfiltration: A Review;;;['Bushra Sabir', 'Faheem Ullah', 'M. Ali Babar', 'Raj Gaire'];;;None;;;ACM Computing Surveys;;;Context: Research at the intersection of cybersecurity, Machine Learning (ML), and Software Engineering (SE) has recently taken significant steps in proposing countermeasures for detecting sophisticated data exfiltration attacks. It is important to systematically review and synthesize the ML-based data exfiltration countermeasures for building a body of knowledge on this important topic. Objective: This article aims at systematically reviewing ML-based data exfiltration countermeasures to identify and classify ML approaches, feature engineering techniques, evaluation datasets, and performance metrics used for these countermeasures. This review also aims at identifying gaps in research on ML-based data exfiltration countermeasures. Method: We used Systematic Literature Review (SLR) method to select and review 92 papers. Results: The review has enabled us to: (a) classify the ML approaches used in the countermeasures into data-driven, and behavior-driven approaches; (b) categorize features into six types: behavioral, content-based, statistical, syntactical, spatial, and temporal; (c) classify the evaluation datasets into simulated, synthesized, and real datasets; and (d) identify 11 performance measures used by these studies. Conclusion: We conclude that: (i) The integration of data-driven and behavior-driven approaches should be explored; (ii) There is a need of developing high quality and large size evaluation datasets; (iii) Incremental ML model training should be incorporated in countermeasures; (iv) Resilience to adversarial learning should be considered and explored during the development of countermeasures to avoid poisoning attacks; and (v) The use of automated feature engineering should be encouraged for efficiently detecting data exfiltration attacks.;;;https://dl.acm.org/doi/10.1145/3442181;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Pattern Classification of Instantaneous Cognitive Task-load Through GMM Clustering, Laplacian Eigenmap, and Ensemble SVMs;;;['Jianhua Zhang', 'Zhong Yin', 'Rubin Wang'];;;None;;;IEEE/ACM Transactions on Computational Biology and Bioinformatics;;;The identification of the temporal variations in human operator cognitive task-load CTL is crucial for preventing possible accidents in human-machine collaborative systems. Recent literature has shown that the change of discrete CTL level during human-machine system operations can be objectively recognized using neurophysiological data and supervised learning technique. The objective of this work is to design subject-specific multi-class CTL classifier to reveal the complex unknown relationship between the operator's task performance and neurophysiological features by combining target class labeling, physiological feature reduction and selection, and ensemble classification techniques. The psychophysiological data acquisition experiments were performed under multiple human-machine process control tasks. Four or five target classes of CTL were determined by using a Gaussian mixture model and three human performance variables. By using Laplacian eigenmap, a few salient EEG features were extracted, and heart rates were used as the input features of the CTL classifier. Then, multiple support vector machines were aggregated via majority voting to create an ensemble classifier for recognizing the CTL classes. Finally, the obtained CTL classification results were compared with those of several existing methods. The results showed that the proposed methods are capable of deriving a reasonable number of target classes and low-dimensional optimal EEG features for individual human operator subjects.;;;https://dl.acm.org/doi/10.1109/TCBB.2016.2561927;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Rotom: A Meta-Learned Data Augmentation Framework for Entity Matching, Data Cleaning, Text Classification, and Beyond;;;['Zhengjie Miao', 'Yuliang Li', 'Xiaolan Wang'];;;June 2021;;;SIGMOD '21: Proceedings of the 2021 International Conference on Management of Data;;;Deep Learning revolutionizes almost all fields of computer science including data management. However, the demand for high-quality training data is slowing down deep neural nets' wider adoption. To this end, data augmentation (DA), which generates more labeled examples from existing ones, becomes a common technique. Meanwhile, the risk of creating noisy examples and the large space of hyper-parameters make DA less attractive in practice. We introduce Rotom, a multi-purpose data augmentation framework for a range of data management and mining tasks including entity matching, data cleaning, and text classification. Rotom features InvDA, a new DA operator that generates natural yet diverse augmented examples by formulating DA as a seq2seq task. The key technical novelty of Rotom is a meta-learning framework that automatically learns a policy for combining examples from different DA operators, whereby combinatorially reduces the hyper-parameters space. Our experimental results show that Rotom effectively improves a model's performance by combining multiple DA operators, even when applying them individually does not yield performance improvement. With this strength, Rotom outperforms the state-of-the-art entity matching and data cleaning systems in the low-resource settings as well as two recently proposed DA techniques for text classification.;;;https://dl.acm.org/doi/10.1145/3448016.3457258;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Machine learning predictive analytics for player movement prediction in NBA: applications, opportunities, and challenges;;;['Dembe Koi Stephanos', 'Ghaith Husari', 'Brian T. Bennett', 'Emma Stephanos'];;;April 2021;;;ACM SE '21: Proceedings of the 2021 ACM Southeast Conference;;;Recently, strategies of National Basketball Association (NBA) teams have evolved with the skillsets of players and the emergence of advanced analytics. This has led to a more free-flowing game in which traditional positions and play calls have been replaced with player archetypes and read-and-react offensives that operate off a variety of isolated actions. The introduction of position tracking technology by SportVU has aided the analysis of these patterns by offering a vast dataset of on-court behavior. There have been numerous attempts to identify and classify patterns by evaluating the outcomes of offensive and defensive strategies associated with actions within this dataset, a job currently done manually by reviewing game tape. Some of these classification attempts have used supervised techniques that begin with labeled sets of plays and feature sets to automate the detection of future cases. Increasingly, however, deep learning approaches such as convolutional neural networks have been used in conjunction with player trajectory images generated from positional data. This enables classification to occur in a bottom-up manner, potentially discerning unexpected patterns. Others have shifted focus from classification, instead using this positional data to evaluate the success of a given possession based on spatial factors such as defender proximity and player factors such as role or skillset. While play/action detection, classification and analysis have each been addressed in literature, a comprehensive approach that accounts for modern trends is still lacking. In this paper, we discuss various approaches to action detection and analysis and ultimately propose an outline for a deep learning approach of identification and analysis resulting in a queryable dataset complete with shot evaluations, thus combining multiple contributions into a serviceable tool capable of assisting and automating much of the work currently done by NBA professionals.;;;https://dl.acm.org/doi/10.1145/3409334.3452064;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Process-mining based dynamic software architecture reconstruction;;;['Tijmen de Jong', 'Jan Martijn E. M. van der Werf'];;;September 2019;;;ECSA '19: Proceedings of the 13th European Conference on Software Architecture - Volume 2;;;Dynamic architecture reconstruction approaches aim to reconstruct the run-time architecture of a software system. Process mining is an emerging field combining process analytics and data science techniques. In this paper, we present an approach that creates interactive architecture visualizations without requiring any knowledge of the source code of the system under study. The approach is implemented in the tool AJPOLog. with two case studies, we show that this approach creates reliable results with relatively little effort. Though the studies also show that more research is needed to apply process mining techniques in the field of architecture reconstruction.;;;https://dl.acm.org/doi/10.1145/3344948.3344985;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Large-Scale Frequent Episode Mining from Complex Event Sequences with Hierarchies;;;['Xiang Ao', 'Haoran Shi', 'Jin Wang', 'Luo Zuo', 'Hongwei Li', 'Qing He'];;;None;;;ACM Transactions on Intelligent Systems and Technology;;;Frequent Episode Mining (FEM), which aims at mining frequent sub-sequences from a single long event sequence, is one of the essential building blocks for the sequence mining research field. Existing studies about FEM suffer from unsatisfied scalability when faced with complex sequences as it is an NP-complete problem for testing whether an episode occurs in a sequence. In this article, we propose a scalable, distributed framework to support FEM on “big” event sequences. As a rule of thumb, “big” illustrates an event sequence is either very long or with masses of simultaneous events. Meanwhile, the events in this article are arranged in a predefined hierarchy. It derives some abstractive events that can form episodes that may not directly appear in the input sequence. Specifically, we devise an event-centered and hierarchy-aware partitioning strategy to allocate events from different levels of the hierarchy into local processes. We then present an efficient special-purpose algorithm to improve the local mining performance. We also extend our framework to support maximal and closed episode mining in the context of event hierarchy, and to the best of our knowledge, we are the first attempt to define and discover hierarchy-aware maximal and closed episodes. We implement the proposed framework on Apache Spark and conduct experiments on both synthetic and real-world datasets. Experimental results demonstrate the efficiency and scalability of the proposed approach and show that we can find practical patterns when taking event hierarchies into account.;;;https://dl.acm.org/doi/10.1145/3326163;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Pattern Classification of Instantaneous Cognitive Task-load Through GMM Clustering, Laplacian Eigenmap, and Ensemble SVMs;;;['Jianhua Zhang', 'Zhong Yin', 'Rubin Wang'];;;None;;;IEEE/ACM Transactions on Computational Biology and Bioinformatics;;;The identification of the temporal variations in human operator cognitive task-load CTL is crucial for preventing possible accidents in human-machine collaborative systems. Recent literature has shown that the change of discrete CTL level during human-machine system operations can be objectively recognized using neurophysiological data and supervised learning technique. The objective of this work is to design subject-specific multi-class CTL classifier to reveal the complex unknown relationship between the operator's task performance and neurophysiological features by combining target class labeling, physiological feature reduction and selection, and ensemble classification techniques. The psychophysiological data acquisition experiments were performed under multiple human-machine process control tasks. Four or five target classes of CTL were determined by using a Gaussian mixture model and three human performance variables. By using Laplacian eigenmap, a few salient EEG features were extracted, and heart rates were used as the input features of the CTL classifier. Then, multiple support vector machines were aggregated via majority voting to create an ensemble classifier for recognizing the CTL classes. Finally, the obtained CTL classification results were compared with those of several existing methods. The results showed that the proposed methods are capable of deriving a reasonable number of target classes and low-dimensional optimal EEG features for individual human operator subjects.;;;https://dl.acm.org/doi/10.1109/TCBB.2016.2561927;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A Label Extension Schema for Improved Text Emotion Classification;;;['Zongxi Li', 'Xianming Li', 'Haoran Xie', 'Qing Li', 'Xiaohui Tao'];;;December 2021;;;WI-IAT '21: IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology;;;Due to the subjectiveness and fuzziness of emotions in texts, researchers have been aware that it is ubiquitous to observe multiple emotions in a sentence, and the one-hot label approach is not informative enough in emotion-relevant text classification tasks. Therefore, to facilitate the classification task, recent works focus on generating and employing a coarse-grained emotion distribution, which is based on coarse-grained labels provided by the underlying dataset. Although such methods can alleviate the problem of overfitting and improve robustness, they may cause inter-class confusion between similar emotion categories and introduce undesirable noise during training. Meanwhile, current studies neglect the fine-grained emotions associated with these coarse-grained labels. To address the issue caused by utilizing a coarse-grained distribution, we propose in this paper a general and novel emotion label extension method based on fine-grained emotions. Specifically, we first identify a mapping function between coarse-grained emotions and fine-grained emotion concepts, and extend the original label space with specific fine-grained emotions. Then, we generate a fine-grained emotion distribution by employing a rule-based method, and utilize it as a model constraint to incorporate the dependencies among fine-grained emotions to predict the original coarse-grained emotion labels. We conduct extensive experiments to demonstrate the effectiveness of our proposed label extension method. The results indicate that our proposed method can produce notable improvements over baseline models on the applied datasets.;;;https://dl.acm.org/doi/10.1145/3486622.3493935;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Prediction of Injuries and Fatalities in Aviation Accidents through Machine Learning;;;['R. Alan Burnett', 'Dong Si'];;;May 2017;;;ICCDA '17: Proceedings of the International Conference on Compute and Data Analysis;;;This paper concerns application of various machine learning techniques to derive classification models for predicting conditions that increase the likelihood of aviation accidents involving fatalities and serious injuries. Machine learning classification techniques, including Decision Trees, K-Nearest Neighbors, Support Vector Machines (SVMs), and Artificial Neural Networks (ANNs) are applied to datasets derived from original data obtained from Federal Aviation Administration (FAA) Aviation Accident and Incident Records from 1975-2002. The accident data are filtered to focus on FAA Part 91 (General Aviation) accidents involving powered, fixed-wing, manufactured aircraft. The results demonstrate ANNs to yield the most accurate prediction levels for both fatal accidents and accidents involving severe injuries. The results also demonstrate that machine learning approaches may yield insightful information beyond what is available through traditional statistical analysis methodologies.;;;https://dl.acm.org/doi/10.1145/3093241.3093288;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Evaluation of large scale RoI mining applications in edge computing environments;;;['Loris Belcastro', 'Alberto Falcone', 'Alfredo Garro', 'Fabrizio Marozzo'];;;September 2021;;;DS-RT '21: Proceedings of the 2021 IEEE/ACM 25th International Symposium on Distributed Simulation and Real Time Applications;;;Researchers and leading IT companies are increasingly proposing hybrid cloud/edge solutions, which allow to move part of the workload from the cloud to the edge nodes, by reducing the network traffic and energy consumption, but also getting low latency responses near to real time. This paper proposes a novel hybrid cloud/edge architecture for efficiently extracting Regions-of-Interest (RoI) in a large scale urban computing environment, where a huge amount of geotagged data are generated and collected through users's mobile devices. The proposal is organized in two parts: (i) a modeling part that defines the hybrid cloud/edge architecture capable of managing a large number of devices; (ii) a simulation part in which different design choices are evaluated to improve the performance of RoI mining algorithms in terms of processing time, network delay, task failure and computing resource utilization. Several experiments have been carried out to evaluate the performance of the proposed architecture starting from different configurations and orchestration policies. The achieved results showed that the proposed hybrid cloud/edge architecture, with the use of two novel orchestration policies (network- and utilization-based), permits to improve the exploitation of resources, also granting low network latency and task failure rate in comparison with other standard scenarios (only-edge or only-cloud).;;;https://dl.acm.org/doi/10.1109/DS-RT52167.2021.9576131;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Anomaly detection for machinery by using Big Data Real-Time processing and clustering technique;;;['Zhuo Wang', 'Yanghui Zhou', 'Gangmin Li'];;;November 2019;;;ICBDR '19: Proceedings of the 3rd International Conference on Big Data Research;;;This paper aims to apply techniques of Big Data Analytics including K-Means Clustering to diagnose potential problems for offshore rotating machinery. The innovative methods are attempted in both Batch K-Means and Streaming K-Means. Their performances are compared with the conventional signal analysis method. Both K-Means models have a better performance on detecting significant mechanical faults as anomalies for offshore rotating machinery which can be considered as appropriate method for machine operational maintenance.;;;https://dl.acm.org/doi/10.1145/3372454.3372480;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Text Classification of Micro-blog's "Tree Hole" Based on Convolutional Neural Network;;;['Xiaoli Zhao', 'Shaofu Lin', 'Zhisheng Huang'];;;December 2018;;;ACAI '18: Proceedings of the 2018 International Conference on Algorithms, Computing and Artificial Intelligence;;;Rapid recognition of depression is an important step in the research of depression. With the development of social networking platform, more and more depressive patients regard micro-blog as one of the ways of self-expression. And this information provides support of data for the recognition of depression. In this study, the data crawled from micro-blog's "tree hole"[1] is used as experimental corpus. Combined with the features of micro-blog text with depression, a double-input convolutional neural network structure (D-CNN) is proposed. This method takes both the external features and the semantic features of text as input. By comparing the accuracy of classification with Support Vector Machine (SVM) and convolutional neural network (CNN) algorithm, it is finally shown that the D-CNN can further improve the accuracy of text classify.;;;https://dl.acm.org/doi/10.1145/3302425.3302501;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Multi-Label Emotion Mining From Student Comments;;;['Angelina Tzacheva', 'Jaishree Ranganathan', 'Rajendra Jadi'];;;July 2019;;;ICIEI '19: Proceedings of the 4th International Conference on Information and Education Innovations;;;Science, Technology, Engineering, and Mathematics (STEM) education is gaining more attention not today but has been under research, and discussion for the past few decades. Factors that are considered for research include but not limited to the following, culture on campus, teaching and learning models, and student experience in classroom, gender bias, and stereotypes. One of the major factors is the teaching model adopted which have impact on the student learning styles and their experience in the classroom. Teaching models include traditional models, modern flipped class-room models, and active learning approaches. This study focuses on active learning approaches and their impact on students learning and experience. Light-weight team is an active learning approach, in which team members have little direct impact on each other's final grades, with significant long-term socialization. In this work we used data from end of course student evaluation. We propose extend our previous method for assessing the effectiveness of the Light-weight team teaching model, through automatic detection of emotions in student feedback in computer science course by creating multi-label for each text comment. The students are surveyed about their feelings and thoughts about teaching and learning models adopted and student experience in the classroom. Results show that implementation of these methods result in increased positivity in student emotions.;;;https://dl.acm.org/doi/10.1145/3345094.3345112;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Online Analysis of Simulation Data with Stream-based Data Mining;;;['Niclas Feldkamp', 'Soeren Bergmann', 'Steffen Strassburger'];;;May 2017;;;SIGSIM-PADS '17: Proceedings of the 2017 ACM SIGSIM Conference on Principles of Advanced Discrete Simulation;;;Discrete event simulation is an accepted instrument for investigating the dynamic behavior of complex systems and evaluating processes. Usually simulation experts conduct simulation experiments for a predetermined system specification by manually varying parameters through educated assumptions and according to a prior defined goal. As an alternative, data farming and knowledge discovery in simulation data are ongoing and popular methods in order to uncover unknown relationships and effects in the model to gain useful information about the underlying system. Those methods usually demand broad scale and data intensive experimental design, so computing time can quickly become large. As a solution to that, we extend an existing concept of knowledge discovery in simulation data with an online stream mining component to get data mining results even while experiments are still running. For this purpose, we introduce a method for using decision tree classification in combination with clustering algorithms for analyzing simulation output data that considers the flow of experiments as a data stream. A prototypical implementation proves the basic applicability of the concept and yields large possibilities for future research.;;;https://dl.acm.org/doi/10.1145/3064911.3064915;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
E-Commerce Merchant Classification using Website Information;;;['Galuh Tunggadewi Sahid', 'Rahmad Mahendra', 'Indra Budi'];;;June 2019;;;WIMS2019: Proceedings of the 9th International Conference on Web Intelligence, Mining and Semantics;;;With the rapid growth of the e-commerce landscape, classifying e-commerce merchants has become an important task as it is an integral part of various processes in e-commerce. One of the examples is merchant on boarding, where the category of an e-commerce merchant has proven to be a good indicator of the risk of the merchant. However, since most of e-commerce businesses do not have brick-and-mortar stores from which we can assess it directly, the only source of information regarding the merchant itself is its website. Thus, we can view this problem as a web classification problem, where we classify e-commerce websites into a category. In this research, we aim to build an end-to-end classification system for e-commerce websites. There are a few challenges such as the number of pages to be processed, imbalanced dataset, and the language of e-commerce websites that can be mixed language. We built a website classification system and experimented with case study of Indonesian and English e-commerce webs, that are classified into 37 different categories. Our best result achieved an F-score of 0.83.;;;https://dl.acm.org/doi/10.1145/3326467.3326486;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Effective Media Traffic Classification Using Deep Learning;;;['Qing Lyu', 'Xingjian Lu'];;;March 2019;;;ICCDA '19: Proceedings of the 2019 3rd International Conference on Compute and Data Analysis;;;Traffic classification (TC) is very important as it can provide useful information which can be used in the flexible management of the network. However, TC has become more and more complicated because of the emergence of various network applications and techniques. In this paper, we apply deep learning based method to the classification of four different kinds of media traffic, i.e., audio, picture, text and video. We collect traffic data from the real network environment. Multilayer Perceptron (MLP) and Convolutional Neural Network (CNN) based traffic classification methods are designed to accurately classify the target traffic into different categories. We found that MLP has very good performance in most scenarios. Moreover, specific architecture can reduce the training time of the neural network in the classification.;;;https://dl.acm.org/doi/10.1145/3314545.3316278;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A Deep Learning Approach to the Malware Classification Problem using Autoencoders;;;['Dhiego Ramos Pinto', 'Julio Cesar Duarte', "Ricardo Sant'Ana"];;;May 2019;;;SBSI '19: Proceedings of the XV Brazilian Symposium on Information Systems;;;Detecting malicious code or categorizing it among families has become an increasingly difficult task. Malware1 exploits vulnerabilities and employ sophisticated techniques to avoid their detection and further classification, challenging cybersecurity teams, governments, enterprises, and the ordinary user, causing uncountable losses annually. Traditional machine learning algorithms have been used to attack the problem, although, these methods are heavily relying on domain expertise to be successful. Deep Learning methods requires less dependency on feature engineering, discovering the important features straightly from the raw data, recognizing patterns that humans usually can't. This work presents a deep learning approach for malware multi-class classification based on an unsupervised pre-trained classifier, using opcodes and its operands frequencies as raw data, ignoring knowledge that could be acquired from any known features from the malware families. The results confirmed that the approach is well succeeded and our best model achieved a MacroF1 of 93.14% a competitive result comparing to best-known classifier, since it uses less information about the malware.;;;https://dl.acm.org/doi/10.1145/3330204.3330229;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Functional Classification of Websites;;;['Najlah Gali', 'Radu Mariescu Istodor', 'Pasi Fränti'];;;December 2017;;;SoICT '17: Proceedings of the 8th International Symposium on Information and Communication Technology;;;We propose a novel method to classify websites based on their functional purpose. A website is classified either as single service, brand or service directory. We utilize a number of features that are derived from the link of the website, the postal addresses found in the website, the size of the website, and the text of the anchor element in the Document Object Model tree. We utilize two models to perform the classification task: decision tree and clustering-based models. Our method is fully automated and does not require extensive training data or user interaction. The proposed website classifier improves the baseline by 2 percentage points in case of single service, 33 percentage points in case of brand and 18 percentage points in case of service directory.;;;https://dl.acm.org/doi/10.1145/3155133.3155178;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Prediction of Coronary Heart Disease using Machine Learning: An Experimental Analysis;;;['Amanda H. Gonsalves', 'Fadi Thabtah', 'Rami Mustafa A. Mohammad', 'Gurpreet Singh'];;;July 2019;;;ICDLT '19: Proceedings of the 2019 3rd International Conference on Deep Learning Technologies;;;The field of medical analysis is often referred to be a valuable source of rich information. Coronary Heart Disease (CHD) is one of the major causes of death all around the world therefore early detection of CHD can help reduce these rates. The challenge lies in the complexity of the data and correlations when it comes to prediction using conventional techniques. The aim of this research is to use the historical medical data to predict CHD using Machine Learning (ML) technology. The scope of this research is limited to using three supervised learning techniques namely Naïve Bayes (NB), Support Vector Machine (SVM) and Decision Tree (DT), to discover correlations in CHD data that might help improving the prediction rate. Using the South African Heart Disease dataset of 462 instances, intelligent models are derived by the considered ML techniques using 10-fold cross validation. Empirical results using different performance evaluation measures report that probabilistic models derived by NB are promising in detecting CHD.;;;https://dl.acm.org/doi/10.1145/3342999.3343015;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Collective classification in social networks;;;['Omar Jaafor', 'Babiga Birregah'];;;July 2017;;;ASONAM '17: Proceedings of the 2017 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining 2017;;;Classification is one of the most studied subjects in machine learning. Most classification methods that were developed this last decade either account for structure (interactions, relationships) or attributes (text, numerical, etc). This leads to ignoring significant patterns in a dataset that could only be captured by analyzing the features of an item and its interactions. Collective classification methods use both structure and attributes, often by aggregating data from neighbors of a node and learning a model on the aggregated data. In social networks, the degree distribution of nodes follows a power law where few nodes have many neighbors. High degree nodes have incoming links from low degree nodes of different classes and many nodes have very few edges. Hence, using only local structure may lead to poor predictions. Also, many social networks allow for different types of interactions (retweet, reply, like, etc.) that affect classification differently. This article proposes a collective classification method that makes use of the structure of a network to determine its neighbors. It then presents experiments aimed at detecting jihadi propagandists and malware distributors on social networks.;;;https://dl.acm.org/doi/10.1145/3110025.3110128;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
CAST: A Correlation-based Adaptive Spectral Clustering Algorithm on Multi-scale Data;;;['Xiang Li', 'Ben Kao', 'Caihua Shan', 'Dawei Yin', 'Martin Ester'];;;August 2020;;;KDD '20: Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining;;;We study the problem of applying spectral clustering to cluster multi-scale data, which is data whose clusters are of various sizes and densities. Traditional spectral clustering techniques discover clusters by processing a similarity matrix that reflects the proximity of objects. For multi-scale data, distance-based similarity is not effective because objects of a sparse cluster could be far apart while those of a dense cluster have to be sufficiently close. Following [16], we solve the problem of spectral clustering on multi-scale data by integrating the concept of objects' "reachability similarity" with a given distance-based similarity to derive an objects' coefficient matrix. We propose the algorithm CAST that applies trace Lasso to regularize the coefficient matrix. We prove that the resulting coefficient matrix has the "grouping effect" and that it exhibits "sparsity". We show that these two characteristics imply very effective spectral clustering. We evaluate CAST and 10 other clustering methods on a wide range of datasets w.r.t. various measures. Experimental results show that CAST provides excellent performance and is highly robust across test cases of multi-scale data.;;;https://dl.acm.org/doi/10.1145/3394486.3403086;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A Deep Learning approach to Hyperspectral Image Classification using an improved Hybrid 3D-2D Convolutional Neural Network;;;['Dimitra Koumoutsou', 'Eleni Charou'];;;September 2020;;;SETN 2020: 11th Hellenic Conference on Artificial Intelligence;;;In recent years, the task of Hyperspectral Image (HSI) classification has appeared in various fields, including Remote Sensing. Meanwhile, the evolution of Deep Learning, and the prevalence of the Convolutional Neural Network (CNN) has revolutionized the way unstructured, especially visual, data are processed. 2D CNN have proved highly efficient in exploiting the spatial information of images, but in HSI classification, data contain both spectral and spatial features. To make use of these characteristics, many variations of a 3D CNN have been proposed, but a 3D Convolution comes at a high computational cost. A fusion of 3D and 2D convolutions decreases processing time by distributing spectral-spatial feature extraction across a lighter, less complex model. An enhanced Hybrid network architecture is proposed alongside a data preprocessing plan, with the aim of achieving a significant improvement in classification results. Four benchmark datasets (Indian Pines, Pavia University, Salinas and Data Fusion 2013 Contest) are used to compare the model to other hand-crafted or deep learning architectures. It is demonstrated that the proposed network outperforms state-of-the-art approaches in terms of classification accuracy, while avoiding some commonly used, computationally expensive design choices.;;;https://dl.acm.org/doi/10.1145/3411408.3411462;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Seeds Classification and Quality Testing Using Deep Learning and YOLO v5;;;['Nidhi Kundu', 'Geeta Rani', 'Vijaypal Singh Dhaka'];;;August 2021;;;DSMLAI '21': Proceedings of the International Conference on Data Science, Machine Learning and Artificial Intelligence;;;Segregation of seeds of different crops grown in the mixed cropping is a major cause of concern for the farmers as well as the food industry. Also, the classification and packaging of seeds based on their quality is a challenging task for farmers and agro-industries. Moreover, Post-thrashing separation of seeds by the traditional techniques such as sieving, hand-picking, etc. is a time-consuming and tedious task. Thus, there is a need to automate seed segregation. The potential of deep learning and machine learning techniques in object detection, classification, and pattern recognition motivated the researchers to employ these techniques for the automatic segregation of seeds at the harvesting site. The techniques proposed so far focus on the classification of seeds of different crops. Limited research work is observed that focuses on the classification of seeds of crops grown as a part of mixed cropping as well as seeds of different quality standards. Also, there is a huge scope to improve the classification performance of the proposed models. The purpose of this research to develop the deep learning-based system 'Mixed Cropping Seed Classifier and Quality Tester (MCSCQT)' for accurate classification and quality testing of seeds based on their shape, color, and texture. The system is trained on the dataset comprising labelled images of healthy and diseased seeds of pearl millet and maize. It reports the highest precision and recall of 99%. The efficacy of the system in discriminating the seeds of pearl millet and maize may prove a game-changer for the food industry. Also, its capability in recognition of diseased and healthy seeds of maize enhances its utility in the food industry.;;;https://dl.acm.org/doi/10.1145/3484824.3484913;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Horse Breed Classification Based on Transfer Learning;;;['Yang Fu', 'Xiangnian Huang', 'Yunfeng Li'];;;November 2020;;;ICAIP '20: Proceedings of the 4th International Conference on Advances in Image Processing;;;Expert identification of horse breeds is an age-old task that can now be identified using genetic techniques. However, neither approach is cheap nor efficient. The automatic classification of horse breeds by computer vision is an effective solution. In this paper, we solve this task by proposing a novel method using transfer learning of pre-trained deep convolution neural networks architectures. The pre-trained convolutional neural networks include MobilenetV2, Mobilenet, Xception, VGG16, and VGG19. We use the keras deep learning framework, and train these deep convolution neural networks for transfer learning, which overcomes the problem of small amount of data in the early stage. An extensive experimental study on various horse breeds datasets shows that our method obtains an average accuracy rate of automatic classification of horse breeds to 89.34%, which has obvious advantage over other deep convolutional neural network models such as xception, vgg16, vgg19 and self-made convolutional neural network.;;;https://dl.acm.org/doi/10.1145/3441250.3441264;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Argument Mining: A Survey;;;['John Lawrence', 'Chris Reed'];;;None;;;Computational Linguistics;;;Argument mining is the automatic identification and extraction of the structure of inference and reasoning expressed as arguments presented in natural language. Understanding argumentative structure makes it possible to determine not only what positions people are adopting, but also why they hold the opinions they do, providing valuable insights in domains as diverse as financial market prediction and public relations. This survey explores the techniques that establish the foundations for argument mining, provides a review of recent advances in argument mining techniques, and discusses the challenges faced in automatically extracting a deeper understanding of reasoning expressed in language in general.;;;https://dl.acm.org/doi/10.1162/coli_a_00364;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Big data scalability based on Spark Machine Learning Libraries;;;['Anna Karen Garate-Escamilla', 'Amir Hajjam El Hassani', 'Emmanuel Andres'];;;November 2019;;;ICBDR '19: Proceedings of the 3rd International Conference on Big Data Research;;;The paper introduces the challenge of scalability in machine learning algorithms suitable for massive datasets. Today, big data has relevant applications in the industry due to improvements in the system performance and by turning information into knowledge. Big data challenges include the lack of strategies to process computational cost and the large amount of data when computing machine learning predictions. To overcome these scalability issues, it is convenient to work with distributed and parallelized architecture across multiple nodes. The approach is based on Apache Spark, an in-memory distributed application that offers extensive machine learning libraries. The main contribution of the study is to measure the scalability by calculating the execution time that a classifier achieves with larger workloads. We validate our classifier models with experiments on logistic regression and random forest by studying their adaptability to the Apache Spark framework. The present work expects to combine the areas of big data and machine learning on scalability, and the use of optimization methods, cache and persist. In addition, a comparison between the classifiers is provided. The evaluation experiments show that logistic regression performed the shortest execution time and best scalability.;;;https://dl.acm.org/doi/10.1145/3372454.3372469;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Keeping the Data Lake in Form: Proximity Mining for Pre-Filtering Schema Matching;;;['Ayman Alserafi', 'Alberto Abelló', 'Oscar Romero', 'Toon Calders'];;;None;;;ACM Transactions on Information Systems;;;Data lakes (DLs) are large repositories of raw datasets from disparate sources. As more datasets are ingested into a DL, there is an increasing need for efficient techniques to profile them and to detect the relationships among their schemata, commonly known as holistic schema matching. Schema matching detects similarity between the information stored in the datasets to support information discovery and retrieval. Currently, this is computationally expensive with the volume of state-of-the-art DLs. To handle this challenge, we propose a novel early-pruning approach to improve efficiency, where we collect different types of content metadata and schema metadata about the datasets, and then use this metadata in early-pruning steps to pre-filter the schema matching comparisons. This involves computing proximities between datasets based on their metadata, discovering their relationships based on overall proximities and proposing similar dataset pairs for schema matching. We improve the effectiveness of this task by introducing a supervised mining approach for effectively detecting similar datasets that are proposed for further schema matching. We conduct extensive experiments on a real-world DL that proves the success of our approach in effectively detecting similar datasets for schema matching, with recall rates of more than 85% and efficiency improvements above 70%. We empirically show the computational cost saving in space and time by applying our approach in comparison to instance-based schema matching techniques.;;;https://dl.acm.org/doi/10.1145/3388870;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Analysis of Hotspot Data for Drought Clustering Using K-Means Algorithm;;;['Ekki Rizki Ramadhan', 'Edi Sutoyo', 'Ahmad Musnansyah', 'Halda Aditya Belgaman'];;;September 2020;;;ICONETSI '20: Proceedings of the 2020 International Conference on Engineering and Information Technology for Sustainable Industry;;;Drought is a disaster that is often experienced in Indonesia. This disaster occurred because Indonesia's geographical location is on the equator. Drought has had a major impact on the community such as crop failure, forest fires, soil damage, the emergence of disease outbreaks, and the extinction of animals and plants. Based on data from the Ministry of Environment of the Republic of Indonesia, the distribution of Riau's hotspots is quite unique. It is said so, because in this distribution, Riau has increased in every February and March as many as 277 and 248 hotspots in the last two years, namely between 2018 and 2019. To anticipate the drought that occurred in Riau, the clustering of drought-prone areas was conducted based on the analysis of hotspots data. This clustering of vulnerable areas is done by the K-Means algorithm. In determining the number of clusters of vulnerable areas, the elbow method is used as a determinant and produces as many as 4 cluster. The results of these method were analyzed by the silhouette coefficient. The result of analyzed is 0.388632163 and were classified as well-clustered. From these results, Rokan Hilir, Bengkalis, Kota Dumai are the dangerous district with 3106, 2361, and 117 point of dangerous distribution, respectively.;;;https://dl.acm.org/doi/10.1145/3429789.3429824;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Mining Rank Data;;;['Sascha Henzgen', 'Eyke Hüllermeier'];;;None;;;ACM Transactions on Knowledge Discovery from Data;;;The problem of frequent pattern mining has been studied quite extensively for various types of data, including sets, sequences, and graphs. Somewhat surprisingly, another important type of data, namely rank data, has received very little attention in data mining so far. In this article, we therefore address the problem of mining rank data, that is, data in the form of rankings (total orders) of an underlying set of items. More specifically, two types of patterns are considered, namely frequent rankings and dependencies between such rankings in the form of association rules. Algorithms for mining frequent rankings and frequent closed rankings are proposed and tested experimentally, using both synthetic and real data.;;;https://dl.acm.org/doi/10.1145/3363572;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Using Classification Technique for Customer Relationship Management based on Thai Social Media Data;;;['Todsanai Chumwatana', 'Karnsiree Wongkolkitsilp'];;;February 2019;;;ICCAE 2019: Proceedings of the 2019 11th International Conference on Computer and Automation Engineering;;;Many businesses nowadays use social media as a main channel to connect with their customers. To utilize the data gained from social media, businesses can manage the relationship with customers effectively. This paper proposed the technique classifying the customer intentions into 2 groups; purchase intention and quit intention, by analyzing the text-based data collected from social media platforms. The analyzing process consists of 4 steps including source identification, data extraction, data preparation, and data classification. A thousand of Thai social media texts were used as an input dataset for training and testing steps, which apply to two classification models: Naïve Bayes and Support Vector Machine (SVM). The accuracy performance of SVM model is 78.1% while Naïve Bayes provided 63.4% accuracy. As a result, from the large number of texts posted and commented on social media, the businesses can identify their customers intention in order to manage the relationship with them; by approaching the customers who intend to purchase with a sales offer as well as solving the problems for those who are quitting to reduce the customer churn rate.;;;https://dl.acm.org/doi/10.1145/3313991.3314010;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Coupled Clustering Ensemble by Exploring Data Interdependence;;;['Can Wang', 'Chi-Hung Chi', 'Zhong She', 'Longbing Cao', 'Bela Stantic'];;;None;;;ACM Transactions on Knowledge Discovery from Data;;;Clustering ensembles combine multiple partitions of data into a single clustering solution. It is an effective technique for improving the quality of clustering results. Current clustering ensemble algorithms are usually built on the pairwise agreements between clusterings that focus on the similarity via consensus functions, between data objects that induce similarity measures from partitions and re-cluster objects, and between clusters that collapse groups of clusters into meta-clusters. In most of those models, there is a strong assumption on IIDness (i.e., independent and identical distribution), which states that base clusterings perform independently of one another and all objects are also independent. In the real world, however, objects are generally likely related to each other through features that are either explicit or even implicit. There is also latent but definite relationship among intermediate base clusterings because they are derived from the same set of data. All these demand a further investigation of clustering ensembles that explores the interdependence characteristics of data. To solve this problem, a new coupled clustering ensemble (CCE) framework that works on the interdependence nature of objects and intermediate base clusterings is proposed in this article. The main idea is to model the coupling relationship between objects by aggregating the similarity of base clusterings, and the interactive relationship among objects by addressing their neighborhood domains. Once these interdependence relationships are discovered, they will act as critical supplements to clustering ensembles. We verified our proposed framework by using three types of consensus function: clustering-based, object-based, and cluster-based. Substantial experiments on multiple synthetic and real-life benchmark datasets indicate that CCE can effectively capture the implicit interdependence relationships among base clusterings and among objects with higher clustering accuracy, stability, and robustness compared to 14 state-of-the-art techniques, supported by statistical analysis. In addition, we show that the final clustering quality is dependent on the data characteristics (e.g., quality and consistency) of base clusterings in terms of sensitivity analysis. Finally, the applications in document clustering, as well as on the datasets with much larger size and dimensionality, further demonstrate the effectiveness, efficiency, and scalability of our proposed models.;;;https://dl.acm.org/doi/10.1145/3230967;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A clustering-based rule-mining approach for monitoring long-term energy use and understanding system behavior;;;['Seyed Hamid Mirebrahim', 'Mohammad Shokoohi-Yekta', 'Unmesh Kurup', 'Torsten Welfonder', 'Mohak Shah'];;;November 2017;;;BuildSys '17: Proceedings of the 4th ACM International Conference on Systems for Energy-Efficient Built Environments;;;We describe a data mining approach to discover possible explanations for long-term energy consumption patterns in commercial and residential buildings. Our approach uses clustering to identify interesting patterns in energy data and correlates these patterns to other sensor information. These correlations, written in the form of rules, provide potential explanations for the patterns. Our approach is different from existing approaches in a number of ways: First, we apply these techniques to producing explanatory rules in long-term energy usage for large datasets. Second, we use clustering to find interesting patterns and provide explanatory rules about these patterns by applying rule mining on a dataset made up of secondary information (including temporal ranges and other building sensors) that include these cluster ids. Finally, we include in our analysis the list of rules that are exclusive to each cluster. We show that our approach for finding the rules is capable of finding useful explanatory rules for a real dataset.;;;https://dl.acm.org/doi/10.1145/3137133.3137144;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Mining Domain Terminologies Using Search Engine's Query Log;;;['Weijian Ni', 'Tong Liu', 'Qingtian Zeng', 'Nengfu Xie'];;;None;;;ACM Transactions on Asian and Low-Resource Language Information Processing;;;Domain terminologies are a basic resource for various natural language processing tasks. To automatically discover terminologies for a domain of interest, most traditional approaches mostly rely on a domain-specific corpus given in advance; thus, the performance of traditional approaches can only be guaranteed when collecting a high-quality domain-specific corpus, which requires extensive human involvement and domain expertise. In this article, we propose a novel approach that is capable of automatically mining domain terminologies using search engine's query log—a type of domain-independent corpus of higher availability, coverage, and timeliness than a manually collected domain-specific corpus. In particular, we represent query log as a heterogeneous network and formulate the task of mining domain terminology as transductive learning on the heterogeneous network. In the proposed approach, the manifold structure of domain-specificity inherent in query log is captured by using a novel network embedding algorithm and further exploited to reduce the need for the manual annotation efforts for domain terminology classification. We select Agriculture and Healthcare as the target domains and experiment using a real query log from a commercial search engine. Experimental results show that the proposed approach outperforms several state-of-the-art approaches.;;;https://dl.acm.org/doi/10.1145/3462327;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
An evidence-based approach to mining patterns;;;['Michael Weiss'];;;March 2017;;;VikingPLoP '17: Proceedings of the VikingPLoP 2017 Conference on Pattern Languages of Program;;;In this paper, we experiment with an evidence-based approach to mining patterns. The goal of the approach is to support pattern discovery from design documentation. The approach is semi-automated: semantic word clouds are generated from the design documentation and then examined by a domain expert for interesting configurations of design elements. These configurations are expected to indicate elements of pattern candidates like the solution, problem, or context. Unlike regular word clouds, which are purely visual, semantic word clouds preserve semantic relationships in the underlying text. Hence, pattern elements found in close proximity in the same word cloud can be expected to be related. Clusters of pattern elements can be interpreted as the core of a pattern to be mined. The approach will be tested using design documentation for several projects related to the design of online communities. As a text-based approach, the approach is expected to be useful for pattern discovery in software architecture, high-level designs, requirements, as well as business models.;;;https://dl.acm.org/doi/10.1145/3158491.3158492;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Learning from Multi-annotator Data: A Noise-aware Classification Framework;;;['Xueying Zhan', 'Yaowei Wang', 'Yanghui Rao', 'Qing Li'];;;None;;;ACM Transactions on Information Systems;;;In the field of sentiment analysis and emotion detection in social media, or other tasks such as text classification involving supervised learning, researchers rely more heavily on large and accurate labelled training datasets. However, obtaining large-scale labelled datasets is time-consuming and high-quality labelled datasets are expensive and scarce. To deal with these problems, online crowdsourcing systems provide us an efficient way to accelerate the process of collecting training data via distributing the enormous tasks to various annotators to help create large amounts of labelled data at an affordable cost. Nowadays, these crowdsourcing platforms are heavily needed in dealing with social media text, since the social network platforms (e.g., Twitter) generate huge amounts of data in textual form everyday. However, people from different social and knowledge backgrounds have different views on various texts, which may lead to noisy labels. The existing noisy label aggregation/refinement algorithms mostly focus on aggregating labels from noisy annotations, which would not guarantee their effectiveness on the subsequent classification/ranking tasks. In this article, we propose a noise-aware classification framework that integrates the steps of noisy label aggregation and classification. The aggregated noisy crowd labels are fed into a classifier for training, while the predicted labels are employed as feedback for adjusting the parameters at the label aggregating stage. The classification framework is suitable for directly running on crowdsourcing datasets and applies to various kinds of classification algorithms. The feedback strategy makes it possible for us to find optimal parameters instead of using known data for parameter selection. Simulation experiments demonstrate that our method provide significant label aggregation performance for both binary and multiple classification tasks under various noisy environments. Experimenting on real-world data validates the feasibility of our framework in real noise data and helps us verify the reasonableness of the simulated experiment settings.;;;https://dl.acm.org/doi/10.1145/3309543;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A Dictionary-Based Method for Classification with Universum Data;;;['Zhiyong Che', 'Bo Liu', 'Yanshan Xiao'];;;October 2021;;;CSAE '21: Proceedings of the 5th International Conference on Computer Science and Application Engineering;;;In fact, the collected examples included the third-class examples, they do not belong to positive samples or negative samples, which are referred as the Universum data. And Universum data can make better performance for the classifier. In this paper, a dictionary-based method for classification with Universum data is proposed to construct a unified model. In the proposed method, we embed the dictionary and Universum data to construct a unified framework, and the Universum data is introduced into the framework by the ɛ-insensitive loss. For the optimization, the SVD algorithm and gradient-based optimization methods are utilized to alternately optimize and update the dictionary, and the Lagrangian function is used to iteratively optimize the unified framework to obtain the classifier. Finally, extensive experiments are conducted on the benchmark datasets to evaluate the performance of the proposed U-DL method and baselines. The results have shown that the proposed U-DL method makes better performance than previous methods.;;;https://dl.acm.org/doi/10.1145/3487075.3487115;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Statistical guarantees for local spectral clustering on random neighborhood graphs;;;['Alden Green', 'Sivaraman Balakrishnan', 'Ryan J. Tibshirani'];;;None;;;The Journal of Machine Learning Research;;;We study the Personalized PageRank (PPR) algorithm, a local spectral method for clustering, which extracts clusters using locally-biased random walks around a given seed node. In contrast to previous work, we adopt a classical statistical learning setup, where we obtain samples from an unknown nonparametric distribution, and aim to identify sufficiently salient clusters. We introduce a trio of population-level functionals--the normalized cut, conductance, and local spread, analogous to graph-based functionals of the same name--and prove that PPR, run on a neighborhood graph, recovers clusters with small population normalized cut and large conductance and local spread. We apply our general theory to establish that PPR identifies connected regions of high density (density clusters) that satisfy a set of natural geometric conditions. We also show a converse result, that PPR can fail to recover geometrically poorly-conditioned density clusters, even asymptotically. Finally, we provide empirical support for our theory.;;;https://dl.acm.org/doi/10.5555/3546258.3546505;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Abnormal Data Classification Using Time-Frequency Temporal Logic;;;['Luan Viet Nguyen', 'James Kapinski', 'Xiaoqing Jin', 'Jyotirmoy V. Deshmukh', 'Ken Butts', 'Taylor T. Johnson'];;;April 2017;;;HSCC '17: Proceedings of the 20th International Conference on Hybrid Systems: Computation and Control;;;We present a technique to investigate abnormal behaviors of signals in both time and frequency domains using an extension of time-frequency logic that uses the continuous wavelet transform. Abnormal signal behaviors such as unexpected oscillations, called hunting behavior, can be challenging to capture in the time domain; however, these behaviors can be naturally captured in the time-frequency domain. We introduce the concept of parametric time-frequency logic and propose a parameter synthesis approach that can be used to classify hunting behavior. We perform a comparative analysis between the proposed algorithm, an approach based on support vector machines using linear classification, and a method that infers a signal temporal logic formula as a data classifier. We present experimental results based on data from a hydrogen fuel cell vehicle application and electrocardiogram data extracted from the MIT-BIH Arrhythmia Database.;;;https://dl.acm.org/doi/10.1145/3049797.3049809;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
150 Successful Machine Learning Models: 6 Lessons Learned at Booking.com;;;['Lucas Bernardi', 'Themistoklis Mavridis', 'Pablo Estevez'];;;July 2019;;;KDD '19: Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining;;;Booking.com is the world's largest online travel agent where millions of guests find their accommodation and millions of accommodation providers list their properties including hotels, apartments, bed and breakfasts, guest houses, and more. During the last years we have applied Machine Learning to improve the experience of our customers and our business. While most of the Machine Learning literature focuses on the algorithmic or mathematical aspects of the field, not much has been published about how Machine Learning can deliver meaningful impact in an industrial environment where commercial gains are paramount. We conducted an analysis on about 150 successful customer facing applications of Machine Learning, developed by dozens of teams in Booking.com, exposed to hundreds of millions of users worldwide and validated through rigorous Randomized Controlled Trials. Following the phases of a Machine Learning project we describe our approach, the many challenges we found, and the lessons we learned while scaling up such a complex technology across our organization. Our main conclusion is that an iterative, hypothesis driven process, integrated with other disciplines was fundamental to build 150 successful products enabled by Machine Learning.;;;https://dl.acm.org/doi/10.1145/3292500.3330744;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Melanoma Segmentation and Classification in Clinical Images Using Deep Learning;;;['Yunhao Ge', 'Bin Li', 'Yanzheng Zhao', 'Enguang Guan', 'Weixin Yan'];;;February 2018;;;ICMLC '18: Proceedings of the 2018 10th International Conference on Machine Learning and Computing;;;In this paper, a deep learning computer aided diagnosis system (CADs) is proposed for automatic segmentation and classification of melanoma lesions, containing a fully convolutional neural network (FCN) and a specific convolutional neural network (CNN). FCN, which consists of a 28-layer neural structure, is designed for segmentation and with a mask for region of interest (ROI) as its output. Later, the CNN only uses the segmented ROI of raw image to extract features, while the DLCM features, statistical and contrast location features extracted from same ROI are merged into CNN features. Finally, the combined features are utilized by the fully connected layers in CNN to obtain the final classification of melanoma, malignant or benign. The training of FCN and CNN are separated with different loss functions. Publicly available database ISBI 2016 is used for evaluating the effectiveness, efficiency, and generalization capability with evaluating indicator, such as accuracy, precision, and recall. Preprocessing methods, such as data argumentation and balancing are utilized to make further improvements to performance. Experiments on a batch size of 100 images yielded an accuracy of 92%, a specificity of 93% and a sensitivity of 94%, revealing that the proposed system is superior in terms of diagnostic accuracy in comparison with the state-of-the-art methods.;;;https://dl.acm.org/doi/10.1145/3195106.3195164;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Deep learning-based defective product classification system for smart factory;;;['Huy Toan Nguyen', 'Nu-ri Shin', 'Gwang-Hyun Yu', 'Gyeong-Ju Kwon', 'Woo-Young Kwak', 'Jin-Young Kim'];;;September 2020;;;SMA 2020: The 9th International Conference on Smart Media and Applications;;;In this paper, the defective product classification based on deep learning for a smart factory is introduced. The proposed system contains PLC (Programmable Logic Controller), Artificial Intelligence (AI) embedded board and cloud service. The AI embedded board is connected and communicated to receive and send commands to PLC via SPI (Serial Peripheral Interface) protocol. The pre-trained defective product classification model is uploaded, saved on a cloud server and downloaded to AI Embedded board for each particular product. The core technique of the system is the AI-based embedded board. Due to the limitation of label data, we use transfer learning method to retrain deep neural networks (DNN). We implement and compare the classification results on different deep neural network including ResNet, DenseNet, and GoogLeNet. We trained these networks by GPU server on casting product classification data. After that, the pre-trained models are optimized and applied on practical embedded board. The experimental results show that our system is able to classify defective products with high accuracy and fast speed.;;;https://dl.acm.org/doi/10.1145/3426020.3426039;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Mining Activity Log Data to Predict Student's Outcome in a Course;;;['Rahila Umer', 'Anuradha Mathrani', 'Teo Susnjak', 'Suriadi Lim'];;;March 2019;;;ICBDE '19: Proceedings of the 2019 International Conference on Big Data and Education;;;Use of learning management system (LMS) is very common, which provide support to teaching staff for communication, delivery of resources and in design of learning activities. The wide spread use of technologies like LMS, provide large amount of data. Research shows that higher education institutes can make use of this data to extract data-driven insights to understand the learning process and benefit the students by supporting them in their academics. In this study we used several machine learning algorithms to predict student's outcome in a course using LMS trace data and assessment scores. Selection of the courses is based on the extent the LMS is used and is divided into two categories; distance and internal. This study confirms the importance of LMS data and assessment scores in the prediction of academic performance. However, frequent use of LMS may increase the trace data but it is not necessary improve the predictive accuracy. Predictive models developed for courses, without considering the context of use of LMS data, may not generalize the effects of LMS trace data on student's outcome in the course.;;;https://dl.acm.org/doi/10.1145/3322134.3322140;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Mining Twitter data for a more responsive software engineering process;;;['Grant Williams', 'Anas Mahmoud'];;;May 2017;;;ICSE-C '17: Proceedings of the 39th International Conference on Software Engineering Companion;;;Twitter has created an unprecedented opportunity for software developers to monitor the opinions of large populations of end-users of their software. However, automatically classifying useful tweets is not a trivial task. Challenges stem from the scale of the data available, its unique format, diverse nature, and high percentage of spam. To overcome these challenges, this extended abstract introduces a three-fold procedure that is aimed at leveraging Twitter as a main source of technical feedback that software developers can benefit from. The main objective is to enable a more responsive, interactive, and adaptive software engineering process. Our analysis is conducted using a dataset of tweets collected from the Twitter feeds of three software systems. Our results provide an initial proof of the technical value of software-relevant tweets and uncover several challenges to be pursued in our future work.;;;https://dl.acm.org/doi/10.1109/ICSE-C.2017.53;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Research on Comprehensive Potato Classification Based on Support Vector Machine;;;['Wenhu Nan', 'Yanjun Liu', 'Shuzhen Zhang'];;;January 2021;;;CONF-CDS 2021: The 2nd International Conference on Computing and Data Science;;;In order to identify the potato accurately and quickly, this paper uses saturation and support vector machine to classify potatoes. Firstly, we collect 90 potato image samples, and then use the method of extracting the S component to filter out the unusable potato targets due to budding. Secondly, the R, G and B components are extracted and to perform R+G which is gray-scaled. The point noise is removed through corrosion expansion, then we use the boundary function for finding the image boundary. Finally, according to the rectangle degree and other parameters as the shape feature, the support vector machine is trained to classify the potatoes. The experimental results show that this method can classify potatoes effectively in potato shape and budding, it meets the demand for potato commercial production.;;;https://dl.acm.org/doi/10.1145/3448734.3450929;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
An Efficient Angle-based Universum Least Squares Twin Support Vector Machine for Classification;;;['B. Richhariya', 'M. Tanveer', 'Alzheimer’s Disease Neuroimaging InitiativeDiscipline of Mathematics, Indian Institute of Technology Indore, Simrol, Indore, IndiaProgram'];;;None;;;ACM Transactions on Internet Technology;;;Universum-based support vector machine incorporates prior information about the distribution of data in training of the classifier. This leads to better generalization performance but with increased computation cost. Various twin hyperplane-based models are proposed to reduce the computation cost of universum-based algorithms. In this work, we present an efficient angle-based universum least squares twin support vector machine (AULSTSVM) for classification. This is a novel approach of incorporating universum in the formulation of least squares-based twin SVM model. First, the proposed AULSTSVM constructs a universum hyperplane, which is proximal to universum data points. Then, the classifying hyperplane is constructed by minimizing the angle with the universum hyperplane. This gives prior information about data distribution to the classifier. In addition to the quadratic loss, we introduce linear loss in the optimization problem of the proposed AULSTSVM, which leads to lesser computation cost of the model. Numerical experiments are performed on several benchmark synthetic, real-world, and large-scale datasets. The results show that proposed AULSTSVM performs better than existing algorithms w.r.t. generalization performance as well as computation time. Moreover, an application to Alzheimer’s disease is presented, where AULSTSVM obtains accuracy of 95% for classification of healthy and Alzheimers subjects. The results imply that the proposed AULSTSVM is a better alternative for classification of large-scale datasets and biomedical applications.;;;https://dl.acm.org/doi/10.1145/3387131;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Design of Intelligent Recognition English Translation Model based on Association Rule Mining;;;['Kang Sun'];;;December 2021;;;ICASIT 2021: 2021 International Conference on Aviation Safety and Information Technology;;;Due to the rapid development of globalization, the information flow between different countries shows high speed, and English has become the main language of international communication. At present, the application value of intelligent recognition technology in different fields is increasing. The English machine translation model based on modern intelligent recognition technology can improve the efficiency and accuracy of English machine translation and realize barrier free communication. However, the traditional English machine translation method based on syntactic analysis can not solve the problem of partial structural ambiguity in the massive English language in intelligent recognition technology, which has the problem of low accuracy of machine translation. With the development of modern intelligent recognition technology, there are many intelligent machine translation tools. The current machine translation results of online machine translation still have some defects, especially after the server is used to carry out comparative learning on data in different languages in the full text range, it can obtain the grammar and text correlation laws between languages, which has the disadvantages of low efficiency and low accuracy of machine translation. Therefore, the recognizable technology of association rule mining should be used to realize accurate machine translation of English.;;;https://dl.acm.org/doi/10.1145/3510858.3511426;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Transfer Learning for Multi-language Twitter Election Classification;;;['Xiao Yang', 'Richard McCreadie', 'Craig Macdonald', 'Iadh Ounis'];;;July 2017;;;ASONAM '17: Proceedings of the 2017 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining 2017;;;Both politicians and citizens are increasingly embracing social media as a means to disseminate information and comment on various topics, particularly during significant political events, such as elections. Such commentary during elections is also of interest to social scientists and pollsters. To facilitate the study of social media during elections, there is a need to automatically identify posts that are topically related to those elections. However, current studies have focused on elections within English-speaking regions, and hence the resultant election content classifiers are only applicable for elections in countries where the predominant language is English. On the other hand, as social media is becoming more prevalent worldwide, there is an increasing need for election classifiers that can be generalised across different languages, without building a training dataset for each election. In this paper, based upon transfer learning, we study the development of effective and reusable election classifiers for use on social media across multiple languages. We combine transfer learning with different classifiers such as Support Vector Machines (SVM) and state-of-the-art Convolutional Neural Networks (CNN), which make use of word embedding representations for each social media post. We generalise the learned classifier models for cross-language classification by using a linear translation approach to map the word embedding vectors from one language into another. Experiments conducted over two election datasets in different languages show that without using any training data from the target language, linear translations outperform a classical transfer learning approach, namely Transfer Component Analysis (TCA), by 80% in recall and 25% in F1 measure.;;;https://dl.acm.org/doi/10.1145/3110025.3110059;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Hybrid Classification and Clustering Algorithm on Recent Android Malware Detection;;;['jiezhong xiao', 'qian han', 'yumeng gao'];;;December 2021;;;CSAI '21: Proceedings of the 2021 5th International Conference on Computer Science and Artificial Intelligence;;;With the explosion in the popularity of smartphones over the previous decade, mobile malware appears to be unavoidable. Because Android is an open platform that is fast dominating other rival platforms (e.g. iOS) in the mobile smart device industry, Android malware has been much more widespread. Recent Android malware developers have more advanced capabilities when building their malicious apps, which make the apps themselves much more difficult to detect using conventional methods. In our paper, we proposed a hybrid machine learning classification and clustering algorithm to detect recent Android malware. The proposed algorithm performs better than the state-of-art algorithms with both F1-score and recall of 0.9944. More importantly, the top features returned by our algorithm clearly explain the important factors in the detection task. They can not only be used for enhanced Android malware detection but also quicker white-box analysis by means of more interpretable results.;;;https://dl.acm.org/doi/10.1145/3507548.3507586;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Vertica-ML: Distributed Machine Learning in Vertica Database;;;['Arash Fard', 'Anh Le', 'George Larionov', 'Waqas Dhillon', 'Chuck Bear'];;;June 2020;;;SIGMOD '20: Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data;;;A growing number of companies rely on machine learning as a key element for gaining a competitive edge from their collected Big Data. An in-database machine learning system can provide many advantages in this scenario, e.g., eliminating the overhead of data transfer, avoiding the maintenance costs of a separate analytical system, and addressing data security and provenance concerns. In this paper, we present our distributed machine learning subsystem within the Vertica database. This subsystem, Vertica-ML, includes machine learning functionalities with SQL API which cover a complete data science workflow as well as model management. We treat machine learning models in Vertica as first-class database objects like tables and views; therefore, they enjoy a similar mechanism for archiving and managing. We explain the architecture of the subsystem, and present a set of experiments to evaluate the performance of the machine learning algorithms implemented on top of it.;;;https://dl.acm.org/doi/10.1145/3318464.3386137;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Unbalanced data sentiment classification method based on ensemble learning;;;['Jidong Duan', 'Kun Ma', 'Runyuan Sun'];;;August 2019;;;ICBDT '19: Proceedings of the 2nd International Conference on Big Data Technologies;;;Sentiment classification is a hot research direction at present, but most research is based on balanced data sets. In real life, the sample is impossible to balance. For sentiment analysis of unbalanced data, we not only need to pay attention to the overall classification performance, but also need to care about the classification performance of a few classes. How to improve the recognition rate of a few types of samples while improving the overall recognition rate has become a research hotspot. Aiming at this problem, this paper proposes a model based on ensemble learning, extracts features by TF-IDF+SVD, and integrates five base classifiers by stacking to sentiment classification. The experimental results show that it can be more effective in emotional classification on unbalanced data sets than other methods.;;;https://dl.acm.org/doi/10.1145/3358528.3358597;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Differentially private sequential pattern mining considering time interval for electronic medical record systems;;;['Hieu Hanh Le', 'Muneo Kushima', 'Kenji Araki', 'Haruo Yokota'];;;June 2019;;;IDEAS '19: Proceedings of the 23rd International Database Applications &amp; Engineering Symposium;;;Electronic medical record (EMR) systems have now been widely adopted to support medical workers. There also has been much interest in the machine-based generation of clinical pathways that can utilize sequential pattern mining (SPM) to extract them from historical EMR systems. However, the existing methods do not protect individual privacy, even though they involve sensitive medical data. To ensure the privacy of individual data, this paper describes two algorithms that deploy differential privacy by adding noise during calculations in the SPM considering time interval for guaranteeing privacy. The proposals can limit the amount of added noise by adding noise to the frequency calculations of only a part of candidate closed sequences. Experiments on real medical datasets show that our proposal can ensure the robust and high utility of mining process even with minimum privacy budget and amount of added noise.;;;https://dl.acm.org/doi/10.1145/3331076.3331098;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Research on outlier detection of data based on machine learning;;;['Chunyang Wang'];;;July 2021;;;ACM TURC '21: Proceedings of the ACM Turing Award Celebration Conference - China;;;With the increasing magnitude of data, the accuracy of single data cannot be guaranteed. In order to improve the accuracy of model prediction data, and further for the subsequent data processing, this paper focuses on the detection of data on outliers. This paper introduces the density clustering and outlier detection methods of Isolation Forest in outlier recognition, and mainly describes the principle and process of outlier recognition using density clustering and Isolation Forest. Based on this, according to the features of data, an improved algorithm combining density clustering and Isolation Forest is proposed. Finally, through the existing common outlier detection data set, the statistical outlier recognition method, the existing machine learning algorithm and the improved algorithm proposed in this paper are compared to identify outliers, which verifies the stability of the proposed method and the effective improvement compared with the existing outlier detection.;;;https://dl.acm.org/doi/10.1145/3472634.3474072;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Evolutionary Classifier and Cluster Selection Approach for Ensemble Classification;;;['Zohaib Md. Jan', 'Brijesh Verma'];;;None;;;ACM Transactions on Knowledge Discovery from Data;;;Ensemble classifiers improve the classification performance by combining several classifiers using a suitable fusion methodology. Many ensemble classifier generation methods have been developed that allowed the training of multiple classifiers on a single dataset. As such random subspace is a common methodology utilized by many state-of-the-art ensemble classifiers that generate random subsamples from the input data and train classifiers on different subsamples. Real-world datasets have randomness and noise in them, therefore not all randomly generated samples are suitable for training. In this article, we propose a novel particle swarm optimization-based approach to optimize the random subspace to generate an ensemble classifier. We first generate a random subspace by incrementally clustering input data and then optimize all generated data clusters. On all optimized data clusters, a set of classifiers is trained and added to the pool. The pool of classifiers is then optimized and an optimized ensemble classifier is generated. The proposed approach is tested on 12 benchmark datasets from the UCI repository and results are compared with current state-of-the-art ensemble classifier approaches. A statistical significance test is also conducted and an analysis is presented.;;;https://dl.acm.org/doi/10.1145/3366633;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Differentially private sequential pattern mining considering time interval for electronic medical record systems;;;['Hieu Hanh Le', 'Muneo Kushima', 'Kenji Araki', 'Haruo Yokota'];;;June 2019;;;IDEAS '19: Proceedings of the 23rd International Database Applications &amp; Engineering Symposium;;;Electronic medical record (EMR) systems have now been widely adopted to support medical workers. There also has been much interest in the machine-based generation of clinical pathways that can utilize sequential pattern mining (SPM) to extract them from historical EMR systems. However, the existing methods do not protect individual privacy, even though they involve sensitive medical data. To ensure the privacy of individual data, this paper describes two algorithms that deploy differential privacy by adding noise during calculations in the SPM considering time interval for guaranteeing privacy. The proposals can limit the amount of added noise by adding noise to the frequency calculations of only a part of candidate closed sequences. Experiments on real medical datasets show that our proposal can ensure the robust and high utility of mining process even with minimum privacy budget and amount of added noise.;;;https://dl.acm.org/doi/10.1145/3331076.3331098;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Mining Implicit Entity Preference from User-Item Interaction Data for Knowledge Graph Completion via Adversarial Learning;;;['Gaole He', 'Junyi Li', 'Wayne Xin Zhao', 'Peiju Liu', 'Ji-Rong Wen'];;;April 2020;;;WWW '20: Proceedings of The Web Conference 2020;;;The task of Knowledge Graph Completion (KGC) aims to automatically infer the missing fact information in Knowledge Graph (KG). In this paper, we take a new perspective that aims to leverage rich user-item interaction data (user interaction data for short) for improving the KGC task. Our work is inspired by the observation that many KG entities correspond to online items in application systems. However, the two kinds of data sources have very different intrinsic characteristics, and it is likely to hurt the original performance using simple fusion strategy.  To address this challenge, we propose a novel adversarial learning approach by leveraging user interaction data for the KGC task. Our generator is isolated from user interaction data, and serves to improve the performance of the discriminator. The discriminator takes the learned useful information from user interaction data as input, and gradually enhances the evaluation capacity in order to identify the fake samples generated by the generator. To discover implicit entity preference of users, we design an elaborate collaborative learning algorithms based on graph neural networks, which will be jointly optimized with the discriminator. Such an approach is effective to alleviate the issues about data heterogeneity and semantic complexity for the KGC task. Extensive experiments on three real-world datasets have demonstrated the effectiveness of our approach on the KGC task.;;;https://dl.acm.org/doi/10.1145/3366423.3380155;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Coupling topic modelling in opinion mining for social media analysis;;;['Xujuan Zhou', 'Xiaohui Tao', 'Md Mostafijur Rahman', 'Ji Zhang'];;;August 2017;;;WI '17: Proceedings of the International Conference on Web Intelligence;;;Many of social media platforms such as Facebook and Twitter make it easy for everyone to share their thoughts on literally anything. Topic and opinion detection in social media facilitates the identification of emerging societal trends, analysis of public reactions to policies and business products. In this paper, we proposed a new method that combines the opining mining and context-based topic modelling to analyse public opinions on social media data. Context based topic modelling is used to categorise data in groups and discover hidden communities in data group. The unwanted data group discovered by the topic model then will be discarded. A lexicon based opinion mining method will be applied to the remaining data groups to spot out the public sentiment about the entities. A set of Tweets data on Australian Federal Election 2010 was used in our experiments. Our experimental results demonstrate that, with the help of topic modelling, our social media analysis model is accurate and effective.;;;https://dl.acm.org/doi/10.1145/3106426.3106459;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Utilizing the buckshot algorithm for efficient big data clustering in the MapReduce model;;;['Sergios Gerakidis', 'Basilis Mamalis'];;;November 2019;;;PCI '19: Proceedings of the 23rd Pan-Hellenic Conference on Informatics;;;Clustering is an efficient data mining as well as machine-learning method when we need to get an insight of the objects of a dataset that could be grouped together. The K-Means algorithm and the Hierarchical Agglomerative Clustering (HAC) algorithm are two of the most known and commonly used methods of clustering; the former due to its low time cost and the latter due to its accuracy. However, even the use of K-Means in document clustering over large-scale collections can lead to unpredictable time costs. In this paper, towards the direction of the efficient handling of big text data, we present a hybrid clustering approach based on a customized version of the Buckshot algorithm, which first applies a hierarchical clustering procedure on a sample of the input dataset and then uses the results as the initial centers for a K-Means based assignment of the remaining documents, with very few iterations. We also give a highly efficient adaptation of the proposed Buckshot-based approach in the MapReduce model which is then experimentally tested using Apache Hadoop over a real cluster environment. As it comes out of the experiments, it leads to acceptable clustering quality as well as to significant execution time improvements. Preliminary results drawn from relevant experiments using the Spark framework are also presented.;;;https://dl.acm.org/doi/10.1145/3368640.3368658;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Utilizing cost-sensitive machine learning classifiers to identify compounds that inhibit Alzheimer's APP translation;;;['Hany Alashwal', 'Juwayni Lucman'];;;August 2020;;;ICCBDC '20: Proceedings of the 2020 4th International Conference on Cloud and Big Data Computing;;;Virtual screening of bioassay data can be of immense benefit to identify compounds which can assist in restricting the production of amyloid beta peptides (Aβ), observed in Alzheimer patients, by inhibiting the translation of amyloid precursor protein (APP). Machine learning classifiers can be adopted on the dataset to investigate those compounds. The ratio of the active molecules that achieve the goal of inhibiting APP, nonetheless, is minimal compared to their inactive counterparts. The imbalance between the two classes is handled by introducing cost-sensitivity to reweight the training instances depending on the misclassification cost allotted to each class. The paper shows the performance of cost-sensitive classifiers (Random Forest, Naive Bayes, and Logistic Regression classifier) to spot the minority (active) molecules from the majority (inactive) classes and shows their evaluation metrics. Sensitivity, specificity, False Negative rate, ROC area, and accuracy are evaluated while keeping the False Positive rate at 20.6%. The aim of the study is to investigate the most reliable classifier for the bioassay data and to explore the ideal misclassification cost. Random Forest classifier was the most robust model compared to Naive Bayes and Logistic Regression Classifiers. Moreover, each classifier had a different optimal misclassification cost.;;;https://dl.acm.org/doi/10.1145/3416921.3416931;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Enhanced Data Mining Technique to Measure Satisfaction Degree of Social Media Users of Xeljanz Drug;;;['M. M. Abd-Elaziz', 'Hazem M. El-Bakry', 'Ahmed Abou Elfetouh', 'Amira Elzeiny'];;;None;;;ACM Transactions on Knowledge Discovery from Data;;;In the recent times, social media has become important in the field of health care as a major resource of valuable health information. Social media can provide massive amounts of data in real-time through user interaction, and this data can be analysed to reflect the harms and benefits of treatment by using the personal health experiences of users to improve health outcomes. In this study, we propose an enhanced data mining framework for analysing user opinions on Twitter and on a health-care forum. The proposed framework measures the degree of satisfaction of consumers regarding the drug Xeljanz, which is used to treat rheumatoid arthritis. The proposed framework is based on seven steps distributed in two phases. The first phase involves aggregating data related to the drug Xeljanz. This data is pre-processed to produce a list of words with a term frequency-inverse document frequency score. The word list is then classified into the following three categories: positive, negative and neutral. The second phase involves modelling social media posts using network analysis, identifying sub-graphs, calculating average opinions and detecting influential users. The results showed 77.3% user satisfaction with Xeljanz. Positive opinions were especially pronounced among users who switched to Xeljanz based on advice from a physician. Negative opinions of Xeljanz typically pertained to the high cost of the drug.;;;https://dl.acm.org/doi/10.1145/3389433;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Resource-centric process mining: clustering using local process models;;;['Landelin Delcoucq', 'Fabian Lecron', 'Philippe Fortemps', 'Wil. M. P. van der Aalst'];;;March 2020;;;SAC '20: Proceedings of the 35th Annual ACM Symposium on Applied Computing;;;In this paper, we focus on the resource perspective in the context of process mining. Most process mining techniques focus on the control-flow to uncover problems related to performance or compliance. However, the behavior of resources (e.g., employees) influences the effectiveness and efficiency of processes and should not be considered as secondary. We aim to identify resources exhibiting similar behavioral patterns that go beyond just looking at the mix of activities performed. We want to be able to identify subgroups of resources that perform similar activities but in a different order. We also provide a comparison between existing ways of grouping resources into roles and our resource-centered approach that takes into account the order in which work is performed. We will compare the results of clustering based only on the activities performed and clustering based on local process models that identify work patterns. Experiments are considered on synthetic and real data.;;;https://dl.acm.org/doi/10.1145/3341105.3373864;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Efficient mining of regional movement patterns in semantic trajectories;;;['Dong-Wan Choi', 'Jian Pei', 'Thomas Heinis'];;;None;;;Proceedings of the VLDB Endowment;;;Semantic trajectory pattern mining is becoming more and more important with the rapidly growing volumes of semantically rich trajectory data. Extracting sequential patterns in semantic trajectories plays a key role in understanding semantic behaviour of human movement, which can widely be used in many applications such as location-based advertising, road capacity optimisation, and urban planning. However, most of existing works on semantic trajectory pattern mining focus on the entire spatial area, leading to missing some locally significant patterns within a region. Based on this motivation, this paper studies a regional semantic trajectory pattern mining problem, aiming at identifying all the regional sequential patterns in semantic trajectories. Specifically, we propose a new density scheme to quantify the frequency of a particular pattern in space, and thereby formulate a new mining problem of finding all the regions in which such a pattern densely occurs. For the proposed problem, we develop an efficient mining algorithm, called RegMiner (<u>Reg</u>ional Semantic Trajectory Pattern <u>Miner</u>), which effectively reveals movement patterns that are locally frequent in such a region but not necessarily dominant in the entire space. Our empirical study using real trajectory data shows that RegMiner finds many interesting local patterns that are hard to find by a state-of-the-art global pattern mining scheme, and it also runs several orders of magnitude faster than the global pattern mining algorithm.;;;https://dl.acm.org/doi/10.14778/3151106.3151111;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Near-Optimal Clustering in the k-machine model;;;['Sayan Bandyapadhyay', 'Tanmay Inamdar', 'Shreyas Pai', 'Sriram V. Pemmaraju'];;;January 2018;;;ICDCN '18: Proceedings of the 19th International Conference on Distributed Computing and Networking;;;The clustering problem, in its many variants, has numerous applications in operations research and computer science (e.g., in applications in bioinformatics, image processing, social network analysis, etc.). As sizes of data sets have grown rapidly, researchers have focused on designing algorithms for clustering problems in models of computation suited for large-scale computation such as MapReduce, Pregel, and streaming models. The k-machine model (Klauck et al., SODA 2015) is a simple, message-passing model for large-scale distributed graph processing. This paper considers three of the most prominent examples of clustering problems: the uncapacitated facility location problem, the p-median problem, and the p-center problem and presents O (1)-factor approximation algorithms for these problems running in Õ (n/k) rounds in the k -machine model. These algorithms are optimal upto polylogarithmic factors because this paper also shows Ω (n/k) lower bounds for obtaining poly(n)-factor approximation algorithms for these problems. These are the first results for clustering problems in the k -machine model. We assume that the metric provided as input for these clustering problems in only implicitly provided, as an edge-weighted graph and in a nutshell, our main technical contribution is to show that constant-factor approximation algorithms for all three clustering problems can be obtained by learning only a small portion of the input metric.;;;https://dl.acm.org/doi/10.1145/3154273.3154317;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Data integration and machine learning: a natural synergy;;;['Xin Luna Dong', 'Theodoros Rekatsinas'];;;None;;;Proceedings of the VLDB Endowment;;;As data volume and variety have increased, so have the ties between machine learning and data integration become stronger. For machine learning to be effective, one must utilize data from the greatest possible variety of sources; and this is why data integration plays a key role. At the same time machine learning is driving automation in data integration, resulting in overall reduction of integration costs and improved accuracy. This tutorial focuses on three aspects of the synergistic relationship between data integration and machine learning: (1) we survey how state-of-the-art data integration solutions rely on machine learning-based approaches for accurate results and effective human-in-the-loop pipelines, (2) we review how end-to-end machine learning applications rely on data integration to identify accurate, clean, and relevant data for their analytics exercises, and (3) we discuss open research challenges and opportunities that span across data integration and machine learning.;;;https://dl.acm.org/doi/10.14778/3229863.3229876;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A machine learning based approach to identify geo-location of Twitter users;;;['Aytuğ Onan'];;;March 2017;;;ICC '17: Proceedings of the Second International Conference on Internet of things, Data and Cloud Computing;;;Twitter, a popular microblogging platform, has attracted great attention. Twitter enables people from all over the world to interact in an extremely personal way. The immense quantity of user-generated text messages become available on Twitter that could potentially serve as an important source of information for researchers and practitioners. The information available on Twitter may be utilized for many purposes, such as event detection, public health and crisis management. In order to effectively coordinate such activities, the identification of Twitter users' geo-locations is extremely important. Though online social networks can provide some sort of geo-location information based on GPS coordinates, Twitter suffers from geo-location sparseness problem. The identification of Twitter users' geo-location based on the content of send out messages, becomes extremely important. In this regard, this paper presents a machine learning based approach to the problem. In this study, our corpora is represented as a word vector. To obtain a classification scheme with high predictive performance, the performance of five classification algorithms, three ensemble methods and two feature selection methods are evaluated. Among the compared algorithms, the highest results (84.85%) is achieved by AdaBoost ensemble of Random Forest, when the feature set is selected with the use of consistency-based feature selection method in conjunction with best first search.;;;https://dl.acm.org/doi/10.1145/3018896.3018969;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Data mining and image analysis using genetic programming;;;['Mahsa Shokri Varniab', 'Chih-Cheng Hung', 'Vahid Khalilzad Sharghi'];;;December 2019;;;ACM SIGAPP Applied Computing Review;;;Genetic programming (GP) is an artificial intelligence technique that benefits from evolutionary computations allowing computers to solve problems automatically. In this paper, we present an optimized genetic-programming-based classifier that directly solves the multi-class classification problems in data mining and image analysis. A new fitness function is proposed for multiclass classification and brain tumor detection, which is validated by 10-fold cross validation. Instead of defining static thresholds as boundaries to differentiate between multiple labels, our work presents a method of classification where a GP system learns the relationships among experiential data and models them mathematically during the evolutionary process. We propose an optimized GP classifier based on a combination of pruning subtrees and a new fitness function. An orthogonal least squares algorithm is also applied in the training phase to create a robust GP classifier. Our approach has been assessed on six multiclass datasets and on a magnetic resonance imaging (MRI) brain image for tumor detection. The results of data classification for Iris, Wine, Glass, Pima, BUPA Liver and Balance Scale datasets are compared with existing algorithms. The high accuracy of brain tumor classification provided by our GP classifier confirms the strong ability of the developed technique for complicated classification problems. We compared our approach in terms of speed with previous GP algorithms as well. The analyzed results illustrate that the developed classifier produces a productive and rapid method for classification tasks that outperforms the previous methods for more challenging multiclass classification problems.;;;https://dl.acm.org/doi/10.1145/3381307.3381311;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Modeling Customer Experience in a Contact Center through Process Log Mining;;;['Teng Fu', 'Guido Zampieri', 'David Hodgson', 'Claudio Angione', 'Yifeng Zeng'];;;None;;;ACM Transactions on Intelligent Systems and Technology;;;The use of data mining and modeling methods in service industry is a promising avenue for optimizing current processes in a targeted manner, ultimately reducing costs and improving customer experience. However, the introduction of such tools in already established pipelines often must adapt to the way data is sampled and to its content. In this study, we tackle the challenge of characterizing and predicting customer experience having available only process log data with time-stamp information, without any ground truth feedback from the customers. As a case study, we consider the context of a contact center managed by TeleWare and analyze phone call logs relative to a two months span. We develop an approach to interpret the phone call process events registered in the logs and infer concrete points of improvement in the service management. Our approach is based on latent tree modeling and multi-class Naïve Bayes classification, which jointly allow us to infer a spectrum of customer experiences and test their predictability based on the current data sampling strategy. Moreover, such approach can overcome limitations in customer feedback collection and sharing across organizations, thus having wide applicability and being complementary to tools relying on more heavily constrained data.;;;https://dl.acm.org/doi/10.1145/3468269;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Mining the Human Metabolome for Precision Oncology Research;;;['Mercy E. Edoho', 'Moses E. Ekpenyong', 'Aliu B. Momodu', 'Geoffery Joseph'];;;August 2020;;;ICMHI '20: Proceedings of the 4th International Conference on Medical and Health Informatics;;;Access to clinical data is critical for advancing translational research; but regulatory constraints and policies surrounding the use of clinical data often challenge data access and sharing. Mixed medical datasets (structured and unstructured) are increasingly dominating the clinical information space, hence, demanding AI-driven techniques such as Natural Language Processing-to reorganize them for effective usage. This paper excavates the HMDB (Human Metabolome Database), for efficient knowledge mining, supported by diversely certified oncology physicians and pharmacists' contributions. We propose a novel taxonomy for knowledge representation and establish a universe of discourse for disease clustering and prediction. Excavated data include metabolites and their respective concentration values, age, gender, as well as gene and protein sequences, of normal and abnormal patients. These data were then merged to form an AI-ready 'Omic' technology datasets. Preliminary results reveal that the proposed AI-ready datasets would aid precision oncology research by adding quality analysis to the present HMDB, and for explaining the variations in concentration values of cancer patients.;;;https://dl.acm.org/doi/10.1145/3418094.3418123;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A Deep Feedforward Neural Network and Shallow Architectures Effectiveness Comparison: Flight Delays Classification Perspective;;;['Desmond Bala Bisandu', 'Mohammed Salih Homaid', 'irene Moulitsas', 'Salvatore Filippone'];;;November 2021;;;ICAAI '21: Proceedings of the 5th International Conference on Advances in Artificial Intelligence;;;Flight delays have negatively impacted the socio-economics state of passengers, airlines and airports, resulting in huge economic losses. Hence, it has become necessary to correctly predict their occurrences in decision-making because it is important for the effective management of the aviation industry. Developing accurate flight delays classification models depends mostly on the air transportation system complexity and the infrastructure available in airports, which may be a region-specific issue. However, no specific prediction or classification model can handle the individual characteristics of all airlines and airports at the same time. Hence, the need to further develop and compare predictive models for the aviation decision system of the future cannot be over-emphasised. In this research, flight on-time data records from the United State Bureau of Transportation Statistics was employed to evaluate the performances of Deep Feedforward Neural Network, Neural Network, and Support Vector Machine models on a binary classification problem. The research revealed that the models achieved different accuracies of flight delay classifications. The Support Vector Machine had the worst average accuracy than Neural Network and Deep Feedforward Neural Network in the initial experiment. The Deep Feedforward Neural Network outperformed Support Vector Machines and Neural Network with the best average percentage accuracies. Going further to investigate the Deep Feedforward Neural Network architecture on different parameters against itself suggest that training a Deep Feedforward Neural Network algorithm, regardless of data training size, the classification accuracy peaks. We examine which number of epochs works best in our flight delay classification settings for the Deep Feedforward Neural Network. Our experiment results demonstrate that having many epochs affects the convergence rate of the model; unlike when hidden layers are increased, it does not ensure better or higher accuracy in a binary classification of flight delays. Finally, we recommended further studies on the applicability of the Deep Feedforward Neural Network in flight delays prediction with specific case studies of either airlines or airports to check the impact on the model's performance.;;;https://dl.acm.org/doi/10.1145/3505711.3505712;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
An Interpretable Classification Model Based on Characteristic Element Extraction;;;['Mingwei Zhang', 'Xiuxiu He', 'Bin Zhang'];;;February 2019;;;ICMLC '19: Proceedings of the 2019 11th International Conference on Machine Learning and Computing;;;The process of a classification application is usually dynamic and long. During the process of an application, better classification application effect can be acquired by enlarging and adjusting the training dataset continuously, for example, modifying the wrong labels of original instances. For this kind of dynamic classification applications, how to build an interpretable classifier which can help domain experts to understand each label's meanings reflected from the dataset, then to compare and discriminate them with their own mastered domain knowledge, and finally to adjust and optimize the training set to enhance the effect of classification applications, is a neglected but worth studying issue. Therefore, an interpretable classification model based on characteristic element extraction is proposed in this paper. The proposed classifier is constructed by extracting positive and negative characteristic elements for all class labels which can intuitively reflect their instinct characteristics. Thus, it has high interpretability obviously and can effectively help domain experts optimize classification effect. At the same time, experiment results show that our classifier also has higher accuracy compared with other kinds of classical classifiers. Consequently, the classification model proposed in this paper is effective and efficient, especially in practical applications.;;;https://dl.acm.org/doi/10.1145/3318299.3318370;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Big Data Financial Algorithm Technology Based on Machine Learning Technology;;;['Yiming Zhao'];;;December 2021;;;ICASIT 2021: 2021 International Conference on Aviation Safety and Information Technology;;;With the development and wide application of machine learning technology, the use of machine learning technology for economic algorithm technology research has become a new type of financial technology field. Today's financial big data has penetrated into all walks of life and has become an important factor of production. The extraction and application of massive amounts of data by humans heralds the arrival of a new wave of productivity growth and consumer surplus. Big data originally refers to a large number of data sets generated through batch processing or web search index analysis. This paper uses machine learning technology to explore and research big data financial algorithms, analyze risk control measures, report on the improvement and perfection of traditional finance, and analyze and study the future development of big data finance. The main research content of this paper is the analysis of big data financial algorithm technology by machine learning algorithms. Machine learning technology is one of the main methods to solve big data mining problems. Machine learning technology is a process of self-improvement using the system itself, so that computer programs can automatically improve performance through accumulated experience. This paper analyzes the relevant theories and characteristics of machine learning algorithms, and integrates them into the research of big data economic algorithm technology. The final result of the research shows that when the data volume is 1G, the training time of SVM is 8 minutes, while the training time of Bayesian is 12 minutes, and the data volume is relatively small. The SVM algorithm still has obvious advantages in training time.;;;https://dl.acm.org/doi/10.1145/3510858.3510934;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Application of Data Mining in College English Discourse Teaching;;;['Xue Wang', 'Renqing Hu'];;;September 2021;;;ICISCAE 2021: 2021 4th International Conference on Information Systems and Computer Aided Education;;;Classroom discourse teaching must conform to the principles of wholeness, psychology, schema theory and cognitive theory. Many students are not proficient in reading. Most of the time, they just stay at the superficial level of understanding sentences and do not have a comprehensive and profound understanding of the content through discourse analysis from a deep perspective. This paper constructs a classroom teaching mode guided by schema theory and cognitive theory, with discourse teaching method as the means and developing English ability as the index. This paper also analyzes the characteristics of mind mapping and discourse teaching, as well as the relationship between them. This paper discusses how to apply mind map in discourse teaching. The experimental results show that the teaching method proposed in this paper can be used for reference and inspiration to English teaching.;;;https://dl.acm.org/doi/10.1145/3482632.3482680;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Learning to Classify: A Flow-Based Relation Network for Encrypted Traffic Classification;;;['Wenbo Zheng', 'Chao Gou', 'Lan Yan', 'Shaocong Mo'];;;April 2020;;;WWW '20: Proceedings of The Web Conference 2020;;;As the size and source of network traffic increase, so does the challenge of monitoring and analyzing network traffic. The challenging problems of classifying encrypted traffic are the imbalanced property of network data, the generalization on an unseen dataset, and overly dependent on data size. In this paper, we propose an application of a meta-learning approach to address these problems in encrypted traffic classification, named Flow-Based Relation Network (RBRN). The RBRN is an end-to-end classification model that learns representative features from the raw flows and then classifies them in a unified framework. Moreover, we design “hallucinator” to produce additional training samples for the imbalanced classification, and then focus on meta-learning to classify unseen categories from few labeled samples. We validate the effectiveness of the RBRN on the real-world network traffic dataset, and the experimental results demonstrate that the RBRN can achieve an excellent classification performance and outperform the state-of-the-art methods on encrypted traffic classification. What is more interesting, our model trained on the real-world dataset can generalize very well to unseen datasets, outperforming multiple state-of-art methods.;;;https://dl.acm.org/doi/10.1145/3366423.3380090;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Online Embedding and Clustering of Data Streams;;;['Alaettin Zubaroğlu', 'Volkan Atalay'];;;November 2019;;;ICBDR '19: Proceedings of the 3rd International Conference on Big Data Research;;;Number of connected devices is steadily increasing and these devices continuously generate data streams. These data streams are often high dimensional and contain concept drift. Real-time processing of data streams is arousing interest despite many challenges. Clustering is a method that does not need labeled instances (it is unsupervised) and it can be applied with less prior information about the data. These properties make clustering one of the most suitable methods for real-time data stream processing. Moreover, data embedding is a process that may simplify clustering and makes visualization of high dimensional data possible. There exist several data stream clustering algorithms in the literature, however no data stream embedding method exists. UMAP is a data embedding algorithm that is suitable to be applied on data streams, but it cannot adopt concept drift. In this study, we have developed a new method to apply UMAP on data streams, adopt concept drift and cluster embedded data instances using any distance based clustering algorithms.;;;https://dl.acm.org/doi/10.1145/3372454.3372481;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Sentiment Classification of Chinese Text Based on Extending Semantic Similar Sentiment Words;;;['Yanying Mao'];;;September 2021;;;ICISCAE 2021: 2021 4th International Conference on Information Systems and Computer Aided Education;;;None;;;https://dl.acm.org/doi/10.1145/3482632.3484084;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
CUSUM Based Concept Drift Detector for Data Stream Clustering;;;['Namitha K.', 'G. Santhosh Kumar'];;;August 2020;;;BDIOT '20: Proceedings of the 2020 4th International Conference on Big Data and Internet of Things;;;The last few decades mark an unprecedented growth in the number of applications producing high-speed data streams. Learning from such fast data streams has many inherent challenges. The dynamic change in the concept of the stream is a significant challenge to be handled by the learning systems. This problem termed concept drift is given due focus in data stream classification scenarios. But, data stream clustering algorithms usually treat concept drift implicitly as part of the learning process. The need for explicit drift detection and adaptation is often neglected. This paper discusses a statistical method of change detection for data stream clustering problems. The change detection is done based on CUSUM test. On identifying a change, the model is re-built using the recent samples from the stream. The change detection process has been validated using real and synthetic datasets.;;;https://dl.acm.org/doi/10.1145/3421537.3421548;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Global-Local Mutual Attention Model for Text Classification;;;['Qianli Ma', 'Liuhong Yu', 'Shuai Tian', 'Enhuan Chen', 'Wing W. Y. Ng'];;;None;;;IEEE/ACM Transactions on Audio, Speech and Language Processing;;;Text classification is a central field of inquiry in natural language processing NLP. Although some models learn local semantic features and global long-term dependencies simultaneously, they simply combine them through concatenation either in a cascade way or in parallel while mutual effects between them are ignored. In this paper, we propose the Global-Local Mutual Attention GLMA model for text classification problems, which introduces a mutual attention mechanism for mutual learning between local semantic features and global long-term dependencies. The mutual attention mechanism consists of a Local-Guided Global-Attention LGGA and a Global-Guided Local-Attention GGLA. The LGGA allows to assign weights and combine global long-term dependencies of word positions that are semantic related. It captures combined semantics and alleviates the gradient vanishing problem. The GGLA automatically assigns more weights to relevant local semantic features, which captures key local semantic information and filters both noises and irrelevant words/phrases. Furthermore, a weighted-over-time pooling operation is developed to aggregate the most informative and discriminative features for classification. Extensive experiments demonstrate that our model obtains the state-of-the-art performance on seven benchmark datasets and sixteen Amazon product reviews datasets. Both the result analysis and the mutual attention weights visualization further demonstrate the effectiveness of the proposed model.;;;https://dl.acm.org/doi/10.1109/TASLP.2019.2942160;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Robust Spectral Clustering for Noisy Data: Modeling Sparse Corruptions Improves Latent Embeddings;;;['Aleksandar Bojchevski', 'Yves Matkovic', 'Stephan Günnemann'];;;August 2017;;;KDD '17: Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining;;;Spectral clustering is one of the most prominent clustering approaches. However, it is highly sensitive to noisy input data. In this work, we propose a robust spectral clustering technique able to handle such scenarios. To achieve this goal, we propose a sparse and latent decomposition of the similarity graph used in spectral clustering. In our model, we jointly learn the spectral embedding as well as the corrupted data - thus, enhancing the clustering performance overall. We propose algorithmic solutions to all three established variants of spectral clustering, each showing linear complexity in the number of edges. Our experimental analysis confirms the significant potential of our approach for robust spectral clustering. Supplementary material is available at www.kdd.in.tum.de/RSC.;;;https://dl.acm.org/doi/10.1145/3097983.3098156;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Spectral Clustering of Large-scale Data by Directly Solving Normalized Cut;;;['Xiaojun Chen', 'Weijun Hong', 'Feiping Nie', 'Dan He', 'Min Yang', 'Joshua Zhexue Huang'];;;July 2018;;;KDD '18: Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining;;;During the past decades, many spectral clustering algorithms have been proposed. However, their high computational complexities hinder their applications on large-scale data. Moreover, most of them use a two-step approach to obtain the optimal solution, which may deviate from the solution by directly solving the original problem. In this paper, we propose a new optimization algorithm, namely Direct Normalized Cut (DNC), to directly optimize the normalized cut model. DNC has a quadratic time complexity, which is a significant reduction comparing with the cubic time complexity of the traditional spectral clustering. To cope with large-scale data, a Fast Normalized Cut (FNC) method with linear time and space complexities is proposed by extending DNC with an anchor-based strategy. In the new method, we first seek a set of anchors and then construct a representative similarity matrix by computing distances between the anchors and the whole data set. To find high quality anchors that best represent the whole data set, we propose a Balanced k-means (BKM) to partition a data set into balanced clusters and use the cluster centers as anchors. Then DNC is used to obtain the final clustering result from the representative similarity matrix. A series of experiments were conducted on both synthetic data and real-world data sets, and the experimental results show the superior performance of BKM, DNC and FNC.;;;https://dl.acm.org/doi/10.1145/3219819.3220039;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Reinforcement Learning with Sequential Information Clustering in Real-Time Bidding;;;['Junwei Lu', 'Chaoqi Yang', 'Xiaofeng Gao', 'Liubin Wang', 'Changcheng Li', 'Guihai Chen'];;;November 2019;;;CIKM '19: Proceedings of the 28th ACM International Conference on Information and Knowledge Management;;;Display advertising is a billion dollar business which is the primary income of many companies. In this scenario, real-time bidding optimization is one of the most important problems, where the bids of ads for each impression are determined by an intelligent policy such that some global key performance indicators are optimized. Due to the highly dynamic bidding environment, many recent works try to use reinforcement learning algorithms to train the bidding agents. However, as the probability of the occurrence of a particular state is typically low and the state representation in current work lacks sequential information, the convergence speed and performance of deep reinforcement algorithms are disappointing. To tackle these two challenges in the real-time bidding scenario, we propose ClusterA3C, a novel Advantage Asynchronous Actor-Critic (A3C) variant integrated with a sequential information extraction scheme and a clustering based state aggregation scheme. We conduct extensive experiments to validate the proposed scheme on a real-world commercial dataset. Experimental results show that the proposed scheme outperforms the state of the art methods in terms of either performance or convergence speed.;;;https://dl.acm.org/doi/10.1145/3357384.3358027;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
VRoC: Variational Autoencoder-aided Multi-task Rumor Classifier Based on Text;;;['Mingxi Cheng', 'Shahin Nazarian', 'Paul Bogdan'];;;April 2020;;;WWW '20: Proceedings of The Web Conference 2020;;;Social media became popular and percolated almost all aspects of our daily lives. While online posting proves very convenient for individual users, it also fosters fast-spreading of various rumors. The rapid and wide percolation of rumors can cause persistent adverse or detrimental impacts. Therefore, researchers invest great efforts on reducing the negative impacts of rumors. Towards this end, the rumor classification system aims to to detect, track, and verify rumors in social media. Such systems typically include four components: (i) a rumor detector, (ii) a rumor tracker, (iii) a stance classifier, and (iv) a veracity classifier. In order to improve the state-of-the-art in rumor detection, tracking, and verification, we propose VRoC, a tweet-level variational autoencoder-based rumor classification system. VRoC consists of a co-train engine that trains variational autoencoders (VAEs) and rumor classification components. The co-train engine helps the VAEs to tune their latent representations to be classifier-friendly. We also show that VRoC is able to classify unseen rumors with high levels of accuracy. For the PHEME dataset, VRoC consistently outperforms several state-of-the-art techniques, on both observed and unobserved rumors, by up to 26.9%, in terms of macro-F1 scores.;;;https://dl.acm.org/doi/10.1145/3366423.3380054;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Speaker and Time-aware Joint Contextual Learning for Dialogue-act Classification in Counselling Conversations;;;['Ganeshan Malhotra', 'Abdul Waheed', 'Aseem Srivastava', 'Md Shad Akhtar', 'Tanmoy Chakraborty'];;;February 2022;;;WSDM '22: Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining;;;The onset of the COVID-19 pandemic has brought the mental health of people under risk. Social counselling has gained remarkable significance in this environment. Unlike general goal-oriented dialogues, a conversation between a patient and a therapist is considerably implicit, though the objective of the conversation is quite apparent. In such a case, understanding the intent of the patient is imperative in providing effective counselling in therapy sessions, and the same applies to a dialogue system as well. In this work, we take forward a small but an important step in the development of an automated dialogue system for mental-health counselling. We develop a novel dataset, named HOPE, to provide a platform for the dialogue-act classification in counselling conversations. We identify the requirement of such conversation and propose twelve domain-specific dialogue-act (DAC) labels. We collect ~ 12.9K utterances from publicly-available counselling session videos on YouTube, extract their transcripts, clean, and annotate them with DAC labels. Further, we propose SPARTA, a transformer-based architecture with a novel speaker- and time-aware contextual learning for the dialogue-act classification. Our evaluation shows convincing performance over several baselines, achieving state-of-the-art on HOPE. We also supplement our experiments with extensive empirical and qualitative analyses of SPARTA.;;;https://dl.acm.org/doi/10.1145/3488560.3498509;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
HGCN: A Heterogeneous Graph Convolutional Network-Based Deep Learning Model Toward Collective Classification;;;['Zhihua Zhu', 'Xinxin Fan', 'Xiaokai Chu', 'Jingping Bi'];;;August 2020;;;KDD '20: Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining;;;Collective classification, as an important technique to study networked data, aims to exploit the label autocorrelation for a group of inter-connected entities with complex dependencies. As the emergence of various heterogeneous information networks (HINs), collective classification at present is confronting several severe challenges stemming from the heterogeneity of HINs, such as complex relational hierarchy, potential incompatible semantics and node-context relational semantics. To address the challenges, in this paper, we propose a novel heterogeneous graph convolutional network-based deep learning model, called HGCN, to collectively categorize the entities in HINs. Our work involves three primary contributions: i) HGCN not only learns the latent relations from the relation-sophisticated HINs via multi-layer heterogeneous convolutions, but also captures the semantic incompatibility among relations with properly-learned edge-level filter parameters; ii) to preserve the fine-grained relational semantics of different-type nodes, we propose a heterogeneous graph convolution to directly tackle the original HINs without any in advance transforming the network from heterogeneity to homogeneity; iii) we perform extensive experiments using four real-world datasets to validate our proposed HGCN, the multi-facet results show that our proposed HGCN can significantly improve the performance of collective classification compared with the state-of-the-art baseline methods.;;;https://dl.acm.org/doi/10.1145/3394486.3403169;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Name-Nationality Classification Technology under Keras Deep Learning;;;['Yu Kang'];;;May 2020;;;BDE 2020: Proceedings of the 2020 2nd International Conference on Big Data Engineering;;;To improve the classification efficiency of personnel nationality information, the classification method of personnel nationality information is explored. First, a new classification method is proposed using the Keras model and deep learning theory. Two methods based on support vector machine (SVM) and convolutional neural network classification are proposed. (1) The personal name is input and a set of numbers corresponding to the positions in the alphabet are output orderly. (2) The personal name is input and the number output relies on the number of occurrences of each character of a name, regardless of order. Second, for the problem that the classification accuracy of nationality information by name is not high, the adaptive moment estimation (Adam) algorithm is used to optimize it. Finally, to prove the reliability of the proposed methods, these methods are used to verify the nationality information of Olympic personnel. The results show that comparing the two methods, the classification method that relies on the number of occurrences of characters in the name gets good grades, and the ultimate average score is 90.35. The score of the first method is only 79.34. Through this investigation, it is found that the second method proposed can effectively use the name of the person to determine the nationality information. Applying it in real life can improve the classification efficiency of personnel nationality information.;;;https://dl.acm.org/doi/10.1145/3404512.3404517;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Understanding Association Between Logged Vehicle Data and Vehicle Marketing Parameters: Using Clustering and Rule-Based Machine Learning;;;['Oskar Dahl', 'Fredrik Johansson', 'Reza Khoshkangini', 'Sepideh Pashami', 'Sławomir Nowaczyk', 'Pihl Claes'];;;August 2020;;;IMMS '20: Proceedings of the 3rd International Conference on Information Management and Management Science;;;Trucks are designed, configured and marketed for various working environments. There lies a concern whether trucks are used as intended by the manufacturer, as usage may impact the longevity, efficiency and productivity of the trucks. In this paper we propose a framework that aims to extract costumers' vehicle behaviours from Logged Vehicle Data (LVD) in order to evaluate whether they align with vehicle configurations, so-called Global Transport Application (GTA) parameters. Gaussian mixture model (GMM)s are employed to cluster and classify various vehicle behaviors from the LVD. Rule-based machine learning (RBML) was applied on the clusters to examine whether vehicle behaviors follow the GTA configuration. Particularly, we propose an approach based on studying associations that is able to extract insights on whether the trucks are used as intended. Experimental results shown that while for the vast majority of the trucks' behaviors seemingly follows their GTA configuration, there are also interesting outliers that warrant further analysis.;;;https://dl.acm.org/doi/10.1145/3416028.3417215;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Mining Semantic Subspaces to Express Discipline-Specific Similarities;;;['Janus Wawrzinek', 'José María González Pinto', 'Wolf-Tilo Balke'];;;August 2020;;;JCDL '20: Proceedings of the ACM/IEEE Joint Conference on Digital Libraries in 2020;;;Word embeddings enable state-of-the-art NLP workflows in im-portant tasks including semantic similarity matching, NER, question answering, and document classification. Recently also the biomedical field started to use word embeddings to provide new access paths for a better understanding of pharmaceutical entities and their relationships, as well as to predict certain chemical properties. The central idea is to gain access to knowledge embedded, but not explicated in biomedical literature. However, a core challenge is the interpretability of the underly-ing embeddings model. Previous work has attempted to inter-pret the semantics of dimensions in word embeddings models to ease model interpretation when applied to semantic similarity task. To do so, the original embedding space is transformed to a sparse or a more condensed space, which then has to be inter-preted in an exploratory (and hence time-consuming) fashion. However, little has been done to assess in real-time whether specific user-provided semantics are actually reflected in the original embedding space. We solve this problem by extracting a semantic subspace from large embedding spaces that better fits the query semantics defined by a user. Our method builds on least-angle regression to rank dimensions according to given semantics properly, i.e. to uncover a subspace to ease both in-terpretation and exploration of the embedding space. We com-pare our methodology to querying the original space as well as to several other recent approaches and show that our method consistently outperforms all competitors.;;;https://dl.acm.org/doi/10.1145/3383583.3398523;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Host-Based Virtual Machine Workload Characterization Using Hypervisor Trace Mining;;;['Hani Nemati', 'Seyed Vahid Azhari', 'Mahsa Shakeri', 'Michel Dagenais'];;;None;;;ACM Transactions on Modeling and Performance Evaluation of Computing Systems;;;Cloud computing is a fast-growing technology that provides on-demand access to a pool of shared resources. This type of distributed and complex environment requires advanced resource management solutions that could model virtual machine (VM) behavior. Different workload measurements, such as CPU, memory, disk, and network usage, are usually derived from each VM to model resource utilization and group similar VMs. However, these course workload metrics require internal access to each VM with the available performance analysis toolkit, which is not feasible with many cloud environments privacy policies.In this article, we propose a non-intrusive host-based virtual machine workload characterization using hypervisor tracing. VM blockings duration, along with virtual interrupt injection rates, are derived as features to reveal multiple levels of resource intensiveness. In addition, the VM exit reason is considered, as well as the resource contention rate due to the host and other VMs. Moreover, the processes and threads preemption rates in each VM are extracted using the collected tracing logs. Our proposed approach further improves the selected features by exploiting a page ranking based algorithm to filter non-important processes running on each VM. Once the metric features are defined, a two-stage VM clustering technique is employed to perform both coarse- and fine-grain workload characterization. The inter-cluster and intra-cluster similarity metrics of the silhouette score is used to reveal distinct VM workload groups, as well as the ones with significant overlap. The proposed framework can provide a detailed vision of the underlying behavior of the running VMs. This can assist infrastructure administrators in efficient resource management, as well as root cause analysis.;;;https://dl.acm.org/doi/10.1145/3460197;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Deep Learning for Neuromarketing; Classification of User Preference using EEG Signals;;;['Maryam Alimardani', 'Mory Kaba'];;;May 2021;;;AH2021: 12th Augmented Human International Conference;;;The present study investigates the applicability of deep learning methods in EEG neuromarketing prediction tasks, compared to traditional machine learning approaches. Neuroscientific methods have expanded research capabilities in marketing and created new insights into consumer behavior and decision making processes. Both machine learning and deep learning approaches can be employed to predict relevant consumer preference from brain activity. The former requires extensive signal processing and feature engineering for classification whereas the later relies on raw brain signals and thus avoids time-consuming preprocessing. In this paper, the performance of a machine learning model comprising an ensemble of algorithms was compared to the performance of a convolutional neural network (CNN) on two independently collected EEG datasets, one concerning product choices and the other movie ratings. While both models showed poor performance for prediction of product choices, the convolutional neural network proved more accurate in the prediction of movie ratings. This provides evidence for the superiority of deep learning algorithms in certain neuromarketing prediction tasks. We discuss the limitations and future application opportunities.;;;https://dl.acm.org/doi/10.1145/3460881.3460930;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Comparison of Land Cover Classification of Ir Sutami Dam Using Machine Learning and Multisource Satellite Imagery;;;['Ainia Walidaroyani', 'Fatwa Ramdani', 'Tri Astoto Kurniawan'];;;September 2021;;;SIET '21: Proceedings of the 6th International Conference on Sustainable Information Engineering and Technology;;;The latest land cover information in the form of maps resulting from image classification can be obtained through remote sensing techniques that utilize satellite imagery, such as Landsat 8 and Sentinel-2. However, no study compares the two satellite images with high classification algorithm accuracy. The previous literature describes several techniques that can be used to classify land cover, but there has been no specific use of similar techniques in the Ir. Sutami. In this study, the author uses a classification technique using the CART (Classification and Regression Tree) algorithm which can present the classification results as a simple tree structure to make the classification process easier and closer. The results of processing Landsat 8 and Sentinel-2 satellite imagery in 2020 show accuracy test results at 91% and 97% for vegetation classes, water bodies, built land, open land, and rice fields. We hope this research can help in providing information to cover the land in the area around Ir. Sutami to avoid the negative impacts of future land-use changes.;;;https://dl.acm.org/doi/10.1145/3479645.3479681;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
ALEX: Active Learning based Enhancement of a Classification Model's EXplainability;;;['Ishani Mondal', 'Debasis Ganguly'];;;October 2020;;;CIKM '20: Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management;;;An active learning (AL) algorithm seeks to construct an effective classifier with a minimal number of labeled examples in a bootstrapping manner. While standard AL heuristics, such as selecting those points for annotation for which a classification model yields least confident predictions, there has been no empirical investigation to see if these heuristics lead to models that are more interpretable to humans. In the era of data-driven learning, this is an important research direction to pursue. This paper describes our work-in-progress towards developing an AL selection function that in addition to model effectiveness also seeks to improve on the interpretability of a model during the bootstrapping steps. Concretely speaking, our proposed selection function trains an 'explainer' model in addition to the classifier model, and favours those instances where a different part of the data is used, on an average, to explain the predicted class. Initial experiments exhibited encouraging trends in showing that such a heuristic can lead to developing more effective and more explainable end-to-end data-driven classifiers.;;;https://dl.acm.org/doi/10.1145/3340531.3417456;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A streaming clustering approach using a heterogeneous system for big data analysis;;;['Dajung Lee', 'Alric Althoff', 'Dustin Richmond', 'Ryan Kastner'];;;November 2017;;;ICCAD '17: Proceedings of the 36th International Conference on Computer-Aided Design;;;Data clustering is a fundamental challenge in data analytics. It is the main task in exploratory data mining and a core technique in machine learning. As the volume, variety, velocity, and variability of data grows, we need more efficient data analysis methods that can scale towards increasingly large and high dimensional data sets. We develop a streaming clustering algorithm that is highly amenable to hardware acceleration. Our algorithm eliminates the need to store the data objects, which removes limits on the size of the data that we can analyze. Our algorithm is highly parameterizable, which allows it to fit to the characteristics of the data set, and scale towards the available hardware resources. Our streaming hardware core can handle more than 40 Msamples/s when processing 3-dimensional streaming data and up to 1.78 Msamples/s for 70-dimensional data. To validate the accuracy and performance of our algorithms we compare it with several common clustering techniques on several different applications. The experimental result shows that it outperforms other prior hardware accelerated clustering systems.;;;https://dl.acm.org/doi/10.5555/3199700.3199793;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Classification with incomplete data and ensemble learners for the prediction of cervical cancer risk;;;['Pinar Yildirim'];;;June 2018;;;ICIST '18: Proceedings of the International Conference on Intelligent Science and Technology;;;Incomplete data is an important problem in analyzing medical data sets. In this study, a comparative analysis of ensemble learning algorithms was carried out for the prediction of cervical cancer risk with incomplete data. Cervical cancer is one of the most common cancers for women world-wide, and many researchers focused on this disease. The dataset was collected from UCI Machine Learning Repository. Mean imputation was used to deal with missing values and some ensemble and standalone classifiers were used to analyze the dataset for the evaluation of the performance. This study supported that imputation approaches and ensemble learning can improve the performance of learning algorithms.;;;https://dl.acm.org/doi/10.1145/3233740.3233741;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Bitcoin Price Prediction Through Opinion Mining;;;['Germán Cheuque Cerda', 'Juan L. Reutter'];;;May 2019;;;WWW '19: Companion Proceedings of The 2019 World Wide Web Conference;;;The Bitcoin protocol and its underlying cryptocurrency have started to shape the way we view digital currency, and opened up a large list of new and interesting challenges. Amongst them, we focus on the question of how is the price of digital currencies affected, which is a natural question especially when considering the price rollercoaster we witnessed for bitcoin in 2017-2018. We work under the hypothesis that price is affected by the web footprint of influential people, we refer to them as crypto-influencers. In this paper we provide neural models for predicting bitcoin price. We compare what happens when the model is fed only with recent price history versus what happens when fed, in addition, with a measure of the positivity or negativity of the sayings of these influencers, measured through a sentiment analysis of their twitter posts. We show preliminary evidence that twitter data should indeed help to predict the price of bitcoin, even though the measures we use in this paper have a lot of room for refinement. In particular, we also discuss the challenges of measuring the correct sensation of these posts, and discuss the work that should help improving our discoveries even further.;;;https://dl.acm.org/doi/10.1145/3308560.3316454;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
PUMiner: Mining Security Posts from Developer Question and Answer Websites with PU Learning;;;['Triet Huynh Minh Le', 'David Hin', 'Roland Croft', 'M. Ali Babar'];;;June 2020;;;MSR '20: Proceedings of the 17th International Conference on Mining Software Repositories;;;Security is an increasing concern in software development. Developer Question and Answer (Q&A) websites provide a large amount of security discussion. Existing studies have used human-defined rules to mine security discussions, but these works still miss many posts, which may lead to an incomplete analysis of the security practices reported on Q&A websites. Traditional supervised Machine Learning methods can automate the mining process; however, the required negative (non-security) class is too expensive to obtain. We propose a novel learning framework, PUMiner, to automatically mine security posts from Q&A websites. PUMiner builds a context-aware embedding model to extract features of the posts, and then develops a two-stage PU model to identify security content using the labelled Positive and Un-labelled posts. We evaluate PUMiner on more than 17.2 million posts on Stack Overflow and 52,611 posts on Security StackExchange. We show that PUMiner is effective with the validation performance of at least 0.85 across all model configurations. Moreover, Matthews Correlation Coefficient (MCC) of PUMiner is 0.906, 0.534 and 0.084 points higher than one-class SVM, positive-similarity filtering, and one-stage PU models on unseen testing posts, respectively. PUMiner also performs well with an MCC of 0.745 for scenarios where string matching totally fails. Even when the ratio of the labelled positive posts to the un-labelled ones is only 1:100, PUMiner still achieves a strong MCC of 0.65, which is 160% better than fully-supervised learning. Using PUMiner, we provide the largest and up-to-date security content on Q&A websites for practitioners and researchers.;;;https://dl.acm.org/doi/10.1145/3379597.3387443;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Machine learning algorithms for oncology big data treatment;;;['Zouiten Mohammed'];;;November 2017;;;ICCWCS'17: Proceedings of the 2nd International Conference on Computing and Wireless Communication Systems;;;Two-dimensional arrays of bi-component structures made of cobalt and permalloy elliptical dots with thickness of 25 nm, length 1 m and width of 225 nm, have been prepared by a self-aligned shadow deposition technique. Brillouin light scattering has been exploited to study the frequency dependence of thermally excited magnetic eigenmodes on the intensity of the external magnetic field, applied along the easy axis of the elements. Our work is part of user-centered healthcare decision-making systems based on a process of predicting cancer distribution. This process should lead to a set of knowledge in Datamining, Ontologies and Geographical Information Systems. It is in the same time iterative and interactive. Therefore, it seems essential to take into account principles and methods of Human-Machine Interaction in the development of such systems. In this respect, development of interactive decision-making systems is currently being approached using two opposing approaches. In the first one, technology is fundamental; the second one is user centered placing the human actors in a central position. Although the first approach is still present in healthcare organizations, the current trend is definitely the user centric. In our framework we propose an approach that aims to integrate the steps of the predicting future from data process into a development model enriched from human-machine interactions. Our application context is the fight against breast cancer in hospitals. We demonstrate that medical decision can be based on a spatial analysis of the geographical distribution of many cancers. Several factors explain our choice of datamining for assistance of health decision-makers for learning in the CART algorithm about patients who are future actors of suspicion.;;;https://dl.acm.org/doi/10.1145/3167486.3167565;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A classification of code changes and test types dependencies for improving machine learning based test selection;;;['Khaled Al-Sabbagh', 'Miroslaw Staron', 'Regina Hebig', 'Francisco Gomes'];;;August 2021;;;PROMISE 2021: Proceedings of the 17th International Conference on Predictive Models and Data Analytics in Software Engineering;;;Machine learning has been increasingly used to solve various software engineering tasks. One example of their usage is in regression testing, where a classifier is built using historical code commits to predict which test cases require execution. In this paper, we address the problem of how to link specific code commits to test types to improve the predictive performance of learning models in improving regression testing. We design a dependency taxonomy of the content of committed code and the type of a test case. The taxonomy focuses on two types of code commits: changing memory management and algorithm complexity. We reviewed the literature, surveyed experienced testers from three Swedish-based software companies, and conducted a workshop to develop the taxonomy. The derived taxonomy shows that memory management code should be tested with tests related to performance, load, soak, stress, volume, and capacity; the complexity changes should be tested with the same dedicated tests and maintainability tests. We conclude that this taxonomy can improve the effectiveness of building learning models for regression testing.;;;https://dl.acm.org/doi/10.1145/3475960.3475987;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Multimodal Deep Learning Based Crop Classification Using Multispectral and Multitemporal Satellite Imagery;;;['Krishna Karthik Gadiraju', 'Bharathkumar Ramachandra', 'Zexi Chen', 'Ranga Raju Vatsavai'];;;August 2020;;;KDD '20: Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining;;;The Food and Agriculture Organization (FAO) of the United Nations predicts that in order to meet the needs of the expected 3 billion population growth by 2050, food production has to increase by 60%. Therefore, monitoring and mapping crops accurately is essential for estimating food production during each crop growing season across the globe. Traditionally, multispectral remote sensing imagery has been widely used for mapping crops worldwide. However, single date imagery does not capture temporal characteristics (phenology) of growing crops, leading to imprecise crop maps and food estimates. On the other hand, purely temporal classification approaches also produce inaccurate crop maps as they do not account for spatial autocorrelations. In this paper, we present a multimodal deep learning solution that jointly exploits spatial-spectral and phenological properties to identify major crop types. Using a two stream architecture, spatial characteristics are captured via a spatial stream consisting of very high resolution images (single date, 1m, 3-spectral bands, USDA NAIP) with a CNN and the phenological characteristics via a temporal stream images (biweekly, 250m, MODIS NDVI) with an LSTM. Experimental results show that the proposed multimodal solution reduces prediction error by 60%.;;;https://dl.acm.org/doi/10.1145/3394486.3403375;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Combining multiple clustering and network analysis for discoveries in gene expression data;;;['Sleiman Alhajj', 'Aya Alhajj', 'Sibel Tariyan Özyer'];;;November 2021;;;ASONAM '21: Proceedings of the 2021 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining;;;Clustering is a challenging research task which could benefit a wide range of practical applications, including bioinformatics. It targets success by optimizing a number of objectives, a characteristic mostly ignored by clustering approaches. This paper describes a synthetic clustering algorithm which first applies multi-objective based approach to produce the alternative clustering solutions. Then the best clusters from each solution are selected and combined into a seed for a compact and effective solution which is expected to be better than all the individual solutions because it combines the best of each. This way, the developed algorithm may be classified as a fuzzy clustering approach because each object may belong to more than one cluster in the synthesized solution with a degree of membership in each cluster. Another interesting aspect of the algorithm is that it identifies the outliers. Further, a network is built from the relationships of the objects within the various clusters. The network is analyzed to reveal interesting discoveries not clearly reflected in the clustering outcome. The validity and applicability of the presented methodology has been assessed using synthetic and real data from the cancer.;;;https://dl.acm.org/doi/10.1145/3487351.3490961;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Machine learning for streaming data: state of the art, challenges, and opportunities;;;['Heitor Murilo Gomes', 'Jesse Read', 'Albert Bifet', 'Jean Paul Barddal', 'João Gama'];;;December 2019;;;ACM SIGKDD Explorations Newsletter;;;Incremental learning, online learning, and data stream learning are terms commonly associated with learning algorithms that update their models given a continuous influx of data without performing multiple passes over data. Several works have been devoted to this area, either directly or indirectly as characteristics of big data processing, i.e., Velocity and Volume. Given the current industry needs, there are many challenges to be addressed before existing methods can be efficiently applied to real-world problems. In this work, we focus on elucidating the connections among the current stateof- the-art on related fields; and clarifying open challenges in both academia and industry. We treat with special care topics that were not thoroughly investigated in past position and survey papers. This work aims to evoke discussion and elucidate the current research opportunities, highlighting the relationship of different subareas and suggesting courses of action when possible.;;;https://dl.acm.org/doi/10.1145/3373464.3373470;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Hotel Reviews Analysis based on Sentiment Classification: Oman Case Study;;;['Aiman Moyaid Said', 'Amal Sultan AI Muqrashi'];;;April 2020;;;ICCTA '20: Proceedings of the 2020 6th International Conference on Computer and Technology Applications;;;Advances in technology and in particular web applications that are related to customer relations management have encouraged users to voice their opinions with the rest of the world. Relevant information needs to be sorted within the large amount data that can employed by the organization to ensure optimal corrective actions. Sentimental Analysis is one such technique that is popular due to its ability to distil relevant information from opinionated text. Managing customer satisfaction and expectations are vital components that add credibility and ensures survival of the organization. It is commonly agreed that these are the strategic components enhance customer allegiance and covet retention. Hotels in particular are wary of the fact that opinions do matter for their reputation and credibility. Hence, they strive to seek feedback from their guests. In this paper, the authors aim to develop a model to classify hotel visitors feedback based on their experience. Four different supervised learning approaches were employed and tested on the collected data set. The result indicates Support Vector Machine (SVM) classifier outperformed the rest of the classifiers in term of effectiveness.;;;https://dl.acm.org/doi/10.1145/3397125.3397147;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Challenge Paper: The Vision for Time Profiled Temporal Association Mining;;;['Vangipuram Radhakrishna', 'Gali Suresh Reddy', 'Puligadda Veereswara Kumar', 'Vinjamuri Janaki'];;;None;;;Journal of Data and Information Quality;;;None;;;https://dl.acm.org/doi/10.1145/3404198;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Benchmarking Data Flow Systems for Scalable Machine Learning;;;['Christoph Boden', 'Andrea Spina', 'Tilmann Rabl', 'Volker Markl'];;;May 2017;;;BeyondMR'17: Proceedings of the 4th ACM SIGMOD Workshop on Algorithms and Systems for MapReduce and Beyond;;;Distributed data flow systems such as Apache Spark or Apache Flink are popular choices for scaling machine learning algorithms in production. Industry applications of large scale machine learning such as click-through rate prediction rely on models trained on billions of data points which are both highly sparse and high-dimensional. Existing Benchmarks attempt to assess the performance of data flow systems such as Apache Flink, Spark or Hadoop with non-representative workloads such as WordCount, Grep or Sort. They only evaluate scalability with respect to data set size and fail to address the crucial requirement of handling high dimensional data. We introduce a representative set of distributed machine learning algorithms suitable for large scale distributed settings which have close resemblance to industry-relevant applications and provide generalizable insights into system performance. We implement mathematically equivalent versions of these algorithms in Apache Flink and Apache Spark, tune relevant system parameters and run a comprehensive set of experiments to assess their scalability with respect to both: data set size and dimensionality of the data. We evaluate the systems for data up to four billion data points and 100 million dimensions. Additionally we compare the performance to single-node implementations to put the scalability results into perspective. Our results indicate that while being able to robustly scale with increasing data set sizes, current state of the art data flow systems are surprisingly inefficient at coping with high dimensional data, which is a crucial requirement for large scale machine learning algorithms.;;;https://dl.acm.org/doi/10.1145/3070607.3070612;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Mining Exoticism from Visual Content with Fusion-based Deep Neural Networks;;;['Andrea Ceroni', 'Chenyang Ma', 'Ralph Ewerth'];;;June 2018;;;ICMR '18: Proceedings of the 2018 ACM on International Conference on Multimedia Retrieval;;;Exoticism is the charm of the unfamiliar, it often means unusual, mystery, and it can evoke the atmosphere of remote lands. Although it has received interest in different arts, like painting and music, no study has been conducted on understanding exoticism from a computational perspective. To the best of our knowledge, this work is the first to explore the problem of exoticism-aware image classification, aiming at automatically measuring the amount of exoticism in images and investigating the significant aspects of the task. The estimation of image exoticism could be applied in fields like advertising and travel suggestion, as well as to increase serendipity and diversity of recommendations and search results. We propose a Fusion-based Deep Neural Network (FDNN) for this task, which combines image representations learned by Deep Neural Networks with visual and semantic hand-crafted features. Comparisons with other Machine Learning models show that our proposed architecture is the best performing one, reaching accuracy over 83% and 91% on two different datasets. Moreover, experiments with classifiers exploiting both visual and semantic features allow to analyze what are the most important aspects for identifying exotic content. Ground truth has been gathered by retrieving exotic and not exotic images through a web search engine by posing queries with exotic and not exotic semantics, and then assessing the exoticism of the retrieved images via a crowdsourcing evaluation. The dataset is publicly released to promote advances in this novel field.;;;https://dl.acm.org/doi/10.1145/3206025.3206044;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
An Empirical Analysis of Backward Compatibility in Machine Learning Systems;;;['Megha Srivastava', 'Besmira Nushi', 'Ece Kamar', 'Shital Shah', 'Eric Horvitz'];;;August 2020;;;KDD '20: Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining;;;In many applications of machine learning (ML), updates are performed with the goal of enhancing model performance. However, current practices for updating models rely solely on isolated, aggregate performance analyses, overlooking important dependencies, expectations, and needs in real-world deployments. We consider how updates, intended to improve ML models, can introduce new errors that can significantly affect downstream systems and users. For example, updates in models used in cloud-based classification services, such as image recognition, can cause unexpected erroneous behavior in systems that make calls to the services. Prior work has shown the importance of "backward compatibility" for maintaining human trust. We study challenges with backward compatibility across different ML architectures and datasets, focusing on common settings including data shifts with structured noise and ML employed in inferential pipelines. Our results show that (i) compatibility issues arise even without data shift due to optimization stochasticity, (ii) training on large-scale noisy datasets often results in significant decreases in backward compatibility even when model accuracy increases, and (iii) distributions of incompatible points align with noise bias, motivating the need for compatibility aware de-noising and robustness methods.;;;https://dl.acm.org/doi/10.1145/3394486.3403379;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Mining Exoticism from Visual Content with Fusion-based Deep Neural Networks;;;['Andrea Ceroni', 'Chenyang Ma', 'Ralph Ewerth'];;;June 2018;;;ICMR '18: Proceedings of the 2018 ACM on International Conference on Multimedia Retrieval;;;Exoticism is the charm of the unfamiliar, it often means unusual, mystery, and it can evoke the atmosphere of remote lands. Although it has received interest in different arts, like painting and music, no study has been conducted on understanding exoticism from a computational perspective. To the best of our knowledge, this work is the first to explore the problem of exoticism-aware image classification, aiming at automatically measuring the amount of exoticism in images and investigating the significant aspects of the task. The estimation of image exoticism could be applied in fields like advertising and travel suggestion, as well as to increase serendipity and diversity of recommendations and search results. We propose a Fusion-based Deep Neural Network (FDNN) for this task, which combines image representations learned by Deep Neural Networks with visual and semantic hand-crafted features. Comparisons with other Machine Learning models show that our proposed architecture is the best performing one, reaching accuracy over 83% and 91% on two different datasets. Moreover, experiments with classifiers exploiting both visual and semantic features allow to analyze what are the most important aspects for identifying exotic content. Ground truth has been gathered by retrieving exotic and not exotic images through a web search engine by posing queries with exotic and not exotic semantics, and then assessing the exoticism of the retrieved images via a crowdsourcing evaluation. The dataset is publicly released to promote advances in this novel field.;;;https://dl.acm.org/doi/10.1145/3206025.3206044;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Feature Selection for the Classification of Alzheimer's Disease Data;;;['Hany Alashwal', 'Areeg Abdalla', 'Mohamed El Halaby', 'Ahmed A. Moustafa'];;;January 2020;;;ICSIM '20: Proceedings of the 3rd International Conference on Software Engineering and Information Management;;;In this paper, we describe the features of our large dataset (6400+ rows and 400+ features) that includes Alzheimer's disease (AD) patients, individuals with mild cognitive impairment (MCI, prodromal stage of Alzheimer's disease), and healthy individuals (without AD or MCI). We also, present a feature selection method applied on the dataset. Unlike prior data mining models that were applied to AD, our dataset is big in nature and includes genetic, neural, nutritional, and cognitive measures of all the individuals. All of these measures in the data have been shown by empirical studies to be related to the development of AD. We used a random forest classifier to discover which features best classify and differentiate between AD patients and healthy individuals. Identifying these features will likely provide evidence for protective factors against the development of AD.;;;https://dl.acm.org/doi/10.1145/3378936.3378982;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
PrivacyCheck: Automatic Summarization of Privacy Policies Using Data Mining;;;['Razieh Nokhbeh Zaeem', 'Rachel L. German', 'K. Suzanne Barber'];;;None;;;ACM Transactions on Internet Technology;;;Prior research shows that only a tiny percentage of users actually read the online privacy policies they implicitly agree to while using a website. Prior research also suggests that users ignore privacy policies because these policies are lengthy and, on average, require 2 years of college education to comprehend. We propose a novel technique that tackles this problem by automatically extracting summaries of online privacy policies. We use data mining models to analyze the text of privacy policies and answer 10 basic questions concerning the privacy and security of user data, what information is gathered from them, and how this information is used. In order to train the data mining models, we thoroughly study privacy policies of 400 companies (considering 10% of all listings on NYSE, Nasdaq, and AMEX stock markets) across industries. Our free Chrome browser extension, PrivacyCheck, utilizes the data mining models to summarize any HTML page that contains a privacy policy. PrivacyCheck stands out from currently available counterparts because it is readily applicable on any online privacy policy. Cross-validation results show that PrivacyCheck summaries are accurate 40% to 73% of the time. Over 400 independent Chrome users are currently using PrivacyCheck.;;;https://dl.acm.org/doi/10.1145/3127519;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Association Rule Mining of Anaphora Based on ParCorFull Corpus;;;['Siqiao Guo', 'Xianbo Li', 'Zhixin Ma'];;;January 2020;;;ICCDE '20: Proceedings of 2020 6th International Conference on Computing and Data Engineering;;;Based on the Apriori algorithm, the association rules of the anaphora in ParCorFull corpus are mined, and the similarities and differences between the written and spoken language represented by speech and discussion are compared. The rules of the whole mining show that the most important anaphora types in news, speech and discussion styles are noun phrases and pronouns respectively. In news style, pronoun is easier to realize the function of antecedent, while in speech and discussion style, noun phrase is more commonly used as anaphora. The rules of local mining show that in journalism, verb phrases are generally not omitted, noun phrases are more directly appeared without modification, and pronouns often point to singular person entity objects with the subject. The rules of speech and discussion are more flexible. Subordinate clauses are all used as anaphoric objects in anaphoric without anaphoric functions.;;;https://dl.acm.org/doi/10.1145/3379247.3379277;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Adaptive-Halting Policy Network for Early Classification;;;['Thomas Hartvigsen', 'Cansu Sen', 'Xiangnan Kong', 'Elke Rundensteiner'];;;July 2019;;;KDD '19: Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining;;;Early classification of time series is the prediction of the class label of a time series before it is observed in its entirety. In time-sensitive domains where information is collected over time it is worth sacrificing some classification accuracy in favor of earlier predictions, ideally early enough for actions to be taken. However, since accuracy and earliness are contradictory objectives, a solution must address this challenge to discover task-dependent trade-offs. We design an early classification model, called EARLIEST, which tackles this multi-objective optimization problem, jointly learning (1) to classify time series and (2) at which timestep to halt and generate this prediction. By learning the objectives together, we achieve a user-controlled balance between these contradictory goals while capturing their natural relationship. Our model consists of the novel pairing of a recurrent discriminator network with a stochastic policy network, with the latter learning a halting-policy as a reinforcement learning task. The learned policy interprets representations generated by the recurrent model and controls its dynamics, sequentially deciding whether or not to request observations from future timesteps. For a rich variety of datasets (four synthetic and three real-world), we demonstrate that EARLIEST consistently out-performs state-of-the-art alternatives in accuracy and earliness while discovering signal locations without supervision.;;;https://dl.acm.org/doi/10.1145/3292500.3330974;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Mutual information using sample variance for text feature selection;;;['Deepak Agnihotri', 'Kesari Verma', 'Priyanka Tripathi'];;;November 2017;;;ICCIP '17: Proceedings of the 3rd International Conference on Communication and Information Processing;;;Feature selection improves the training speed of the classifier without affecting its predictive capability. It selects a subset of most informative words (terms) from the set of all words. Term distribution affects the feature selection process, e.g. an even distribution of terms in a specific class ensures a higher association of these terms with that class, but an even distribution in almost classes shows a lesser association. This paper computes sample variance using standard Mutual Information (MI) method to measure the variations in distribution of terms. MI method assigns a higher rank to the terms distributed in a specific category (i.e. rare terms) which shows it strong influence with the rare terms than common terms (i.e. terms which most frequently in almost classes). To address this issue, a new text feature selection method named Mutual Information Using Sample Variance (MIUSV) is proposed in this paper. It considers sample variance in term distribution while computing the Mutual Information score of the term. Multinomial Naive Bayes (MNB) and k Nearest Neighbor (kNN) classifiers model, check the utilities of the selected terms by the proposed MIUSV. These models classify four standard text data sets, viz. Webkb, 20Newsgroup, Ohsumed10, and Ohsumed23. Two standard performance measures named Macro-F1 and Micro-F1 show a significant improvement in the results using proposed MIUSV method.;;;https://dl.acm.org/doi/10.1145/3162957.3163054;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A Reduced Network Traffic Method for IoT Data Clustering;;;['Ricardo De Azevedo', 'Gabriel Resende Machado', 'Ronaldo Ribeiro Goldschmidt', 'Ricardo Choren'];;;None;;;ACM Transactions on Knowledge Discovery from Data;;;Internet of Things (IoT) systems usually involve interconnected, low processing capacity, and low memory sensor nodes (devices) that collect data in several sorts of applications that interconnect people and things. In this scenario, mining tasks, such as clustering, have been commonly deployed to detect behavioral patterns from the collected data. The centralized clustering of IoT data demands high network traffic to transmit the data from the devices to a central node, where a clustering algorithm must be applied. This approach does not scale as the number of devices increases, and the amount of data grows. However, distributing the clustering process through the devices may not be a feasible approach as well, since the devices are usually simple and may not have the ability to execute complex procedures. This work proposes a centralized IoT data clustering method that demands reduced network traffic and low processing power in the devices. The proposed method uses a data grid to summarize the information at the devices before transmitting it to the central node, reducing network traffic. After the data transfer, the proposed method applies a clustering algorithm that was developed to process data in the summarized representation. Tests with seven datasets provided experimental evidence that the proposed method reduces network traffic and produces results comparable to the ones generated by DBSCAN and HDBSCAN, two robust centralized clustering algorithms.;;;https://dl.acm.org/doi/10.1145/3423139;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Cell Mechanics Based Computational Classification of Red Blood Cells Via Machine Intelligence Applied to Morpho-Rheological Markers;;;['Yan Ge', 'Philipp Rosendahl', 'Claudio Durán', 'Nicole Töpfner', 'Sara Ciucci', 'Jochen Guck', 'Carlo Vittorio Cannistraci'];;;None;;;IEEE/ACM Transactions on Computational Biology and Bioinformatics;;;Despite fluorescent cell-labelling being widely employed in biomedical studies, some of its drawbacks are inevitable, with unsuitable fluorescent probes or probes inducing a functional change being the main limitations. Consequently, the demand for and development of label-free methodologies to classify cells is strong and its impact on precision medicine is relevant. Towards this end, high-throughput techniques for cell mechanical phenotyping have been proposed to get a multidimensional biophysical characterization of single cells. With this motivation, our goal here is to investigate the extent to which an unsupervised machine learning methodology, which is applied exclusively on morpho-rheological markers obtained by real-time deformability and fluorescence cytometry (RT-FDC), can address the difficult task of providing label-free discrimination of reticulocytes from mature red blood cells. We focused on this problem, since the characterization of reticulocytes (their percentage and cellular features) in the blood is vital in multiple human disease conditions, especially bone-marrow disorders such as anemia and leukemia. Our approach reports promising label-free results in the classification of reticulocytes from mature red blood cells, and it represents a step forward in the development of high-throughput morpho-rheological-based methodologies for the computational categorization of single cells. Besides, our methodology can be an alternative but also a complementary method to integrate with existing cell-labelling techniques.;;;https://dl.acm.org/doi/10.1109/TCBB.2019.2945762;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A data modeling approach for classification problems: application to bank telemarketing prediction;;;['Stéphane Cédric Koumetio Tekouabou', 'Walid Cherif', 'Hassan Silkan'];;;March 2019;;;NISS '19: Proceedings of the 2nd International Conference on Networking, Information Systems &amp; Security;;;In this paper, we present a new data modeling approach for five common classification algorithms to optimize the prediction of telemarketing target calls for selling bank long-term deposits. A Portuguese retail bank addressed, from 2008 until 2013, data on its clients, products and social-economic attributes including the effects of the financial crisis. An original set of 150 features has been explored and 21 features are retained for the proposed approach including label. This paper introduces a new modeling approach that preprocessed separately each type of features and normalize them to optimize prediction performance. To evaluate the proposed approach, this paper compares the results obtained with five most known machine learning techniques: Naïve Bayes (NB), Logistic Regression (LR), Decision Trees (DT), Artificial Neural Network (ANN) and Support Vector Machines (SVM) and it yielded better improved performances for all these algorithms in terms of accuracy and f-measure.;;;https://dl.acm.org/doi/10.1145/3320326.3320389;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Gender Classification from Fingerprint-images using Deep Learning Approach;;;['Beanbonyka Rim', 'Junseob Kim', 'Min Hong'];;;October 2020;;;RACS '20: Proceedings of the International Conference on Research in Adaptive and Convergent Systems;;;Accurate gender classification from fingerprint-images brings benefits to various forensic, security and authentication analysis. Those benefits help to narrow down the space for searching and speed up the process for matching for applications such as automatic fingerprint identification systems (AFIS). However, achieving high prediction accuracy without human intervention (such as preprocessing and hand-crafted feature extraction) is currently and potentially a challenge. Therefore, this paper presents a deep learning method to automatically and conveniently estimate gender from fingerprint-images. In particular, the VGG-19, ResNet-50 and EfficientNet-B3 model were exploited to train from scratch. The raw images of fingerprints were fed into the networks for end-to-end learning. The networks trained on 8,000 images, validated on 1,520 images and tested on 360 images. Our experimental results showed that by comparing between those state-of-the-art models (VGG-19, ResNet-50 and EfficientNet-B3), EfficientNet-B3 model achieved the best accuracy of 97.89%, 69.86% and 63.05% for training, validating, and testing, respectively.;;;https://dl.acm.org/doi/10.1145/3400286.3418237;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Design, implementation and test of a flexible tor-oriented web mining toolkit;;;['Alessandro Celestini', 'Stefano Guarino'];;;June 2017;;;WIMS '17: Proceedings of the 7th International Conference on Web Intelligence, Mining and Semantics;;;Searching and retrieving information from the Web is a primary activity needed to monitor the development and usage of Web resources. Possible benefits include improving user experience (e.g. by optimizing query results) and enforcing data/user security (e.g. by identifying harmful websites). Motivated by the lack of ready-to-use solutions, in this paper we present a flexible and accessible toolkit for structure and content mining, able to crawl, download, extract and index resources from the Web. While being easily configurable to work in the "surface" Web, our suite is specifically tailored to explore the Tor dark Web, i.e. the ensemble of Web servers composing the world's most famous darknet. Notably, the toolkit is not just a Web scraper, but it includes two mining modules, respectively able to prepare content to be fed to an (external) semantic engine, and to reconstruct the graph structure of the explored portion of the Web. Other than discussing in detail the design, features and performance of our toolkit, we report the findings of a preliminary run over Tor, that clarify the potential of our solution.;;;https://dl.acm.org/doi/10.1145/3102254.3102266;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
XAI beyond classification: interpretable neural clustering;;;['Xi Peng', 'Yunfan Li', 'Ivor W. Tsang', 'Hongyuan Zhu', 'Jiancheng Lv', 'Joey Tianyi Zhou'];;;None;;;The Journal of Machine Learning Research;;;In this paper, we study two challenging problems in explainable AI (XAI) and data clustering. The first is how to directly design a neural network with inherent interpretability, rather than giving post-hoc explanations of a black-box model. The second is implementing discrete k-means with a differentiable neural network that embraces the advantages of parallel computing, online clustering, and clustering-favorable representation learning. To address these two challenges, we design a novel neural network, which is a differentiable reformulation of the vanilla k-means, called in-Terpretable nEuraL cLustering (TELL). Our contributions are threefold. First, to the best of our knowledge, most existing XAI works focus on supervised learning paradigms. This work is one of the few XAI studies on unsupervised learning, in particular, data clustering. Second, TELL is an interpretable, or the so-called intrinsically explainable and transparent model. In contrast, most existing XAI studies resort to various means for understanding a black-box model with post-hoc explanations. Third, from the view of data clustering, TELL possesses many properties highly desired by k-means, including but not limited to online clustering, plug-and-play module, parallel computing, and provable convergence. Extensive experiments show that our method achieves superior performance comparing with 14 clustering approaches on three challenging data sets.;;;https://dl.acm.org/doi/10.5555/3586589.3586595;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A Geometric Approach for CAD Models Classification based on Shallow Learning;;;['Min Wan', 'Hang Guo', 'Wenjuan Jian'];;;October 2020;;;CAIH2020: Proceedings of the 2020 Conference on Artificial Intelligence and Healthcare;;;Automated classification of three-dimensional geometric models is significant for three-dimensional shape retrieval as well as artificial intelligence application in areas such as civil engineering and mechanical engineering. In this paper, we proposed a geometric approach to classify three-dimensional CAD models. More than 16,000 CAD models were collected from 27 construction projects. Bounding boxes, convex hulls, and alpha shapes were computed on all CAD models and corresponding parameters were extracted as features. Classic supervised learning methods were applied to the extracted features and trained classifiers were evaluated on the collected data to show the efficiency and effectiveness of our method.;;;https://dl.acm.org/doi/10.1145/3433996.3434002;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
HeteGCN: Heterogeneous Graph Convolutional Networks for Text Classification;;;['Rahul Ragesh', 'Sundararajan Sellamanickam', 'Arun Iyer', 'Ramakrishna Bairi', 'Vijay Lingam'];;;March 2021;;;WSDM '21: Proceedings of the 14th ACM International Conference on Web Search and Data Mining;;;We consider the problem of learning efficient and inductive graph convolutional networks for text classification with a large number of examples and features. Existing state-of-the-art graph embedding based methods such as predictive text embedding (PTE) and TextGCN have shortcomings in terms of predictive performance, scalability and inductive capability. To address these limitations, we propose a heterogeneous graph convolutional network (HeteGCN) modeling approach that unites the best aspects of PTE and TextGCN together. The main idea is to learn feature embeddings and derive document embeddings using a HeteGCN architecture with different graphs used across layers. We simplify TextGCN by dissecting into several HeteGCN models which (a) helps to study the usefulness of individual models and (b) offers flexibility in fusing learned embeddings from different models. In effect, the number of model parameters is reduced significantly, enabling faster training and improving performance in small labeled training set scenario. Our detailed experimental studies demonstrate the efficacy of the proposed approach.;;;https://dl.acm.org/doi/10.1145/3437963.3441746;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Research on Ecological Concept of Environmental Art Design Based on Data Mining Technology;;;['Xianghui Zhang'];;;September 2021;;;ICISCAE 2021: 2021 4th International Conference on Information Systems and Computer Aided Education;;;With the rapid development of economy and the continuous improvement of people's living standards, people pay more and more attention to the needs of the spiritual world. Therefore, higher requirements are put forward for environmental art design. With the promotion of global economic integration, people's quality of life has been effectively improved, but at the same time, the rapid development of industrial industries has caused serious pollution to the ecological environment, which has seriously affected people's health and life. At present, people pay more and more attention to the relationship between architecture and ecology, and put forward higher requirements for environmental art design. Infiltrating ecological concept into environmental art design can not only strengthen the artistic effect of design, but also promote the organic combination of ecology and architecture, and realize the common development of ecological benefits and social benefits. Based on data mining technology, this paper explores the principle of adhering to ecological concept in environmental art design, and puts forward the application countermeasures of ecological concept in environmental design, so as to improve the quality of environmental art design and enhance ecological benefits.;;;https://dl.acm.org/doi/10.1145/3482632.3487505;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Representation Learning for Classification in Heterogeneous Graphs with Application to Social Networks;;;['Ludovic Dos Santos', 'Benjamin Piwowarski', 'Ludovic Denoyer', 'Patrick Gallinari'];;;None;;;ACM Transactions on Knowledge Discovery from Data;;;We address the task of node classification in heterogeneous networks, where the nodes are of different types, each type having its own set of labels, and the relations between nodes may also be of different types. A typical example is provided by social networks where node types may for example be users, content, or films, and relations friendship, like, authorship. Learning and performing inference on such heterogeneous networks is a recent task requiring new models and algorithms. We propose a model, Labeling Heterogeneous Network (LaHNet), a transductive approach to classification that learns to project the different types of nodes into a common latent space. This embedding is learned so as to reflect different characteristics of the problem such as the correlation between node labels, as well as the graph topology. The application focus is on social graphs, but the algorithm is general and can be used for other domains. The model is evaluated on five datasets representative of different instances of social data.;;;https://dl.acm.org/doi/10.1145/3201603;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Interpolation-based k-means Clustering Improvement for Sparse, High Dimensional Data;;;['Wanghu Chen', 'Zhen Tian'];;;August 2019;;;ICCBDC '19: Proceedings of the 2019 3rd International Conference on Cloud and Big Data Computing;;;The k-means algorithm is characterized by simple implementation and fast speed, and is the most widely used clustering algorithm. Aiming at the shortcomings of k-means algorithm in noise sensitivity in high-dimensional sparse data sets, the IB k-means (Interpolation-based k-means clustering) algorithm is proposed. Based on the k-means algorithm, the genetic algorithm is used for interpolation, which solves the problem that the sparse data in k-means clustering is easy to merge. The experimental results show that compared with several improved k-means-based clustering methods, the proposed method can achieve better clustering effect and better deal with clustering in high-dimensional sparse data.;;;https://dl.acm.org/doi/10.1145/3358505.3358517;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Shifu: Deep Learning Based Advisor-advisee Relationship Mining in Scholarly Big Data;;;['Wei Wang', 'Jiaying Liu', 'Feng Xia', 'Irwin King', 'Hanghang Tong'];;;April 2017;;;WWW '17 Companion: Proceedings of the 26th International Conference on World Wide Web Companion;;;Scholars in academia are involved in various social relationships such as advisor-advisee relationships. The analysis of such relationship can provide invaluable information for understanding the interactions among scholars as well as providing many researcher-specific applications such as advisor recommendation and academic rising star identification. However, in most cases, high quality advisor-advisee relationship dataset is unavailable. To address this problem, we propose Shifu, a deep-learning-based advisor-advisee relationship identification method which takes into account both the local properties and network characteristics. In particular, we explore how to crawl advisor-advisee pairs from PhDtree project and extract their publication information by matching them with DBLP dataset as the experimental dataset. To the best of our knowledge, no prior effort has been made to address the scientific collaboration network features for relationship identification by exploiting deep learning. Our experiments demonstrate that the proposed method outperforms other state-of-the-art machine learning methods in precision (94%). Furthermore, we apply Shifu to the entire DBLP dataset and obtain a large-scale advisor-advisee relationship dataset.;;;https://dl.acm.org/doi/10.1145/3041021.3054159;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Customer Churn Prediction In Telecommunication Industry Using Machine Learning Classifiers;;;['Nurul Izzati Mohammad', 'Saiful Adli Ismail', 'Mohd Nazri Kama', 'Othman Mohd Yusop', 'Azri Azmi'];;;August 2019;;;ICVISP 2019: Proceedings of the 3rd International Conference on Vision, Image and Signal Processing;;;Customer churn is one of the main problems in telecommunication industry. This study aims to identify the factors that influence customer churn and develop an effective churn prediction model as well as provide best analysis of data visualization results. The dataset has been collected from Kaggle open data website. The proposed methodology for analysis of churn prediction covers several phases: data pre-processing, analysis, implementing machine learning algorithms, evaluation of the classifiers and choose the best one for prediction. Data preprocessing process involved three major action, which are data cleaning, data transformation and feature selection. Machine learning classifiers was chosen are Logistic Regression, Artificial Neural Network and Random Forest. Then, classifiers were evaluated by using performance measurement which are accuracy, precision, recall and error rate in order to find the best classifier. Based on this study, the output shows that logistic regression outperform compared to artificial neural network and random forest.;;;https://dl.acm.org/doi/10.1145/3387168.3387219;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Extracting Relations Between Organizational Patterns Using Association Mining;;;['Shakirullah Waseeb', 'Waheedullah Sulaiman Khail', 'Haji Gul Wahaj', 'Valentino Vranić'];;;July 2020;;;EuroPLoP '20: Proceedings of the European Conference on Pattern Languages of Programs 2020;;;Patterns are powerful when used in combinations. Identifying relationships between patterns is challenging. The existing approaches and pattern formats reflect the relationships with other patterns in a very informal and traditional way. We are proposing an automatic approach which discover such relationships from the patterns descriptive text using text mining and natural language processing techniques. In this work, we demonstrate how it contributes in inference of relationships and its strength among patterns.;;;https://dl.acm.org/doi/10.1145/3424771.3424817;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Cluster management framework for autonomic machine learning platform;;;['Heejin Kim', 'Younggwan Kim', 'Jiman Hong'];;;September 2019;;;RACS '19: Proceedings of the Conference on Research in Adaptive and Convergent Systems;;;Autonomic machine learning platforms must provide the necessary management tasks while monitoring the execution status of remotely running machine learning tasks and the performance of the model being trained. In this paper, we design a cluster management framework. The proposed cluster management framework monitors distributed computing resources so that it helps the autonomic machine learning platform to select the proper machine learning algorithm and to execute the proper machine learning model.;;;https://dl.acm.org/doi/10.1145/3338840.3355691;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Mining string patterns for individuating reading pathologies;;;['Fabio Fassetti', 'Ilaria Fassetti'];;;April 2018;;;SAC '18: Proceedings of the 33rd Annual ACM Symposium on Applied Computing;;;Tachistoscopes are devices that display a word for several seconds and ask the user to write down the word. They have been widely employed to increase recognition speed, to increase reading comprehension and, specially, to individuate reading difficulties and disabilities. Once the therapist is provided with the answers of the patients, a challenging problem is the analysis of the strings to individuate common patterns in the erroneous strings that could raise suspicion of related disabilities. In this direction, this work presents a machine-learning technique aimed at mining exceptional string patterns and precisely designed to tackle the above mentioned problem. The technique is based on non-negative matrix factorization (nnmf) and exploits as features the structure of the words in terms of the letters composing them. To the best of our knowledge this is the first attempt of mining tachistoscope answers to discover intrinsic peculiarities of the words possibly involved in reading disabilities. From the technical point of view, we present a novel variant of nnmf methods with the adjunctive goal of discriminating between sets. The technique has been experimented in a real case study with the help of a speech therapist center.;;;https://dl.acm.org/doi/10.1145/3167132.3167161;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Text-Independent Speaker ID for Automatic Video Lecture Classification Using Deep Learning;;;['Ali Shariq Imran', 'Zenun Kastrati', 'Torbjørn Karl Svendsen', 'Arianit Kurti'];;;April 2019;;;ICCAI '19: Proceedings of the 2019 5th International Conference on Computing and Artificial Intelligence;;;This paper proposes to use acoustic features employing deep neural network (DNN) and convolutional neural network (CNN) models for classifying video lectures in a massive open online course (MOOC). The models exploit the voice pattern of the lecturer for identification and for classifying the video lecture according to the right speaker category. Filter bank and Mel frequency cepstral coefficient (MFCC) feature along with first and second order derivatives (Δ/ΔΔ) are used as input features to the proposed models. These features are extracted from the speech signal which is obtained from the video lectures by separating the audio from the video using FFmpeg. The deep learning models are evaluated using precision, recall, and F1 score and the obtained accuracy is compared for both acoustic features with traditional machine learning classifiers for speaker identification. A significant improvement of 3% to 7% classification accuracy is achieved over the DNN and twice to that of shallow machine learning classifiers for 2D-CNN with MFCC. The proposed 2D-CNN model with an F1 score of 85.71% for text-independent speaker identification makes it plausible to use speaker ID as a classification approach for organizing video lectures automatically in a MOOC setting.;;;https://dl.acm.org/doi/10.1145/3330482.3330508;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
The impact of automatic text translation on classification of online discussions for social and cognitive presences;;;['Arthur Barbosa', 'Máverick Ferreira', 'Rafael Ferreira Mello', 'Rafael Dueire Lins', 'Dragan Gasevic'];;;April 2021;;;LAK21: LAK21: 11th International Learning Analytics and Knowledge Conference;;;This paper reports the findings of a study that measured the effectiveness of employing automatic text translation methods in automated classification of online discussion messages according to the categories of social and cognitive presences. Specifically, we examined the classification of 1,500 Portuguese and 1,747 English discussion messages using classifiers trained on the datasets before and after the application of text translation. While the English model generated, with the original and translated texts, achieved results (accuracy and Cohen’s κ) similar to those of the previously reported studies, the translation to Portuguese led to a decrease in the performance. The indicates the general viability of the proposed approach when converting the text to English. Moreover, this study highlighted the importance of different features and resources, and the limitations of the resources for Portuguese as reasons of the results obtained.;;;https://dl.acm.org/doi/10.1145/3448139.3448147;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A Combination of Transfer Learning and Deep Learning for Medicinal Plant Classification;;;['Nghia Duong-Trung', 'Luyl-Da Quach', 'Minh-Hoang Nguyen', 'Chi-Ngon Nguyen'];;;February 2019;;;ICIIT '19: Proceedings of the 2019 4th International Conference on Intelligent Information Technology;;;Medicinal plants are an important element of indigenous medical systems in Viet Nam. These resources are usually regarded as a part of culture's traditional knowledge. One of the prerequisites for any medical recommendation systems and/or applications is accurate identification and classification of medicinal plants. Hence, leveraging technology in automatic classification of these curative herbs has become essential. Unfortunately, building and training a machine learning model from scratch is next to impossible due to the lack of hardware infrastructure and finance support. It painfully restricts the requirements of rapid solutions to deal with the demand. For this purpose, this paper exploits the idea of transfer learning which is the improvement of learning in a new prediction task through the transferability of knowledge from a related prediction task that has already been learned. By utilizing state-of-the-art deep networks re-trained with our collected data, our extensive experiments show that the proposed combination performs perfectly and achieves the classification accuracy of 98.7% within the acceptable training time.;;;https://dl.acm.org/doi/10.1145/3321454.3321464;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
SDDSMOTE:Synthetic Minority Oversampling Technique based on Sample Density Distribution for Enhanced Classification on Imbalanced Microarray Data;;;['Qikang Wan', 'Xiongshi Deng', 'Min Li', 'Haotian Yang'];;;February 2022;;;ICCDA '22: Proceedings of the 2022 6th International Conference on Compute and Data Analysis;;;Microarray gene expression data contain an unbalanced distribution of data samples among different classes, which poses a challenge to machine learning-based cancer diagnosis. In addition, microarray data consists of small samples and a huge number of genes, which cause the curse of dimensionality. In order to enhance the performance of learning models on imbalanced microarray data, we propose a novel preprocessing method based on the SMOTE, named SDDSMOTE (Synthetic Minority Oversampling Technique based on Sample Density Distribution). The whole preprocessing includes two steps. First, by using a feature selection technology, irrelevant genes are eliminated and obtaining reduced gene data. Second, SDDSMOTE is used to rebalance the reduced data. We performed comprehensive experiments to compare SDDSMOTE with other state-of-the-art Oversampling algorithms using two Support Vector Machine and Logistic Regression on 8 publicly available microarray expression data sets. The experimental results show that SDDSMOTE outperforms compared algorithms in terms of various evaluation criteria, such as Accuracy, F-score, G-mean, and AUC, which indicates its superiority.;;;https://dl.acm.org/doi/10.1145/3523089.3523096;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Using constraint mining to analyze software development processes;;;['Thomas Krismayer', 'Christoph Mayr-Dorn', 'Johann Tuder', 'Rick Rabiser', 'Paul Grünbacher'];;;May 2019;;;ICSSP '19: Proceedings of the International Conference on Software and System Processes;;;Most software development organizations nowadays use issue-tracking tools to manage software processes throughout the life-cycle. Still, understanding development processes, keeping track of process execution, and reacting to deviations in projects remains challenging. In particular, the actual process usually differs from the process perceived by developers, making it hard to define the processes developers are expected to carry out. This is further challenged by frequently changing processes and process variations in different projects and teams. In this paper we describe an empirical study in which we applied a constraint mining approach from the field of software monitoring to automatically extract process definitions in the form of constraints. Specifically, we applied the approach to datasets extracted from four real-world projects (using the Jira issue-tracking tool) in a company developing a recreational activities platform. The mined constraints describe the boundaries of the actual processes and thus help to understand process behavior. Constraints can be frequently re-mined to understand process evolution. The mined constraints can also be used to monitor future processes to detect problems in the development process early on. We involved a domain expert to evaluate the usefulness of our results and investigated to what extent the mined constraints reflect the official development process of the company. We also report mining results for different issue types, across projects, and over different time windows.;;;https://dl.acm.org/doi/10.1109/ICSSP.2019.00021;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Data Mining Techniques in Direct Marketing on Imbalanced Data using Tomek Link Combined with Random Under-sampling;;;['Ümit Yılmaz', 'Cengiz Gezer', 'Zafer Aydın', 'V. Çağrı Güngör'];;;May 2021;;;ICISDM '21: Proceedings of the 2021 5th International Conference on Information System and Data Mining;;;Determining the potential customers is very important in direct marketing. Data mining techniques are one of the most important methods for companies to determine potential customers. However, since the number of potential customers is very low compared to the number of non-potential customers, there is a class imbalance problem that significantly affects the performance of data mining techniques. In this paper, different combinations of basic and advanced resampling techniques such as Synthetic Minority Oversampling Technique (SMOTE), Tomek Link, RUS, and ROS were evaluated to improve the performance of customer classification. Different feature selection techniques are used in order the decrease the number of non-informative features from the data such as Information Gain, Gain Ratio, Chi-squared, and Relief. Classification performance was compared and utilized using several data mining techniques, such as LightGBM, XGBoost, Gradient Boost, Random Forest, AdaBoost, ANN, Logistic Regression, Decision Trees, SVC, Bagging Classifier based on ROC AUC and sensitivity metrics. A combination of Tomek Link and Random Under-Sampling as a resampling technique and Chi-squared method as feature selection algorithm showed superior performance among the other combinations. Detailed performance evaluations demonstrated that with the proposed approach, LightGBM, which is a gradient boosting algorithm based on decision tree, gave the best results among the other classifiers with 0.947 sensitivity and 0.896 ROC AUC value.;;;https://dl.acm.org/doi/10.1145/3471287.3471299;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Search, Mining, and Their Applications on Mobile Devices: Introduction to the Special Issue;;;['Hongning Wang', 'Rui Li', 'Milad Shokouhi', 'Hang Li', 'Yi Chang'];;;None;;;ACM Transactions on Information Systems;;;In recent years, mobile devices have become the most popular interface for users to retrieve and access information: recent reports show that users spend significantly more time and issue more search queries on mobile devices than on desktops in the United States.1 The accelerated growth of mobile usage brings unique opportunities to the information retrieval and data mining research communities.Mobile devices capture rich contextual and personal signals that can be leveraged to accurately predict users’ intent for serving more relevant content and can even proactively provide novel zero-query recommendations. Apple Siri, Google Now, and Microsoft Cortana are recent examples of such emerging systems. Furthermore, mobile devices constantly generate a huge amount of sensor footprints (e.g., GPS, motion sensors) and user activity data (e.g., used apps) that are often missing from their desktop counterparts. These new sources of implicit and explicit user feedback are valuable for discovering actionable knowledge, and designing better systems that serve each individual the right content at the right time and location. In addition, by aggregating mobile interactions across individuals, one can infer interesting conclusions beyond search and recommendation. Generating real-time traffic estimates is one example of such applications.This special issue focuses on research problems of search, mining, and their applications in mobile devices. Topics of interest in this special issue include but are not limited to mobile data mining and management, mobile search, personalization and recommendation, mobile user interfaces and human-computer interaction, and new applications in the mobile environment. The aim of this special issue is to bring together top experts across multiple disciplines, including information retrieval, data mining, mobile computing, and cyberphysical systems, such that academic and industrial researchers can exchange ideas and share the latest developments on the state of the art and practice of mobile search and mobile data mining.;;;https://dl.acm.org/doi/10.1145/3086665;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Deep Learning-Based Models for Classification of Invasive Plant Species from Hyperspectral Remotely Sensed Data;;;['Abdulla A. Omeer', 'Ratnadeep R. Deshmukh'];;;August 2021;;;DSMLAI '21': Proceedings of the International Conference on Data Science, Machine Learning and Artificial Intelligence;;;Invasive plant species are plants, which spread extensively outside their native ecosystem. They pose a threat to the environment and economy at global and local scales, making effective mapping and detecting essential. This study aims to develop deep neural network-based classification models for hyperspectral data. The spectral reflectance of ten invasive plant leaves was collected using ASD FieldSpec4 standard Hi-Res device. Samples were collected from Dr. Babasaheb Ambedkar Marathwada university campus and Himayat Bagh garden in Aurangabad city, Maharashtra, India. Two types of deep neural networks (DNN) were applied: the first one is based on the one-dimensional convolutional neural network (1D CNN), and the second is based on the convolutional long short term memory (CNN-LSTM). We proposed and compare the performance of the two models with three existing models, multilayer perceptron (MLP), random forest (RF), and support vector machine (SVM). The CNN-LSTM model achieves the highest discrimination accuracy among all the other models with an overall test accuracy of 99.3% and an F1_score of 0.98. Moreover, the CNN model achieves a high classification accuracy of 97.3% and an F1 score of 0.97, which contains the inception layer. In the CNN-LSTM model, the convolutional layer extracts the input vector of spectral features and feeds them to the LSTM layer to capture contextual information. In 1D CNN, the inception layer concatenates the output of multiple kernel sizes and adds flexibility to the model to improve the classification performance. This study revealed that our proposed models provide better performance than traditional machine learning methods and simple deep learning ones.;;;https://dl.acm.org/doi/10.1145/3484824.3484884;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Classification of Imbalanced Documents by Feature Selection;;;['Yusuke Adachi', 'Naoya Onimura', 'Takanori Yamashita', 'Sachio Hirokawa'];;;May 2017;;;ICCDA '17: Proceedings of the International Conference on Compute and Data Analysis;;;We previously worked on category classification problem of reuter 's newspaper article using SVM and feature selection. In the study, feature selection by SVM-score [Sakai, Hirokawa, 2012] showed high accuracy. It was also expected to be superior to other standard indicators in case data is imbalanced. This study aimed to show the effectiveness of feature selection by SVM-score in machine learning with imbalanced data. For the reuter's data, F-measure was calculated in the classification experiment of all 13 categories. As a result, feature selection by SVM-score shows high f-measure and precision. In addition, we found feature words of negative example improve the classification performance.;;;https://dl.acm.org/doi/10.1145/3093241.3093246;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Attributed Collaboration Network Embedding for Academic Relationship Mining;;;['Wei Wang', 'Jiaying Liu', 'Tao Tang', 'Suppawong Tuarob', 'Feng Xia', 'Zhiguo Gong', 'Irwin King'];;;None;;;ACM Transactions on the Web;;;Finding both efficient and effective quantitative representations for scholars in scientific digital libraries has been a focal point of research. The unprecedented amounts of scholarly datasets, combined with contemporary machine learning and big data techniques, have enabled intelligent and automatic profiling of scholars from this vast and ever-increasing pool of scholarly data. Meanwhile, recent advance in network embedding techniques enables us to mitigate the challenges of large scale and sparsity of academic collaboration networks. In real-world academic social networks, scholars are accompanied with various attributes or features, such as co-authorship and publication records, which result in attributed collaboration networks. It has been observed that both network topology and scholar attributes are important in academic relationship mining. However, previous studies mainly focus on network topology, whereas scholar attributes are overlooked. Moreover, the influence of different scholar attributes are unclear. To bridge this gap, in this work, we present a novel framework of Attributed Collaboration Network Embedding (ACNE) for academic relationship mining. ACNE extracts four types of scholar attributes based on the proposed scholar profiling model, including demographics, research, influence, and sociability. ACNE can learn a low-dimensional representation of scholars considering both scholar attributes and network topology simultaneously. We demonstrate the effectiveness and potentials of ACNE in academic relationship mining by performing collaborator recommendation on two real-world datasets and the contribution and importance of each scholar attribute on scientific collaborator recommendation is investigated. Our work may shed light on academic relationship mining by taking advantage of attributed collaboration network embedding.;;;https://dl.acm.org/doi/10.1145/3409736;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Transfer Learning for Molecular Cancer Classification Using Deep Neural Networks;;;['Rahul K. Sevakula', 'Vikas Singh', 'Nishchal K. Verma', 'Chandan Kumar', 'Yan Cui'];;;None;;;IEEE/ACM Transactions on Computational Biology and Bioinformatics;;;The emergence of deep learning has impacted numerous machine learning based applications and research. The reason for its success lies in two main advantages: 1) it provides the ability to learn very complex non-linear relationships between features and 2) it allows one to leverage information from unlabeled data that does not belong to the problem being handled. This paper presents a transfer learning procedure for cancer classification, which uses feature selection and normalization techniques in conjunction with s sparse auto-encoders on gene expression data. While classifying any two tumor types, data of other tumor types were used in unsupervised manner to improve the feature representation. The performance of our algorithm was tested on 36 two-class benchmark datasets from the GEMLeR repository. On performing statistical tests, it is clearly ascertained that our algorithm statistically outperforms several generally used cancer classification approaches. The deep learning based molecular disease classification can be used to guide decisions made on the diagnosis and treatment of diseases, and therefore may have important applications in precision medicine.;;;https://dl.acm.org/doi/10.1109/TCBB.2018.2822803;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Enhanced situation space mining for data streams;;;['Yisroel Mirsky', 'Tal Halpern', 'Rishabh Upadhyay', 'Sivan Toledo', 'Yuval Elovici'];;;April 2017;;;SAC '17: Proceedings of the Symposium on Applied Computing;;;Data streams can capture the situation which an actor is experiencing. Knowledge of the present situation is highly beneficial for a wide range of applications. An algorithm called pcStream can be used to extract situations from a numerical data stream in an unsupervised manner. Although pcStream outperforms other stream clustering algorithms at this task, pcStream has two major flaws. The first is its complexity due to continuously performing principal component analysis (PCA). The second is its difficulty in detecting emerging situations whose distributions overlap in the same feature space. In this paper we introduce pcStream2, a variant of pcStream which employs windowing and persistence in order to distinguish between emerging overlapping concepts. We also propose the use of incremental PCA (IPCA) to reduce the overall complexity and memory requirements of the algorithm. Although any IPCA algorithm can be used, we use a novel IPCA algorithm called Just-In-Time PCA which is better suited for processing streams. JIT-PCA makes intelligent 'short cuts' in order to reduce computations. We provide experimental results on real-world datasets that demonstrates how the proposed improvements make pcStream2 a more accurate and practical tool for situation space mining.;;;https://dl.acm.org/doi/10.1145/3019612.3019671;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Identification and Classification of Chinese Traditional Musical Instruments Based on Deep Learning Algorithm;;;['Peipei Cao'];;;January 2021;;;CONF-CDS 2021: The 2nd International Conference on Computing and Data Science;;;The classification of musical instruments based on deep learning is the application of deep learning in the direction of music information retrieval, which is a hot topic in the field of speech recognition in recent years. Deep learning is an important branch of artificial intelligence and a new direction of data mining in recent years. Deep learning is born from artificial neural networks. It has more hidden layers than shallow neural networks. This is the origin of the word "depth ". Unlike traditional neural networks, deep learning increases unsupervised learning. Therefore, this paper studies whether we can use the powerful feature extraction ability of deep learning to study the classification algorithm of music genre recognition based on deep confidence network for the recognition and classification of music genres and traditional Chinese musical instruments. The experimental results show that the accuracy of the algorithm is as high as 99.2.;;;https://dl.acm.org/doi/10.1145/3448734.3450836;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Convolutional Neural Networks for Toxic Comment Classification;;;['Spiros V. Georgakopoulos', 'Sotiris K. Tasoulis', 'Aristidis G. Vrahatis', 'Vassilis P. Plagianakos'];;;July 2018;;;SETN '18: Proceedings of the 10th Hellenic Conference on Artificial Intelligence;;;Flood of information is produced in a daily basis through the global internet usage arising from the online interactive communications among users. While this situation contributes significantly to the quality of human life, unfortunately it involves enormous dangers, since online texts with high toxicity can cause personal attacks, online harassment and bullying behaviors. This has triggered both industrial and research community in the last few years while there are several attempts to identify an efficient model for online toxic comment prediction. However, these steps are still in their infancy and new approaches and frameworks are required. On parallel, the data explosion that appears constantly, makes the construction of new machine learning computational tools for managing this information, an imperative need. Thankfully advances in hardware, cloud computing and big data management allow the development of Deep Learning approaches appearing very promising performance so far. For text classification in particular the use of Convolutional Neural Networks (CNN) have recently been proposed approaching text analytics in a modern manner emphasizing in the structure of words in a document. In this work, we employ this approach to discover toxic comments in a large pool of documents provided by a current Kaggle's competition regarding Wikipedia's talk page edits. To justify this decision we choose to compare CNNs against the traditional bag-of-words approach for text analysis combined with a selection of algorithms proven to be very effective in text classification. The reported results provide enough evidence that CNN enhance toxic comment classification reinforcing research interest towards this direction.;;;https://dl.acm.org/doi/10.1145/3200947.3208069;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
ROM: A Requirement Opinions Mining Method Preliminary Try Based on Software Review Data;;;['Ying Wang', 'Liwei Zheng', 'Ning Li'];;;January 2020;;;ICMSS 2020: Proceedings of the 2020 4th International Conference on Management Engineering, Software Engineering and Service Sciences;;;Requirement opinion mining aims to mine user opinions that can be used to help the mining of software requirements from various data sources. However, in the development of social network systems, software application platforms or stores and other data sources, the massive, noisy, non-standard data, makes the mining of effective requirement opinions more difficult. Therefore, there is less work in software requirements mining based on the data of software review in development social media or application market. This paper attempts to provide some knowledge support for requirement user story establishing in RE based on the opinion mining and clustering of massively software review data. First of all, this paper combines the requirements of the requirements engineering field to define the requirement opinions, functional requirement opinions and non-functional requirements opinions. Secondly, using the deep learning model to classify the functional requirement reviews and non-functional requirements reviews included in the reviews; Based on the differences between functional data and non-functional data, this paper defines three categories in the description of software functional data, and chooses to use sequence labeling methods to identify functional requirements. Then use the K-means clustering method based on word vector to cluster the review data, and combine TF-IDF and syntactic analysis to extract the aspect and aspect requirements or specific requirements of the requirement opinion respectively, so as to realize the requirement opinion mining of software review data. Finally, this article will give a case study based on the user review data of the mobile phone application service platform 360 mobile assistants.;;;https://dl.acm.org/doi/10.1145/3380625.3380665;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A particle swarm optimization based feature selection approach to transfer learning in classification;;;['Bach Hoai Nguyen', 'Bing Xue', 'Peter Andreae'];;;July 2018;;;GECCO '18: Proceedings of the Genetic and Evolutionary Computation Conference;;;Transfer learning aims to use acquired knowledge from existing (source) domains to improve learning performance on a different but similar (target) domains. Feature-based transfer learning builds a common feature space, which can minimize differences between source and target domains. However, most existing feature-based approaches usually build a common feature space with certain assumptions about the differences between domains. The number of common features needs to be predefined. In this work, we propose a new feature-based transfer learning method using particle swarm optimization (PSO), where a new fitness function is developed to guide PSO to automatically select a number of original features and shift source and target domains to be closer. Classification performance is used in the proposed fitness function to maintain the discriminative ability of selected features in both domains. The use of classification accuracy leads to a minimum number of model assumptions. The proposed algorithm is compared with four state-of-the-art feature-based transfer learning approaches on three well-known real-world problems. The results show that the proposed algorithm is able to extract less than half of the original features with better performance than using all features and outperforms the four benchmark semi-supervised and unsupervised algorithms. This is the first time Evolutionary Computation, especially PSO, is utilized to achieve feature selection for transfer learning.;;;https://dl.acm.org/doi/10.1145/3205455.3205540;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Data Label System Classification Method of Power Equipment and Customers Based on Data Middle Platform;;;['Xiaojing Lin', 'Hu Liu', 'Honggang Wang', 'Shi Liu', 'Min Guo', 'Wenjin Zhou'];;;October 2021;;;AIAM2021: 2021 3rd International Conference on Artificial Intelligence and Advanced Manufacture;;;The development of digital information technology promotes the reform and reform of information digitization of electric power enterprises in the power industry. The role of data in business process is highlighted. As a data product, data label is more and more applied to business system. Power equipment and customers are the two core subjects of power grid power enterprises, including "generation, transmission, distribution, transformation and utilization". Through the construction of data label system, the application efficiency and application value of power data can be improved. The construction of corresponding label system can effectively enhance the safe and stable operation level of power grid and the lean management and service level of power grid enterprises. Data label classification is the basis of the construction of the label system, and the scientificity and rationality of the classification are very important to the promotion and application of data labels. This paper focuses on the core management resources of power enterprises, based on the data center of power enterprises, takes the business demand as the core, combines the typical classification methods and relevant theoretical basis, studies the classification method and benchmarking of big data label system of power enterprises Through the statistics of user tags and the calculation of root mean square error, the relevant conclusion is drawn that label classification can optimize customer energy efficiency and realize Internet precision marketing.;;;https://dl.acm.org/doi/10.1145/3495018.3495436;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Adaptive Spatial Clustering for Multi-Dimensional Data and Its Cloud Model Representation;;;['Bin Gao', 'Xinhai Zhang', 'Xiaobin Xu', 'Yifeng Liu'];;;April 2020;;;ICCAI '20: Proceedings of the 2020 6th International Conference on Computing and Artificial Intelligence;;;In view of the problem that the number of clusters need to be set manually, it is difficult to process the multi-dimensional data effectively, and the clustering results are not described effectively when the multi-dimensional data need to be clustered. This paper proposes a method of adaptive spatial clustering and its cloud model representation for the multi-dimensional data. This method can be used to cluster multi-dimensional spatial data, form qualitative description of clustering results, and realize the reconstruction and verification of qualitative description features. Through simulation experiments, this method can cluster data adaptively without the need to set the number of clusters. At the same time, it has a good ability to abstract and reconstruct digital features.;;;https://dl.acm.org/doi/10.1145/3404555.3404634;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Water governance network analysis using graphlet mining;;;['Apratim Das', 'Mike Drakos', 'Alex Aravind', 'Darwin Horning'];;;August 2019;;;ASONAM '19: Proceedings of the 2019 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining;;;Growing population, urbanization, increased sophistication in life, global warming, and climate change are some of the factors that can worsen the scarcity and quality of water in coming decades. Therefore, a sustainable water governance is essential across the world to face this challenge. In this paper, we study two water governance networks constructed from ground-truth using a new network analysis technique called graphlet analysis. Graphlet is gaining popularity in network analysis due to its power in exposing network structure and functions. To the best of our knowledge, this is the first work to apply graphlet analysis to study water governance network.;;;https://dl.acm.org/doi/10.1145/3341161.3343696;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A Novel Online Stacked Ensemble for Multi-Label Stream Classification;;;['Alican Büyükçakir', 'Hamed Bonab', 'Fazli Can'];;;October 2018;;;CIKM '18: Proceedings of the 27th ACM International Conference on Information and Knowledge Management;;;As data streams become more prevalent, the necessity for online algorithms that mine this transient and dynamic data becomes clearer. Multi-label data stream classification is a supervised learning problem where each instance in the data stream is classified into one or more pre-defined sets of labels. Many methods have been proposed to tackle this problem, including but not limited to ensemble-based methods. Some of these ensemble-based methods are specifically designed to work with certain multi-label base classifiers; some others employ online bagging schemes to build their ensembles. In this study, we introduce a novel online and dynamically-weighted stacked ensemble for multi-label classification, called GOOWE-ML, that utilizes spatial modeling to assign optimal weights to its component classifiers. Our model can be used with any existing incremental multi-label classification algorithm as its base classifier. We conduct experiments with 4 GOOWE-ML-based multi-label ensembles and 7 baseline models on 7 real-world datasets from diverse areas of interest. Our experiments show that GOOWE-ML ensembles yield consistently better results in terms of predictive performance in almost all of the datasets, with respect to the other prominent ensemble models.;;;https://dl.acm.org/doi/10.1145/3269206.3271774;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Joint Distributed Representation of Text and Structure of Semi-Structured Documents;;;['Abhishek Laddha', 'Salil Joshi', 'Samiulla Shaikh', 'Sameep Mehta'];;;July 2018;;;HT '18: Proceedings of the 29th on Hypertext and Social Media;;;Majority of textual data over web is in the form of semi-structured documents. Thus, structural skeleton of such documents plays important role in determining the semantics of the data content. Presence of structure sometimes allows us to write simple rules to extract such information, but it may not be always possible due to flexibility in the structure and the frequency with which such structures are altered. In this paper, we propose a joint modeling of text and the associated structure to effectively capture the semantics of the semi-structure documents. The model simultaneously learns the dense continuous representation for word tokens and the structure associated with them. We utilize the context of structures for projection such that similar structures containing semantically similar topics are close to each other in vector space. We explore two semantic text mining tasks over web data to test the effectiveness of our representation viz., document similarity, and table semantic component identification. In context of traditional rule-based approaches, both these tasks demand rich, domain-specific knowledge sources, homogeneous schema for the documents, and rules that capture the semantics. On the other hand, our approach is unsupervised and resource conscious in nature. Despite of working without knowledge resources and large training data, it performs at par with state-of-the-art rule based and other unsupervised approaches.;;;https://dl.acm.org/doi/10.1145/3209542.3209551;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Explainable Recommendation via Multi-Task Learning in Opinionated Text Data;;;['Nan Wang', 'Hongning Wang', 'Yiling Jia', 'Yue Yin'];;;June 2018;;;SIGIR '18: The 41st International ACM SIGIR Conference on Research &amp; Development in Information Retrieval;;;Explaining automatically generated recommendations allows users to make more informed and accurate decisions about which results to utilize, and therefore improves their satisfaction. In this work, we develop a multi-task learning solution for explainable recommendation. Two companion learning tasks of user preference modeling for recommendation and opinionated content modeling for explanation are integrated via a joint tensor factorization. As a result, the algorithm predicts not only a user's preference over a list of items, i.e., recommendation, but also how the user would appreciate a particular item at the feature level, i.e., opinionated textual explanation. Extensive experiments on two large collections of Amazon and Yelp reviews confirmed the effectiveness of our solution in both recommendation and explanation tasks, compared with several existing recommendation algorithms. And our extensive user study clearly demonstrates the practical value of the explainable recommendations generated by our algorithm.;;;https://dl.acm.org/doi/10.1145/3209978.3210010;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A Novel Feature Hashing With Efficient Collision Resolution for Bag-of-Words Representation of Text Data;;;['Bobby A. Eclarin', 'Arnel C. Fajardo', 'Ruji P. Medina'];;;September 2018;;;NLPIR '18: Proceedings of the 2nd International Conference on Natural Language Processing and Information Retrieval;;;Text Mining is widely used in many areas transforming unstructured text data from all sources such as patients' record, social media network, insurance data, and news, among others into an invaluable source of information. The Bag Of Words (BoW) representation is a means of extracting features from text data for use in modeling. In text classification, a word in a document is assigned a weight according to its frequency and frequency between different documents; therefore, words together with their weights form the BoW. One way to solve the issue of voluminous data is to use the feature hashing method or hashing trick. However, collision is inevitable and might change the result of the whole process of feature generation and selection. Using the vector data structure, the lookup performance is improved while resolving collision and the memory usage is also efficient.;;;https://dl.acm.org/doi/10.1145/3278293.3278301;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Towards Sustainable Dairy Management - A Machine Learning Enhanced Method for Estrus Detection;;;['Kevin Fauvel', 'Véronique Masson', 'Élisa Fromont', 'Philippe Faverdin', 'Alexandre Termier'];;;July 2019;;;KDD '19: Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining;;;Our research tackles the challenge of milk production resource use efficiency in dairy farms with machine learning methods. Reproduction is a key factor for dairy farm performance since cows milk production begin with the birth of a calf. Therefore, detecting estrus, the only period when the cow is susceptible to pregnancy, is crucial for farm efficiency. Our goal is to enhance estrus detection (performance, interpretability), especially on the currently undetected silent estrus (35% of total estrus), and allow farmers to rely on automatic estrus detection solutions based on affordable data (activity, temperature). In this paper, we first propose a novel approach with real-world data analysis to address both behavioral and silent estrus detection through machine learning methods. Second, we present LCE, a local cascade based algorithm that significantly outperforms a typical commercial solution for estrus detection, driven by its ability to detect silent estrus. Then, our study reveals the pivotal role of activity sensors deployment in estrus detection. Finally, we propose an approach relying on global and local (behavioral versus silent) algorithm interpretability (SHAP) to reduce the mistrust in estrus detection solutions.;;;https://dl.acm.org/doi/10.1145/3292500.3330712;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
DeepSinger: Singing Voice Synthesis with Data Mined From the Web;;;['Yi Ren', 'Xu Tan', 'Tao Qin', 'Jian Luan', 'Zhou Zhao', 'Tie-Yan Liu'];;;August 2020;;;KDD '20: Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining;;;In this paper, we develop DeepSinger, a multi-lingual multi-singer singing voice synthesis (SVS) system, which is built from scratch using singing training data mined from music websites. The pipeline of DeepSinger consists of several steps, including data crawling, singing and accompaniment separation, lyrics-to-singing alignment, data filtration, and singing modeling. Specifically, we design a lyrics-to-singing alignment model to automatically extract the duration of each phoneme in lyrics starting from coarse-grained sentence level to fine-grained phoneme level, and further design a multi-lingual multi-singer singing model based on a feed-forward Transformer to directly generate linear-spectrograms from lyrics, and synthesize voices using Griffn-Lim. DeepSinger has several advantages over previous SVS systems: 1) to the best of our knowledge, it is the first SVS system that directly mines training data from music websites, 2) the lyrics-to-singing alignment model further avoids any human efforts for alignment labeling and greatly reduces labeling cost, 3) the singing model based on a feed-forward Transformer is simple and efficient, by removing the complicated acoustic feature modeling in parametric synthesis and leveraging a reference encoder to capture the timbre of a singer from noisy singing data, and 4) it can synthesize singing voices in multiple languages and multiple singers. We evaluate DeepSinger on our mined singing dataset that consists of about 92 hours data from 89 singers on three languages (Chinese, Cantonese and English). The results demonstrate that with the singing data purely mined from the Web, DeepSinger can synthesize high-quality singing voices in terms of both pitch accuracy and voice naturalness. Our audio samples are shown in https://speechresearch.github.io/deepsinger/.;;;https://dl.acm.org/doi/10.1145/3394486.3403249;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Understanding E-learners' Behaviour Using Data Mining Techniques;;;['Muna Al Fanah', 'Muhammad Ayub Ansari'];;;March 2019;;;ICBDE '19: Proceedings of the 2019 International Conference on Big Data and Education;;;The information from Higher Education Institutions (HEIs) is primarily relevant for decision maker and educators. This study tackles e-learners behaviour using machine learning, particularly association rules and classifiers. Learners are characterized by a set of behaviours and attitudes that determine their learning abilities and skills. Learning from data generated by online learners may have significant impacts, however, few studies cover this resource from machine learning perspectives. We examine different data mining techniques including Random Forests, Logistic Regressions and Bayesian Networks as classifiers used for predicting e-learners' classes (High, Medium and Low). The novelty of this study is that it explores and compares classifiers performance on the behaviour of online learners on four variables: raise hands, visiting IT resources, view announcement and discussion impact on e-learners. The results of this study indicate an 80% accuracy level obtained by Bayesian Networks; in contrast, the Random Forests have only 63% accuracy level and Logistic Regressions for 58%.;;;https://dl.acm.org/doi/10.1145/3322134.3322145;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Machine Learning Based Graph Mining of Large-scale Network and Optimization;;;['Mingyue Liu'];;;May 2021;;;ICAIIS 2021: 2021 2nd International Conference on Artificial Intelligence and Information Systems;;;Network science possesses an unreplaceable status in solving social and scientific problems. This study focuses on investigating machine learning based graph mining of large-scale network and optimization by using the California road network dataset from Stanford as the large-scale social network. After building different neural networks with various hyperparameters and selected learning activation functions, accuracy results were compared and conclusions include: 1) Changing the activation functions does not have much effect on accuracy compared to neural network structures, 2) Changing the learning rate does not have much effect either and 3) exponential linear unit (ELU) is sensitive to the change of hidden layer size and kernel compared to rectifier linear unit (ReLU) and hyperbolic tangent (Tanh), causing decrement of accuracy after growth of hidden layer size brings overfitting. These conclusions were drawn based on numeric experiments where the final accuracy rate kept the average of every ten trials. However, given this specific dataset, the accuracy of all the models remain high so that varying neural network parameters or structures does not present much distinctive divergence.;;;https://dl.acm.org/doi/10.1145/3469213.3470320;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Deep Learning--based Text Classification: A Comprehensive Review;;;['Shervin Minaee', 'Nal Kalchbrenner', 'Erik Cambria', 'Narjes Nikzad', 'Meysam Chenaghlu', 'Jianfeng Gao'];;;None;;;ACM Computing Surveys;;;Deep learning--based models have surpassed classical machine learning--based approaches in various text classification tasks, including sentiment analysis, news categorization, question answering, and natural language inference. In this article, we provide a comprehensive review of more than 150 deep learning--based models for text classification developed in recent years, and we discuss their technical contributions, similarities, and strengths. We also provide a summary of more than 40 popular datasets widely used for text classification. Finally, we provide a quantitative analysis of the performance of different deep learning models on popular benchmarks, and we discuss future research directions.;;;https://dl.acm.org/doi/10.1145/3439726;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Research on Financial Technology Ability Evaluation of Global Systemically Important Banks Based on Data Mining;;;['Kexin Yu'];;;September 2021;;;ICISCAE 2021: 2021 4th International Conference on Information Systems and Computer Aided Education;;;Financial science and technology is a technology-driven financial innovation, which aims to use modern scientific and technological achievements to transform or innovate financial products, business models, business processes, etc., and to promote financial development, improve quality and increase efficiency. This paper uses data mining technology to construct an index of the degree of financial technology application of G-SIBs, and uses the 2019 G-SIBs data to examine the heterogeneous impact of financial technology application on different types of G-SIBs risks. The results show that: with the adjustment of G-SIBs itself and the standardization of supervision, the risk-taking level of G-SIBs is effectively suppressed. Non-systemic and significant banks have good risk-taking ability. In this process, G-SIBs seized some high-quality and low-risk customers of small and medium-sized banks due to its advantages in capital cost, which had crowding-out effect on small and medium-sized banks.;;;https://dl.acm.org/doi/10.1145/3482632.3482640;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A Gene-disease-based Machine Learning Approach to Identify Prostate Cancer Biomarkers;;;['Osama Hamzeh', 'Luis Rueda'];;;September 2019;;;BCB '19: Proceedings of the 10th ACM International Conference on Bioinformatics, Computational Biology and Health Informatics;;;Identifying biomarkers that can be used to classify certain disease stages, or identify when a disease becomes more aggressive is one of the most important applications of machine learning. Traditional biomarker identification approaches, typically, use machine learning techniques to identify a number of genes and macromolecules as biomarkers that can be used to diagnose specific diseases or states of diseases with very high accuracy, using molecular measurements such as mutations, gene expression, copy number variations, and others. However, Experts' opinions and knowledge is required to validate such findings. We propose a new machine learning model that incorporates a knowledge-based system used to integrate the findings of the DisGeNET database which is a framework that provides proven relationships among diseases and genes. The machine learning pipeline starts by reducing the number of features using a filter based feature selection method. The DisGeNET database is used to score each gene relating to the given cancer name. Then a wrapper-based feature-selection method picks the best set of genes with the highest classification accuracy. The method returned key genes from multiple data sets that classify with high accuracy while being biologically relevant, and no human intervention needed. Initial results provide a high area under the curve with a handful of genes that are already proven to be related to the relevant disease and state based on the latest published medical findings.;;;https://dl.acm.org/doi/10.1145/3307339.3343479;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Features Exploration for Grades Prediction using Machine Learning;;;['Kevin Bouchard', 'Lucas Gonzales', 'Julien Maitre', 'Sébastien Gaboury'];;;September 2020;;;GoodTechs '20: Proceedings of the 6th EAI International Conference on Smart Objects and Technologies for Social Good;;;The province of Quebec in Canada has begun to implement an important plan to bring a digital shift to the educational system. One of the key aspects of this plan is to implement a global electronic student file system. These electronic files encompass a lot of information that can in turn be used to monitor the progress of the students. In this paper, our team was able to obtain a large dataset from this new technological platform and used it to predict the grade of students. We tested up to 328 features and produced different datasets for classification. Moreover, different features selection methods were used. Finally, we were able to predict the end of the year final grade with up to 75% accuracy.;;;https://dl.acm.org/doi/10.1145/3411170.3411232;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Emotional Contagion-Based Social Sentiment Mining in Social Networks by Introducing Network Communities;;;['Xiaobao Wang', 'Di Jin', 'Mengquan Liu', 'Dongxiao He', 'Katarzyna Musial', 'Jianwu Dang'];;;November 2019;;;CIKM '19: Proceedings of the 28th ACM International Conference on Information and Knowledge Management;;;The rapid development of social media services has facilitated the communication of opinions through online news, blogs, microblogs, instant-messages, and so on. This article concentrates on the mining of readers' social sentiments evoked by social media materials. Existing methods are only applicable to a minority of social media like news portals with emotional voting information, while ignore the emotional contagion between writers and readers. However, incorporating such factors is challenging since the learned hidden variables would be very fuzzy (because of the short and noisy text in social networks). In this paper, we try to solve this problem by introducing a high-order network structure, i.e. communities. We first propose a new generative model called Community-Enhanced Social Sentiment Mining (CESSM), which 1) considers the emotional contagion between writers and readers to capture precise social sentiment, and 2) incorporates network communities to capture coherent topics. We then derive an inference algorithm based on Gibbs sampling. Empirical results show that, CESSM achieves significantly superior performance against the state-of-the-art techniques for text sentiment classification and interestingness in social sentiment mining.;;;https://dl.acm.org/doi/10.1145/3357384.3357941;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A novel network traffic classification approach via discriminative feature learning;;;['Lixin Zhao', 'Lijun Cai', 'Aimin Yu', 'Zhen Xu', 'Dan Meng'];;;March 2020;;;SAC '20: Proceedings of the 35th Annual ACM Symposium on Applied Computing;;;Network traffic classification plays an important role in many network monitoring and security tasks. More recently, with the development of deep learning techniques, the performance of network traffic classification has been significantly improved due to the powerful feature representations learned by deep neural networks. Despite the great success that has been achieved, the problems of within-class diversity and between-class similarity are still big challenges. In this paper, we propose to train a CNN model by optimizing a new discriminative objective function, where apart from minimizing the empirical risk, a metric learning regularization term is also imposed on the learned features. This metric learning regularization term enforces the CNN model to learn more discriminative features in the mapped feature space, where the instances from the same class are closer together while the instances of different classes are farther apart. We conduct extensive experiments to evaluate the proposed method on three traffic datasets. The experimental results demonstrate that our proposed method outperforms the existing baseline methods and obtains state-of-the-art results on all the three datasets.;;;https://dl.acm.org/doi/10.1145/3341105.3373844;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Classification of vessel activity in streaming data;;;['Ioannis Kontopoulos', 'Konstantinos Chatzikokolakis', 'Konstantinos Tserpes', 'Dimitris Zissis'];;;July 2020;;;DEBS '20: Proceedings of the 14th ACM International Conference on Distributed and Event-based Systems;;;In this paper we motivate the need for real-time vessel behaviour classification and describe in detail our event-based classification approach, as implemented in our real-world industry strong maritime event detection service at MarineTraffic.com. A novel approach is presented for the classification of vessel activity from real-time data streams. The proposed solution splits vessel trajectories into multiple overlapping segments and distinguishes the ones in which a vessel is engaged in trawling or longlining operation (e.g. fishing activity) from other segments that a vessel is simply underway from its departure towards its destination. We evaluate the effectiveness of our tool on real-world data, demonstrating that it can practically achieve high accuracy results. We present our results and findings intended for both researchers and practitioners in the field of intelligent ship tracking and surveillance.;;;https://dl.acm.org/doi/10.1145/3401025.3401763;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Towards safe machine learning for CPS: infer uncertainty from training data;;;['Xiaozhe Gu', 'Arvind Easwaran'];;;April 2019;;;ICCPS '19: Proceedings of the 10th ACM/IEEE International Conference on Cyber-Physical Systems;;;Machine learning (ML) techniques are increasingly applied to decision-making and control problems in Cyber-Physical Systems among which many are safety-critical, e.g., chemical plants, robotics, autonomous vehicles. Despite the significant benefits brought by ML techniques, they also raise additional safety issues because 1) most expressive and powerful ML models are not transparent and behave as a black box and 2) the training data which plays a crucial role in ML safety is usually incomplete. An important technique to achieve safety for ML models is "Safe Fail", i.e., a model selects a reject option and applies the backup solution, a traditional controller or a human operator for example, when it has low confidence in a prediction. Data-driven models produced by ML algorithms learn from training data, and hence they are only as good as the examples they have learnt. As pointed in [17], ML models work well in the "training space" (i.e., feature space with sufficient training data), but they could not extrapolate beyond the training space. As observed in many previous studies, a feature space that lacks training data generally has a much higher error rate than the one that contains sufficient training samples [31]. Therefore, it is essential to identify the training space and avoid extrapolating beyond the training space. In this paper, we propose an efficient Feature Space Partitioning Tree (FSPT) to address this problem. Using experiments, we also show that, a strong relationship exists between model performance and FSPT score.;;;https://dl.acm.org/doi/10.1145/3302509.3311038;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Transfer Learning for Classification of Fruit Ripeness Using VGG16;;;['Asep Nana Hermana', 'Dewi Rosmala', 'Milda Gustiana Husada'];;;January 2021;;;ICCMB '21: Proceedings of the 2021 4th International Conference on Computers in Management and Business;;;Early diagnosis of maturity carried out by experts in laboratory tests is often not applicable for fast and inexpensive implementation. Using deep learning, an image of various fruits used as data input. Training deep learning models requires large, hard-to-come datasets to perform the task in order to achieve optimal results. In this study. There are 4 research objects, namely apples, oranges, mangoes, and tomatoes used totaling around 9000 training data. Data were trained using 200 epoch iterations using the transfer learning method with the VGG16 models. At the top layer of both models, the same MLP is applied with several parameters, data is converted from RGB to L * a * b with the aim of being a color descriptor on the fruit. Trained using CNN VGG16 with the transfer learning method. The Dropout 0.5 shows the best performance of experiment with 4 scenario that used different technique and show result the best performance with an average score of accuracy rate from scenario 4 is 92%.;;;https://dl.acm.org/doi/10.1145/3450588.3450943;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Few-Shot Text and Image Classification via Analogical Transfer Learning;;;['Wenhe Liu', 'Xiaojun Chang', 'Yan Yan', 'Yi Yang', 'Alexander G. Hauptmann'];;;None;;;ACM Transactions on Intelligent Systems and Technology;;;Learning from very few samples is a challenge for machine learning tasks, such as text and image classification. Performance of such task can be enhanced via transfer of helpful knowledge from related domains, which is referred to as transfer learning. In previous transfer learning works, instance transfer learning algorithms mostly focus on selecting the source domain instances similar to the target domain instances for transfer. However, the selected instances usually do not directly contribute to the learning performance in the target domain. Hypothesis transfer learning algorithms focus on the model/parameter level transfer. They treat the source hypotheses as well-trained and transfer their knowledge in terms of parameters to learn the target hypothesis. Such algorithms directly optimize the target hypothesis by the observable performance improvements. However, they fail to consider the problem that instances that contribute to the source hypotheses may be harmful for the target hypothesis, as instance transfer learning analyzed. To relieve the aforementioned problems, we propose a novel transfer learning algorithm, which follows an analogical strategy. Particularly, the proposed algorithm first learns a revised source hypothesis with only instances contributing to the target hypothesis. Then, the proposed algorithm transfers both the revised source hypothesis and the target hypothesis (only trained with a few samples) to learn an analogical hypothesis. We denote our algorithm as Analogical Transfer Learning. Extensive experiments on one synthetic dataset and three real-world benchmark datasets demonstrate the superior performance of the proposed algorithm.;;;https://dl.acm.org/doi/10.1145/3230709;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Mining Infrequent High-Quality Phrases from Domain-Specific Corpora;;;['Li Wang', 'Wei Zhu', 'Sihang Jiang', 'Sheng Zhang', 'Keqiang Wang', 'Yuan Ni', 'Guotong Xie', 'Yanghua Xiao'];;;October 2020;;;CIKM '20: Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management;;;Phrase mining is a fundamental task for text analysis and has various downstream applications such as named entity recognition, topic modeling, and relation extraction. In this paper, we focus on mining high-quality phrases from domain-specific corpora with special consideration of infrequent ones. Previous methods might miss infrequent high-quality phrases in the candidate selection stage. And these methods rely on explicit features to mine phrases while rarely considering the implicit features. In addition, completeness is rarely explicitly considered in the evaluation of a high-quality phrase. In this paper, we propose a novel approach that exploits a sequence labeling model to capture infrequent phrases. And we employ implicit semantic features and contextual POS tag statistics to measure meaningfulness and completeness, respectively. Experiments over four real-world corpora demonstrate that our method achieves significant improvements over previous state-of-the-art methods across different domains and languages.;;;https://dl.acm.org/doi/10.1145/3340531.3412029;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Survey on High-Dimensional Medical Data Clustering;;;['Velmurugan Arresh Balaji', 'Chulwoong Choi', 'Kyungbaek Kim'];;;September 2020;;;SMA 2020: The 9th International Conference on Smart Media and Applications;;;In a relative less span of time we can process and store a large quantity of data due to technological advancements. There is a rapid change in the nature of data, specifically, the dimensional property of data, mostly in multi and high-dimensional. In terms of heterogeneity of data, Data analysis have becoming a humungous task, Because the volume and complexity in data has been increasing incrementally. In data mining, there is a tool called Data clustering, used in many disciplines in order to extract the meaningful knowledge from seemingly unstructured data. The high-dimensional patient's health records such as immune system status, DICOM Images like CT/PET images, electronic medical records, microarray data like gene expressions, genetic background, etc., In this article we have done a survey on high dimensional medical data clustering and different approaches related to this problem. It also focusses on the real-life applications and recent methods in high dimensional cluster analysis.;;;https://dl.acm.org/doi/10.1145/3426020.3426071;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Frequent subtree mining on the automata processor: challenges and opportunities;;;['Elaheh Sadredini', 'Reza Rahimi', 'Ke Wang', 'Kevin Skadron'];;;June 2017;;;ICS '17: Proceedings of the International Conference on Supercomputing;;;Frequency counting of complex patterns such as subtrees is more challenging than for simple itemsets and sequences, as the number of possible candidate patterns in a tree is much higher than one-dimensional data structures, with dramatically higher processing times. In this paper, we propose a new and scalable solution for frequent subtree mining (FTM) on the Automata Processor (AP), a new and highly parallel accelerator architecture. We present a multi-stage pruning framework on the AP, called AP-FTM, to reduce the search space of FTM candidates. This achieves up to 353X speedup at the cost of a small reduction in accuracy, on four real-world and synthetic datasets, when compared with PatternMatcher, a practical and exact CPU solution. To provide a fully accurate and still scalable solution, we propose a hybrid method to combine AP-FTM with a CPU exact-matching approach, and achieve up to 262X speedup over PatternMatcher on a challenging database. We also develop a GPU algorithm for FTM, but show that the AP also outperforms this. The results on a synthetic database show the AP advantage grows further with larger datasets.;;;https://dl.acm.org/doi/10.1145/3079079.3079084;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Fast Outage Analysis of Large-scale Production Clouds with Service Correlation Mining;;;['Yaohui Wang', 'Guozheng Li', 'Zijian Wang', 'Yu Kang', 'Yangfan Zhou', 'Hongyu Zhang', 'Feng Gao', 'Jeffrey Sun', 'Li Yang', 'Pochian Lee', 'Zhangwei Xu', 'Pu Zhao', 'Bo Qiao', 'Liqun Li', 'Xu Zhang', 'Qingwei Lin'];;;May 2021;;;ICSE '21: Proceedings of the 43rd International Conference on Software Engineering;;;Cloud-based services are surging into popularity in recent years. However, outages, i.e., severe incidents that always impact multiple services, can dramatically affect user experience and incur severe economic losses. Locating the root-cause service, i.e., the service that contains the root cause of the outage, is a crucial step to mitigate the impact of the outage. In current industrial practice, this is generally performed in a bootstrap manner and largely depends on human efforts: the service that directly causes the outage is identified first, and the suspected root cause is traced back manually from service to service during diagnosis until the actual root cause is found. Unfortunately, production cloud systems typically contain a large number of interdependent services. Such a manual root cause analysis is often time-consuming and labor-intensive. In this work, we propose COT, the first outage triage approach that considers the global view of service correlations. COT mines the correlations among services from outage diagnosis data. After learning from historical outages, COT can infer the root cause of emerging ones accurately. We implement COT and evaluate it on a real-world dataset containing one year of data collected from Microsoft Azure, one of the representative cloud computing platforms in the world. Our experimental results show that COT can reach a triage accuracy of 82.1%~83.5%, which outperforms the state-of-the-art triage approach by 28.0%~29.7%.;;;https://dl.acm.org/doi/10.1109/ICSE43902.2021.00085;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A User Profile Analysis Framework Driven by Distributed Machine Learning for Big Data;;;['Xiaodong Wang', 'Qing Wang', 'Ye Tao'];;;July 2019;;;AICS 2019: Proceedings of the 2019 International Conference on Artificial Intelligence and Computer Science;;;In recent years, big data has become the new focus of attention from all walks of life. The valuable information contained in big data becomes the driving force for people to process and analyze big data. Big data analytics helps enterprises to take better decisions to improve business output. As a user description tool, user profile is widely used in various fields. However, it is difficult to deal with large-scale datasets using traditional methods since the established processes was not designed to handle large volumes of data. In this paper, we propose a user profile analysis framework using machine learning approach which apply advanced machine learning programs to solve industrial scale problems. And this approach can be effective to speculate real and potential needs of various groups of users and precisely extract individual characteristics and group generality. By introducing high-level data parallel framework, the process of large-scale data processing can be executed efficiently. We use real-world data to validate the effectiveness of the proposed framework.;;;https://dl.acm.org/doi/10.1145/3349341.3349431;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Classifying Feature Models Maintainability based on Machine Learning Algorithms;;;['Publio Silva', 'Carla I. M. Bezerra', 'Rafael Lima', 'Ivan Machado'];;;October 2020;;;SBCARS '20: Proceedings of the 14th Brazilian Symposium on Software Components, Architectures, and Reuse;;;Maintenance in the context of SPLs is a topic of interest, and that still needs further investigation. There are several ways to evaluate the maintainability of a feature model (FM), one of which is a manual or automated analysis of quality measures. However, the use of measures does not allow to evaluate the FM quality as a whole, as each measure considers a specific characteristic of FM. In general, the measures have wide ranges of values and do not have a clear definition of what is appropriate and inappropriate. In this context, the goal of this work is to investigate the use of machine learning techniques to classify the feature model maintainability. The research questions investigated in the study were: (i) how could machine learning techniques aid to classify FMs maintainability; and, (ii) which FM classification model has the best accuracy and precision. In this work, we proposed an approach for FM maintainability classification using machine learning technics. For that, we used a dataset of 15 FM maintainability measures calculated for 326 FMs, and we used machine learning algorithms to clustering. After this, we used thresholds to evaluate the general maintainability of each cluster. With this, we built 5 maintainability classification models that have been evaluated with the accuracy and precision metrics.;;;https://dl.acm.org/doi/10.1145/3425269.3425276;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A Comparative Study for Classification on Different Domain;;;['Noviyanti Tri Maretta Sagala', 'Jenq-Haur Wang'];;;February 2018;;;ICMLC '18: Proceedings of the 2018 10th International Conference on Machine Learning and Computing;;;There is no individual classification technique has been shown to deal with all kinds of classification problems. The objective is to select the technique which more possibly reaches the best performance for any domain of data set. We focus on classifying datasets in different domains and properties such as numerical, categorical, and textual. We deal with one versus all strategy to handle multi-class problems. In the experiment, we compared the performance of 4 classification techniques namely Boosted C5.0, KNN, Naïve Bayes, and SVM on 10-fold cross-validation on different number of features. For numerical data set (low and high dimensional data set), the performance of KNN was better than other classification methods. For a categorical and textual data set, Naïve Bayes and SVM were outperformed, respectively.;;;https://dl.acm.org/doi/10.1145/3195106.3195129;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Clustering Stability via Concept-based Nonnegative Matrix Factorization;;;['Nghia Duong-Trung', 'Minh-Hoang Nguyen', 'Hanh T. H. Nguyen'];;;January 2019;;;ICMLSC '19: Proceedings of the 3rd International Conference on Machine Learning and Soft Computing;;;One of the most important contributions of topic modeling is to accurately and the ectively discover and classify documents in a collection of texts by a number of clusters/topics. However, finding an appropriate number of topics is a particularly challenging model selection question. In this context, we introduce a new unsupervised conceptual stability framework to access the validity of a clustering solution. We integrate the proposed framework into nonnegative matrix factorization (NMF) to guide the selection of desired number of topics. Our model provides a exible way to enhance the interpretation of NMF for the effective clustering solutions. The work presented in this paper crosses the bridge between stability-based validation of clustering solutions and NMF in the context of unsupervised learning. We perform a thorough evaluation of our approach over a wide range of real-world datasets and compare it to current state-of-the-art which are two NMF-based approaches and four Latent Dirichlet Allocation (LDA) based models. the quantitative experimental results show that integrating such conceptual stability analysis into NMF can lead to significant improvements in the document clustering and information retrieval the ectiveness.;;;https://dl.acm.org/doi/10.1145/3310986.3310991;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Classification of Grain Discoloration via Transfer Learning and Convolutional Neural Networks;;;['Nghia Duong-Trung', 'Luyl-Da Quach', 'Minh-Hoang Nguyen', 'Chi-Ngon Nguyen'];;;January 2019;;;ICMLSC '19: Proceedings of the 3rd International Conference on Machine Learning and Soft Computing;;;Grain discoloration disease of rice is an emerging threat to rice harvest in Vietnam as well as all over the world and it acquires specific attention as it results in qualitative loss of harvested crop. An accurate classification is preliminary to any kind of intervention. Unfortunately, collecting enough grain discoloration data as well as building and training a machine learning model from scratch is next to impossible due to the lack of hardware infrastructure and finance support. It painfully restricts the needs of rapid solutions to deal with the disease. For this purpose, this paper exploits the idea of transfer learning which is the improvement of learning in a new prediction task through the transfer of knowledge from a related prediction task that has already been learned. By utilizing convolutional neural networks trained with our collected data, our experiment shows that the proposed idea performs perfectly and achieves the classification accuracy of 88.2% with the acceptable training time on a normal laptop.;;;https://dl.acm.org/doi/10.1145/3310986.3310997;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Recurrent Halting Chain for Early Multi-label Classification;;;['Thomas Hartvigsen', 'Cansu Sen', 'Xiangnan Kong', 'Elke Rundensteiner'];;;August 2020;;;KDD '20: Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining;;;Early multi-label classification of time series, the assignment of a label set to a time series before the series is entirely observed, is critical for time-sensitive domains such as healthcare. In such cases, waiting too long to classify can render predictions useless, regardless of their accuracy, while predicting prematurely can result in potentially costly erroneous results. When predicting multiple labels (for example, types of infections), dependencies between labels can be learned and leveraged to improve overall accuracy. Together, reliably predicting the correct label set of a time series while observing as few timesteps as possible is challenging because these goals are contradictory in that fewer timesteps often means worse accuracy. To achieve early yet sufficiently accurate predictions, correlations between labels must be accounted for since direct evidence of some labels may only appear late in the series. We design an effective solution to this open problem, the Recurrent Halting Chain (RHC), that for the first time integrates key innovations in both Early and Multi-label Classification into one multi-objective model. RHC uses a recurrent neural network to jointly model raw time series as well as correlations between labels, resulting in a novel order-free classifier chain that tackles this time-sensitive multi-label learning task. Further, RHC employs a reinforcement learning-based halting network to decide at each timestep which, if any, classes should be predicted, learning to build the label set over time. Using two real-world time-sensitive datasets and popular multi-label metrics, we show that RHC outperforms recent alternatives by predicting more-accurate label sets earlier.;;;https://dl.acm.org/doi/10.1145/3394486.3403191;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A Novel Classification Scheme of Moving Targets at Sea Based on Ward's and K-means Clustering;;;['Yan Jiang', 'Bo Li', 'Hao Zhang', 'Quming Luo', 'Pengxin Zhou'];;;October 2018;;;CSAE '18: Proceedings of the 2nd International Conference on Computer Science and Application Engineering;;;Based1 on the structure database technology, Ward's and K-means clustering, a classification and identification scheme is proposed for the monitoring data of the moving targets at sea. First, a structural database is built to store the monitored data. Secondly, by analyzing the movement rules of ships which derived from the automatic identification system(AIS), the identification features of the moving targets at sea are obtained and extracted them from the monitored data. And then, the Ward's clustering is used to classify the feature data. Finally, the K-means clustering is used to identify the existing formation ships. The simulation results show that the proposed scheme is applicable to classify and identify the moving targets at sea.;;;https://dl.acm.org/doi/10.1145/3207677.3278058;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Learning to Cluster Documents into Workspaces Using Large Scale Activity Logs;;;['Weize Kong', 'Michael Bendersky', 'Marc Najork', 'Brandon Vargo', 'Mike Colagrosso'];;;August 2020;;;KDD '20: Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining;;;Google Drive is widely used for managing personal and work-related documents in the cloud. To help users organize their documents in Google Drive, we develop a new feature to allow users to create a set of working files for ongoing easy access, called workspace. A workspace is a cluster of documents, but unlike a typical document cluster, it contains documents that are not only topically coherent, but are also useful in the ongoing user tasks. To alleviate the burden of creating workspaces manually, we automatically cluster documents into suggested workspaces. We go beyond the textual similarity-based unsupervised clustering paradigm and instead directly learn from users' activity for document clustering. More specifically, we extract co-access signals (i.e., whether a user accessed two documents around the same time) to measure document relatedness. We then use a neural document similarity model that incorporates text, metadata, as well as co-access features. Since human labels are often difficult or expensive to collect, we extract weak labels based on co-access data at large scale for model training. Our offline and online experiments based on Google Drive show that (a) co-access features are very effective for document clustering; (b) our weakly supervised clustering achieves comparable or even better performance compared to the models trained with human labels; and (c) the weakly supervised method leads to better workspace suggestions that the users accept more often in the production system than baseline approaches.;;;https://dl.acm.org/doi/10.1145/3394486.3403291;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
English Teaching Ability Evaluation Based on Big Data Fuzzy k-means Clustering Algorithm;;;['Wei Zhang'];;;January 2021;;;CONF-CDS 2021: The 2nd International Conference on Computing and Data Science;;;In recent years, various data acquisition methods have produced a large number of data acquisition methods from multiple perspectives. Mufti view data clustering is of great significance and challenge in large-scale data analysis. In particular, the importance of clustering analysis in data mining is discussed. Based on the practical application and theoretical research of data mining, the research status of data mining technology at home and abroad is analyzed. The fuzzy membership method is used to describe the probability that the sample belongs to a certain class. Firstly, the constraint parameter analysis model is established. The evaluation model suitable for modern teaching mode such as "micro course" and "flipped classroom" is constructed, and fuzzy clustering technology is adopted. The number of clusters depends on the distance between the cluster node and the whole cluster.;;;https://dl.acm.org/doi/10.1145/3448734.3450832;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A state-of-the-art review of machine learning techniques for fraud detection research;;;['Sinayobye Janvier Omar', 'Kiwanuka Fred', 'Kaawaase Kyanda Swaib'];;;May 2018;;;SEiA '18: Proceedings of the 2018 International Conference on Software Engineering in Africa;;;The area of fraud detection1 has been traditionally correlated with data mining and text mining. Even before the "big data" phenomena started in 2008, text mining and data mining were used as instruments of fraud detection. However, the limited technological capabilities of the pre-big data technologies made it very difficult for researchers to run fraud detection algorithms on large amounts of data. This paper reviews the existing research done in fraud detection across different areas with the aim of investigating the machine learning techniques used and find out their strengths and weaknesses. It used the systematic quantitative literature review methodology to review the research studies in the field of fraud detection research within the last decade using machine learning techniques. Various combinations of keywords were used to identify the pertinent articles and were retrieved from ACM Digital Library, IEEE Xplorer Digital Library, Science Direct, Springer Link, etc. This search used a sample of 80 relevant articles (peer-reviewed journals articles and conference papers). The most used machine learning techniques were identified, and their strengths and weaknesses. Finally, the conclusion, limitations and future work have been shown.;;;https://dl.acm.org/doi/10.1145/3195528.3195534;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Citrus Fruits Diseases Detection and Classification Using Transfer Learning;;;['Ashok Kumar Saini', 'Roheet Bhatnagar', 'Devesh Kumar Srivastava'];;;August 2021;;;DSMLAI '21': Proceedings of the International Conference on Data Science, Machine Learning and Artificial Intelligence;;;Diseases in plants have a devastating effect on food protection and may significantly reduce the worth and amount of farming products. In extreme circumstances, plant illnesses may destroy the entire crop. Thus, in agriculture, an automated plant disease detection and diagnosis system are widely needed. Many approaches have been suggested to solve this problem till now, but deep learning has been the preferred solution because of its outstanding results. Electronic apparatus is used to recognize and even monitor crop diseases rather than manual observation. In this paper, a transfer learning-based model is proposed, which used deep convolutional neural networks for identifying and classifying citrus fruits diseases. The InceptionV3, ResNet50, VGG16 and VGG19 models are pre-trained model on a large dataset (ImageNet) used to improve prediction accuracy. Data augmentation is used for getting better accuracy of classification. We collected various performance parameters for comparing accuracy on our dataset; Our results show that VGG19 got the highest accuracy, 99.89%. Our experimental results show that transfer learning provides better prediction with minimal computational resources.;;;https://dl.acm.org/doi/10.1145/3484824.3484893;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Data Mining and Analysis of College Student's Network Learning Behavior Factors;;;['Xiang Yu', 'Liu Jian min'];;;May 2021;;;ICDEL '21: Proceedings of the 2021 6th International Conference on Distance Education and Learning;;;This study intends to explore the influencing factors of online learning behavior of college students from the perspective of learners' perception. By modifying and expanding the expectation confirmation model (ECM), and drawing on the relevant scales to form a questionnaire suitable for this study, this paper attempts to build a research model on the influencing factors of college student's online learning willingness and satisfaction. Through the empirical study of college students, with the help of SPSS and Amos and other related software, this paper analyzes the collected effective samples in order to obtain the factor model and research conclusion that have certain explanatory power on the online learning behavior of college students.;;;https://dl.acm.org/doi/10.1145/3474995.3475031;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Incremental Temporal Pattern Mining Using Efficient Batch-Free Stream Clustering;;;['Yifeng Lu', 'Marwan Hassani', 'Thomas Seidl'];;;June 2017;;;SSDBM '17: Proceedings of the 29th International Conference on Scientific and Statistical Database Management;;;This paper address the problem of temporal pattern mining from multiple data streams containing temporal events. Temporal events are considered as real world events aligned with comprehensive starting and ending timing information rather than simple integer timestamps. Predefined relations, such as "before" and "after", describe the heterogeneous relationships hidden in temporal data with limited diversity. In this work, the relationships among events are learned dynamically from the temporal information. Each event is treated as an object with a label and numerical attributes. An online-offline model is used as the primary structure for analyzing the evolving multiple streams. Different distance functions on temporal events and sequences can be applied depending on the application scenario. A prefix tree is introduced for a fast incremental pattern update. Events in the real world usually persist for some period. It is more natural to model events as intervals with temporal information rather than as points on the timeline. Based on the representation proposed in this work, our approach can also be extended to handle interval data. Experiments show how the method, with richer information and more accurate results than the state-of-the-art, processes both point-based and interval-based event streams efficiently.;;;https://dl.acm.org/doi/10.1145/3085504.3085511;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Qualitative Activity Recognition using Machine and Deep Learning: Experimenting with Data-Human Interfaces for non Data-scientists;;;['Norman Riedel', 'Alessia Angeli', 'Gustavo Marfia'];;;September 2019;;;GoodTechs '19: Proceedings of the 5th EAI International Conference on Smart Objects and Technologies for Social Good;;;Data science has become more and more powerful as the development of algorithms and computing power has made huge progresses. Researchers have used machine learning and deep learning algorithms in order to solve hard problems in a variety of domains. Nevertheless, data science will only show its true potential the moment that all categories of interested parties (not only specialist data scientists) will be capable of understanding and interacting with data. This work, hence, is not about data science in a classical way, but about exploring the data-human interface that may be possible to establish utilizing available tools, with little or no background knowledge of how a data science pipeline works. In this paper we show how, within a Sports Science degree course, where no specific knowledge regarding algorithms, statistics or data science is acquired, it was possible to obtain significant results in relation to a data analysis problem, using off-the-shelf application packages. In particular, we here show how, without any specific customization, it has been possible to employ the machine and deep learning algorithms offered by the publicly available platforms, to solve a fitness exercise classification problem, obtaining performances that would have been deemed remarkable until not long ago.;;;https://dl.acm.org/doi/10.1145/3342428.3342671;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Research on Emotion Classification Based on Clustering Algorithm;;;['Hanwei Liu', 'Huiling Cai', 'Qingcheng Lin', 'Xuefeng Li', 'Hui Xiao', 'Lei Wang'];;;May 2021;;;ICAIIS 2021: 2021 2nd International Conference on Artificial Intelligence and Information Systems;;;Emotion recognition, especially facial expression recognition (FER), has played a vital role in understanding human cognition. The current work focuses on the classification, learning and analysis of the six basic emotions (happy, sadness, fear, disgust, anger, and surprise) and other in-depth research fields. However, from the perspective of psychology, human emotions are subjective and complex, and the definition of emotion categories is also controversial, which has an important impact on the accuracy of the analysis results. This paper focuses on the basic issues of emotion classification, presets the position of complex emotions, and uses the improved k-means clustering algorithm to reclassify emotion categories with different emotions based on the subjective voting results of the FER+ face emotion data set. The recognition accuracy is used as objective data to classify the subjective emotion categories, and finally, the recognition accuracy of the emotion classification categories is used as a verification method to prove that the reclassified emotion categories can significantly improve the results of its classification, learning and analysis.;;;https://dl.acm.org/doi/10.1145/3469213.3470689;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Defect Classification using Pressure Change of Sleeve Soldering Machine;;;['Yoshinobu Fukumitsu', 'Keita Nakamichi', 'Hidetake Uwano', 'Hiroshi Fukuoka'];;;March 2021;;;ICRCA 2021: 2021 the 5th International Conference on Robotics, Control and Automation;;;Abstract: The solder joint significantly affects the quality of the electronic equipment. Recent researches focus on the automatic inspection of solder joints to detect the fault with high accuracy. The sleeve soldering system is one of the soldering equipment. The system puts a heated ceramic sleeve over the through-hole of the print circuit board and melts the solder piece dropped into the sleeve. The system also feeds a certain amount of nitrogen gas into the sleeve continuously, and the gas goes out through the lower end of the sleeve. Pressure in the sleeve is changed by narrowing down or blocking the exit hole in each soldering process, such as the sleeve approaches to the print circuit board, drop off the solder piece, and solder melting. Here, the pressure at each process may differ between correct and incorrect soldering. In this paper, the authors classify the correct and incorrect soldering from the pressure change's features. The results of the experiment show that both correct and incorrect are classified with 98.3% accuracy.;;;https://dl.acm.org/doi/10.1145/3471985.3472371;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A Deep Q-Learning Sanitization Approach for Privacy Preserving Data Mining;;;['Usman Ahmed', 'Jerry Chun-Wei Lin', 'Gautam Srivastava', 'Youcef Djenouri'];;;January 2021;;;ICDCN '21: Adjunct Proceedings of the 2021 International Conference on Distributed Computing and Networking;;;With the establishment of the 5G network, a number of data-intensive applications will be developed. Privacy of information over the network is increasingly relevant, and require protection. The privacy of information while utilizing data is a trade-off that needs to be addressed. In this paper, we propose data privacy of 5G connected devices over heterogeneous networks (5G-Hetnets). A deep Q learning (DQL) based technique is applied to sensitize sensitive information from a given database while keeping the balance between privacy protection and knowledge discovery during the sanitization process. It takes transaction states as input and results in state and action pair. The DQL discovers the transactions dynamically, then the sanitization operation hide the sensitive information by minimizing side effects. The proposed approach shows significant improvement of performance compared to greedy and meta-heuristics and heuristics approaches.;;;https://dl.acm.org/doi/10.1145/3427477.3429990;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Detection of AI-Manipulated Fake Faces via Mining Generalized Features;;;['Yang Yu', 'Rongrong Ni', 'Wenjie Li', 'Yao Zhao'];;;None;;;ACM Transactions on Multimedia Computing, Communications, and Applications;;;Recently, AI-manipulated face techniques have developed rapidly and constantly, which has raised new security issues in society. Although existing detection methods consider different categories of fake faces, the performance on detecting the fake faces with “unseen” manipulation techniques is still poor due to the distribution bias among cross-manipulation techniques. To solve this problem, we propose a novel framework that focuses on mining intrinsic features and further eliminating the distribution bias to improve the generalization ability. First, we focus on mining the intrinsic clues in the channel difference image (CDI) and spectrum image (SI) view of two different aspects, including the camera imaging process and the indispensable step in AI manipulation process. Then, we introduce the Octave Convolution and an attention-based fusion module to effectively and adaptively mine intrinsic features from CDI and SI view of these two different but intrinsic aspects. Finally, we design an alignment module to eliminate the bias of manipulation techniques to obtain a more generalized detection framework. We evaluate the proposed framework on four categories of fake faces datasets with the most popular and state-of-the-art manipulation techniques and achieve very competitive performances. We further conduct experiments on cross-manipulation techniques, and the results of our method show the superior advantages on improving generalization ability.;;;https://dl.acm.org/doi/10.1145/3499026;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Imbalanced Breast Cancer Classification Using Transfer Learning;;;['Rishav Singh', 'Tanveer Ahmed', 'Abhinav Kumar', 'Amit Kumar Singh', 'Anil Kumar Pandey', 'Sanjay Kumar Singh'];;;None;;;IEEE/ACM Transactions on Computational Biology and Bioinformatics;;;Accurate breast cancer detection using automated algorithms remains a problem within the literature. Although a plethora of work has tried to address this issue, an exact solution is yet to be found. This problem is further exacerbated by the fact that most of the existing datasets are imbalanced, i.e., the number of instances of a particular class far exceeds that of the others. In this paper, we propose a framework based on the notion of transfer learning to address this issue and focus our efforts on histopathological and imbalanced image classification. We use the popular VGG-19 as the base model and complement it with several state-of-the-art techniques to improve the overall performance of the system. With the ImageNet dataset taken as the source domain, we apply the learned knowledge in the target domain consisting of histopathological images. With experimentation performed on a large-scale dataset consisting of 277,524 images, we show that the framework proposed in this paper gives superior performance than those available in the existing literature. Through numerical simulations conducted on a supercomputer, we also present guidelines for work in transfer learning and imbalanced image classification.;;;https://dl.acm.org/doi/10.1109/TCBB.2020.2980831;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Rectified Meta-learning from Noisy Labels for Robust Image-based Plant Disease Classification;;;['Deming Zhai', 'Ruifeng Shi', 'Junjun Jiang', 'Xianming Liu'];;;None;;;ACM Transactions on Multimedia Computing, Communications, and Applications;;;Plant diseases serve as one of main threats to food security and crop production. It is thus valuable to exploit recent advances of artificial intelligence to assist plant disease diagnosis. One popular approach is to transform this problem as a leaf image classification task, which can be then addressed by the powerful convolutional neural networks (CNNs). However, the performance of CNN-based classification approach depends on a large amount of high-quality manually labeled training data, which inevitably introduce noise on labels in practice, leading to model overfitting and performance degradation. To overcome this problem, we propose a novel framework that incorporates rectified meta-learning module into common CNN paradigm to train a noise-robust deep network without using extra supervision information. The proposed method enjoys the following merits: (i) A rectified meta-learning is designed to pay more attention to unbiased samples, leading to accelerated convergence and improved classification accuracy. (ii) Our method is free on assumption of label noise distribution, which works well on various kinds of noise. (iii) Our method serves as a plug-and-play module, which can be embedded into any deep models optimized by gradient descent-based method. Extensive experiments are conducted to demonstrate the superior performance of our algorithm over the state-of-the-arts.;;;https://dl.acm.org/doi/10.1145/3472809;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Do Switches Dream of Machine Learning?: Toward In-Network Classification;;;['Zhaoqi Xiong', 'Noa Zilberman'];;;November 2019;;;HotNets '19: Proceedings of the 18th ACM Workshop on Hot Topics in Networks;;;Machine learning is currently driving a technological and societal revolution. While programmable switches have been proven to be useful for in-network computing, machine learning within programmable switches had little success so far. Not using network devices for machine learning has a high toll, given the known power efficiency and performance benefits of processing within the network. In this paper, we explore the potential use of commodity programmable switches for in-network classification, by mapping trained machine learning models to match-action pipelines. We introduce IIsy, a software and hardware based prototype of our approach, and discuss the suitability of mapping to different targets. Our solution can be generalized to additional machine learning algorithms, using the methods presented in this work.;;;https://dl.acm.org/doi/10.1145/3365609.3365864;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Effects of Mining Parameters on the Performance of the Sequence Pattern Variants Analyzing Method Applied to Electronic Medical Record Systems;;;['Hieu Hanh Le', 'Tatsuhiro Yamada', 'Yuichi Honda', 'Masaaki Kayahara', 'Muneo Kushima', 'Kenji Araki', 'Haruo Yokota'];;;December 2019;;;iiWAS2019: Proceedings of the 21st International Conference on Information Integration and Web-based Applications &amp; Services;;;Sequential pattern mining (SPM) is widely used for data mining and knowledge discovery in various application domains. Recently, we have proposed an analyzing method to evaluate the sequence pattern variant (SPV) that is the original sequence containing frequent patterns including variants. Such a study is meaningful for medical tasks such as improving the quality of a disease's treatment method. This paper aims to evaluate the effectiveness of the proposed analyzing method in more detail when it was applied to Electronic Medical Record Systems. Using a real dataset, it is observed that the analyzing method is successful in statistically discovering the meaningful indicators that are leading to the difference between comparative SPVs, such as complicated risk, severity risk of the disease, the length of stay in the hospital and the total medical cost. Moreover, it is observed that the length of stay and the medical cost can gain more benefit from increasing the significance level parameter used in comparing the SPVs.;;;https://dl.acm.org/doi/10.1145/3366030.3366074;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Ultrasound Tongue Image Classification using Transfer Learning;;;['Yi Feng', 'Xianglin Wang'];;;November 2019;;;DMIP '19: Proceedings of the 2019 2nd International Conference on Digital Medicine and Image Processing;;;The ultrasound image of the tongue consists of high-level speckle noise, and efficient approach to interpret the image sequences is desired. Automatic ultrasound tongue image classification is of great interest for the clinical linguists, as hand labeling is costly. In this paper, we explore the classification of midsagittal tongue gestures by employing transfer- learning, which can be effective with limited labeled data size. Within the transfer-learning framework, four state- of-the-art convolutional neural network (CNN) architectures are used to make a quantitatively comparison. Classification experiments are conducted using the data from two females. Based on the experimental results, we observed that the learned knowledge from one subject can be transferred to improve the classification accuracy of another subject.;;;https://dl.acm.org/doi/10.1145/3379299.3379301;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
An application of spectral clustering approach to detect communities in data modeled by graphs;;;['Zakariyaa Ait El Mouden', 'Abdeslam Jakimi', 'Moha Hajar'];;;March 2019;;;NISS '19: Proceedings of the 2nd International Conference on Networking, Information Systems &amp; Security;;;Graph clustering is a popular classification technique with numerous algorithms, with a high number of published proposals, this field keeps expanding. Spectral clustering is one of graph clustering algorithms and one of the most active tools in machine learning community in general and unsupervised classification methods especially, with several applications in different fields this technique has shown its performance and its ability to deal with different data formats. In this paper we present an application of spectral clustering to detect communities in data from real world after modeling those data by graphs. We present also a comparison between the obtained results from the two most known families of spectral clustering using the unnormalized and the normalized algorithms. We finally discuss the obtained results in the output of this application and present our future works.;;;https://dl.acm.org/doi/10.1145/3320326.3320330;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Evolutionary feature manipulation in data mining/big data;;;['Bing Xue', 'Mengjie Zhang'];;;March 2017;;;ACM SIGEVOlution;;;Known as the GIGO (Garbage In, Garbage Out) principle, the quality of the input data highly influences or even determines the quality of the output of any machine learning, big data and data mining algorithm. The input data which is often represented by a set of features may suffer from many issues. Feature manipulation is an effective means to improve the feature set quality, but it is a challenging task. Evolutionary computation (EC) techniques have shown advantages and achieved good performance in feature manipulation. This paper reviews recent advances on EC based feature manipulation methods in classifcation, clustering, regression, incomplete data, and image analysis, to provide the community the state-of-the-art work in the field.;;;https://dl.acm.org/doi/10.1145/3089251.3089252;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Hybrid Human-Machine Classification System for Cultural Heritage Data;;;['Shaban Shabani', 'Maria Sokhn', 'Heiko Schuldt'];;;October 2020;;;SUMAC'20: Proceedings of the 2nd Workshop on Structuring and Understanding of Multimedia heritAge Contents;;;The advancement of digital technologies has helped cultural heritage organizations to digitize their data collections and improve the accessibility via online platforms. These platforms have enabled citizens to contribute to the process of digital preservation of cultural heritage by sharing documents and their knowledge. However, many historical datasets have problems due to incomplete metadata. To solve this issue, cultural heritage organizations heavily depend on domain experts. In this paper, we address the issue of completing the metadata of historical digital collections. For this, we introduce a new hybrid human-machine model. This model jointly integrates predictions of a deep multi-input model and inferred labels from multiple crowd judgements. The multi-input model uses visual features extracted from the images and textual features from the metadata, complemented with Wikipedia classes of concepts extracted in the text. On the crowd answer aggregation, our method considers the workers' reliability scores. This score is based on the performance of workers' task history and their performance in our task. We have applied our hybrid approach to a culture heritage platform and the evaluations show that it outperforms both deep learning and crowdsourcing when applied individually.;;;https://dl.acm.org/doi/10.1145/3423323.3423413;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
PETGEN: Personalized Text Generation Attack on Deep Sequence Embedding-based Classification Models;;;['Bing He', 'Mustaque Ahamad', 'Srijan Kumar'];;;August 2021;;;KDD '21: Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining;;;What should a malicious user write next to fool a detection model? Identifying malicious users is critical to ensure the safety and integrity of internet platforms. Several deep learning based detection models have been created. However, malicious users can evade deep detection models by manipulating their behavior, rendering these models of little use. The vulnerability of such deep detection models against adversarial attacks is unknown. Here we create a novel adversarial attack model against deep user sequence embedding-based classification models, which use the sequence of user posts to generate user embeddings and detect malicious users. In the attack, the adversary generates a new post to fool the classifier. We propose a novel end-to-end Personalized Text Generation Attack model, called PETGEN, that simultaneously reduces the efficacy of the detection model and generates posts that have several key desirable properties. Specifically, PETGEN generates posts that are personalized to the user's writing style, have knowledge about a given target context, are aware of the user's historical posts on the target context, and encapsulate the user's recent topical interests. We conduct extensive experiments on two real-world datasets (Yelp and Wikipedia, both with ground-truth of malicious users) to show that PETGEN significantly reduces the performance of popular deep user sequence embedding-based classification models. PETGEN outperforms five attack baselines in terms of text quality and attack efficacy in both white-box and black-box classifier settings. Overall, this work paves the path towards the next generation of adversary-aware sequence classification models.;;;https://dl.acm.org/doi/10.1145/3447548.3467390;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Construction and Practice of Virtual Simulation Experimental Teaching Platform for Metal and Nonmetal Mines Underground Mining;;;['Nan Yao', 'Lihua Ke', 'Jianlong Sheng', 'Wenjing Li', 'Dong Yin'];;;June 2021;;;ICFET '21: Proceedings of the 7th International Conference on Frontiers of Educational Technologies;;;In order to develop the virtual simulation experiment teaching platform for underground mining of metal and nonmetal mines, the connotation of the course knowledge system around the complete process of underground mining was fully excavated firstly. On this basis, the knowledge system framework of the virtual simulation teaching platform was established. Finally, with the goal of improving the function operation and interactivity of the platform system, the function design of the virtual simulation experiment platform was carried out. The platform has been applied well in the daily teaching of mining engineering major in Wuhan University of Science and Technology. This paper can provide reference for the development of virtual simulation experimental platform for similar majors.;;;https://dl.acm.org/doi/10.1145/3473141.3473220;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A Study of MOOC Course Review Topics Mining Based on LDA Topic Model;;;['Xiao Yang-cai', 'Wang Rui'];;;November 2021;;;AADNIC-ABMECR '21: Proceedings of the 3rd Africa-Asia Dialogue Network (AADN) International Conference on Advances in Business Management and Electronic Commerce Research;;;In order to dig deeper into the implied thematic information about online course review data on MOOC learning platforms and obtain the topic concerns of course learners in the process of participating in online courses, as a demand guide to improve the quality level of online classes. This study analyzes the course review data in the form of word cloud map for word frequency, and at the same time, uses LDA topic model for semantic analysis of online course review data to extract learners' topic concerns. The results show that learners focus on course content, lecture style, course discussion, learning resources, architecture, teacher quality, exercise explanation and sound effect in the learning process of MOOC online education platform . By mining online course review data for underlying themes, it is possible to understand learners' demand tendencies, which is meaningful and valuable for improving teaching quality.;;;https://dl.acm.org/doi/10.1145/3503491.3503498;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Protein Family Classification from Scratch: A CNN Based Deep Learning Approach;;;['Da Zhang', 'Mansur R. Kabuka'];;;None;;;IEEE/ACM Transactions on Computational Biology and Bioinformatics;;;Next-generation sequencing techniques provide us with an opportunity for generating sequenced proteins and identifying the biological families and functions of these proteins. However, compared with identified proteins, uncharacterized proteins consist of a notable percentage of the overall proteins in the bioinformatics research field. Traditional family classification methods often devote themselves to extracting N-Gram features from sequences while ignoring motif information as well as affinity information between motifs and adjacent amino acids. Previous clustering-based algorithms have typically been used to define protein features with domain knowledge and annotate protein families based on extensive data samples. In this paper, we apply CNN based amino acid representation learning with limited characterized proteins to explore the performances of annotated protein families by taking into account the amino acid location information. Additionally, we apply the method to all reviewed protein sequences with their families retrieved from the UniProt database to evaluate our approach. Last but not least, we verify our model using those unreviewed protein records, which is typically ignored by other methods.;;;https://dl.acm.org/doi/10.1109/TCBB.2020.2966633;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Mining Historical Data towards Interference Management in Wireless SDNs;;;['Maryam Karimi', 'Prashant Krishnamurthy', 'James Joshi', 'David Tipper'];;;November 2017;;;Q2SWinet '17: Proceedings of the 13th ACM Symposium on QoS and Security for Wireless and Mobile Networks;;;WiFi networks often seek to reduce interference through network planning, macroscopic self-organization (e.g. channel switching) or network management. In this paper, we explore the use of historical data to automatically predict traffic bottlenecks and make rapid decisions in a wireless (WiFi-like) network on a smaller scale. This is now possible with software defined networks (SDN), whose controllers can have a global view of traffic flows in a network. Models such as classification trees can be used to quickly make decisions on how to manage network resources based on the quality needs, service level agreement or other criteria provided by a network administrator. The objective of this paper is to use data generated by simulation tools to see if such classification models can be developed and to evaluate their efficacy. For this purpose, extensive simulation data was collected and data mining techniques were then used to develop QoS prediction trees. Such trees can predict the maximum delay that results due to specific traffic situations with specific parameters. We evaluated these decision/classification trees by placing them in an SDN controller. OpenFlow cannot directly provide the necessary information for managing wireless networks so we used POX messenger to set up an agent on each AP for adjusting the network. Finally we explored the possibility of updating the tree using feedback that the controller receives from hosts. Our results show that such trees are effective and can be used to manage the network and decrease maximum packet delay.;;;https://dl.acm.org/doi/10.1145/3132114.3132125;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Augment to Prevent: Short-Text Data Augmentation in Deep Learning for Hate-Speech Classification;;;['Georgios Rizos', 'Konstantin Hemker', 'Björn Schuller'];;;November 2019;;;CIKM '19: Proceedings of the 28th ACM International Conference on Information and Knowledge Management;;;In this paper, we address the issue of augmenting text data in supervised Natural Language Processing problems, exemplified by deep online hate speech classification. A great challenge in this domain is that although the presence of hate speech can be deleterious to the quality of service provided by social platforms, it still comprises only a tiny fraction of the content that can be found online, which can lead to performance deterioration due to majority class overfitting. To this end, we perform a thorough study on the application of deep learning to the hate speech detection problem: a) we propose three text-based data augmentation techniques aimed at reducing the degree of class imbalance and to maximise the amount of information we can extract from our limited resources and b) we apply them on a selection of top-performing deep architectures and hate speech databases in order to showcase their generalisation properties. The data augmentation techniques are based on a) synonym replacement based on word embedding vector closeness, b) warping of the word tokens along the padded sequence or c) class-conditional, recurrent neural language generation. Our proposed framework yields a significant increase in multi-class hate speech detection, outperforming the baseline in the largest online hate speech database by an absolute 5.7% increase in Macro-F1 score and 30% in hate speech class recall.;;;https://dl.acm.org/doi/10.1145/3357384.3358040;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Functional module extraction from gene expression data using data mining techniques;;;['Monica Jha', 'Swarup Roy'];;;May 2019;;;ACM SIGBioinformatics Record;;;A set of correlated and co-expressed genes, often referred as a functional module, play a synergistic role during any disease or any biological activities. Genes participating in a common module may cause clinically similar diseases and shares the common genetic origin of their associated disease phenotypes. Identifying such modules may be helpful in system level understanding of biological and cellular processes or pathophysiologic basis of associated diseases. As a result, detecting such functional modules is an active research issue in the area of computational biology.Many techniques have been proposed so far to find functional modules based on gene co-regulation or co-expression data. These methods are broadly categorized into nonnetwork based gene expression clustering techniques and network-based methods that extract modules from gene co-expression networks using expression data sources. We surved main approaches for obtaining modules, and we evaluated their performance regarding finding biologically significant gene modules in the light of both microarray and RNASeq data. No prior effort, other than independent assessment, has been made so far to evaluate their performances in an integrated way in the light of both microarray and RNASeq data.It could be observed that these methods are basically based on certain features and several other features are ignored. No single technique appears to be effective in all respect. Therefore, there is a possibility that some significant modules might be missed out. Keeping this in view we came up with a solution which would engulf the goodness of all the methods into one. We proposed a multilayer ensemble approach based on few well-known module detection techniques into one. We observed that ensemble of techniques enhances the quality of modules in terms biological significance. We evaluated the effectiveness of the ensemble approach in detecting disease specific modules.Often, a set of genes found to be responsible for dual (or even more) functionalities while participating in multiple overlapping module formation. A more compact form of overlapping module structure is intrinsic structure, where a set of genes within a module playing additional role despite its parent role where it belongs to. We proposed a unique way of detecting such module structures by using the ensemble of modules obtained by the subspace clustering. We used the concept of frequent itemset mining, a step in Association Rule Mining, to derive such compact modules as subspace clusters. To the best of our knowledge, no prior work is attempted so far to detect overlapping and intrinsic modules simultaneously from ensemble outcomes.Finally, we proposed a ranking method to infer disease responsible key genes based on gene expression data. We used top ranked disease significant modules derived by our ensemble method and based on significance of the module with respect to disease pathways. We applied our ranking method in Breast Cancer and Alzheimer's Disease (AD). We inferred top genes and assessed their significance related to the disease with the help of various gene-disease association databases. Experimental results revealed that BRCA1, BRCA2, PTEN, ABI1 and CASP8 are the top key genes in Breast Cancer, whereas, MAPK1, APP, CASP7, APOE and PSEN1 are the key players in AD.;;;https://dl.acm.org/doi/10.1145/3383672.3383674;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A Study on ELM(Election pledge management for Local governors Model) Based on Machine Learning -Focused on On-Nara Document System-;;;['Hong-Jae Lee', 'Kyeong-Seok Han', 'Tae-Hyun Kwon', 'Sang-Ung Han'];;;January 2019;;;ICSIM '19: Proceedings of the 2nd International Conference on Software Engineering and Information Management;;;The background of this paper is new social trend of more public's interest in the implementation of the pledge of the local governors who were elected by citizens. In these days the election pledge for enhanced local governmental policies became more important. The objective of this paper is to suggest the model of election pledge management for local government heads based on machine learning focused on On-Nara document system. The system is currently used by Korean governmental organizations for document processes. The methods to prove a comparative advantage of the proposed model are the comparison tests between As-Is system and To-Be system based on a few criteria such as time, efficiency and extraction rate. Through this model, local governors could present systematic goals and road map of pledges in order to get closer to citizens and local residents. In other words, this study proposes a model, so called ELM(Election pledge management for Local governors Model), for efficiently extracting necessary data from planned and implemented details of pledge projects that are prepared in the form of unstructured documents. We carried out research to prove empirically our machine learning-based model is more efficient than current semi-manual system with some automated processes in order to manage efficiently the pledge project implementation of local governors to get the results. In conclusion, this research proved that the proposed model is more competitive than the existing models. In the 4th industrial revolution era the new approach using machine learning and big data will become more popular.;;;https://dl.acm.org/doi/10.1145/3305160.3305208;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Acoustic Classification of Bird Species Using Wavelets and Learning Algorithms;;;['Song Yang', 'Ryan Frier', 'Qiang Shi'];;;February 2021;;;ICMLC '21: Proceedings of the 2021 13th International Conference on Machine Learning and Computing;;;In this project, we derived an effective and efficient mathematical algorithm to identify bird species based on bird calls. Classifying bird species can be useful in real applications, such as determining the health of an ecosystem, or identifying hazardous species of birds near airports and reducing the bird-aircraft strikes. Having well-trained ornithologists to identify the characteristics of birds requires many man hours, and the results may be subjective. Our research was intended to develop a semi-automatic classification algorithm. We first performed a wavelet decomposition algorithm over more than 1200 syllables from 12 different bird species, and then extracted a set of eight parameters from each instance. The dataset formed by the instances and associated parameters was used to train and test different classifiers. Our results showed that among all the classifiers we tested, Cubic Support Vector Machine and Random Forest achieved the highest classification rates, each of which was over 93%.;;;https://dl.acm.org/doi/10.1145/3457682.3457692;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Stock Price Analysis with Natural Language Processing and Machine Learning;;;['Sukanchalika Boonmatham', 'Phayung Meesad'];;;July 2020;;;IAIT '20: Proceedings of the 11th International Conference on Advances in Information Technology;;;Finding stock price classification based on Thai news corporate is a challenging task. In this research, we try to build machine learning models that capture the relationship of news and stock prices of several companies. In this work, eight companies were selected randomly from Industry Group Index and Sectoral Index. Corporate news articles from the eight selected companies were collected along with their stock prices. Two of traditional machine learning models and two deep learning models were used in this study for comparison purpose. The models were based on Support Vector Machine (SVM), Multilayer Perceptron (MLP), Long Short-Term Memory (LSTM), and Gated Recurrent Unit (GRU). Using news articles as inputs, the models were trained to classify stock prices into two classes: Up and Down of the stock closing price. For classification performance, Accuracy, Precision, Recall and F1 were used. The results showed that GRU had highest average accuracy, precision, recall and F1 higher than other model values with 0.79, 0.79, 0.79, 0.79, respectively.;;;https://dl.acm.org/doi/10.1145/3406601.3406652;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Medical Image Classification based on an Adaptive Size Deep Learning Model;;;['Xiangbin Liu', 'Jiesheng He', 'Liping Song', 'Shuai Liu', 'Gautam Srivastava'];;;None;;;ACM Transactions on Multimedia Computing, Communications, and Applications;;;With the rapid development of Artificial Intelligence (AI), deep learning has increasingly become a research hotspot in various fields, such as medical image classification. Traditional deep learning models use Bilinear Interpolation when processing classification tasks of multi-size medical image dataset, which will cause the loss of information of the image, and then affect the classification effect. In response to this problem, this work proposes a solution for an adaptive size deep learning model. First, according to the characteristics of the multi-size medical image dataset, the optimal size set module is proposed in combination with the unpooling process. Next, an adaptive deep learning model module is proposed based on the existing deep learning model. Then, the model is fused with the size fine-tuning module used to process multi-size medical images to obtain a solution of the adaptive size deep learning model. Finally, the proposed solution model is applied to the pneumonia CT medical image dataset. Through experiments, it can be seen that the model has strong robustness, and the classification effect is improved by about 4% compared with traditional algorithms.;;;https://dl.acm.org/doi/10.1145/3465220;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Detecting Atrial Fibrillation from Single-Lead ECG Using Unbalanced Multi-classification Support Vector Machine;;;['Xingming Mei', 'Nini Rao', 'Quanchi Li', 'Chengsi Luo', 'Biwott Fleix Kipkurui', 'Hongxiu Jiang'];;;June 2019;;;ICMLT '19: Proceedings of the 2019 4th International Conference on Machine Learning Technologies;;;Atrial fibrillation (AF) is an common arrhythmia. The incidence of AF has been increasing with the acceleration of urbanization and social aging. Therefore, the wearable ECG acquisition devices with single-lead ECG came out for early diagnosis, monitoring and management of AF. However, it is still great challenge to accurately detect AF from massive ECG data. This study proposed a method detecting AF from single-lead ECG signals based on unbalanced multi-classification support vector machine(SVM). The novel method first screened 73 effective features by correlation analysis from 110 candidate features, which have been confirmed to be associated with AF in literature. Then, an unbalanced four-class SVM classifier was designed to detect four types of ECG signals (including AF, other arrhythmia, artifactual and normal) based on the distribution of different types of ECG data. Finally, the data provided by the PhysioNet/Computing in Cardiology Challenge 2017 confirmed that the proposed method had a overall good performance compared with five other related methods. Also, the data from MIT Arrhythmia Database and the MIT Atrial Fibrillation Database confirmed the robustness of proposed method with AF detection score of > 0.97 and with the scores of > 0.9 in other arrhythmia, artifactual and normal. The proposed method has a good application prospect in AF aided diagnosis, monitoring and management of AF.;;;https://dl.acm.org/doi/10.1145/3340997.3341004;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Medical Image Classification based on an Adaptive Size Deep Learning Model;;;['Xiangbin Liu', 'Jiesheng He', 'Liping Song', 'Shuai Liu', 'Gautam Srivastava'];;;None;;;ACM Transactions on Multimedia Computing, Communications, and Applications;;;With the rapid development of Artificial Intelligence (AI), deep learning has increasingly become a research hotspot in various fields, such as medical image classification. Traditional deep learning models use Bilinear Interpolation when processing classification tasks of multi-size medical image dataset, which will cause the loss of information of the image, and then affect the classification effect. In response to this problem, this work proposes a solution for an adaptive size deep learning model. First, according to the characteristics of the multi-size medical image dataset, the optimal size set module is proposed in combination with the unpooling process. Next, an adaptive deep learning model module is proposed based on the existing deep learning model. Then, the model is fused with the size fine-tuning module used to process multi-size medical images to obtain a solution of the adaptive size deep learning model. Finally, the proposed solution model is applied to the pneumonia CT medical image dataset. Through experiments, it can be seen that the model has strong robustness, and the classification effect is improved by about 4% compared with traditional algorithms.;;;https://dl.acm.org/doi/10.1145/3465220;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Three trillion lines: infrastructure for mining GitHub in the classroom;;;['Toni Mattis', 'Patrick Rein', 'Robert Hirschfeld'];;;March 2020;;;Programming '20: Companion Proceedings of the 4th International Conference on Art, Science, and Engineering of Programming;;;The increasing interest in collaborative software development on platforms like GitHub has led to the availability of large amounts of data about development activities. The GHTorrent project has recorded a significant proportion of GitHub’s public event stream and hosts the currently largest public dataset of meta-data about open-source development. We describe our infrastructure that makes this data locally available to researchers and students, examples for research activities carried out on this infrastructure, and what we learned from building the system. We identify a need for domain-specific tools, especially databases, that can deal with large-scale code repositories and associated meta-data and outline open challenges to use them more effectively for research and machine learning settings.;;;https://dl.acm.org/doi/10.1145/3397537.3397551;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A deep learning fusion model for brain disorder classification: Application to distinguishing schizophrenia and autism spectrum disorder;;;['Yuhui Du', 'Bang Li', 'Yuliang Hou', 'Vince D. Calhoun'];;;September 2020;;;BCB '20: Proceedings of the 11th ACM International Conference on Bioinformatics, Computational Biology and Health Informatics;;;Deep learning has shown a great promise in classifying brain disorders due to its powerful ability in learning optimal features by nonlinear transformation. However, given the high-dimension property of neuroimaging data, how to jointly exploit complementary information from multimodal neuroimaging data in deep learning is difficult. In this paper, we propose a novel multilevel convolutional neural network (CNN) fusion method that can effectively combine different types of neuroimage-derived features. Importantly, we incorporate a sequential feature selection into the CNN model to increase the feature interpretability. To evaluate our method, we classified two symptom-related brain disorders using large-sample multi-site data from 335 schizophrenia (SZ) patients and 380 autism spectrum disorder (ASD) patients within a cross-validation procedure. Brain functional networks, functional network connectivity, and brain structural morphology were employed to provide possible features. As expected, our fusion method outperformed the CNN model using only single type of features, as our method yielded higher classification accuracy (with mean accuracy >85%) and was more reliable across multiple runs in differentiating the two groups. We found that the default mode, cognitive control, and subcortical regions contributed more in their distinction. Taken together, our method provides an effective means to fuse multimodal features for the diagnosis of different psychiatric and neurological disorders.;;;https://dl.acm.org/doi/10.1145/3388440.3412478;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Prediction of Internet Users' Emotion Tendency in Emergency Events Based on Data Mining;;;['Peng ZHANG', 'Jing LIU', 'Qipeng LI', 'Juan WANG', 'Chenyang Zhao'];;;October 2021;;;AIAM2021: 2021 3rd International Conference on Artificial Intelligence and Advanced Manufacture;;;Through the emotional tendency analysis of subjective texts in emergency events, it can effectively predict the trend of online public opinion, and provide theoretical support for the government and relevant departments to guide online public opinion in the first time. This article uses web crawler technology to crawl and cancel the comment information and personal information of netizens in typical cases of anti-rescue, and uses the emotion analysis method based on emotion dictionary to analyze the emotion of the crawled data. By drawing charts of the proportions of various emotional tendencies of different groups of people, studying the characteristics of emotional tendencies of different groups of people, and predicting the emotional tendencies in emergency events based on the laws drawn from typical cases. And for the predicted groups of people who are prone to negative emotions, the principles and methods for firefighting teams to deal with emergencies are put forward to provide a reference for firefighting teams to deal with online public opinion on emergency events.;;;https://dl.acm.org/doi/10.1145/3495018.3495094;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A Deep Learning–based Approach for Emotions Classification in Big Corpus of Imbalanced Tweets;;;['Nasir Jamal', 'Chen Xianqiao', 'Fadi Al-Turjman', 'Farhan Ullah'];;;None;;;ACM Transactions on Asian and Low-Resource Language Information Processing;;;Emotions detection in natural languages is very effective in analyzing the user's mood about a concerned product, news, topic, and so on. However, it is really a challenging task to extract important features from a burst of raw social text, as emotions are subjective with limited fuzzy boundaries. These subjective features can be conveyed in various perceptions and terminologies. In this article, we proposed an IoT-based framework for emotions classification of tweets using a hybrid approach of Term Frequency Inverse Document Frequency (TFIDF) and deep learning model. First, the raw tweets are filtered using the tokenization method for capturing useful features without noisy information. Second, the TFIDF statistical technique is applied to estimate the importance of features locally as well as globally. Third, the Adaptive Synthetic (ADASYN) class balancing technique is applied to solve the imbalance class issue among different classes of emotions. Finally, a deep learning model is designed to predict the emotions with dynamic epoch curves. The proposed methodology is analyzed on two different Twitter emotions datasets. The dynamic epoch curves are shown to show the behavior of test and train data points. It is proved that this methodology outperformed the popular state-of-the-art methods.;;;https://dl.acm.org/doi/10.1145/3410570;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Dynamic Graph Learning Convolutional Networks for Semi-supervised Classification;;;['Sichao Fu', 'Weifeng Liu', 'Weili Guan', 'Yicong Zhou', 'Dapeng Tao', 'Changsheng Xu'];;;None;;;ACM Transactions on Multimedia Computing, Communications, and Applications;;;Over the past few years, graph representation learning (GRL) has received widespread attention on the feature representations of the non-Euclidean data. As a typical model of GRL, graph convolutional networks (GCN) fuse the graph Laplacian-based static sample structural information. GCN thus generalizes convolutional neural networks to acquire the sample representations with the variously high-order structures. However, most of existing GCN-based variants depend on the static data structural relationships. It will result in the extracted data features lacking of representativeness during the convolution process. To solve this problem, dynamic graph learning convolutional networks (DGLCN) on the application of semi-supervised classification are proposed. First, we introduce a definition of dynamic spectral graph convolution operation. It constantly optimizes the high-order structural relationships between data points according to the loss values of the loss function, and then fits the local geometry information of data exactly. After optimizing our proposed definition with the one-order Chebyshev polynomial, we can obtain a single-layer convolution rule of DGLCN. Due to the fusion of the optimized structural information in the learning process, multi-layer DGLCN can extract richer sample features to improve classification performance. Substantial experiments are conducted on citation network datasets to prove the effectiveness of DGLCN. Experiment results demonstrate that the proposed DGLCN obtains a superior classification performance compared to several existing semi-supervised classification models.;;;https://dl.acm.org/doi/10.1145/3412846;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Classification vs regression in overparameterized regimes: does the loss function matter?;;;['Vidya Muthukumar', 'Adhyyan Narang', 'Vignesh Subramanian', 'Mikhail Belkin', 'Daniel Hsu', 'Anant Sahai'];;;None;;;The Journal of Machine Learning Research;;;We compare classification and regression tasks in an overparameterized linear model with Gaussian features. On the one hand, we show that with sufficient overparameterization all training points are support vectors: solutions obtained by least-squares minimum-norm interpolation, typically used for regression, are identical to those produced by the hard-margin support vector machine (SVM) that minimizes the hinge loss, typically used for training classifiers. On the other hand, we show that there exist regimes where these interpolating solutions generalize well when evaluated by the 0-1 test loss function, but do not generalize if evaluated by the square loss function, i.e. they approach the null risk. Our results demonstrate the very different roles and properties of loss functions used at the training phase (optimization) and the testing phase (generalization).;;;https://dl.acm.org/doi/10.5555/3546258.3546480;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Deep Learning Classification for Epilepsy Detection Using a Single Channel Electroencephalography (EEG);;;['Jianguo Liu', 'Blake Woodson'];;;July 2019;;;ICDLT '19: Proceedings of the 2019 3rd International Conference on Deep Learning Technologies;;;The classification of brain signals using machine learning techniques is a powerful tool in the detection of brain disorders such as Alzheimer's disease and epilepsy. One of the most often used signals is electroencephalography (EEG). Different classification methods have been applied to the analysis of EEG waves with success, such as the support vec- tor machine. We apply deep learning classification to EEG signals for the detection of epilepsy using a convolutional neural network. Besides that this approach advantageously requires no feature extraction, another novelty of this ap- proach is that high classification accuracy can be achieved using only a single channel EEG. Numerical experimentation on a standard test data set shows a 90% or higher accuracy on average.;;;https://dl.acm.org/doi/10.1145/3342999.3343008;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Heart Disease Prediction Using Data Mining Techniques;;;['Ching-seh Mike Wu', 'Mustafa Badshah', 'Vishwa Bhagwat'];;;July 2019;;;DSIT 2019: Proceedings of the 2019 2nd International Conference on Data Science and Information Technology;;;Studies have shown that heart diseases have emerged as the number one cause of deaths. Heart disease is accountable for deaths in all age groups and is common among males and females. A good solution to this problem is to be able to predict what a patient's health status will be like in the future so the doctors can start treatment much sooner which will yield better results. It's a lot better than acting at the last minute where the patient is already at risk and hence the prediction of heart disease is widely researched area. A lot of research and technological advancement has been recorded in similar fields. This paper aims to report about taking advantage of the various data mining techniques and develop prediction models for heart disease survivability.;;;https://dl.acm.org/doi/10.1145/3352411.3352413;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Non-negative Matrix Factorization for Overlapping Clustering of Customer Inquiry and Review Data;;;['Zekun Yang'];;;February 2018;;;ICMLC '18: Proceedings of the 2018 10th International Conference on Machine Learning and Computing;;;Considering the complexity of clustering text datasets in terms of informal user generated content and the fact that there are multiple labels for each data point in many informal user generated content datasets, this paper focuses on Non-negative Matrix Factorization (NMF) algorithms for Overlapping Clustering of customer inquiry and review data, which has seldom been discussed in previous literature. We extend the use of Semi-NMF and Convex-NMF to Overlapping Clustering and develop a procedure of applying SemiNMF and Convex-NMF on Overlapping Clustering of text data. The developed procedure is tested based on customer review and inquiry datasets. The results of comparing SemiNMF and Convex-NMF with a baseline model demonstrate that they have advantages over the baseline model, since they do not need to adjust parameters to obtain similarly strong clustering performances. Moreover, we compare different methods of picking labels for generating Overlapping Clustering results from Soft Clustering algorithms, and it is concluded that thresholding by mean method is a simpler and relatively more reliable method compared to maximum n method.;;;https://dl.acm.org/doi/10.1145/3195106.3195110;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Efficient Mining Multi-Mers in a Variety of Biological Sequences;;;['Jingsong Zhang', 'Jianmei Guo', 'Ming Zhang', 'Xiangtian Yu', 'Xiaoqing Yu', 'Weifeng Guo', 'Tao Zeng', 'Luonan Chen'];;;None;;;IEEE/ACM Transactions on Computational Biology and Bioinformatics;;;Counting the occurrence frequency of each k-mer in a biological sequence is a preliminary yet important step in many bioinformatics applications. However, most k-mer counting algorithms rely on a given k to produce single-length k-mers, which is inefficient for sequence analysis for different k. Moreover, existing k-mer counters focus more on DNA and RNA sequences and less on protein ones. In practice, the analysis of k-mers in protein sequences can provide substantial biological insights in structure, function, and evolution. To this end, an efficient algorithm, called MulMer (Multiple-Mer mining), is proposed to mine k-mers of various lengths termed multi-mers via inverted-index technique, which is orders of magnitude faster than the conventional forward-index methods. Moreover, to the best of our knowledge, MulMer is the first able to mine multi-mers in a variety of sequences, including DNA, RNA, and protein sequences.;;;https://dl.acm.org/doi/10.1109/TCBB.2018.2828313;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Acoustic Classification of Bird Species Using Wavelets and Learning Algorithms;;;['Song Yang', 'Ryan Frier', 'Qiang Shi'];;;February 2021;;;ICMLC '21: Proceedings of the 2021 13th International Conference on Machine Learning and Computing;;;In this project, we derived an effective and efficient mathematical algorithm to identify bird species based on bird calls. Classifying bird species can be useful in real applications, such as determining the health of an ecosystem, or identifying hazardous species of birds near airports and reducing the bird-aircraft strikes. Having well-trained ornithologists to identify the characteristics of birds requires many man hours, and the results may be subjective. Our research was intended to develop a semi-automatic classification algorithm. We first performed a wavelet decomposition algorithm over more than 1200 syllables from 12 different bird species, and then extracted a set of eight parameters from each instance. The dataset formed by the instances and associated parameters was used to train and test different classifiers. Our results showed that among all the classifiers we tested, Cubic Support Vector Machine and Random Forest achieved the highest classification rates, each of which was over 93%.;;;https://dl.acm.org/doi/10.1145/3457682.3457692;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Multi-label Categorization of French Death Certificates using NLP and Machine Learning;;;['Allaouzi Imane', 'Ben Ahmed Mohamed'];;;March 2017;;;BDCA'17: Proceedings of the 2nd international Conference on Big Data, Cloud and Applications;;;The medical information represents an invaluable source of knowledge concerning the medical history of the patient, but the manner of their presentation make it badly exploited. The idea of this paper is based on the analysis of the death reports written in natural language, which are rich of information, and can be exploited in the calculation of mortality statistics, giving preventive solutions, as well as, help medical professional in their research. This paper proposes our approach to the task of Multi-label Categorization of French death certificates according to ICD-10 (International Classification of Diseases) codes. This approach is based on Machine learning techniques, which is evaluated over CépiDC corpus. The experiment showed that our approach gives interesting results, with an average F1-measue of 79.02%.;;;https://dl.acm.org/doi/10.1145/3090354.3090384;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Deep Learning-Based Tool for Automatic Feature Marking, Cropping, Visualization, and Classification of Chest Radiographs;;;['Geeta Rani', 'Akruti Sinha', 'Mahin Anup', 'Vijaypal Singh Dhaka'];;;August 2021;;;DSMLAI '21': Proceedings of the International Conference on Data Science, Machine Learning and Artificial Intelligence;;;The prime objective of this research is to develop an automatic tool 'Lung-Infection Visualizer' for marking the Region of Infection and cropping of the marked region in chest radiographs. The tool is also integrated with the feature extractor, feature visualization algorithm, and deep learning-based classifier. Thus, it facilitates the radiology experts where they can easily mark the infected region and visualize the region of infection. In this manuscript, the authors employ the template-based and Brute Force approach of feature mapping. Further, they applied the ResNet, Faster Recurrent Neural Network, XceptionNet, and VGG-16 deep learning-based classifiers for classifying the chest radiographs into bacterial pneumonia, viral pneumonia, COVID-19, and Normal classes. The authors also fine-tune the model parameters and hyperparameters for optimizing the performance of the deep learning-based models. The comparison in the performance proves that the VGG-16 model reports the highest accuracy of 90.07% and outperforms the other models on the dataset of 5,499 chest radiographs used for this research. The cropping tool is registered as Intellectual Property Rights in the name of authors with the registration number SW-14092/2021. And the title 'AutoCrop Tool'.;;;https://dl.acm.org/doi/10.1145/3484824.3484922;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Filter Selection Methods for Multiclass Classification;;;['Rhodessa J. Cascaro', 'Bobby D. Gerardo', 'Ruji P. Medina'];;;October 2019;;;ICCBD 2019: Proceedings of the 2nd International Conference on Computing and Big Data;;;Feature selection is used in choosing relevant features that contribute to the predictive power of a machine learning model. Irrelevant features tend to decrease model accuracy and cause overfitting. Feature selection is the solution to dimensionality problems, especially that data nowadays are unstructured. There are three types of feature selection techniques; filter, wrapper and embedded. Filter methods uses statistical scoring and ranks features by the score. Wrapper methods uses a model to select features and evaluates according to model accuracy. Embedded methods combine the properties of both previous algorithms and selects features in the process of training. This study is focused on the filter types, specifically Chi-square, Information Gain and Relief. On the other hand, multiclass classification is a task that involves classifying instances into three or more classes. This paper aims to compare the performance of the Support Vector Machine (SVM) multiclass classifier when entered with feature subsets generated from three different filter feature selection methods. The dataset is a clothing review text data taken from Kaggle. It contains multiple classes with 23486 review instances. Since filter selection methods utilize ranking, CHI, IG, and Relief were able to select and rank almost the same number of features. When the data was fed into SVM, CHI garnered 66.84% accuracy, IG got 32.90% accuracy while Relief obtained 29.69% accuracy. Experiments on SVM showed that among the generated data subset from the three filter selection methods, the subset using CHI yielded higher accuracy, precision, recall and F1 score compared to others.;;;https://dl.acm.org/doi/10.1145/3366650.3366655;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Data-Centric Explanations: Explaining Training Data of Machine Learning Systems to Promote Transparency;;;['Ariful Islam Anik', 'Andrea Bunt'];;;May 2021;;;CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems;;;Training datasets fundamentally impact the performance of machine learning (ML) systems. Any biases introduced during training (implicit or explicit) are often reflected in the system's behaviors leading to questions about fairness and loss of trust in the system. Yet, information on training data is rarely communicated to stakeholders. In this work, we explore the concept of data-centric explanations for ML systems that describe the training data to end-users. Through a formative study, we investigate the potential utility of such an approach, including the information about training data that participants find most compelling. In a second study, we investigate reactions to our explanations across four different system scenarios. Our results suggest that data-centric explanations have the potential to impact how users judge the trustworthiness of a system and to assist users in assessing fairness. We discuss the implications of our findings for designing explanations to support users’ perceptions of ML systems.;;;https://dl.acm.org/doi/10.1145/3411764.3445736;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Studying the Classification Accuracy Performance when Representation is Changed on Several Classifier Techniques;;;['Ehab A. Omar Elfallah', 'Wisam H. Benamer'];;;March 2017;;;HP3C-2017: Proceedings of the International Conference on High Performance Compilation, Computing and Communications;;;Introduction: During the process of building a predictive data mining module achieving the highest accuracy is major concern by all researchers. Studying the impact of data representation on the performance of classification accuracy is essential. Recent researches travel among classifiers techniques looking for suitable and higher classification accuracy to build strong modules. Adding extra dimensional by focusing on the reflects that data representation might have on the classification accuracy data mining predictive techniques is the ultimate goal of this research. Methods: In this research seven different data representations were performed on several classifier techniques. These representations were AS_IS representation and three from the binary section and three from normalization section. The binary section included simple binary representation, flag representation and thermometer representation while the normalization section included min max normalization, sigmoidal normalization and standard deviation normalization. These seven representations were applied on eight classifiers Neural Network, Logistic Regression, K nearest Neighbor, Support Vector Machine, Classification Tree, Naive Bayesian, Rule based and Random Forest Decision Tree. Moreover, two datasets have been used for testing the performance of classification accuracy, namely Wisconsin Breast Cancer and German Credit and these two datasets have Boolean target class. Results: The fourteen data representations were raised from two datasets Wisconsin Breast Cancer and German Credit with seven different data representations for each. These data representations were performed on several classifier techniques using Orange software. The results achieved showed variation of the performance among all classifier in classification accuracy. Excluding Naive Bayesian which had over 60 % different from the lowest to the highest accuracy, all other classifier techniques had diverging on classification accuracy around 4.2%.;;;https://dl.acm.org/doi/10.1145/3069593.3069597;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Comparative analysis of deep transfer learning performance on crop classification;;;['Krishna Karthik Gadiraju', 'Ranga Raju Vatsavai'];;;November 2020;;;BigSpatial '20: Proceedings of the 9th ACM SIGSPATIAL International Workshop on Analytics for Big Geospatial Data;;;Building accurate machine learning models for mapping crops using remote sensing imagery is a challenging task. Traditional solutions include per-pixel based and object-based classification solutions using coarse resolution imagery such as MODIS and LANDSAT. These models also require the development of hand-crafted features. In addition, these methods are computationally inefficient when used with very high resolution (VHR) imagery. Deep learning methods, with their ability to automatically learn relevant features provide an efficient alternative. However, deep learning methods are data-hungry, and require large amounts of labeled data sets to achieve accurate results. This is a challenge to the remote sensing community, since there is a lack of large labeled data sets in the domain. Transfer learning is a strategy that has been widely adapted across several domains and has allowed for the usage of deep neural networks even with limited labeled data. In this paper, we perform a comparative analysis of various transfer learning strategies for the domain of crop classification. We perform our experiments using three well-known neural networks and evaluate various strategies such as: (i) training the model from scratch using random weight initialization, (ii) simply using the pretrained models as feature extractors, (iii) finetuning deep CNNs by freezing the early layers of a pretrained CNN, and (iv) using the Imagenet pretrained weights as initialization, and their impact on classification performance.;;;https://dl.acm.org/doi/10.1145/3423336.3431369;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Graph Classification using Structural Attention;;;['John Boaz Lee', 'Ryan Rossi', 'Xiangnan Kong'];;;July 2018;;;KDD '18: Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining;;;Graph classification is a problem with practical applications in many different domains. To solve this problem, one usually calculates certain graph statistics (i.e., graph features) that help discriminate between graphs of different classes. When calculating such features, most existing approaches process the entire graph. In a graphlet-based approach, for instance, the entire graph is processed to get the total count of different graphlets or subgraphs. In many real-world applications, however, graphs can be noisy with discriminative patterns confined to certain regions in the graph only. In this work, we study the problem of attention-based graph classification. The use of attention allows us to focus on small but informative parts of the graph, avoiding noise in the rest of the graph. We present a novel RNN model, called the Graph Attention Model (GAM), that processes only a portion of the graph by adaptively selecting a sequence of "informative" nodes. Experimental results on multiple real-world datasets show that the proposed method is competitive against various well-known methods in graph classification even though our method is limited to only a portion of the graph.;;;https://dl.acm.org/doi/10.1145/3219819.3219980;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Continual Learning for Sentiment Classification by Iterative Networks Combination;;;['Shupeng Wang', 'Junhao Liu'];;;December 2021;;;CSAI '21: Proceedings of the 2021 5th International Conference on Computer Science and Artificial Intelligence;;;Deep neural networks have been reported to exhibit excellent performance on sentiment classification, where the impressive results are obtained with static model incapable of adapting their behavior to new domains over time. However, in practice, static models may become intractable quickly due to storage constraints or privacy issues. In this paper, we propose a novel continual learning approach for sentiment classification by iteratively combining (CSIC) the original network trained on old tasks and the fine-tuned network trained on new tasks with knowledge distillation, which adapts continually and keeps on learning over time without increasing the size of the network. We conduct extensive experiments on 16 popular review corpora. Experimental results demonstrate that the proposed CSIC method significantly outperforms the strong baselines for sentiment classification in continual learning scenario.;;;https://dl.acm.org/doi/10.1145/3507548.3507571;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
The Epidemiological Characteristics of Bronchopneumonias in Children Based on WEB Data Mining;;;['Yonghong Ma', 'Jiao Tan', 'Dongning Zhang', 'Ke Men', 'Mingjuan Shi', 'Ying Cao'];;;August 2021;;;ICIMTECH 21: <italic toggle='yes'>Retracted on September 15, 2021</italic>The Sixth International Conference on Information Management and Technology;;;NOTICE OF RETRACTION: While investigating potential publication-related misconduct in connection with the ICIMTech 2021 Conference Proceedings, serious concerns were raised that cast doubt on the integrity of the peer-review process and all papers published in the Proceedings of this Conference. The integrity of the entire Conference has been called into question. As a result, of its investigation, ACM has decided to retract the Entire Conference Proceedings and all related papers from the ACM Digital Library.None of the papers from this Proceeding should be cited in the literature because of the questionable integrity of the peer review process for this Conference.;;;https://dl.acm.org/doi/10.1145/3465631.3465931;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Generating Better Search Engine Text Advertisements with Deep Reinforcement Learning;;;['J. Weston Hughes', 'Keng-hao Chang', 'Ruofei Zhang'];;;July 2019;;;KDD '19: Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining;;;Deep Reinforcement Learning has been applied in a number of fields to directly optimize non-differentiable reward functions, including in sequence to sequence settings using Self Critical Sequence Training (SCST). Previously, SCST has primarily been applied to bring conditional language models closer to the distribution of their training set, as in traditional neural machine translation and abstractive summarization. We frame the generation of search engine text ads as a sequence to sequence problem, and consider two related goals: to generate ads similar to those a human would write, and to generate ads with high click-through rates. We jointly train a model to minimize cross-entropy on an existing corpus of Landing Page/Text Ad pairs using typical sequence to sequence training techniques while also optimizing the expected click-through rate (CTR) as predicted by an existing oracle model using SCST. Through joint training we achieve a 6.7% increase in expected CTR without a meaningful drop in ROUGE score. Human experiments demonstrate that SCST training produces significantly more attractive ads without reducing grammatical quality.;;;https://dl.acm.org/doi/10.1145/3292500.3330754;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Legal Summarization for Multi-role Debate Dialogue via Controversy Focus Mining and Multi-task Learning;;;['Xinyu Duan', 'Yating Zhang', 'Lin Yuan', 'Xin Zhou', 'Xiaozhong Liu', 'Tianyi Wang', 'Ruocheng Wang', 'Qiong Zhang', 'Changlong Sun', 'Fei Wu'];;;November 2019;;;CIKM '19: Proceedings of the 28th ACM International Conference on Information and Knowledge Management;;;Multi-role court debate is a critical component in a civil trial where parties from different camps (plaintiff, defendant, witness, judge, etc.) actively involved. Unlike other types of dialogue, court debate can be lengthy, and important information, with respect to the controversy focus(es), often hides within the redundant and colloquial dialogue data. Summarizing court debate can be a novel but significant task to assist judge to effectively make the legal decision for the target trial. In this work, we propose an innovative end-to-end model to address this problem. Unlike prior summarization efforts, the proposed model projects the multi-role debate into the controversy focus space, which enables high-quality essential utterance(s) extraction in terms of legal knowledge and judicial factors. An extensive set of experiments with a large civil trial dataset shows that the proposed model can provide more accurate and readable summarization against several alternatives in the multi-role court debate scene.;;;https://dl.acm.org/doi/10.1145/3357384.3357940;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Beyond Statistical Relations: Integrating Knowledge Relations into Style Correlations for Multi-Label Music Style Classification;;;['Qianwen Ma', 'Chunyuan Yuan', 'Wei Zhou', 'Jizhong Han', 'Songlin Hu'];;;January 2020;;;WSDM '20: Proceedings of the 13th International Conference on Web Search and Data Mining;;;Automatically labeling multiple styles for every song is a comprehensive application in all kinds of music websites. Recently, some researches explore review-driven multi-label music style classification and exploit style correlations for this task. However, their methods focus on mining the statistical relations between different music styles and only consider shallow style relations. Moreover, these statistical relations suffer from the underfitting problem because some music styles have little training data. To tackle these problems, we propose a novel knowledge relations integrated framework (KRF) to capture the complete style correlations, which jointly exploits the inherent relations between music styles according to external knowledge and their statistical relations. Based on the two types of relations, we use graph convolutional network to learn the deep correlations between styles automatically. Experimental results show that our framework significantly outperforms the state-of-the-art methods. Further studies demonstrate that our framework can effectively alleviate the underfitting problem and learn meaningful style correlations.;;;https://dl.acm.org/doi/10.1145/3336191.3371838;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Mining Exploratory Behavior to Improve Mobile App Recommendations;;;['Jiangning He', 'Hongyan Liu'];;;None;;;ACM Transactions on Information Systems;;;With the widespread usage of smart phones, more and more mobile apps are developed every day, playing an increasingly important role in changing our lifestyles and business models. In this trend, it becomes a hot research topic for developing effective mobile app recommender systems in both industry and academia. Compared with existing studies about mobile app recommendations, our research aims to improve the recommendation effectiveness based on analyzing a psychological trait of human beings, exploratory behavior, which refers to a type of variety-seeking behavior in unfamiliar domains. To this end, we propose a novel probabilistic model named Goal-oriented Exploratory Model (GEM), integrating exploratory behavior identification with personalized item recommendation. An algorithm combining collapsed Gibbs sampling and Expectation Maximization is developed for model learning and inference. Through extensive experiments conducted on a real dataset, the proposed model demonstrates superior recommendation performances and good interpretability compared with state-of-art recommendation methods. Moreover, empirical analyses on exploratory behavior find that individuals with a strong exploratory tendency exhibit behavioral patterns of variety seeking, risk taking, and higher involvement. Besides, mobile apps that are less popular or in the long tail possess greater potential of arousing exploratory behavior in individuals.;;;https://dl.acm.org/doi/10.1145/3072588;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Resolving Ambiguity in Sentiment Classification: The Role of Dependency Features;;;['Shuyuan Deng', 'Atish P. Sinha', 'Huimin Zhao'];;;None;;;ACM Transactions on Management Information Systems;;;Sentiment analysis has become popular in business intelligence and analytics applications due to the great need for learning insights from the vast amounts of user generated content on the Internet. One major challenge of sentiment analysis, like most text classification tasks, is finding structures from unstructured texts. Existing sentiment analysis techniques employ the supervised learning approach and the lexicon scoring approach, both of which largely rely on the representation of a document as a collection of words and phrases. The semantic ambiguity (i.e., polysemy) of single words and the sparsity of phrases negatively affect the robustness of sentiment analysis, especially in the context of short social media texts. In this study, we propose to represent texts using dependency features. We test the effectiveness of dependency features in supervised sentiment classification. We compare our method with the current standard practice using a labeled data set containing 170,874 microblogging messages. The combination of unigram features and dependency features significantly outperformed other popular types of features.;;;https://dl.acm.org/doi/10.1145/3046684;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Deep Learning Approach for Singer Voice Classification of Vietnamese Popular Music;;;['Toan Pham Van', 'Ngoc Tran Ngo Quang', 'Ta Minh Thanh'];;;December 2019;;;SoICT '19: Proceedings of the 10th International Symposium on Information and Communication Technology;;;Singer voice classification is a meaningful task in the digital era. With a huge number of songs today, identifying a singer is very helpful for music information retrieval, music properties indexing, and so on. In this paper, we propose a new method to identify the singer's name based on analysis of Vietnamese popular music. We employ the use of vocal segment detection and singing voice separation as the preprocessing steps. The purpose of these steps is to extract the singer's voice from the mixture sound. In order to build a singer classifier, we propose a neural network architecture working with Mel Frequency Cepstral Coefficient (MFCC) as extracted input features from said vocal. To verify the accuracy of our methods, we evaluate on a dataset of 300 Vietnamese songs from 18 famous singers. We achieve an accuracy of 92.84% with 5-fold stratified cross-validation, the best result compared to other methods on the same data set.;;;https://dl.acm.org/doi/10.1145/3368926.3369700;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Residual Deep Learning System for Mass Segmentation and Classification in Mammography;;;['Dina Abdelhafiz', 'Sheida Nabavi', 'Reda Ammar', 'Clifford Yang', 'Jinbo Bi'];;;September 2019;;;BCB '19: Proceedings of the 10th ACM International Conference on Bioinformatics, Computational Biology and Health Informatics;;;Automatic extraction of breast mass in mammogram (MG) images is a challenging task due to the varying sizes, shapes, and textures of masses. Moreover, the density of MGs makes mass detection very challenging since masses can be hidden in dense MGs. In this paper, we propose a residual deep learning (DL) system for mass segmentation and classification in mammography. The overall proposed system consists of two cascaded parts: 1) a residual attention U-Net model (RU-Net) to precisely segment mass lesions in MG images, followed by 2) a ResNet classifier to classify the detected binary segmented lesions into benign or malignant. The proposed semantic based CNN model, RU-Net, has the basic architecture of the U-Net model, which extracts contextual information combining low-level feature with high-level ones. We have modified the U-Net structure by adding residual attention modules in order to preserve the spatial and context information, help the network have deeper architecture, and handles the gradient vanishing problem. We compared the performance of the proposed RU-Net model with those of state-of-the-art two semantic segmentation models, and two object detectors using public databases. We also examined the effect of the breast density on the accuracy of localizing and segmenting the breast masses. Our proposed model shows superior performance compared to the other DL methods in detecting and segmenting masses, especially for heterogeneously dense and dense MG images, in terms of intersection over union (IOU) and the Dice index coefficient (DI). Moreover, our results show that the cascaded ResNet model, trained using binary-scale images, classify the masses to benign or malignant with higher accuracy compared to the ResNet model that is trained on gray-scale images.;;;https://dl.acm.org/doi/10.1145/3307339.3342157;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Mining E-Commerce Query Relations using Customer Interaction Networks;;;['Bijaya Adhikari', 'Parikshit Sondhi', 'Wenke Zhang', 'Mohit Sharma', 'B. Aditya Prakash'];;;April 2018;;;WWW '18: Proceedings of the 2018 World Wide Web Conference;;;Customer Interaction Networks (CINs) are a natural framework for representing and mining customer interactions with E-Commerce search engines. Customer interactions begin with the submission of a query formulated based on an initial product intent, followed by a sequence of product engagement and query reformulation actions. Engagement with a product (e.g. clicks) indicates its relevance to the customer»s product intent. Reformulation to a new query indicates either dissatisfaction with current results, or an evolution in the customer»s product intent. Analyzing such interactions within and across sessions, enables us to discover various query-query and query-product relationships. In this work, we begin by studying the properties of CINs developed using Walmart.com»s product search logs. We observe that the properties exhibited by CINs make it possible to mine intent relationships between queries based purely on their structural information. We show how these relations can be exploited for a) clustering queries based on intents, b) significantly improve search quality for poorly performing queries, and c) identify the most influential (aka. »critical») queries whose performance have the highest impact on performance of other queries.;;;https://dl.acm.org/doi/10.1145/3178876.3186174;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
CCTV News Broadcast Information Mining: Keyword Extraction Based on Semantic Model and Statistics Visualization;;;['Yujie Xie', 'Fenghai Liu'];;;October 2020;;;AIAM2020: Proceedings of the 2nd International Conference on Artificial Intelligence and Advanced Manufacture;;;CCTV News Broadcast is one of the most popular news programs in China, and it is also the most important propaganda platform in China. CCTV News Broadcast is established to "Improve the quality of publicity", so it is "A product of visual culture of national ideology" and "Taking politics as the standard" is primary appeal. [1] At present, there is little research on the text of CCTV News Broadcast. This paper focuses on the CCTV News Broadcast, using the visualization model based statistics and semantic based keyword extraction model (SKE) to extract the text features of CCTV News Broadcast. It can help the public quickly capture the key information of CCTV News Broadcast. Moreover, this paper also forms a set of Chinese corpus with keywords tagging in the field of CCTV News Broadcast. It provides important data support for machine learning method and subsequent research. In addition, aiming at some important problems found in this paper, this paper proposes further research direction for text data processing in CCTV News Broadcast field.;;;https://dl.acm.org/doi/10.1145/3421766.3421827;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Few-Shot Learning in Object Classification using Meta-Learning with Between-Class Attribute Transfer;;;['Majed Alsadhan', 'William H. Hsu'];;;February 2022;;;ICMLC '22: Proceedings of the 2022 14th International Conference on Machine Learning and Computing;;;We present a novel framework for the problem of transfer learning between few-shot source and target domains, using synthetic attributes in addition to convolutional neural networks that are pre-trained on larger image corpora. In these corpora, no labeled instances of the target domains are present, though they may contain instances of their superclasses. Using probabilistic inference over predicted classes and inferred attributes, we developed a meta-learning ensemble method that builds upon that of [10]. This paper introduces the new framework BCAT (Between-Class Attribute Transfer), adapting inter-class attribute transfer designed for zero-shot learning (ZSL), combined with fusing transfer learning and probabilistic priors, and thereby extending and improving upon existing deep meta-learning models for FSL. We show how probabilistic learning architectures can be adapted to use state-of-the-field deep learning components in this framework. We applied our technique to four baseline convnet-based FSL ensembles and boosted accuracy by up to 6.24% for 1-shot learning and up to 4.11% for 5-shot learning on the mini-ImageNet dataset, the best result of which is competitive with the current state of the field; using the same technique, we improved accuracy by up to 7.83% for 1-shot learning and up to 3.67% for 5-shot learning on the tiered-ImageNet dataset.;;;https://dl.acm.org/doi/10.1145/3529836.3529914;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Adaptive Low-Rank Multi-Label Active Learning for Image Classification;;;['Jian Wu', 'Anqian Guo', 'Victor S. Sheng', 'Pengpeng Zhao', 'Zhiming Cui', 'Hua Li'];;;October 2017;;;MM '17: Proceedings of the 25th ACM international conference on Multimedia;;;Multi-label active learning for image classification has attracted great attention over recent years and a lot of relevant works are published continuously. However, there still remain some problems that need to be solved, such as existing multi-label active learning algorithms do not reflect on the cleanness of sample data and their ways on label correlation mining are defective. For one thing, sample data is usually contaminated in reality, which disturbs the estimation of data distribution and further hinders the model training. For another, previous approaches for label relationship exploration are purely based on the observed label distribution of an incomplete training set, which cannot provide sufficiently efficient information. To address these issues, we propose a novel adaptive low-rank multi-label active learning algorithm, called LRMAL. Specifically, we first use low-rank matrix recovery to learn an effective low-rank feature representation from the noisy data. In a subsequent sampling phase, we make use of its superiorities to evaluate the general informativeness of each unlabeled example-label pair. Based on an intrinsic mapping relation between the example space and the label space of a certain multi-label dataset, we recover the incomplete labels of a training set for a more comprehensive label correlation mining. Furthermore, to reduce the redundancy among the selected example-label pairs, we use a diversity measurement to diversify the sampled data. Finally, an effective sampling strategy is developed by integrating these two aspects of potential information with uncertainty based on an adaptive integration scheme. Experimental results demonstrate the effectiveness of our approach.;;;https://dl.acm.org/doi/10.1145/3123266.3123388;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Effective Clustering for Single Cell Sequencing Cancer Data;;;['Simone Ciccolella', 'Murray D. Patterson', 'Paola Bonizzoni', 'Gianluca Della Vedova'];;;September 2019;;;BCB '19: Proceedings of the 10th ACM International Conference on Bioinformatics, Computational Biology and Health Informatics;;;Background. Single cell sequencing (SCS) technologies provide a level of resolution that makes it indispensable for inferring from a sequenced tumor, evolutionary trees or phylogenies representing an accumulation of cancerous mutations. A drawback of SCS is elevated false negative and missing value rates, resulting in a large space of possible solutions, which in turn makes infeasible using some approaches and tools. While this has not inhibited the development of methods for inferring phylogenies from SCS data, the continuing increase in size and resolution of these data begin to put a strain on such methods. One possible solution is to reduce the size of an SCS instance --- usually represented as a matrix of presence, absence and missing values of the mutations found in the different sequenced cells --- and to infer the tree from this reduced-size instance. Previous approaches have used k-means to this end, clustering groups of mutations and/or cells, and using these means as the reduced instance. Such an approach typically uses the Euclidean distance for computing means. However, since the values in these matrices are of a categorical nature (having the three categories: present, absent and missing), we explore techniques for clustering categorical data --- commonly used in data mining and machine learning --- to SCS data, with this goal in mind. Results. In this work, we present a new clustering procedure aimed at clustering categorical vector, or matrix data --- here representing SCS instances, called celluloid. We demonstrate that celluloid clusters mutations with high precision: never pairing too many mutations that are unrelated in the ground truth, but also obtains accurate results in terms of the phylogeny inferred downstream from the reduced instance produced by this method. Finally, we demonstrate the usefulness of a clustering step by applying the entire pipeline (clustering + inference method) to a real dataset, showing a significant reduction in the runtime, raising considerably the upper bound on the size of SCS instances which can be solved in practice. Availability. Our approach, celluloid: clustering single cell sequencing data around centroids is available at https://github.com/AlgoLab/celluloid/ under an MIT license.;;;https://dl.acm.org/doi/10.1145/3307339.3342149;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
An Ensemble Deep Active Learning Method for Intent Classification;;;['Leihan Zhang', 'Le Zhang'];;;December 2019;;;CSAI '19: Proceedings of the 2019 3rd International Conference on Computer Science and Artificial Intelligence;;;Intent classification plays a primary and critical role in intelligent dialogue systems. However, faced with the lack of labeled data, the training of robust intent classification model is time-consuming and costly. Thanks to the powerful pre-trained model and active learning, it's possible to construct an integrated method to fulfill this task efficiently. Therefore, we propose an ensemble deep active learning method, which constructs intent classifier based on BERT and uses an ensemble sampling method to choose informative data for efficient training. Experimental results on both Chinese and English intent classification datasets suggest that the proposed ensemble deep active learning method can achieve state-of-the-art performance with less than half of the training data. In addition, the performance of the proposed method is stable and scalable for both datasets. In general, the proposed method shows substantial advantages in building intent classifier across different datasets.;;;https://dl.acm.org/doi/10.1145/3374587.3374611;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Multiclass Sentiment Classification of Online Health Forums using Both Domain-independent and Domain-specific Features;;;['Rana Alnashwan', 'Humphrey Sorensen', "Adrian O'Riordan", 'Cathal Hoare'];;;December 2017;;;BDCAT '17: Proceedings of the Fourth IEEE/ACM International Conference on Big Data Computing, Applications and Technologies;;;Online health-related discussion provides a rich source of information for both informing the public and providing feedback to health professionals to detect trends and inform policy. However, there are few studies that focus on analysing sentiment in medical forum discourse. Online health communities devoted to specific medical conditions and health-related problems support people with similar conditions, enabling them to exchange personal experiences. Analysing sentiment expressed by members of a health community in medical forum discourse can be valuable for identifying a particular aspect of the information space. In this paper, we identify sentiments expressed on online medical forums discussing Lyme disease. There are two goals in our research. First, to identify a set of categories that can represent a comprehensive connotation of emotions expressed in the discussions, while also being adequately distinct for the purposes of machine learning. Second, to identify the sentiments expressed by participants in individual posts. Three types of feature (content-free, content-specific and meta-level) are extracted and inductive learning algorithms utilized to build a feature-based classification model for an automated multi-class classification model. The experimental results demonstrate the effectiveness of our approach.;;;https://dl.acm.org/doi/10.1145/3148055.3148058;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Coupling risk attitude and motion data mining in a preemtive construction safety framework;;;['Khandakar M. Rashid', 'Songjukta Datta', 'Amir H. Behzadan'];;;December 2017;;;WSC '17: Proceedings of the 2017 Winter Simulation Conference;;;Construction sites comprise constantly moving heterogeneous resources that operate in close proximity of each other. The sporadic nature of field tasks creates an accident prone physical space surrounding workers. Despite efforts to improve site safety using location-aware proximity sensing techniques, major scientific gaps still remain in reliably forecasting impending hazardous scenarios before they occur. In the research presented in this paper, spatiotemporal data of workers and site hazards is fused with a quantifiable model of an individual's attitude toward risk to generate proximity-based safety alerts in real time. In particular, a worker's risk index is formulated and coupled with robust hidden Markov model (HMM)-based trajectory prediction to approximate his/her future position, and detect imminent contact collisions. The designed methodology is explained and assessed using several experiments emulating interactions between site workers and hazards. Preliminary results demonstrate the effectiveness of the designed methods in robustly predicting potential collision events.;;;https://dl.acm.org/doi/10.5555/3242181.3242386;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
DECAF: Deep Extreme Classification with Label Features;;;['Anshul Mittal', 'Kunal Dahiya', 'Sheshansh Agrawal', 'Deepak Saini', 'Sumeet Agarwal', 'Purushottam Kar', 'Manik Varma'];;;March 2021;;;WSDM '21: Proceedings of the 14th ACM International Conference on Web Search and Data Mining;;;Extreme multi-label classification (XML) involves tagging a data point with its most relevant subset of labels from an extremely large label set, with several applications such as product-to-product recommendation with millions of products. Although leading XML algorithms scale to millions of labels, they largely ignore label metadata such as textual descriptions of the labels. On the other hand, classical techniques that can utilize label metadata via representation learning using deep networks struggle in extreme settings. This paper develops the DECAF algorithm that addresses these challenges by learning models enriched by label metadata that jointly learn model parameters and feature representations using deep networks and offer accurate classification at the scale of millions of labels. DECAF makes specific contributions to model architecture design, initialization, and training, enabling it to offer up to 2-6% more accurate prediction than leading extreme classifiers on publicly available benchmark product-to-product recommendation datasets, such as LF-AmazonTitles-1.3M. At the same time, DECAF was found to be up to 22x faster at inference than leading deep extreme classifiers, which makes it suitable for real-time applications that require predictions within a few milliseconds. The code for DECAF is available at the following URL: https://github.com/Extreme-classification/DECAF;;;https://dl.acm.org/doi/10.1145/3437963.3441807;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Historical Context-based Style Classification of Painting Images via Label Distribution Learning;;;['Jufeng Yang', 'Liyi Chen', 'Le Zhang', 'Xiaoxiao Sun', 'Dongyu She', 'Shao-Ping Lu', 'Ming-Ming Cheng'];;;October 2018;;;MM '18: Proceedings of the 26th ACM international conference on Multimedia;;;Analyzing and categorizing the style of visual art images, especially paintings, is gaining popularity owing to its importance in understanding and appreciating the art. The evolution of painting style is both continuous, in a sense that new styles may inherit, develop or even mutate from their predecessors and multi-modal because of various issues such as the visual appearance, the birthplace, the origin time and the art movement. Motivated by this peculiarity, we introduce a novel knowledge distilling strategy to assist visual feature learning in the convolutional neural network for painting style classification. More specifically, a multi-factor distribution is employed as soft-labels to distill complementary information with visual input, which extracts from different historical context via label distribution learning. The proposed method is well-encapsulated in a multi-task learning framework which allows end-to-end training. We demonstrate the superiority of the proposed method over the state-of-the-art approaches on Painting91, OilPainting, and Pandora datasets.;;;https://dl.acm.org/doi/10.1145/3240508.3240593;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
STAR: Noisy Semi-Supervised Transfer Learning for Visual Classification;;;['Hasib Zunair', 'Yan Gobeil', 'Samuel Mercier', 'Abdessamad Ben Hamza'];;;October 2021;;;MMSports'21: Proceedings of the 4th International Workshop on Multimedia Content Analysis in Sports;;;Semi-supervised learning (SSL) has proven to be effective at leveraging large-scale unlabeled data to mitigate the dependency on labeled data in order to learn better models for visual recognition and classification tasks. However, recent SSL methods rely on unlabeled image data at a scale of billions to work well. This becomes infeasible for tasks with relatively fewer unlabeled data in terms of runtime, memory and data acquisition. To address this issue, we propose noisy semi-supervised transfer learning, an efficient SSL approach that integrates transfer learning and self-training with noisy student into a single framework, which is tailored for tasks that can leverage unlabeled image data on a scale of thousands. We evaluate our method on both binary and multi-class classification tasks, where the objective is to identify whether an image displays people practicing sports or the type of sport, as well as to identify the pose from a pool of popular yoga poses. Extensive experiments and ablation studies demonstrate that by leveraging unlabeled data, our proposed framework significantly improves visual classification, especially in multi-class classification settings compared to state-of-the-art methods. Moreover, incorporating transfer learning not only improves classification performance, but also requires 6x less compute time and 5x less memory. We also show that our method boosts robustness of visual classification models, even without specifically optimizing for adversarial robustness.;;;https://dl.acm.org/doi/10.1145/3475722.3482791;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Fingerprint classification based on a Q-Gaussian multiclass support vector machine;;;['Mohamed Hammad', 'Kuanquan Wang'];;;April 2017;;;ICBEA '17: Proceedings of the 2017 International Conference on Biometrics Engineering and Application;;;Accurate recognition and actual classification of fingerprint are vital and necessary for fingerprint identification. Previous researchers have used many classification algorithms to develop fingerprint classification model, but they still have some certain problems like time of implementation to do the task, cost of implementation, working on non-linear features, working on multi-dimensional features and under or over learning problems. In this paper, a Q-Gaussian multi-class support vector machine (QG-MSVM) for fingerprint classification is proposed in which Q-Gaussian function is incorporated into SVM as a kernel function. The proposed method is tested in CASIA, FVC2000, FVC2002 and FVC2004 databases and compared with the MSVM methods with linear kernel, Gaussian Radial Basis Function kernel (RBF), Polynomial kernel and other state-of-the-art methods. The experimental results show that QG-MSVM demonstrates better performance than other classifiers and overcome many MSVM problems. The overall performance of the QG-MSVM classifier is comprehensively superior to all others.;;;https://dl.acm.org/doi/10.1145/3077829.3077836;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Machine Learning Based Unified Framework for Diabetes Prediction;;;['S. M. Hasan Mahmud', 'Md Altab Hossin', 'Md. Razu Ahmed', 'Sheak Rashed Haider Noori', 'Md Nazirul Islam Sarkar'];;;August 2018;;;BDET 2018: Proceedings of the 2018 International Conference on Big Data Engineering and Technology;;;Machine learning gained a significant position in healthcare services (HCS) due to its ability to improve the disease prediction in HCS. Machine learning techniques and artificial intelligence have already been worked in the HCS area. Recently, diabetes is a notable public chronic disease worldwide. It is growing rapidly because of bad lifestyles, taking more junk food and also lake of health awareness. Therefore, there is a need of framework that can effectively track and monitor people's diabetes and health condition within an application view. In this study, we proposed a framework for real time diabetes prediction, monitoring and application (DPMA). Our objective is to develop an optimized and efficient machine learning (ML) application which can effectually recognize and predict the condition of the diabetes. In this work, five most important machine learning classification techniques were considered for predicting diabetes. However, we use different evaluation criteria to investigate the performance of these classification techniques. In addition, performance measurement of the classification techniques was evaluated by applying the 10-fold cross validation method. The analysis results show that Naïve Bayes achieved highest performance than the other classifiers, obtaining the F1 measure of 0.74.;;;https://dl.acm.org/doi/10.1145/3297730.3297737;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Deep Learning meets Knowledge Graphs for Scholarly Data Classification;;;['Fabian Hoppe', 'Danilo Dessì', 'Harald Sack'];;;April 2021;;;WWW '21: Companion Proceedings of the Web Conference 2021;;;The amount of scientific literature continuously grows, which poses an increasing challenge for researchers to manage, find and explore research results. Therefore, the classification of scientific work is widely applied to enable the retrieval, support the search of suitable reviewers during the reviewing process, and in general to organize the existing literature according to a given schema. The automation of this classification process not only simplifies the submission process for authors, but also ensures the coherent assignment of classes. However, especially fine-grained classes and new research fields do not provide sufficient training data to automatize the process. Additionally, given the large number of not mutual exclusive classes, it is often difficult and computationally expensive to train models able to deal with multi-class multi-label settings. To overcome these issues, this work presents a preliminary Deep Learning framework as a solution for multi-label text classification for scholarly papers about Computer Science. The proposed model addresses the issue of insufficient data by utilizing the semantics of classes, which is explicitly provided by latent representations of class labels. This study uses Knowledge Graphs as a source of these required external class definitions by identifying corresponding entities in DBpedia to improve the overall classification.;;;https://dl.acm.org/doi/10.1145/3442442.3451361;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
New Incremental Learning Algorithm for Semi-Supervised Support Vector Machine;;;['Bin Gu', 'Xiao-Tong Yuan', 'Songcan Chen', 'Heng Huang'];;;July 2018;;;KDD '18: Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining;;;Semi-supervised learning is especially important in data mining applications because it can make use of plentiful unlabeled data to train the high-quality learning models. Semi-Supervised Support Vector Machine (S3VM) is a powerful semi-supervised learning model. However, the high computational cost and non-convexity severely impede the S3VM method in large-scale applications. Although several learning algorithms were proposed for S3VM, scaling up S3VM is still an open problem. To address this challenging problem, in this paper, we propose a new incremental learning algorithm to scale up S3VM (IL-S3VM) based on the path following technique in the framework of Difference of Convex (DC) programming. The traditional DC programming based algorithms need multiple outer loops and are not suitable for incremental learning, and traditional path following algorithms are limited to convex problems. Our new IL-S3VM algorithm based on the path-following technique can directly update the solution of S3VM to converge to a local minimum within one outer loop so that the efficient incremental learning can be achieved. More importantly, we provide the finite convergence analysis for our new algorithm. To the best of our knowledge, our new IL-S3VM algorithm is the first efficient path following algorithm for a non-convex problem (i.e., S3VM) with local minimum convergence guarantee. Experimental results on a variety of benchmark datasets not only confirm the finite convergence of IL-S3VM, but also show a huge reduction of computational time compared with existing batch and incremental learning algorithms, while retaining the similar generalization performance.;;;https://dl.acm.org/doi/10.1145/3219819.3220092;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
The Evolution of the Industry 4.0: A Retrospective Analysis Using Text Mining;;;['Zeynep Didem Unutmaz Durmuşoğlu', 'Pınar Kocabey Çiftçi'];;;June 2018;;;ICEMIS '18: Proceedings of the Fourth International Conference on Engineering &amp; MIS 2018;;;Industry 4.0 and its applications have attracted the interest of both experts of industry and researchers of academy. This interest started to build a vast body of literature on the related topics and caused to raise a new question about how the related literature has changed over time. In this context, the major objective of the presented study is to provide insight about the scientific researches on industry 4.0 using the publications from the Thomson Reuters Web of Knowledge database during the period of 2007-2017. For this aim, the retrieved academic studies were analyzed using quantitative and text mining analyses to observe the change in number of publications over years and to gain insight about the textual structure. The results of the quantitative analysis showed that the popularity of industry 4.0 in the academy has risen significantly and reached the peak point in 2017 with 2658 articles. According to the text mining study, the most important research topics related to the industry 4.0 field are "mobile", "internet of things" and "cloud computing".;;;https://dl.acm.org/doi/10.1145/3234698.3234757;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Mining High Utility Itemsets with Hill Climbing and Simulated Annealing;;;['M. Saqib Nawaz', 'Philippe Fournier-Viger', 'Unil Yun', 'Youxi Wu', 'Wei Song'];;;None;;;ACM Transactions on Management Information Systems;;;High utility itemset mining (HUIM) is the task of finding all items set, purchased together, that generate a high profit in a transaction database. In the past, several algorithms have been developed to mine high utility itemsets (HUIs). However, most of them cannot properly handle the exponential search space while finding HUIs when the size of the database and total number of items increases. Recently, evolutionary and heuristic algorithms were designed to mine HUIs, which provided considerable performance improvement. However, they can still have a long runtime and some may miss many HUIs. To address this problem, this article proposes two algorithms for HUIM based on Hill Climbing (HUIM-HC) and Simulated Annealing (HUIM-SA). Both algorithms transform the input database into a bitmap for efficient utility computation and for search space pruning. To improve population diversity, HUIs discovered by evolution are used as target values for the next population instead of keeping the current optimal values in the next population. Through experiments on real-life datasets, it was found that the proposed algorithms are faster than state-of-the-art heuristic and evolutionary HUIM algorithms, that HUIM-SA discovers similar HUIs, and that HUIM-SA evolves linearly with the number of iterations.;;;https://dl.acm.org/doi/10.1145/3462636;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Analysis of unstructured text data for a person social profile;;;['Alexey Y. Timonin', 'Alexander S. Bozhday', 'Alexander M. Bershadsky'];;;September 2017;;;eGose '17: Proceedings of the Internationsl Conference on Electronic Governance and Open Society: Challenges in Eurasia;;;The greatest scientific interest for analysts are Internet open social data, because it has a direct link with all kinds of human activity. However, these data are not suitable for the application in its original form. Information should be presented in a structured, convenient, human-readable form which is called a social profile. The social profile building is carried out through the analysis of the filtered Internet open source data. Analysis of personal profile data is achieved through the use of mathematical set theory, Big Data software, NoSQL data stores and analytic tools for social media. This article discusses methods of unstructured textual data analysis in relation to a social profile. Special attention is given to the search of implicit dependences in texts using visual analysis and natural language processing means. Phase of the textual data analysis is the most important in terms of results and complicated to implement. There is the possibility to partially automate the process of information analyzing through the use of visual analysis, natural language processing (NLP), neural networks and specialized algorithms. Resulted data provide a detailed in-depth review of the social profile entities and relations. It can be used in further deeper social researches.;;;https://dl.acm.org/doi/10.1145/3129757.3129758;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Meta-Learning for Few-Shot Time Series Classification;;;['Jyoti Narwariya', 'Pankaj Malhotra', 'Lovekesh Vig', 'Gautam Shroff', 'T. V. Vishnu'];;;January 2020;;;CoDS COMAD 2020: Proceedings of the 7th ACM IKDD CoDS and 25th COMAD;;;Deep neural networks (DNNs) have achieved state-of-the-art results on time series classification (TSC) tasks. In this work, we focus on leveraging DNNs in the often-encountered practical scenario where access to labeled training data is difficult, and where DNNs would be prone to overfitting. We leverage recent advancements in gradient-based meta-learning, and propose an approach to train a residual neural network with convolutional layers as a meta-learning agent for few-shot TSC. The network is trained on a diverse set of few-shot tasks sampled from various domains (e.g. healthcare, activity recognition, etc.) such that it can solve a target task from another domain using only a small number of training samples from the target task. Most existing meta-learning approaches are limited in practice as they assume a fixed number of target classes across tasks. We overcome this limitation in order to train a common agent across domains with each domain having different number of target classes, we utilize a triplet-loss based learning procedure that does not require any constraints to be enforced on the number of classes for the few-shot TSC tasks. To the best of our knowledge, we are the first to use meta-learning based pre-training for TSC. Our approach sets a new benchmark for few-shot TSC, outperforming several strong baselines on few-shot tasks sampled from 41 datasets in UCR TSC Archive. We observe that pre-training under the meta-learning paradigm allows the network to quickly adapt to new unseen tasks with small number of labeled instances.;;;https://dl.acm.org/doi/10.1145/3371158.3371162;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Research on animal image classification based on transfer learning;;;['Man Hu', 'Fucheng You'];;;November 2020;;;EITCE '20: Proceedings of the 2020 4th International Conference on Electronic Information Technology and Computer Engineering;;;Training a convolutional neural network requires a large number of sample data and a large amount of computing power. In some practical application scenarios, there may be difficulties in sample data collection and complex network model construction. To improve the classification accuracy and fitting speed of the convolutional neural network, a transfer learning classification method for an animal image is proposed. The fully connected layer of the pre-trained ResNet18 network is modified, and the eight animals in the animal-10 dataset on Kaggle are used to fine-tune the network model. The best classification accuracy of the obtained network model for a single animal is 97%, and the classification accuracy for all animals is 92%. Compared with the model that did not use transfer learning training, this kind of transfer learning network model has a great improvement in accuracy and fitting speed.;;;https://dl.acm.org/doi/10.1145/3443467.3443849;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Clustering without Over-Representation;;;['Sara Ahmadian', 'Alessandro Epasto', 'Ravi Kumar', 'Mohammad Mahdian'];;;July 2019;;;KDD '19: Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining;;;In this paper we consider clustering problems in which each point is endowed with a color. The goal is to cluster the points to minimize the classical clustering cost but with the additional constraint that no color is over-represented in any cluster. This problem is motivated by practical clustering settings, e.g., in clustering news articles where the color of an article is its source, it is preferable that no single news source dominates any cluster. For the most general version of this problem, we obtain an algorithm that has provable guarantees of performance; our algorithm is based on finding a fractional solution using a linear program and rounding the solution subsequently. For the special case of the problem where no color has an absolute majority in any cluster, we obtain a simpler combinatorial algorithm also with provable guarantees. Experiments on real-world data shows that our algorithms are effective in finding good clustering without over-representation.;;;https://dl.acm.org/doi/10.1145/3292500.3330987;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Clustering without Over-Representation;;;['Sara Ahmadian', 'Alessandro Epasto', 'Ravi Kumar', 'Mohammad Mahdian'];;;July 2019;;;KDD '19: Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining;;;In this paper we consider clustering problems in which each point is endowed with a color. The goal is to cluster the points to minimize the classical clustering cost but with the additional constraint that no color is over-represented in any cluster. This problem is motivated by practical clustering settings, e.g., in clustering news articles where the color of an article is its source, it is preferable that no single news source dominates any cluster. For the most general version of this problem, we obtain an algorithm that has provable guarantees of performance; our algorithm is based on finding a fractional solution using a linear program and rounding the solution subsequently. For the special case of the problem where no color has an absolute majority in any cluster, we obtain a simpler combinatorial algorithm also with provable guarantees. Experiments on real-world data shows that our algorithms are effective in finding good clustering without over-representation.;;;https://dl.acm.org/doi/10.1145/3292500.3330987;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Research on animal image classification based on transfer learning;;;['Man Hu', 'Fucheng You'];;;November 2020;;;EITCE '20: Proceedings of the 2020 4th International Conference on Electronic Information Technology and Computer Engineering;;;Training a convolutional neural network requires a large number of sample data and a large amount of computing power. In some practical application scenarios, there may be difficulties in sample data collection and complex network model construction. To improve the classification accuracy and fitting speed of the convolutional neural network, a transfer learning classification method for an animal image is proposed. The fully connected layer of the pre-trained ResNet18 network is modified, and the eight animals in the animal-10 dataset on Kaggle are used to fine-tune the network model. The best classification accuracy of the obtained network model for a single animal is 97%, and the classification accuracy for all animals is 92%. Compared with the model that did not use transfer learning training, this kind of transfer learning network model has a great improvement in accuracy and fitting speed.;;;https://dl.acm.org/doi/10.1145/3443467.3443849;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
HINFShot: A Challenge Dataset for Few-Shot Node Classification in Heterogeneous Information Network;;;['Zifeng Zhuang', 'Xintao Xiang', 'Siteng Huang', 'Donglin Wang'];;;August 2021;;;ICMR '21: Proceedings of the 2021 International Conference on Multimedia Retrieval;;;Few-shot learning aims to generalize to novel classes. It has achieved great success in image and text classification tasks. Inspired by such success, few-shot node classification in homogeneous graph has attracted much attention but few works have begun to study this problem in Heterogeneous Information Network (HIN) so far. We consider few-shot learning in HIN and study a pioneering problem HIN Few-Shot Node Classification (HIN-FSNC) that aims to generalize the node types with sufficient labeled samples to unseen node types with only few-labeled samples. However, existing HIN datasets contain just one labeled node type, which means they cannot meet the setting of unseen node types. To facilitate the investigation of HIN-FSNC, we propose a large-scale academic HIN dataset called HINFShot. It contains 1,235,031 nodes with four node types (author, paper, venue, institution) and all the nodes regardless of node type are divided into 80 classes. Finally, we conduct extensive experiments on HINFShot and the result indicates a significant challenge of identifying novel classes of unseen node types in HIN-FSNC.;;;https://dl.acm.org/doi/10.1145/3460426.3463614;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A preconception gender assessment using data mining techniques based on implementation of natural laws & favoring factors;;;['Shaista Sabir', 'Usman Qamar', 'Tanveer Ahmed', 'Mubashir Ali'];;;October 2017;;;IML '17: Proceedings of the 1st International Conference on Internet of Things and Machine Learning;;;Healthcare field1 is vital organization of our society as it directly affects the living being A balanced society is the need of the hour that we can achieve by a balanced family structure. In all over the world especially in Asia and Africa, couples show a preference for a particular gender of child, either male or female (1). This preference may be the result of economic, social pressure, custom of the people or it may simply be due to the reason of "Gender balanced family" (2). A lot of research in medical field is present which shows how to achieve the goal of getting a child of desired gender in a way that is more natural. Similarly, in this era of advanced technology data mining techniques are becoming more and more popular in medical field. In this paper, we analyzed different research methods in medical field based on Natural Laws & Favoring Factors, extracted different macroscopic factors affecting directly the possible gender of offspring in the womb of the mother before conception and generated our dataset using these macroscopic factors. Then we applied different Data mining classification techniques on our dataset to classify the possible gender as male or female.;;;https://dl.acm.org/doi/10.1145/3109761.3158405;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Geographical Entity Community Mining Based on Spatial and Semantic Association;;;['Mengyu Yan', 'Ning Jing', 'Zhinong Zhong', 'Ye Wu'];;;October 2019;;;CSAE '19: Proceedings of the 3rd International Conference on Computer Science and Application Engineering;;;The relevance of geographic entities has always been the focus of research on geographic information retrieval, geographic knowledge graph and recommendation systems. Traditional research methods, which use spatial or semantic similarity to calculate the correlation between regions, have certain one-sidedness and limitations. The network topology can clearly represent the relationship between entities. However, semantic relationships are difficult to define, so there are few cases where network-related algorithms are used to solve the relevance of geographic entities. With the development of the Internet, web pages provide people with a huge amount of information, and geographical names as a key element are often ignored by researchers, and the rich semantic information contained in it needs further research. This study attempts to explore the geographic entity relevance of integrated semantics and spatial factors based on textual data from a network perspective. Based on the community mining algorithm, the experiment studies the aggregation characteristics of geographic entities and can find areas that are close to each other and tightly related, which is more satisfied with people's common sense.;;;https://dl.acm.org/doi/10.1145/3331453.3361652;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Review On Sentiment Analysis of Twitter Posts About News Headlines Using Machine Learning Approaches and Naïve Bayes Classifier;;;['Thinesharan Vaseeharan', 'Achala Aponso'];;;February 2020;;;ICCAE 2020: Proceedings of the 2020 12th International Conference on Computer and Automation Engineering;;;In today's world there are so much micro blogging sites, among all twitter is one of the popular site. It has become an important part for all individuals, politicians, companies, celebrities, etc. Almost all the major news outlets have Twitter account where they post news headlines for their followers. People with Twitter accounts can reply or retweet the news headlines. Twitter users who have an account can also post news headlines from any other news outlets. When people post, reply or retweet news posts on Twitter, it is obvious that they are expressing their sentiments through that. The main aim of the paper is to extract subjectivity of opinions of people about particular news in Twitter. Specially, the interest is in determining the sentiment of Twitter posts about particular news. This paper Explores Naïve Bayes Classifier for textual classification and various twitter-specific sentiment analysis studies applied to Twitter data and their Outcomes.;;;https://dl.acm.org/doi/10.1145/3384613.3384650;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Web Video Clustering Based on Emotion Category;;;['Vinath Mekthanavanh', 'Tianrui Li', 'Jie Hu', 'Yan Yang'];;;August 2018;;;BDET 2018: Proceedings of the 2018 International Conference on Big Data Engineering and Technology;;;Web video clustering is a fundamental task in the field of social media mining. Automatically web video categorization methods enable users to find video corresponding to their interests. However, all the previous studies are only conducted on the default categories given by the website, i.e., 15 categories of YouTube. To date, clustering based on emotion category has not been a factor considered in this area. Therefore, in this paper, we propose a method to cluster YouTube videos into six emotion categories (e.g., angry, disgust, happy, horror, sad, surprise) with expect to improve video search results. The YouTube data is collected. Word embedding is utilized for transforming the video document into vectors which are then used in a clustering task. Clustering ensemble is employed to obtain final results. We compare the performance of this method with a state-of-the-art technology, i.e., Term Frequency-Inverse Document Frequency based on Vector Space Model. The experiment is implemented on a benchmark dataset for web video analysis. The results show that the best performance is achieved by applying clustering ensemble which reflects the feasibility of clustering web videos into suitable emotion categories.;;;https://dl.acm.org/doi/10.1145/3297730.3297736;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Analyze NYC Transportation to Mitigate Speeding and Explore New Business Models Using Machine Learning;;;['Joe Ma', 'Dong Si'];;;May 2017;;;ICCDA '17: Proceedings of the International Conference on Compute and Data Analysis;;;Many cities have been releasing their traffic data for companies to do the data analytics for business and other purposes. In this paper, we propose different classification models to analyze the places that most of vehicles speed and the places that most of vehicles visited in specific time range. The result of it can be helpful for the government allocating the police in the correct timing and places to catch vehicles speeding. In addition, by knowing the result of the major places that most of vehicles visited, it's helpful for gas companies to decide where they should build gas stations.;;;https://dl.acm.org/doi/10.1145/3093241.3093291;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Towards mining answer edits to extract evolution patterns in stack overflow;;;['Themistoklis Diamantopoulos', 'Maria-Ioanna Sifaki', 'Andreas L. Symeonidis'];;;May 2019;;;MSR '19: Proceedings of the 16th International Conference on Mining Software Repositories;;;The current state of practice dictates that in order to solve a problem encountered when building software, developers ask for help in online platforms, such as Stack Overflow. In this context of collaboration, answers to question posts often undergo several edits to provide the best solution to the problem stated. In this work, we explore the potential of mining Stack Overflow answer edits to extract common patterns when answering a post. In particular, we design a similarity scheme that takes into account the text and code of answer edits and cluster edits according to their semantics. Upon applying our methodology, we provide frequent edit patterns and indicate how they could be used to answer future research questions. Assessing our approach indicates that it can be effective for identifying commonly applied edits, thus illustrating the transformation path from the initial answer to the optimal solution.;;;https://dl.acm.org/doi/10.1109/MSR.2019.00043;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Research on Mental Health Rating Algorithm Based on Big Data Classification Algorithm;;;['Xiaokun Zhang'];;;September 2021;;;ICISCAE 2021: 2021 4th International Conference on Information Systems and Computer Aided Education;;;In the era of big data, the industries of informatization construction and digital office are increasing, and big data mining has been widely used, which is both an opportunity and a challenge. Facing all kinds of data generated by society and people, it is imperative to classify them accurately, mine effective information and improve the utilization rate of information. College students, as a special group of society, are facing pressure from all sides, and there are more and more mental health problems, which lead to extreme events. How to find valuable information from huge test data has always been a difficult problem in the field of mental health testing. Based on Apriori algorithm, this paper researches association rules mining, finds out the relationship between the main factors and symptoms of college students' mental health, and provides support for solving college students' mental health problems and developing mental health test system. The research shows that Apriori improved algorithm reduces the workload of data calculation and improves the mining efficiency.;;;https://dl.acm.org/doi/10.1145/3482632.3482656;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Towards Integrated Classification Lexicon for Handling Unknown Words in Chinese-Vietnamese Neural Machine Translation;;;['Wanjin Che', 'Zhengtao Yu', 'Zhiqiang Yu', 'Yonghua Wen', 'Junjun Guo'];;;None;;;ACM Transactions on Asian and Low-Resource Language Information Processing;;;In Neural Machine Translation (NMT), due to the limitations of the vocabulary, unknown words cannot be translated properly, which brings suboptimal performance of the translation system. For resource-scarce NMT that have small-scale training corpus, the effect is amplified. The traditional approach of amplifying the scale of the corpus is not applicable, because the parallel corpus is difficult to obtain in a resource-scarce setting; however, it is easy to obtain and utilize external knowledge, bilingual lexicon, and other resources. Therefore, we propose classification lexicon approach for processing unknown words in the Chinese-Vietnamese NMT task. Specifically, three types of unknown Chinese-Vietnamese words are classified and their corresponding classification lexicon are constructed by word alignment, Wikipedia extraction, and rule-based methods, respectively. After translation, the unknown words are restored by lexicon for post-processing. Experiment results on Chinese-Vietnamese, English-Vietnamese, and Mongolian-Chinese translations show that our approach significantly improves the accuracy and the performance of NMT especially in a resource-scarce setting.;;;https://dl.acm.org/doi/10.1145/3373267;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Classification and exploration of TSM log file based on datamining Algorithms;;;['Jamal El abdelkhalki', 'Mohamed Ben ahmed', 'Boudhir Hakim Anouar'];;;November 2017;;;ICCWCS'17: Proceedings of the 2nd International Conference on Computing and Wireless Communication Systems;;;analyzing the log file for software or device provides a focal point for making incremental improvements; it is the performed step to start the incident analysis. Although, log messages format or contents may not always be fully documented, and described in many different formats. It makes the log analysis task more difficult, affects the correction deadline of incidents and therefore involves a high financial risk. In this paper, we survey the log file analysis and the existing systems elaborated to resolve current issue. Then, we propose a methodology to support the log analysis in the complex environment related to big data issues. Finally, we illustrate our proposal on the file log of the Tivoli Storage Manager (TSM) and provide a discussion of the result clusters.;;;https://dl.acm.org/doi/10.1145/3167486.3167553;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Mining patterns from genetic improvement experiments;;;['Oliver Krauss', 'Hanspeter Mössenböck', 'Michael Affenzeller'];;;May 2019;;;GI '19: Proceedings of the 6th International Workshop on Genetic Improvement;;;When conducting genetic improvement experiments, a large amount of individuals (≈ population size * generations) is created and evaluated. The corresponding experiments contain valuable data concerning the fitness of individuals for the defined criteria, such as run-time performance, memory use or robustness. This publication presents an approach to utilize this information in order to identify recurring context independent patterns in abstract syntax trees (ASTs). These patterns can be applied for restricting the search space (in the form of anti-patterns) or for grafting operators in the population. Future work includes an evaluation of this approach, as well as extending it with wildcards and class hierarchies for larger and more generalized patterns.;;;https://dl.acm.org/doi/10.1109/GI.2019.00015;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Discovery of Functional Motifs from the Interface Region of Oligomeric Proteins Using Frequent Subgraph Mining;;;['Tanay Kumar Saha', 'Ataur Katebi', 'Wajdi Dhifli', 'Mohammad Al Hasan'];;;None;;;IEEE/ACM Transactions on Computational Biology and Bioinformatics;;;Modeling the interface region of a protein complex paves the way for understanding its dynamics and functionalities. Existing works model the interface region of a complex by using different approaches, such as, the residue composition at the interface region, the geometry of the interface residues, or the structural alignment of interface regions. These approaches are useful for ranking a set of docked conformation or for building scoring function for protein-protein docking, but they do not provide a generic and scalable technique for the extraction of interface patterns leading to functional motif discovery. In this work, we model the interface region of a protein complex by graphs and extract interface patterns of the given complex in the form of frequent subgraphs. To achieve this, we develop a scalable algorithm for frequent subgraph mining. We show that a systematic review of the mined subgraphs provides an effective method for the discovery of functional motifs that exist along the interface region of a given protein complex. In our experiments, we use three PDB protein structure datasets. The first two datasets are composed of PDB structures from different conformations of two dimeric protein complexes: HIV-1 protease 329 structures, and triosephosphate isomerase TIM 86 structures. The third dataset is a collection of different enzyme structures protein structures from the six top-level enzyme classes, namely: Oxydoreductase, Transferase, Hydrolase, Lyase, Isomerase, and Ligase. We show that for the first two datasets, our method captures the locking mechanism at the dimeric interface by taking into account the spatial positioning of the interfacial residues through graphs. Indeed, our frequent subgraph mining based approach discovers the patterns representing the dimerization lock which is formed at the base of the structure in 323 of the 329 HIV-1 protease structures. Similarly, for 86 TIM structures, our approach discovers the dimerization lock formation in 50 structures. For the enzyme structures, we show that we are able to capture the functional motifs active sites that are specific to each of the six top-level classes of enzymes through frequent subgraphs.;;;https://dl.acm.org/doi/10.1109/TCBB.2017.2756879;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Comparative Study of Arabic Text Categorization Using Feature Selection Techniques and Four Classifier Models;;;['Said Bahassine', 'Abdellah Madani', 'Mohamed Kissi'];;;September 2020;;;SITA'20: Proceedings of the 13th International Conference on Intelligent Systems: Theories and Applications;;;Text classification is the process of assigning appropriate categories to free text according to its content. It is one of the important task in Text mining. Numerous studies have been conducted for natural languages processing using Japanese, French, Latin and Turkish documents, but the number of works related to the text written in Arabic language is still limited. In this paper we conduct a comparative study of three methods of feature selection using four well-known classifiers namely: Decision Tree, Naive Bayes, K-Nearest Neighbors and Support Vector Machine. A corpus contained 250 Arabic text belonging into five classes: sport, politics, economics, culture and art, and society. The data set is used to evaluate and compare the effectiveness of the obtained model. The experimental results reveal that using improved Chi-square method as feature selection and Support Vector Machine as classifier outperforms other combinations in terms of precision. This combination significantly improves the performance of Arabic text classification model. The highest value of precision measure for this model is 89.9%.;;;https://dl.acm.org/doi/10.1145/3419604.3419778;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Application Data Mining Technology in Monitoring Strategies of College Students' English Learning Motivation;;;['Shuang Liu'];;;September 2021;;;ICISCAE 2021: 2021 4th International Conference on Information Systems and Computer Aided Education;;;With the advent of the era of big data, how to apply big data technology to English learning has become a problem that people care about. This research mainly discusses the monitoring strategies of college students' English learning motivation based on data mining. After the collection of Web logs, an information matrix of online learning motivation is formed. Frequent user groups are retrieved through frequently visited page sets, and similar user groups are obtained through association rule analysis, and then related page sets are obtained from frequently visited page sets according to the set distance threshold between pages. Finally, perform cluster analysis on user information to obtain their preferences. Using gender as a categorical variable, the test found that there are significant differences in the intrinsic interest motivation and overall learning motivation dimensions of male and female students. The score of boys (2.6) and the score of girls in this item (3.873) are higher than those of boys. Therefore, the students' learning interest and motivation can be cultivated in a targeted manner, thereby effectively improving the students' academic performance.;;;https://dl.acm.org/doi/10.1145/3482632.3484150;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Imbalanced big data classification: a distributed implementation of SMOTE;;;['Avnish Kumar Rastogi', 'Nitin Narang', 'Zamir Ahmad Siddiqui'];;;January 2018;;;Workshops ICDCN '18: Proceedings of the Workshop Program of the 19th International Conference on Distributed Computing and Networking;;;In the domain of machine learning, quality of data is most critical component for building good models. Predictive analytics is an AI stream used to predict future events based on historical learnings and is used in diverse fields like predicting online frauds, oil slicks, intrusion attacks, credit defaults, prognosis of disease cells etc. Unfortunately, in most of these cases, traditional learning models fail to generate required results due to imbalanced nature of data. Here imbalance denotes small number of instances belonging to the class under prediction like fraud instances in the total online transactions. The prediction in imbalanced classification gets further limited due to factors like small disjuncts which get accentuated during the partitioning of data when learning at scale. Synthetic generation of minority class data (SMOTE [<u>1</u>]) is one pioneering approach by Chawla [<u>1</u>] to offset said limitations and generate more balanced datasets. Although there exists a standard implementation of SMOTE in python, it is unavailable for distributed computing environments for large datasets. Bringing SMOTE to distributed environment under spark is the key motivation for our research. In this paper we present our algorithm, observations and results for synthetic generation of minority class data under spark using Locality Sensitivity Hashing [LSH]. We were able to successfully demonstrate a distributed version of Spark SMOTE which generated quality artificial samples preserving spatial distribution1.;;;https://dl.acm.org/doi/10.1145/3170521.3170535;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Nonparametric Classification of Satellite Images;;;['Romans Dinuls', 'Ints Mednieks'];;;July 2018;;;ICoMS '18: Proceedings of the 2018 1st International Conference on Mathematics and Statistics;;;The task of classifying the objects on a satellite image into predefined categories is the topic of the article. The problems arising while designing a practicable classifier are discussed. The general conditions for robustness of a classifier are provided. To solve the problems mentioned, a robust classification approach is proposed aiming at completely nonparametric unsupervised clustering with consequent association of the clusters with target categories using multiple sources of the testing and training data. The nonparametric clustering used is primarily based on ranking and grouping. Completely nonparametric cluster union and cleaning procedures are presented; theoretical basics for other parts of the approach are provided. The software implementation and complexity of the methodology are discussed. The approach aims at getting the highest possible classification accuracy under real conditions for images with more than 100 million pixels.;;;https://dl.acm.org/doi/10.1145/3274250.3274260;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Automatic Validation of Textual Attribute Values in E-commerce Catalog by Learning with Limited Labeled Data;;;['Yaqing Wang', 'Yifan Ethan Xu', 'Xian Li', 'Xin Luna Dong', 'Jing Gao'];;;August 2020;;;KDD '20: Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining;;;Product catalogs are valuable resources for eCommerce website. In the catalog, a product is associated with multiple attributes whose values are short texts, such as product name, brand, functionality and flavor. Usually individual retailers self-report these key values, and thus the catalog information unavoidably contains noisy facts. It is very important to validate the correctness of these values in order to improve shopper experiences and enable more effective product recommendation. Due to the huge volume of products, an effective automatic validation approach is needed. In this paper, we propose to develop an automatic validation approach that verifies the correctness of textual attribute values for products. This can be formulated as a task as cross-checking a textual attribute value against product profile, which is a short textual description of the product on eCommerce website. Although existing deep neural network models have shown success in conducting cross-checking between two pieces of texts, their success has to be dependent upon a large set of quality labeled data, which are hard to obtain in this validation task: products span a variety of categories. Due to the category difference, annotation has to be done on all the categories, which is impossible to achieve in real practice. To address the aforementioned challenges, we propose a novel meta-learning latent variable approach, called MetaBridge, which can learn transferable knowledge from a subset of categories with limited labeled data and capture the uncertainty of never-seen categories with unlabeled data. More specifically, we make the following contributions. (1) We formalize the problem of validating the textual attribute values of products from a variety of categories as a natural language inference task in the few-shot learning setting, and propose a meta-learning latent variable model to jointly process the signals obtained from product profiles and textual attribute values. (2) We propose to integrate meta learning and latent variable in a unified model to effectively capture the uncertainty of various categories. With this model, annotation costs can be significantly reduced as we make best use of labeled data from limited categories. (3) We propose a novel objective function based on latent variable model in the few-shot learning setting, which ensures distribution consistency between unlabeled and labeled data and prevents overfitting by sampling different records from the learned distribution. Extensive experiments on real eCommerce datasets from hundreds of categories demonstrate the effectiveness of MetaBridge on textual attribute validation and its outstanding performance compared with state-of-the-art approaches.;;;https://dl.acm.org/doi/10.1145/3394486.3403303;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Text Classification Method with Combination of Fuzzy Relation and Feature Distribution Variance;;;['Wei Liu', 'Renze Xiong', 'Ning N Cheng', 'Yiming Y Sun'];;;October 2020;;;CCRIS '20: Proceedings of the 2020 1st International Conference on Control, Robotics and Intelligent System;;;To accurately express the fuzzy relation between word features and texts, and fuzzy relation between word features and categories respectively. A text classification method is proposed based on Fuzzy Relation and Feature Distribution Variance (FRFDV). This method firstly performs feature reduction and category feature word extraction according to the distribution of features in inter-category and intra-category. Then the method defines the word feature set, test text set and category set as fuzzy sets. Next, each text and category are represented respectively by defining the membership function of the word feature set to the test text set and the category set. When using word feature sets to represent categories, pay attention to the membership degree of features to categories and their distribution between categories; when using feature sets to represent test texts, give categorical feature words and non-categorical feature words with different weights. Finally, the fuzzy set correlation formula is used to calculate the correlation between the text and each category, and the category with the largest correlation is the category of the text. Comparing with the XGBOOST [Fang, 2020, Gong and Wang, 2018] algorithm and SVM algorithm, it is proved that the text classification method based on FRFDV is feasible. The accuracy of the results is higher by 2 % and 4 % respectively.;;;https://dl.acm.org/doi/10.1145/3437802.3437829;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Combining Active Learning and Data Augmentation for Image Classification;;;['Yu Ma', 'Shaoxing Lu', 'Erya Xu', 'Tian Yu', 'Lijian Zhou'];;;September 2020;;;ICBDT '20: Proceedings of the 3rd International Conference on Big Data Technologies;;;To solve the problem that the data annotation in image classification task requires a lot of time and economic costs, and a large number of unlabeled images cannot be effectively utilized in reality, an image classification method combining active learning algorithm and data augmentation is proposed. First, data augmentation is performed on a small number of labeled samples, the classification model is initially trained, and then, according to the sampling strategy of active learning, the samples are selected and labeled by experts, which are the most conducive to model training from the unlabeled set. The labeled set is updated by adding the new labeled samples. The same process is performed until the requirements are met. In this paper, experiments are carried out on the digits dataset and the Cifar10 set. The results show that the image classification method proposed in this paper can effectively enhance the accuracy of image classification.;;;https://dl.acm.org/doi/10.1145/3422713.3422726;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Inventory Management of Automobile After-sales Parts Based on Data Mining;;;['Qun Liu', 'Kehua Miao', 'Kaihong Lin'];;;June 2019;;;HPCCT '19: Proceedings of the 2019 3rd High Performance Computing and Cluster Technologies Conference;;;The inventory management of automotive aftermarket parts is of great significance to the after-sales activities of automobile dealers and the reduction of operating costs. In view of the problem of insufficient utilization of automobile after-sales service data, it is necessary to introduce data mining methods to further analyze and mine data. Taking the historical sales data of auto parts as the mining object, K-means clustering algorithm and LSTM recurrent neural network were applied, and the Python tool was used to develop the automobile after-sales parts classification model and the parts inventory prediction model. The classification results can be used to analyze whether the dealer's inventory structure is reasonable. The forecast results can predict the demand for parts in the next stage. Comprehensive classification and prediction results, the study provides reference for the auto dealer to determine the variety structure and quantity structure of the auto parts.;;;https://dl.acm.org/doi/10.1145/3341069.3342975;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Automatic Classification of Glaciers from Sentinel-2 Imagery Using A Novel Deep Learning Model;;;['Shuai Yan', 'Linlin Xu', 'Rui Wu'];;;November 2019;;;ICAIP '19: Proceedings of the 2019 3rd International Conference on Advances in Image Processing;;;The Sentinel-2 imagery provides accessible multispectral imagery, allowing better operation monitoring of glacier for climate change research, sea level rise and human life. Nevertheless, automatic glacial classification from Sentinel-2 is a challenging due to factors such as complex environment, different resolution bands and noisy or correlation in the spectral or spatial domain. In this paper, we propose an automatic glacier discrimination approach named MSSUnet to address several key research issues. First, a spatial-spectral module is used to adaptively learning the feature from different spectral band and neighboring pixels, which can better learn spatial-spectral features and reduce the impact of noise. Second, a band fusion method is applied to achieve fusion of different resolution bands in Sentinel-2 and reduce the interference of additional information. Furthermore, the proposed MSSUNet is compared with several existing neural networks on Sentinel-2 imagery to justify the advantage and improvement of the proposed approach. Experimental results show the improved performance of our proposed network over the other approaches.;;;https://dl.acm.org/doi/10.1145/3373419.3373460;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Making Machine-Learning Applications for Time-Series Sensor Data Graphical and Interactive;;;['Seungjun Kim', 'Dan Tasse', 'Anind K. Dey'];;;None;;;ACM Transactions on Interactive Intelligent Systems;;;The recent profusion of sensors has given consumers and researchers the ability to collect significant amounts of data. However, understanding sensor data can be a challenge, because it is voluminous, multi-sourced, and unintelligible. Nonetheless, intelligent systems, such as activity recognition, require pattern analysis of sensor data streams to produce compelling results; machine learning (ML) applications enable this type of analysis. However, the number of ML experts able to proficiently classify sensor data is limited, and there remains a lack of interactive, usable tools to help intermediate users perform this type of analysis. To learn which features these tools must support, we conducted interviews with intermediate users of ML and conducted two probe-based studies with a prototype ML and visual analytics system, Gimlets. Our system implements ML applications for sensor-based time-series data as a novel domain-specific prototype that integrates interactive visual analytic features into the ML pipeline. We identify future directions for usable ML systems based on sensor data that will enable intermediate users to build systems that have been prohibitively difficult.;;;https://dl.acm.org/doi/10.1145/2983924;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Toward an Effective Analysis of COVID-19 Moroccan Business Survey Data using Machine Learning Techniques;;;['Imane Lasri', 'Anouar RiadSolh', 'Mourad El Belkacemi'];;;February 2021;;;ICMLC '21: Proceedings of the 2021 13th International Conference on Machine Learning and Computing;;;COVID-19 pandemic has gravely affected our societies and economies with severe consequences. To contain the spread of the disease, most governments around the world authorized unprecedented measures, including Morocco, which has closed the borders and adopted full lockdown between March and June 2020. However, these measures have resulted in economic loss and have led to dramatic changes in how businesses act and consumers behave. The main focus of this study was to examine the impact of the full lockdown on Moroccan enterprises based on the COVID-19 Moroccan business survey carried out by the High Commission for Planning (HCP). A three-stage analysis method was employed. First, multiple correspondence analysis (MCA) was used to reduce the dimensionality of the categorical variables, and k-means clustering algorithm was used to cluster the data, then decision tree algorithm was performed in order to interpret each cluster and the maximum accuracy achieved is 84.45%. Compared with the decision tree algorithm, an artificial neural network (ANN) with stratified 10-fold cross-validation was applied to the dataset and has reached an accuracy of 83.4%. The simulation results confirm the effectiveness of the proposed techniques for analyzing survey data.;;;https://dl.acm.org/doi/10.1145/3457682.3457690;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Transportation mode detection using machine learning techniques on mobile phone sensor data;;;['Ifigenia Drosouli', 'Athanasios Voulodimos', 'Georgios Miaoulis'];;;June 2020;;;PETRA '20: Proceedings of the 13th ACM International Conference on PErvasive Technologies Related to Assistive Environments;;;The everyday use of means of transportation by millions of people combined with the continuous spreading of smartphones which are now equipped with various sensors, imply the existence of abundance of real-world transportation-related data and make Transportation Mode Detection (TMD) an interesting research field, essential to urban transportation planning, development of context-aware applications and physical and mental health improvement. The main objective of this work is to develop a machine learning methodology for classifying eight different transportation modes, including: still, walk, run, bike, car, bus, train, and subway, using data from smartphones sensors. To this end, publicly available datasets were used. For example, a subset of the original SHL dataset, including data obtained from one participant's smartphone embedded sensors (accelerometer, magnetometer, gyroscope, pressure sensor), being recorded for 68 days. As classifiers, eight Machine Learning algorithms were employed. The classifiers were firstly developed without Dimensionality Reduction (DR) and then with a DR feature extraction algorithm (Principal Component Analysis - PCA) so as to explore the possibility of using lighter models and potentially improve performance. After dimensionality reduction, the algorithms that performed best, accomplished a very good classification result in all classes while training time was significantly reduced.;;;https://dl.acm.org/doi/10.1145/3389189.3397996;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
MICK: A Meta-Learning Framework for Few-shot Relation Classification with Small Training Data;;;['Xiaoqing Geng', 'Xiwen Chen', 'Kenny Q. Zhu', 'Libin Shen', 'Yinggong Zhao'];;;October 2020;;;CIKM '20: Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management;;;Few-shot relation classification seeks to classify incoming query instances after meeting only few support instances. This ability is gained by training with large amount of in-domain annotated data. In this paper, we tackle an even harder problem by further limiting the amount of data available at training time. We propose a few-shot learning framework for relation classification, which is particularly powerful when the training data is very small. In this framework, models not only strive to classify query instances, but also seek underlying knowledge about the support instances to obtain better instance representations. The framework also includes a method for aggregating cross-domain knowledge into models by open-source task enrichment. Additionally, we construct a brand new dataset: the TinyRel-CM dataset, a few-shot relation classification dataset in health domain with purposely small training data and challenging relation classes. Experimental results demonstrate that our framework brings performance gains for most underlying classification models, outperforms the state-of-the-art results given small training data, and achieves competitive results with sufficiently large training data.;;;https://dl.acm.org/doi/10.1145/3340531.3411858;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Comparison of different model's performances in task of document classification;;;['Kristijan Spirovski', 'Evgenija Stevanoska', 'Andrea Kulakov', 'Zaneta Popeska', 'Goran Velinov'];;;June 2018;;;WIMS '18: Proceedings of the 8th International Conference on Web Intelligence, Mining and Semantics;;;Although the number of additional resources in Macedonian which can be used for solving information retrieval problem (or general Natural Language Processing problem) is very limited, models exist which are general enough and do not need additional knowledge about the language. This paper presents a document classification model, that doesn't rely on any language specific additional resources. The model is trained and tested on a set of news articles extracted from Macedonian websites, and each document is labeled with a class representing one of the twelve category sections from which the documents were extracted. The goal of this paper is to test different methods for feature selection and choice of vocabulary. Furthermore, we choose a model which gives the best accuracy for document classification task and we make sensitivity analysis on its architecture in order to further improve its performance. Although similar research already exists, this paper aims to combine different experiments and test them on Macedonian language documents. The models used in this paper are Random Forest (RF), Support Vector Machines (SVM) and Neural Network (NN). The performed experiments showed that the best accuracy is achieved when each document is represented as tf-idf vector, the vocabulary contains equal number of representative words from each class, and simple Neural Network with 3 hidden layers is used as a model. The main conclusion is that a language independent model for solving document classification problem can be successfully build for Macedonian language, achieving around 80% accuracy on the test set.;;;https://dl.acm.org/doi/10.1145/3227609.3227668;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Mining points of interest via address embeddings: an unsupervised approach;;;['Abhinav Ganesan', 'Anubhav Gupta', 'Jose Mathew'];;;November 2021;;;LocalRec '21: Proceedings of the 5th ACM SIGSPATIAL International Workshop on Location-based Recommendations, Geosocial Networks and Geoadvertising;;;Digital maps are commonly used across the globe for exploring places that users are interested in, commonly referred to as points of interest (PoI). In online food delivery platforms, PoIs could represent any major private compounds where customers could order from such as hospitals, residential complexes, office complexes, educational institutes and hostels. In this work, we propose an end-to-end unsupervised system design for obtaining polygon representations of PoIs (PoI polygons) from address locations and address texts. We preprocess the address texts using locality names and generate embeddings for the address texts using a deep learning-based architecture, viz. RoBERTa, trained on our internal address dataset. The PoI candidates are identified by jointly clustering the anonymised customer phone GPS locations (obtained during address onboarding) and the embeddings of the address texts. The final list of PoI polygons is obtained from these PoI candidates using novel post-processing steps that involve density-based cluster refinement and graph-based technique for cluster merging. This algorithm identified 74.8 % more PoIs than those obtained using the Mummidi-Krumm baseline algorithm run on our internal dataset. We use area-based precision and recall metrics to evaluate the performance of the algorithm. The proposed algorithm achieves a median area precision of 98 %, a median recall of 8 %, and a median F-score of 0.15. In order to improve the recall of the algorithmic polygons, we post-process them using building footprint polygons from the OpenStreetMap (OSM) database. The post-processing algorithm involves reshaping the algorithmic polygon using intersecting polygons and closed private roads from the OSM database, and accounting for intersection with public roads on the OSM database. We achieve a median area recall of 70 %, a median area precision of 69 %, and a median F-score of 0.69 on these post-processed polygons. The ground truth polygons for the evaluation of the metrics were obtained using manual validation of the algorithmic polygons obtained from the Mummidi-Krumm baseline approach. These polygons are not used to train the proposed algorithm pipeline, and hence, the algorithm is unsupervised.;;;https://dl.acm.org/doi/10.1145/3486183.3491002;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Machine Learning for Makers: Interactive Sensor Data Classification Based on Augmented Code Examples;;;['David A. Mellis', 'Ben Zhang', 'Audrey Leung', 'Björn Hartmann'];;;June 2017;;;DIS '17: Proceedings of the 2017 Conference on Designing Interactive Systems;;;Although many software libraries and hardware modules support reading data from sensors, makers of interactive systems often struggle to extract higher-level information from raw sensor data. Available general-purpose machine learning (ML) libraries remain difficult to use for non-experts. Prior research has sought to bridge this gap through domain-specific user interfaces for particular types of sensors or algorithms. Our ESP (Example-based Sensor Prediction) system introduces a more general approach in which interactive visualizations and control interfaces are dynamically generated from augmented code examples written by experts. ESP's augmented examples allow experts to write logic that guides makers through important steps such as sensor calibration, parameter tuning, and assessing signal quality and classification performance. Writing augmented examples requires additional effort. ESP leverages a fundamental dynamic of online communities: experts are often willing to invest such effort to teach and train novices. Thus support for particular sensing domains does not have to be hard-wired a priori by system authors, but can be provided later by its community of users. We illustrate ESP's flexibility by detailing pipelines for four distinct sensors and classification algorithms. We validated the usability and flexibility of our example-based approach through a one-day workshop with 11 participants.;;;https://dl.acm.org/doi/10.1145/3064663.3064735;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Mining drug-drug interactions for healthcare professionals;;;['Lizzy Farrugia', 'Charlie Abela'];;;January 2020;;;APPIS 2020: Proceedings of the 3rd International Conference on Applications of Intelligent Systems;;;The fourth leading cause of death in the US are Adverse Drug Reactions (ADRs)1 that can be brought about through Drug-Drug Interactions (DDIs). In this paper, we propose medicX, a system that can detect DDIs in biomedical texts by leveraging on different machine learning techniques. The main components within medicX are the Drug Named Entity Recognition (DNER) component and the DDI Identification component. The DNER component was evaluated using the CHEMDNER and the DDIExtraction 2013 (DDI2013) challenge corpora. On the other hand, the DDI Identification component was evaluated using the DDI2013 challenge corpus. The DNER component is implemented using an approach based on LSTM-CRF. This method achieves an F1-score of 84.89% when it is trained and evaluated on the DDI2013 corpus, which is 1.43% higher than the system that placed first in the DDI2013 challenge. On the other hand, the DDI Identification component is implemented using a two-stage rich feature-based linear-kernel SVM. This classifier achieves an F1-score of 66.18%, as compared to the SVM state-of-the-art DDI system that reported an F1-score of 71.79%.;;;https://dl.acm.org/doi/10.1145/3378184.3378196;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Emoji-Powered Representation Learning for Cross-Lingual Sentiment Classification;;;['Zhenpeng Chen', 'Sheng Shen', 'Ziniu Hu', 'Xuan Lu', 'Qiaozhu Mei', 'Xuanzhe Liu'];;;May 2019;;;WWW '19: The World Wide Web Conference;;;Sentiment classification typically relies on a large amount of labeled data. In practice, the availability of labels is highly imbalanced among different languages, e.g., more English texts are labeled than texts in any other languages, which creates a considerable inequality in the quality of related information services received by users speaking different languages. To tackle this problem, cross-lingual sentiment classification approaches aim to transfer knowledge learned from one language that has abundant labeled examples (i.e., the source language, usually English) to another language with fewer labels (i.e., the target language). The source and the target languages are usually bridged through off-the-shelf machine translation tools. Through such a channel, cross-language sentiment patterns can be successfully learned from English and transferred into the target languages. This approach, however, often fails to capture sentiment knowledge specific to the target language, and thus compromises the accuracy of the downstream classification task. In this paper, we employ emojis, which are widely available in many languages, as a new channel to learn both the cross-language and the language-specific sentiment patterns. We propose a novel representation learning method that uses emoji prediction as an instrument to learn respective sentiment-aware representations for each language. The learned representations are then integrated to facilitate cross-lingual sentiment classification. The proposed method demonstrates state-of-the-art performance on benchmark datasets, which is sustained even when sentiment labels are scarce.;;;https://dl.acm.org/doi/10.1145/3308558.3313600;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Mining Classification Rules for HIV-1 Protease Cleavage Sites Using Simplified Swarm Optimization;;;['Alice Yeh', 'Wei-Chang Yeh'];;;October 2019;;;AIAM 2019: Proceedings of the 2019 International Conference on Artificial Intelligence and Advanced Manufacturing;;;HIV-1 protease is a crucial enzyme in the HIV life cycle and serves to cleave the polyprotein that is involved in the formation of mature viruses. Due to its sensitivity and important function in virion creation, predicting cleavage classification can aid in the development of HIV-1 protease inhibitors that can improve antiretroviral therapy. Currently available methods are less effective at maintaining high prediction accuracy and consistency when applied to data with class bias and can be simplified and optimized. A prediction method that focused solely on sequential data was proposed and used in this study. A simplified swarm optimization (SSO) algorithm was applied to classifying HIV-1 protease cleavage data, which consisted of octamers that would be cleaved between the fourth and fifth amino acid, and orthogonal array testing was incorporated to improve efficiency. The prediction accuracy was assessed by applying the SSO algorithm to datasets found in the UCI Machine Learning Repository. Our experimental results show that SSO is an effective predictor of HIV-1 protease cleavage, exhibiting prediction accuracy that compared favorably to existing methods for both data with little class bias and data that contains class bias. Additionally, our prediction accuracy results suggest that the use of physicochemical features, as opposed to solely sequential features, does not improve performance.;;;https://dl.acm.org/doi/10.1145/3358331.3358335;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Sichuan Consumers' Mining of Agricultural Product Brand Value Based on Big Data;;;['Huaxue Zhuang', 'Shoudong Chen', 'Zheng Wang', 'Yinjiang Tu', 'Xiaoyun Xie', 'Liangqiang Li'];;;August 2021;;;ICIMTECH 21: <italic toggle='yes'>Retracted on September 15, 2021</italic>The Sixth International Conference on Information Management and Technology;;;NOTICE OF RETRACTION: While investigating potential publication-related misconduct in connection with the ICIMTech 2021 Conference Proceedings, serious concerns were raised that cast doubt on the integrity of the peer-review process and all papers published in the Proceedings of this Conference. The integrity of the entire Conference has been called into question. As a result, of its investigation, ACM has decided to retract the Entire Conference Proceedings and all related papers from the ACM Digital Library.None of the papers from this Proceeding should be cited in the literature because of the questionable integrity of the peer review process for this Conference.;;;https://dl.acm.org/doi/10.1145/3465631.3465641;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Learning Hierarchal Channel Attention for Fine-grained Visual Classification;;;['Xiang Guan', 'Guoqing Wang', 'Xing Xu', 'Yi Bin'];;;October 2021;;;MM '21: Proceedings of the 29th ACM International Conference on Multimedia;;;Learning delicate feature representation of object parts plays a critical role in fine-grained visual classification tasks. However, advanced deep convolutional neural networks trained for general visual classification tasks usually tend to focus on the coarse-grained information while ignoring the fine-grained one, which is of great significance for learning discriminative representation. In this work, we explore the great merit of multi-modal data in introducing semantic knowledge and sequential analysis techniques in learning hierarchical feature representation for generating discriminative fine-grained features. To this end, we propose a novel approach, termed Channel Cusum Attention ResNet (CCA-ResNet ), for multi-modal joint learning of fine-grained representation. Specifically, we use feature-level multi-modal alignment to connect image and text classification models for joint multi-modal training. Through joint training, image classification models trained with semantic level labels tend to focus on the most discriminative parts, which enhances the cognitive ability of the model. Then, we propose a Channel Cusum Attention (CCA ) mechanism to equip feature maps with hierarchical properties through unsupervised reconstruction of local and global features. The benefits brought by the CCA are in two folds: a) allowing fine-grained features from early layers to be preserved in the forward propagation of deep networks; b) leveraging the hierarchical properties to facilitate multi-modal feature alignment. We conduct extensive experiments to verify that our proposed model can achieve state-of-the-art performance on a series of fine-grained visual classification benchmarks.;;;https://dl.acm.org/doi/10.1145/3474085.3475184;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Predictive Modeling of HR Dynamics Using Machine Learning;;;['Ilze Birzniece', 'Ilze Andersone', 'Agris Nikitenko', 'Liga Zvirbule'];;;March 2022;;;ICMLT '22: Proceedings of the 2022 7th International Conference on Machine Learning Technologies;;;Voluntary employee turnover is an essential threat to companies due to the loss of institutional expertise and costs associated with recruitment. In this paper, we continue to tackle the retention problem by developing a machine learning (ML) based solution and providing a prototype tool to predict potential turnover. Both unsupervised and supervised ML methods are applied to identify the appropriate technique. K-Means clustering algorithm with PCA did not show significant results, whereas CART decision tree algorithm reached 89 % accuracy on the test set and 84 % accuracy on the validation set. Having satisfactory classification results are only part of a successful solution for modelling human resource (HR) dynamics. An important yet often underestimated aspect is representation according to end-user needs, which rarely are ML experts. To mitigate the risks of misinterpretation of classification results and take full advantage of decision support, we emphasize engineering the output of classification results for HR employees. We validated the classification system on data sets containing records of more than 2000 employees working in technology companies in Latvia from the year 2014 up to date.;;;https://dl.acm.org/doi/10.1145/3529399.3529403;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Phenotype Prediction from Metagenomic Data Using Clustering and Assembly with Multiple Instance Learning (CAMIL);;;['Mohammad Arifur Rahman', 'Nathan LaPierre', 'Huzefa Rangwala'];;;None;;;IEEE/ACM Transactions on Computational Biology and Bioinformatics;;;The recent advent of Metagenome Wide Association Studies (MGWAS) provides insight into the role of microbes on human health and disease. However, the studies present several computational challenges. In this paper, we demonstrate a novel, efficient, and effective Multiple Instance Learning (MIL) based computational pipeline to predict patient phenotype from metagenomic data. MIL methods have the advantage that besides predicting the clinical phenotype, we can infer the instance level label or role of microbial sequence reads in the specific disease. Specifically, we use a Bag of Words method, which has been shown to be one of the most effective and efficient MIL methods. This involves assembly of the metagenomic sequence data, clustering of the assembled contigs, extracting features from the contigs, and using an SVM classifier to predict patient labels and identify the most relevant sequence clusters. With the exception of the given labels for the patients, this entire process is de novo (unsupervised). We call our pipeline &#x201C;CAMIL&#x201D;, which stands for Clustering and Assembly with Multiple Instance Learning. We use multiple state-of-the-art clustering methods for feature extraction, evaluation, and comparison of the performance of our proposed approach for each of these clustering methods. We also present a fast and scalable pre-clustering algorithm as a preprocessing step for our proposed pipeline. Our approach achieves efficiency by partitioning the large number of sequence reads into groups (called canopies) using locality sensitive hashing (LSH). These canopies are then refined by using state-of-the-art sequence clustering algorithms. We use data from a well-known MGWAS study of patients with Type-2 Diabetes and show that our pipeline significantly outperforms the classifier used in that paper, as well as other common MIL methods.;;;https://dl.acm.org/doi/10.1109/TCBB.2017.2758782;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Comparison of Manifold Learning and Deep Learning on Target Classification;;;['Huang Cheng', 'Wang Hongmei'];;;September 2017;;;ICCBDC '17: Proceedings of the 2017 International Conference on Cloud and Big Data Computing;;;With the development of artificial intelligence, classification tasks become more and more popular, but the amount of data is growing dramatically. There are mainly two ways to deal with this problem, one is to reduce the data dimensions directly, the other one is to take advantage of all data through deep learning. In this paper, we will compare these two data processing methods. The first way is to reduce the extracted features' dimensions through manifold learning and then feed into classifiers, and the other way is to deal it directly with deep learning. The experimental results show that deep learning has a better ability than manifold learning in the classification task.;;;https://dl.acm.org/doi/10.1145/3141128.3141137;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A novel support vector machine algorithm for missing data;;;['Mengeheng Zhu', 'Hong Shi'];;;March 2018;;;ICIAI '18: Proceedings of the 2nd International Conference on Innovation in Artificial Intelligence;;;Missing data problem often occurs in data analysis. The most common way to solve this problem is imputation. But imputation methods are only suitable for dealing with a low proportion of missing data, when assuming that missing data satisfies MCAR (Missing Completely at Random) or MAR (Missing at Random). In this paper, considering the reasons for missing data, we propose a novel support vector machine method using a new kernel function to solve the problem with a relatively large proportion of missing data. This method makes full use of observed data to reduce the error caused by filling a large number of missing values. We validate our method on 4 data sets from UCI Repository of Machine Learning. The accuracy, F-score, Kappa statistics and recall are used to evaluate the performance. Experimental results show that our method achieve significant improvement in terms of classification results compared with common imputation methods, even when the proportion of missing data is high.;;;https://dl.acm.org/doi/10.1145/3194206.3194214;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Fast One-class Classification using Class Boundary-preserving Random Projections;;;['Arindam Bhattacharya', 'Sumanth Varambally', 'Amitabha Bagchi', 'Srikanta Bedathur'];;;August 2021;;;KDD '21: Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining;;;Several applications, like malicious URL detection and web spam detection, require classification on very high-dimensional data. In such cases anomalous data is hard to find but normal data is easily available. As such it is increasingly common to use a one-class classifier (OCC). Unfortunately, most OCC algorithms cannot scale to datasets with extremely high dimensions. In this paper, we present Fast Random projection-based One-Class Classification (FROCC), an extremely efficient, scalable and easily parallelizable method for one-class classification with provable theoretical guarantees. Our method is based on the simple idea of transforming the training data by projecting it onto a set of random unit vectors that are chosen uniformly and independently from the unit sphere, and bounding the regions based on separation of the data. FROCC can be naturally extended with kernels. We provide a new theoretical framework to prove that that FROCC generalizes well in the sense that it is stable and has low bias for some parameter settings. We then develop a fast scalable approximation of FROCC using vectorization, exploiting data sparsity and parallelism to develop a new implementation called ParDFROCC. ParDFROCC achieves up to 2 percent points better ROC than the next best baseline, with up to 12× speedup in training and test times over a range of state-of-the-art benchmarks for the OCC task.;;;https://dl.acm.org/doi/10.1145/3447548.3467440;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Protocol Keywords Extraction Method Based on Frequent Item-Sets Mining;;;['Gaochao Li', 'Qiang Qian', 'Zhonghua Wang', 'Xin Zou', 'Xunxun Chen', 'Xiao Wu'];;;April 2018;;;ICISS '18: Proceedings of the 1st International Conference on Information Science and Systems;;;Network application identification technology is widely used in the fields of network management, network optimization and intrusion detection and so on. And among the methods, the DPI (Deep Packet Inspection) is the most popular one with high accuracy relaying on a small amount of payload data. However, DPI depends on the effective protocol keywords. In order to cope with the speed of the applications updating, we proposed a protocol keywords extraction method for unencrypted network applications based on frequent itemsets mining. It contains two major steps: Firstly, we generate candidate words by using unsupervised methods and reduce the word set size with rules of words length and position. Then, we extract effective protocol keywords with frequent item-sets mining method and remove the noise words and redundant words by evaluating the candidate word co-occurrence relationship. The experiment result shows that our method shrinks the size of the keywords set and is better at extracting the real protocol keywords compared with Proword.;;;https://dl.acm.org/doi/10.1145/3209914.3209937;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A Cluster Switching Method for Sampling Imbalanced Data;;;['Wanthanee Prachuabsupakij', 'Supaporn Simcharoen'];;;March 2018;;;ISMSI '18: Proceedings of the 2nd International Conference on Intelligent Systems, Metaheuristics &amp; Swarm Intelligence;;;Classification on imbalanced data is one of the most interesting in data mining challenge. In this paper, a new repetitive sampling method, namely ClusIM is proposed to improve the prediction performance on imbalanced dataset using Clustering Switching Method based on K-means algorithm in order to generate new subset in attempting to reduce the overlapping between the minority class instances and majority class instances in each subset. Then, SMOTE algorithm is used to operate on each subset according to imbalance ratio of the subset. It generates the synthetic instances of the minority class. The ClusIM will generate two-balanced final training set, which are classified using SVM and to combine the model through maximum probability vote. Our experiments are based on six imbalanced data sets from UCI and one real-world dataset, comparing ClusIM with four well-known classification algorithms (SVM, Bagging, AdaboostM1, and AdaCost). Amongst the compared algorithms, ClusIM has higher F-measure and G-mean results than the other methods. This study supported that ClusIM is capable of improving the performance of learning algorithm on imbalanced dataset.;;;https://dl.acm.org/doi/10.1145/3206185.3206192;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Swarm Intelligence Approaches for Parameter Setting of Deep Learning Neural Network: Case Study on Phishing Websites Classification;;;['Grega Vrbančič', 'Iztok Fister', 'Vili Podgorelec'];;;June 2018;;;WIMS '18: Proceedings of the 8th International Conference on Web Intelligence, Mining and Semantics;;;In last decades, the web and online services have revolutionized the modern world. However, by increasing our dependence on online services, as a result, online security threats are also increasing rapidly. One of the most common online security threats is a so-called Phishing attack, the purpose of which is to mimic a legitimate website such as online banking, e-commerce or social networking website in order to obtain sensitive data such as user-names, passwords, financial and health-related information from potential victims. The problem of detecting phishing websites has been addressed many times using various methodologies from conventional classifiers to more complex hybrid methods. Recent advancements in deep learning approaches suggested that the classification of phishing websites using deep learning neural networks should outperform the traditional machine learning algorithms. However, the results of utilizing deep neural networks heavily depend on the setting of different learning parameters. In this paper, we propose a swarm intelligence based approach to parameter setting of deep learning neural network. By applying the proposed approach to the classification of phishing websites, we were able to improve their detection when compared to existing algorithms.;;;https://dl.acm.org/doi/10.1145/3227609.3227655;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Mining mobile app markets for prioritization of security assessment effort;;;['Alireza Sadeghi', 'Naeem Esfahani', 'Sam Malek'];;;September 2017;;;WAMA 2017: Proceedings of the 2nd ACM SIGSOFT International Workshop on App Market Analytics;;;Like any other software engineering activity, assessing the security of a software system entails prioritizing the resources and minimizing the risks. Techniques ranging from the manual inspection to automated static and dynamic analyses are commonly employed to identify security vulnerabilities prior to the release of the software. However, none of these techniques is perfect, as static analysis is prone to producing lots of false positives and negatives, while dynamic analysis and manual inspection are unwieldy, both in terms of required time and cost. This research aims to improve these techniques by mining relevant information from vulnerabilities found in the app markets. The approach relies on the fact that many modern software systems, in particular mobile software, are developed using rich application development frameworks (ADF), allowing us to raise the level of abstraction for detecting vulnerabilities and thereby making it possible to classify the types of vulnerabilities that are encountered in a given category of application. By coupling this type of information with severity of the vulnerabilities, we are able to improve the efficiency of static and dynamic analyses, and target the manual effort on the riskiest vulnerabilities.;;;https://dl.acm.org/doi/10.1145/3121264.3121265;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
How do visual explanations foster end users' appropriate trust in machine learning?;;;['Fumeng Yang', 'Zhuanyi Huang', 'Jean Scholtz', 'Dustin L. Arendt'];;;March 2020;;;IUI '20: Proceedings of the 25th International Conference on Intelligent User Interfaces;;;We investigated the effects of example-based explanations for a machine learning classifier on end users' appropriate trust. We explored the effects of spatial layout and visual representation in an in-person user study with 33 participants. We measured participants' appropriate trust in the classifier, quantified the effects of different spatial layouts and visual representations, and observed changes in users' trust over time. The results show that each explanation improved users' trust in the classifier, and the combination of explanation, human, and classification algorithm yielded much better decisions than the human and classification algorithm separately. Yet these visual explanations lead to different levels of trust and may cause inappropriate trust if an explanation is difficult to understand. Visual representation and performance feedback strongly affect users' trust, and spatial layout shows a moderate effect. Our results do not support that individual differences (e.g., propensity to trust) affect users' trust in the classifier. This work advances the state-of-the-art in trust-able machine learning and informs the design and appropriate use of automated systems.;;;https://dl.acm.org/doi/10.1145/3377325.3377480;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Customer Segmentation With Machine Learning: New Strategy For Targeted Actions;;;['Lahcen Abidar', 'Dounia Zaidouni', 'Abdeslam Ennouaary'];;;September 2020;;;SITA'20: Proceedings of the 13th International Conference on Intelligent Systems: Theories and Applications;;;Customers Segmentation has been a topic of interest for a lot of industry, academics, and marketing leaders. The potential value of a customer to a company can be a core ingredient in decision-making. One of the big challenges in customer-based organizations is customer cognition, understanding the difference between them, and scoring them. But now with all capabilities we have, using new technologies like machine learning algorithm and data treatment we can create a very powerful framework that allow us to best understand customers needs and behaviors, and act appropriately to satisfy their needs. In the present paper, we propose a new model based on RFM model Recency, Frequency, and Monetary and k-mean algorithm to resolve those challenges. This model will allow us to use clustering, scoring, and distribution to have a clear idea about what action we should take to improve customer satisfaction.;;;https://dl.acm.org/doi/10.1145/3419604.3419794;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Using Data Mining Methods to Detect Medical Fraud;;;['Long-Sheng Chen', 'Jia-Chuan Chen'];;;July 2020;;;ICMECG '20: Proceedings of the 7th International Conference on Management of e-Commerce and e-Government;;;Medical fraudulent activities have made medical insurance expenditures rise year by year. This not only increases the burden on the medical and financial system, but also makes it difficult for many people in need to obtain these resources. Therefore, how to solve this problem has become one of critical issues. Therefore, this study aims to establish a predictive model of medical insurance fraud through data mining methods, and attempts to discover important factors affecting fraud. In this work, we will use Decision Tree (DT), Support Vector Machines (SVM), and Back Propagation Neural Networks (BPN) to establish classification models. A comparison of these three methods will be done. And, we will use decision trees to extract important factors that could provide important information for effectively detect medical fraud. Hopefully, we can effectively reduce the negative impact of medical insurance fraud.;;;https://dl.acm.org/doi/10.1145/3409891.3409902;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Faster Secure Data Mining via Distributed Homomorphic Encryption;;;['Junyi Li', 'Heng Huang'];;;August 2020;;;KDD '20: Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining;;;Due to the rising privacy demand in data mining, Homomorphic Encryption (HE) is receiving more and more attention recently for its capability to do computations over the encrypted field. By using the HE technique, it is possible to securely outsource model learning to the not fully trustful but powerful public cloud computing environments. However, HE-based training scales badly because of the high computation complexity. It is still an open problem whether it is possible to apply HE to large-scale problems. In this paper, we propose a novel general distributed HE-based data mining framework towards one step of solving the scaling problem. The main idea of our approach is to use the slightly more communication overhead in exchange of shallower computational circuit in HE, so as to reduce the overall complexity. We verify the efficiency and effectiveness of our new framework by testing over various data mining algorithms and benchmark data-sets. For example, we successfully train a logistic regression model to recognize the digit 3 and 8 within around 5 minutes, while a centralized counterpart needs almost 2 hours.;;;https://dl.acm.org/doi/10.1145/3394486.3403321;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A Multi-task Learning Approach Based on Convolutional Neural Network for Acoustic Scene Classification;;;['Kuilong Xu', 'Shilei Huang', 'Gang Cheng', 'Xiao Song'];;;December 2019;;;ACAI '19: Proceedings of the 2019 2nd International Conference on Algorithms, Computing and Artificial Intelligence;;;Acoustic Scene Classification (ASC) aim to recognize an acoustic scene in audio signal records. The acoustic scene is a mixture of background sounds and various sound events, and sound events often determine the type of acoustic scene. However, in many research methods for acoustic scene classification, only a few people have noticed the important information of sound events. In this paper, we combine the ASC task and Sound Event Detection (SED) task, and propose a new CNN approach with multi-task Learning (MTL), which uses SED as an auxiliary task to pay more attention to the information of the sound event in the model. Besides, in view of the characteristic of the sound event with high-energy time-frequency components, we use Global Max Pooling (GMP) instead of the Fully Connected layer (FC) in the traditional CNN. The advantage is that the model focused on distinct high-energy time-frequency components of audio signals (sound event). Finally, extensive experiments are carried out on the TUT acoustic scene 2017 dataset. Our proposed CNN approach with MTL shows better generalization, and improves the Unweighted Average Recall (UAR) of 5.2% over the DCASE 2017 ASC baseline system.;;;https://dl.acm.org/doi/10.1145/3377713.3377720;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Query-Based Machine Learning Model for Data Analysis of Infrasonic Signals in Wireless Sensor Networks;;;['Ray-I Chang', 'Chien-Chang Huang', 'Liang-Bin Lai', 'Chia-Yun Lee'];;;February 2018;;;ICDSP '18: Proceedings of the 2nd International Conference on Digital Signal Processing;;;As infrasonic signals can through objects and propagate at a long distance, infrasound sensors are widely applied in wireless sensor networks to monitor environment events of a large area. The signal conditions are usually complex and have various characteristics while monitoring the large area. Different features in both time and frequency domains should be extracted and considered. Big data increases the computation complexity, and the wrong selection of features may decreases the accuracy in event prediction. To overcome this problem, a query-based-learning method is applied to select the proper features for smart edge computing in machine learning. Experimental results show that the proposed method provides good performance when comparing with previous feature selection methods.;;;https://dl.acm.org/doi/10.1145/3193025.3193031;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Prediction of Dengue Disease through Data Mining by using Modified Apriori Algorithm;;;['Iqra Jahangir', 'Abdul-Basit', 'Abdul Hannan', 'Sameen Javed'];;;July 2018;;;ICCES'18: Proceedings of the 4th ACM International Conference of Computing for Engineering and Sciences;;;Dengue is a threatening ailment and it is caused by the bite of a female mosquito. Pakistan has been a victim of this disease from a couple of years. Life of many people is endangered from it. People were facing a problem for the detection of this disease because of the limited resources of time and money. Lives of the people can be saved if the dengue is predicted in early stages. The present research will present a dengue prediction methodology by using the data mining technique. Association rule mining is used in this paper for the prediction of this disease. First, the data was collected which includes patients having dengue or not, then it was used in Weka data mining tool by applying Apriori algorithm. The rules derived from this algorithm were further used for generating a proposed rule which is used for the prediction of dengue in patients. Generated rule was able to identify 75% of records correctly.;;;https://dl.acm.org/doi/10.1145/3213187.3287612;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Stable classification;;;['Dimitris Bertsimas', 'Jack Dunn', 'Ivan Paskov'];;;None;;;The Journal of Machine Learning Research;;;We address the problem of instability of classification models: small changes in the training data leading to large changes in the resulting model and predictions. This phenomenon is especially well established for single tree based methods such as CART, however it is present in all classification methods. We apply robust optimization to improve the stability of four of the most commonly used classification methods: Random Forests, Logistic Regression, Support Vector Machines, and Optimal Classification Trees. Through experiments on 30 data sets with sizes ranging between 102 and 104 observations and features, we show that our approach (a) leads to improvements in stability, and in some cases accuracy, compared to the original methods, with the gains in stability being particularly significant (even, surprisingly, for those methods that were previously thought to be stable, such as Random Forests) and (b) has computational times comparable with (and indeed in some cases even faster than) the original methods allowing the method to be very scalable.;;;https://dl.acm.org/doi/10.5555/3586589.3586885;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Gaussian Processes for Rumour Stance Classification in Social Media;;;['Michal Lukasik', 'Kalina Bontcheva', 'Trevor Cohn', 'Arkaitz Zubiaga', 'Maria Liakata', 'Rob Procter'];;;None;;;ACM Transactions on Information Systems;;;Social media tend to be rife with rumours while new reports are released piecemeal during breaking news. Interestingly, one can mine multiple reactions expressed by social media users in those situations, exploring their stance towards rumours, ultimately enabling the flagging of highly disputed rumours as being potentially false. In this work, we set out to develop an automated, supervised classifier that uses multi-task learning to classify the stance expressed in each individual tweet in a conversation around a rumour as either supporting, denying or questioning the rumour. Using a Gaussian Process classifier, and exploring its effectiveness on two datasets with very different characteristics and varying distributions of stances, we show that our approach consistently outperforms competitive baseline classifiers. Our classifier is especially effective in estimating the distribution of different types of stance associated with a given rumour, which we set forth as a desired characteristic for a rumour-tracking system that will show both ordinary users of Twitter and professional news practitioners how others orient to the disputed veracity of a rumour, with the final aim of establishing its actual truth value.;;;https://dl.acm.org/doi/10.1145/3295823;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Toward an Effective Analysis of COVID-19 Moroccan Business Survey Data using Machine Learning Techniques;;;['Imane Lasri', 'Anouar RiadSolh', 'Mourad El Belkacemi'];;;February 2021;;;ICMLC '21: Proceedings of the 2021 13th International Conference on Machine Learning and Computing;;;COVID-19 pandemic has gravely affected our societies and economies with severe consequences. To contain the spread of the disease, most governments around the world authorized unprecedented measures, including Morocco, which has closed the borders and adopted full lockdown between March and June 2020. However, these measures have resulted in economic loss and have led to dramatic changes in how businesses act and consumers behave. The main focus of this study was to examine the impact of the full lockdown on Moroccan enterprises based on the COVID-19 Moroccan business survey carried out by the High Commission for Planning (HCP). A three-stage analysis method was employed. First, multiple correspondence analysis (MCA) was used to reduce the dimensionality of the categorical variables, and k-means clustering algorithm was used to cluster the data, then decision tree algorithm was performed in order to interpret each cluster and the maximum accuracy achieved is 84.45%. Compared with the decision tree algorithm, an artificial neural network (ANN) with stratified 10-fold cross-validation was applied to the dataset and has reached an accuracy of 83.4%. The simulation results confirm the effectiveness of the proposed techniques for analyzing survey data.;;;https://dl.acm.org/doi/10.1145/3457682.3457690;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Inferring Dynamic User Interests in Streams of Short Texts for User Clustering;;;['Shangsong Liang', 'Zhaochun Ren', 'Yukun Zhao', 'Jun Ma', 'Emine Yilmaz', 'Maarten De Rijke'];;;None;;;ACM Transactions on Information Systems;;;User clustering has been studied from different angles. In order to identify shared interests, behavior-based methods consider similar browsing or search patterns of users, whereas content-based methods use information from the contents of the documents visited by the users. So far, content-based user clustering has mostly focused on static sets of relatively long documents. Given the dynamic nature of social media, there is a need to dynamically cluster users in the context of streams of short texts. User clustering in this setting is more challenging than in the case of long documents, as it is difficult to capture the users’ dynamic topic distributions in sparse data settings. To address this problem, we propose a dynamic user clustering topic model (UCT). UCT adaptively tracks changes of each user’s time-varying topic distributions based both on the short texts the user posts during a given time period and on previously estimated distributions. To infer changes, we propose a Gibbs sampling algorithm where a set of word pairs from each user is constructed for sampling. UCT can be used in two ways: (1) as a short-term dependency model that infers a user’s current topic distribution based on the user’s topic distributions during the previous time period only, and (2) as a long-term dependency model that infers a user’s current topic distributions based on the user’s topic distributions during multiple time periods in the past. The clustering results are explainable and human-understandable, in contrast to many other clustering algorithms. For evaluation purposes, we work with a dataset consisting of users and tweets from each user. Experimental results demonstrate the effectiveness of our proposed short-term and long-term dependency user clustering models compared to state-of-the-art baselines.;;;https://dl.acm.org/doi/10.1145/3072606;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A New Contrast Pattern-Based Classification for Imbalanced Data;;;['Xiangtao Chen', 'Yajing Gao', 'Siqi Ren'];;;September 2018;;;ISCSIC '18: Proceedings of the 2nd International Symposium on Computer Science and Intelligent Control;;;Contrast pattern-based classifiers become more understandable and accurate on binary classification. However, these classifiers do not achieve good performance on class imbalance problems. Thus, this paper introduces a new contrast pattern-based classifier for class imbalance problems. The proposed method selects the appropriate contrast patterns by quality measures. Then we combine the quality measure of the pattern and class confidence proportion with the class imbalance level at the classification stage of the model. The simulation results show that our proposed outperforms the current contrast pattern-based classifiers and other state-of-the-art classifiers not directly based on contrast patterns for class imbalance problems.;;;https://dl.acm.org/doi/10.1145/3284557.3284708;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
How do visual explanations foster end users' appropriate trust in machine learning?;;;['Fumeng Yang', 'Zhuanyi Huang', 'Jean Scholtz', 'Dustin L. Arendt'];;;March 2020;;;IUI '20: Proceedings of the 25th International Conference on Intelligent User Interfaces;;;We investigated the effects of example-based explanations for a machine learning classifier on end users' appropriate trust. We explored the effects of spatial layout and visual representation in an in-person user study with 33 participants. We measured participants' appropriate trust in the classifier, quantified the effects of different spatial layouts and visual representations, and observed changes in users' trust over time. The results show that each explanation improved users' trust in the classifier, and the combination of explanation, human, and classification algorithm yielded much better decisions than the human and classification algorithm separately. Yet these visual explanations lead to different levels of trust and may cause inappropriate trust if an explanation is difficult to understand. Visual representation and performance feedback strongly affect users' trust, and spatial layout shows a moderate effect. Our results do not support that individual differences (e.g., propensity to trust) affect users' trust in the classifier. This work advances the state-of-the-art in trust-able machine learning and informs the design and appropriate use of automated systems.;;;https://dl.acm.org/doi/10.1145/3377325.3377480;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A Data Mining Framework for Valuing Large Portfolios of Variable Annuities;;;['Guojun Gan', 'Jimmy Xiangji Huang'];;;August 2017;;;KDD '17: Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining;;;A variable annuity is a tax-deferred retirement vehicle created to address concerns that many people have about outliving their assets. In the past decade, the rapid growth of variable annuities has posed great challenges to insurance companies especially when it comes to valuing the complex guarantees embedded in these products. In this paper, we propose a novel data mining framework to address the computational issue associated with the valuation of large portfolios of variable annuity contracts. The data mining framework consists of two major components: a data clustering algorithm which is used to select representative variable annuity contracts, and a regression model which is used to predict quantities of interest for the whole portfolio based on the representative contracts. A series of numerical experiments are conducted on a portfolio of synthetic variable annuity contracts to demonstrate the performance of our proposed data mining framework in terms of accuracy and speed. The experimental results show that our proposed framework is able to produce accurate estimates of various quantities of interest and can reduce the runtime significantly.;;;https://dl.acm.org/doi/10.1145/3097983.3098013;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Classification of Acute Stress-Induced Response Patterns;;;['Luca Abel', 'Robert Richer', 'Arne Küderle', 'Stefan Gradl', 'Bjoern M. Eskofier', 'Nicolas Rohleder'];;;May 2019;;;PervasiveHealth'19: Proceedings of the 13th EAI International Conference on Pervasive Computing Technologies for Healthcare;;;Modern machine learning techniques enable new possibilities for the analysis of psychological data. In the field of health psychology, it is of interest to explore the biological processes triggered by acute stress. This work introduces a method to automatically classify individuals into distinct stress responder groups based on these biological processes. Two important stress-sensitive markers were used: Salivary cortisol and Interleukin-6 (IL-6) in blood plasma. Controlled stress was induced using the Trier Social Stress Test on two consecutive days. Results show that Support Vector Machines performed best on the given dataset. We distinguished four different cortisol and three different IL-6 responder types with high mean accuracies (92.2 % ± 9.7 % and 91.2 % ± 6.3 %, respectively). Classification results were mainly limited by class imbalances and high intra-class standard deviations. Whereas promising as a first application of machine learning on such datasets, generalizability and real-world applicability of our results need to be proven by further research.;;;https://dl.acm.org/doi/10.1145/3329189.3329231;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Cross-Domain Classification Model With Knowledge Utilization Maximization for Recognition of Epileptic EEG Signals;;;['Kaijian Xia', 'TongGuang Ni', 'Hongsheng Yin', 'Bo Chen'];;;None;;;IEEE/ACM Transactions on Computational Biology and Bioinformatics;;;Conventional classification models for epileptic EEG signal recognition need sufficient labeled samples as training dataset. In addition, when training and testing EEG signal samples are collected from different distributions, for example, due to differences in patient groups or acquisition devices, such methods generally cannot perform well. In this paper, a cross-domain classification model with knowledge utilization maximization called CDC-KUM is presented, which takes advantage of the data global structure provided by the labeled samples in the related domain and unlabeled samples in the current domain. Through mapping the data into kernel space, the pairwise constraint regularization term is combined together the predictive differences of the labeled data in the source domain. Meanwhile, the soft clustering regularization term using quadratic weights and Gini-Simpson diversity is applied to exploit the distribution information of unlabeled data in the target domain. Experimental results show that CDC-KUM model outperformed several traditional non-transfer and transfer classification methods for recognition of epileptic EEG signals.;;;https://dl.acm.org/doi/10.1109/TCBB.2020.2973978;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Detecting spam tweets using machine learning and effective preprocessing;;;['Berk Kardaş', 'İsmail Erdem Bayar', 'Tansel Özyer', 'Reda Alhajj'];;;November 2021;;;ASONAM '21: Proceedings of the 2021 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining;;;Nowadays, with the rapid increase in popularity of online social networks (OSNs), these platforms are realized as ideal places for spammers. Unfortunately, these spammers can easily publish malicious content, advertise phishing scams by taking advantage of OSNs. Therefore, effective identification and filtering of spam tweets will be beneficial to both OSNs and users. However, it is becoming increasingly difficult to check and eliminate spam tweets due to this great flow of posts. Motivated by these observations, in this paper we propose an approach for the detection of spam tweets using machine learning and effective preprocessing techniques. The approach proposes the advantages of the preprocessing and which of these preprocessing techniques are the most effective. To compare these techniques UtkML Twitter spam dataset is used in testing. After the most effective methods determined, the detection accuracy of the spam tweets will be better optimized by combining them. We have evaluated our solution with four different machine learning algorithms namely - Naïve Bayes Classifier, Neural Network, Logistic Regression and Support Vector Machine. With SVM Classifier, we are able to achieve an accuracy of 93.02%. Experimental results show that our approach can improve the performance of spam tweet classification effectively.;;;https://dl.acm.org/doi/10.1145/3487351.3490968;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Fruit-fly Inspired Neighborhood Encoding for Classification;;;['Kaushik Sinha', 'Parikshit Ram'];;;August 2021;;;KDD '21: Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining;;;Inspired by the fruit-fly olfactory circuit, the Fly Bloom Filter is able to efficiently summarize the data with a single pass and has been used for novelty detection. We propose a new classifier that effectively encodes the different local neighborhoods for each class with a per-class Fly Bloom Filter. The inference on test data requires an efficient Flyhash[6] operation followed by a high-dimensional, but very sparse, dot product with the per-class Bloom Filters. On the theoretical side, we establish conditions under which the predictions of our proposed classifier agrees with the predictions of the nearest neighbor classifier. We extensively evaluate our proposed scheme with 71 data sets of varied data dimensionality to demonstrate that the predictive performance of our proposed neuroscience inspired classifier is competitive to the nearest-neighbor classifiers and other single-pass classifiers.;;;https://dl.acm.org/doi/10.1145/3447548.3467246;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Fast One-class Classification using Class Boundary-preserving Random Projections;;;['Arindam Bhattacharya', 'Sumanth Varambally', 'Amitabha Bagchi', 'Srikanta Bedathur'];;;August 2021;;;KDD '21: Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining;;;Several applications, like malicious URL detection and web spam detection, require classification on very high-dimensional data. In such cases anomalous data is hard to find but normal data is easily available. As such it is increasingly common to use a one-class classifier (OCC). Unfortunately, most OCC algorithms cannot scale to datasets with extremely high dimensions. In this paper, we present Fast Random projection-based One-Class Classification (FROCC), an extremely efficient, scalable and easily parallelizable method for one-class classification with provable theoretical guarantees. Our method is based on the simple idea of transforming the training data by projecting it onto a set of random unit vectors that are chosen uniformly and independently from the unit sphere, and bounding the regions based on separation of the data. FROCC can be naturally extended with kernels. We provide a new theoretical framework to prove that that FROCC generalizes well in the sense that it is stable and has low bias for some parameter settings. We then develop a fast scalable approximation of FROCC using vectorization, exploiting data sparsity and parallelism to develop a new implementation called ParDFROCC. ParDFROCC achieves up to 2 percent points better ROC than the next best baseline, with up to 12× speedup in training and test times over a range of state-of-the-art benchmarks for the OCC task.;;;https://dl.acm.org/doi/10.1145/3447548.3467440;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
CurGraph: Curriculum Learning for Graph Classification;;;['Yiwei Wang', 'Wei Wang', 'Yuxuan Liang', 'Yujun Cai', 'Bryan Hooi'];;;April 2021;;;WWW '21: Proceedings of the Web Conference 2021;;;Graph neural networks (GNNs) have achieved state-of-the-art performance on graph classification tasks. Existing work usually feeds graphs to GNNs in random order for training. However, graphs can vary greatly in their difficulty for classification, and we argue that GNNs can benefit from an easy-to-difficult curriculum, similar to the learning process of humans. Evaluating the difficulty of graphs is challenging due to the high irregularity of graph data. To address this issue, we present the CurGraph (Curriculum Learning for Graph Classification) framework, that analyzes the graph difficulty in the high-level semantic feature space. Specifically, we use the infomax method to obtain graph-level embeddings and a neural density estimator to model the embedding distributions. Then we calculate the difficulty scores of graphs based on the intra-class and inter-class distributions of their embeddings. Given the difficulty scores, CurGraph first exposes a GNN to easy graphs, before gradually moving on to hard ones. To provide a soft transition from easy to hard, we propose a smooth-step method, which utilizes a time-variant smooth function to filter out hard graphs. Thanks to CurGraph, a GNN learns from the graphs at the border of its capability, neither too easy or too hard, to gradually expand its border at each training step. Empirically, CurGraph yields significant gains for popular GNN models on graph classification and enables them to achieve superior performance on miscellaneous graphs.;;;https://dl.acm.org/doi/10.1145/3442381.3450025;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Spatio-Temporal Clustering of Traffic Data with Deep Embedded Clustering;;;['Reza Asadi', 'Amelia Regan'];;;November 2019;;;PredictGIS'19: Proceedings of the 3rd ACM SIGSPATIAL International Workshop on Prediction of Human Mobility;;;Traffic data is a challenging spatio-temporal data, and a multivariate time series data with spatial similarities. Clustering of traffic data is a fundamental tool for various machine learning tasks including anomaly detection, missing data imputation and short term forecasting problems. In this paper, first, we formulate a spatio-temporal clustering problem and define temporal and spatial clusters. Then, we propose an approach for finding temporal and spatial clusters with a deep embedded clustering model. The proposed approach is examined on traffic flow data. In the analysis, we present the properties of clusters and patterns in the dataset. The analysis shows that the temporal and spatial clusters have meaningful relationships with temporal and spatial patterns in traffic data, and the clustering method effectively finds similarities in traffic data.;;;https://dl.acm.org/doi/10.1145/3356995.3364537;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A new self-organizing map based algorithm for multi-label stream classification;;;['Ricardo Cerri', 'Joel David C. Junior', 'Elaine. R. Faria', 'João Gama'];;;March 2021;;;SAC '21: Proceedings of the 36th Annual ACM Symposium on Applied Computing;;;Several algorithms have been proposed for offline multi-label classification. However, applications in areas such as traffic monitoring, social networks, and sensors produce data continuously, the so called data streams, posing challenges to batch multi-label learning. With the lack of stationarity in the distribution of data streams, new algorithms are needed to online adapt to such changes (concept drift). Also, in realistic applications, changes occur in scenarios with infinitely delayed labels, where the true classes of the arrival instances are never available. We propose an online unsupervised incremental method based on self-organizing maps for multi-label stream classification in scenarios with infinitely delayed labels. We consider the existence of an initial set of labeled instances to train a self-organizing map for each label. The learned models are then used and adapted in an evolving stream to classify new instances, considering that their classes will never be available. We adapt to incremental concept drifts by online updating the weight vectors of winner neurons and the dataset label cardinality. Predictions are obtained using the Bayes rule and the outputs of each neuron, adapting the prior probabilities and conditional probabilities of the classes in the stream. Experiments using synthetic and real datasets show that our method is highly competitive with several ones from the literature, in both stationary and concept drift scenarios.;;;https://dl.acm.org/doi/10.1145/3412841.3441922;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
The Dynamic Hyper-ellipsoidal Micro-Clustering for Evolving Data Stream Using Only Incoming Datum;;;['Narongrid Tangpathompong', 'Ureerat Suksawatchon', 'Jakkarin Suksawatchon'];;;July 2017;;;ICIIP '17: Proceedings of the 2nd International Conference on Intelligent Information Processing;;;Data stream clustering is becoming the efficient method to cluster an online massive data. The clustering task requires a process capable of partitioning data continuously with incremental learning method. In this paper, we present a new clustering method, called DyHEMstream, which is online and offline algorithm. In online phase, dynamic hyper-ellipsoidal micro-cluster is proposed used to keep summary information about evolving data stream based on new incoming data sample. The shape of proposed micro-cluster can represent the incoming data better than traditional micro-cluster. The algorithm processes each data point in one-pass fashion without storing the entire data set. In offline phase, each cluster is generated by expanding hyper-ellipsoidal micro-clusters to form the final clusters. The DyHEMstream algorithm is evaluated on various synthetic data sets using different quality metrics compared with a famous data stream clustering -- DenStream. Based on purity, Rand index, and Jaccard index, DyHEMstrem is very efficient than DenStream in term of clustering quality in different shapes, sizes, and densities in noisy data.;;;https://dl.acm.org/doi/10.1145/3144789.3144818;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Anomaly Detection in Business Process based on Data Stream Mining;;;['Gabriel Marques Tavares', 'Victor G. Turrisi da Costa', 'Vinicius Eiji Martins', 'Paolo Ceravolo', 'Sylvio Barbon'];;;June 2018;;;SBSI '18: Proceedings of the XIV Brazilian Symposium on Information Systems;;;Identifying fraudulent or anomalous business procedures is today a key challenge for organisations of any dimension. Nevertheless, the continuous nature of business conveys to the continuous acquisition of data in support of business process monitoring. In light of this, we propose a method for online anomaly detection in business processes. From a stream of events, our approach extract cases descriptors and applies a density-based clustering technique to detect outliers. We applied our method to a real-life dataset, and we used streaming clustering measures for evaluating performances. In particular, we obtained Cluster Mapping Measure of 95.3% and Homogeneity of 98.1% discovering anomalous cases in real-time.;;;https://dl.acm.org/doi/10.1145/3229345.3229362;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Exploring Classification of SPECT MPI images applying convolutional neural networks;;;['Nikolaos Papandrianos', 'Anna Feleki', 'Elpiniki Papageorgiou'];;;November 2021;;;PCI '21: Proceedings of the 25th Pan-Hellenic Conference on Informatics;;;The main goal of this research paper is to address the problem of SPECT myocardial perfusion imaging (MPI) diagnosis, exploring the capabilities of convolutional neural networks (CNN). Up to date, very few research studies have been conducted regarding the application of machine learning algorithms focusing on efficient structures of convolutional neural networks (CNNs) for the diagnosis of ischemia in MPI images. In the presented work, the dataset consists of SPECT images in stress and rest representation, and a two-class classification problem corresponding to 262 normal and 251 ischemic cases is explored. The data augmentation technique was used for increasing the number of the training dataset by rotating the images and zooming randomly. In this research study, a simple but robust CNN model for automatic classification of MPI images in two categories, was applied, after a proper exploration process concerning different values for number of layers, dense nodes, convolutional parameters as well as batch size and pixel size. The proposed CNN achieved an accuracy of 90.2075% and an AUC value of 93.77%. The results proved that the convolutional neural network is able to differentiate between normal and ischemic cases and would be a great assist to medical industry, when researching myocardial perfusion images. The model we are proposing is considered a valuable asset for this medical classification problem, as it manages to produce more reliable results compared to traditional clinical methods.;;;https://dl.acm.org/doi/10.1145/3503823.3503911;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Local Constraint and Label Embedding Multi-layer Dictionary Learning for Sperm Head Classification;;;['Tongguang Ni', 'Yan Ding', 'Jing Xue', 'Kaijian Xia', 'Xiaoqing Gu', 'Yizhang Jiang'];;;None;;;ACM Transactions on Multimedia Computing, Communications, and Applications;;;Morphological classification of human sperm heads is a key technology for diagnosing male infertility. Due to its sparse representation and learning capability, dictionary learning has shown remarkable performance in human sperm head classification. To promote the discriminability of the classification model, a novel local constraint and label embedding multi-layer dictionary learning model called LCLM-MDL is proposed in this study. Based on the multi-layer dictionary learning framework, two dictionaries are built on the basis of Laplacian regularized constraint and label embedding term in each layer, and the two dictionaries are approximated to each other as much as possible, so as to well exploit the nonlinear structure and discriminability features of the morphology of human sperm heads. In addition, to promote the robustness of the model, the asymmetric Huber loss is adopted in the last layer of LCLM-MDL, which approximates the misclassification error by using the absolute error function. Finally, the experimental results on HuSHeM dataset demonstrate the validity of the LCLM-MDL.;;;https://dl.acm.org/doi/10.1145/3458927;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
SISA: Set-Centric Instruction Set Architecture for Graph Mining on Processing-in-Memory Systems;;;['Maciej Besta', 'Raghavendra Kanakagiri', 'Grzegorz Kwasniewski', 'Rachata Ausavarungnirun', 'Jakub Beránek', 'Konstantinos Kanellopoulos', 'Kacper Janda', 'Zur Vonarburg-Shmaria', 'Lukas Gianinazzi', 'Ioana Stefan', 'Juan Gómez Luna', 'Jakub Golinowski', 'Marcin Copik', 'Lukas Kapp-Schwoerer', 'Salvatore Di Girolamo', 'Nils Blach', 'Marek Konieczny', 'Onur Mutlu', 'Torsten Hoefler'];;;October 2021;;;MICRO '21: MICRO-54: 54th Annual IEEE/ACM International Symposium on Microarchitecture;;;Simple graph algorithms such as PageRank have been the target of numerous hardware accelerators. Yet, there also exist much more complex graph mining algorithms for problems such as clustering or maximal clique listing. These algorithms are memory-bound and thus could be accelerated by hardware techniques such as Processing-in-Memory (PIM). However, they also come with non-straightforward parallelism and complicated memory access patterns. In this work, we address this problem with a simple yet surprisingly powerful observation: operations on sets of vertices, such as intersection or union, form a large part of many complex graph mining algorithms, and can offer rich and simple parallelism at multiple levels. This observation drives our cross-layer design, in which we (1) expose set operations using a novel programming paradigm, (2) express and execute these operations efficiently with carefully designed set-centric ISA extensions called SISA, and (3) use PIM to accelerate SISA instructions. The key design idea is to alleviate the bandwidth needs of SISA instructions by mapping set operations to two types of PIM: in-DRAM bulk bitwise computing for bitvectors representing high-degree vertices, and near-memory logic layers for integer arrays representing low-degree vertices. Set-centric SISA-enhanced algorithms are efficient and outperform hand-tuned baselines, offering more than 10 × speedup over the established Bron-Kerbosch algorithm for listing maximal cliques. We deliver more than 10 SISA set-centric algorithm formulations, illustrating SISA’s wide applicability.;;;https://dl.acm.org/doi/10.1145/3466752.3480133;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Recurrent Attention Walk for Semi-supervised Classification;;;['Uchenna Akujuobi', 'Qiannan Zhang', 'Han Yufei', 'Xiangliang Zhang'];;;January 2020;;;WSDM '20: Proceedings of the 13th International Conference on Web Search and Data Mining;;;In this paper, we study the graph-based semi-supervised learning for classifying nodes in attributed networks, where the nodes and edges possess content information. Recent approaches like graph convolution networks and attention mechanisms have been proposed to ensemble the first-order neighbors and incorporate the relevant neighbors. However, it is costly (especially in memory) to consider all neighbors without a prior differentiation. We propose to explore the neighborhood in a reinforcement learning setting and find a walk path well-tuned for classifying the unlabelled target nodes. We let an agent (of node classification task) walk over the graph and decide where to move to maximize classification accuracy. We define the graph walk as a partially observable Markov decision process (POMDP). The proposed method is flexible for working in both transductive and inductive setting. Extensive experiments on four datasets demonstrate that our proposed method outperforms several state-of-the-art methods. Several case studies also illustrate the meaningful movement trajectory made by the agent.;;;https://dl.acm.org/doi/10.1145/3336191.3371853;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
PinText: A Multitask Text Embedding System in Pinterest;;;['Jinfeng Zhuang', 'Yu Liu'];;;July 2019;;;KDD '19: Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining;;;Text embedding is a fundamental component for extracting text features in production-level data mining and machine learning systems given textual information is the most ubiqutious signals. However, practitioners often face the tradeoff between effectiveness of underlying embedding algorithms and cost of training and maintaining various embedding results in large-scale applications. In this paper, we propose a multitask text embedding solution called PinText for three major vertical surfaces including homefeed, related pins, and search in Pinterest, which consolidates existing text embedding algorithms into a single solution and produces state-of-the-art performance. Specifically, we learn word level semantic vectors by enforcing that the similarity between positive engagement pairs is larger than the similarity between a randomly sampled background pairs. Based on the learned semantic vectors, we derive embedding vector of a user, a pin, or a search query by simply averaging its word level vectors. In this common compact vector space, we are able to do unified nearest neighbor search with hashing by Hadoop jobs or dockerized images on Kubernetes cluster. Both offline evaluation and online experiments show effectiveness of this PinText system and save storage cost of multiple open-sourced embeddings significantly.;;;https://dl.acm.org/doi/10.1145/3292500.3330671;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Machine Learning Techniques for Heart Disease Datasets: A Survey;;;['Younas Khan', 'Usman Qamar', 'Nazish Yousaf', 'Aimal Khan'];;;February 2019;;;ICMLC '19: Proceedings of the 2019 11th International Conference on Machine Learning and Computing;;;Heart Failure (HF) has been proven one of the leading causes of death that is why an accurate and timely prediction of HF risks is extremely essential. Clinical methods, for instance, angiography is the best and most effective way of diagnosing HF, however, studies show that it is not only costly but has side effects as well. Lately, machine learning techniques have been used for the stated purpose. This survey paper aims to present a systematic literature review based on 35 journal articles published since 2012, where state of the art machine learning classification techniques have been implemented on heart disease datasets. This study critically analyzes the selected papers and finds gaps in the existing literature and is assistive for researchers who intend to apply machine learning in medical domains, particularly on heart disease datasets. The survey finds out that the most popular classification techniques are Support Vector Machine, Neural Networks, and ensemble classifiers.;;;https://dl.acm.org/doi/10.1145/3318299.3318343;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Collaborative SQL-injections detection system with machine learning;;;['Moisés Lodeiro-Santiago', 'Cándido Caballero-Gil', 'Pino Caballero-Gil'];;;October 2017;;;IML '17: Proceedings of the 1st International Conference on Internet of Things and Machine Learning;;;Data mining and information extraction from data is a field that has gained relevance in recent years thanks to techniques based on artificial intelligence and use of machine and deep learning. The main aim of the present work is the development of a tool based on a previous behaviour study of security audit tools (oriented to SQL pentesting) with the purpose of creating testing sets capable of performing an accurate detection of a SQL attack. The study is based on the information collected through the generated web server logs in a pentesting laboratory environment. Then, making use of the common extracted patterns from the logs, each attack vector has been classified in risk levels (dangerous attack, normal attack, non-attack, etc.). Finally, a training with the generated data was performed in order to obtain a classifier system that has a variable performance between 97 and 99 percent in positive attack detection. The training data is shared to other servers in order to create a distributed network capable of deciding if a query is an attack or is a real petition and inform to connected clients in order to block the petitions from the attacker's IP.;;;https://dl.acm.org/doi/10.1145/3109761.3158395;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A Classification Model for Thai Statement Sentiments by Deep Learning Techniques;;;['Pakawan Pugsee', 'Nitikorn Ongsirimongkol'];;;November 2019;;;CIIS '19: Proceedings of the 2019 2nd International Conference on Computational Intelligence and Intelligent Systems;;;At present, many organizations realized the importance of sentiment analysis for consumer reviews. The positive and negative comments can help to evaluate the user satisfaction of products and services to control and improve their qualities. In addition, the deep learning techniques are very interesting methods for current researches in the data mining field. Therefore, this research studied on the deep learning techniques to analyzed user reviews and comments in Thai Language from the TripAdvisor website. To begin with, user comments in four categories: hotels, restaurants, tourist attractions, and airlines were collected and tested on the combination of two basic deep learning technique that are convolutional neural network and long-short term memory. All user comments were divided into individual statements to classify into three groups: positive feelings, negative feelings, non-expressed feelings or neutrality. The research results found that the best classification model is the combination of three convolutional neural networks with 32, 64, and 128 filters, respectively, and the kernel size of 2 equal to the three components. Moreover, the performance of the proposed classification model was evaluated by accuracy, precision, and recall values which were higher than 80% in positive and negative groups, including F1 score about 0.8.;;;https://dl.acm.org/doi/10.1145/3372422.3372448;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Ship Classification for Space-based AIS Data Using 1D-CNN;;;['Yitao Wang', 'Lei Yang', 'Xin Song'];;;October 2021;;;EITCE '21: Proceedings of the 2021 5th International Conference on Electronic Information Technology and Computer Engineering;;;The wild application of AIS (Automatic Identification System) provides large quantities of data for maritime traffic research. There are many ships with types unknown in AIS data. The data-driven methods to identify the ship's class is one of the research hotspots in AIS data mining. In this paper, a 1D-CNN (one-dimensional convolutional neural network) method is applied to classify ships from the distribution of ships motion features, which achieves an accuracy of 78.83%. Moreover, the importance of features is discussed, which explains how the 1D-CNN works in this task and the reason why some classes of ships are mislabeled. The method in this paper is proved to be effective in ship classification using dynamic data in AIS.;;;https://dl.acm.org/doi/10.1145/3501409.3501560;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A Deep Learning-based Approach for Human Posture Classification;;;['Jui-Sheng Hung', 'Pin-Ling Liu', 'Chien-Chi Chang'];;;April 2020;;;MSIE '20: Proceedings of the 2020 2nd International Conference on Management Science and Industrial Engineering;;;Lifting posture is considered as a leading factor in low back injuries in the workplace. Hence, it is necessary to evaluate the risk of various lifting tasks. Classifying postures is important before performing an ergonomic task assessment. Recently, many studies have revealed that the deep learning method has a high accuracy in identifying human postures. However, few studies have explored how the deep learning method can be applied to classify different postures during a lifting task. The objective of this study was to develop a deep learning technique-based model for classifying three states of postures (squatting, standing and stooping) during a lifting task. A dataset comprising 2,600 various static images (squatting, standing and stooping) taken from 0° and 90° camera view angles and their corresponding 3D joint coordinate data recorded by the marker-based motion tracking system was used in this study. The images were randomly divided into training (1,300 images), validation (650 images) and testing (650 images) datasets. After all of the images were cropped to a fixed size, the training dataset was processed in the neural network as the input, and the validation dataset was used to revise the weight of the model while training to build the classifying model. Finally, the testing dataset was processed as input for classifying three static postures using the proposed model. A classification based on the 3D coordinate data captured by the marker-based motion tracking system was used as the reference to validate the accuracy of this classifying model. Overall, the model developed in this study reached 91.23% accuracy. The accuracy of correctly classifying the squatting, standing and stooping postures is 94.35%, 98.33% and 75.86%, respectively. In addition, this model showed a nearly equivalent accuracy for identifying the images taken from 0° (91.64%) and 90° (90.86%) cameras. The results of this preliminary test showed that the deep learning method has the potential to classify different static postures within a lifting pattern.;;;https://dl.acm.org/doi/10.1145/3396743.3396763;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Deep Learning of Pre-Classification for Fast Image Retrieval;;;['Fan Liu', 'Bin Wang', 'Qian Zhang'];;;December 2018;;;ACAI '18: Proceedings of the 2018 International Conference on Algorithms, Computing and Artificial Intelligence;;;Two dominant aspects of image retrieval are feature extraction and similarity metrics. Both of them have a great influence on the accuracy and efficiency of image retrieval. Traditional approaches always leverage pre-defined features to represent images without exploiting semantic information hidden in the dataset. In this paper, we propose a simple yet practical approach, namely deep learning of pre-classification (DLPC), which integrates classification into the image retrieval framework. Specifically, DLPC learns a Convolutional Neural Network (CNN) model via transfer learning, which can simultaneously finish feature extraction and image pre-classification. The results of image pre-classification provide feedback information indicating that features of images belonging to the same class should be stored together. For new-coming query images, they can easily find their similar images from the image library, as the similarity metric is performed only on images in the same category according to the pre-classification results. Extended experiments are performed on the Wang dataset and the Pet Dataset. Experimental results on these two large scale image datasets validate the promising performance of our method compared with the state-of-the-art approaches.;;;https://dl.acm.org/doi/10.1145/3302425.3302436;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Research on Hainan Cross-border Tourism Image Elements Based on Tourist Perception and Network Communication Based on Data Mining;;;['Xiuqing Fu', 'Zhiguo Zheng', 'Bo Xu'];;;May 2021;;;ICAIIS 2021: 2021 2nd International Conference on Artificial Intelligence and Information Systems;;;Tourism has been cultivated as an important industry in the national economy. With the great attention of all sectors of society to tourism, the development speed of China's tourism industry has been accelerated in an all-round way. People are increasingly aware that a good tourism image is one of the core competitiveness of tourism destinations. This paper combines theoretical analysis and empirical investigation, from the perspective of tourists' perception, obtains the attribute characteristics of Hainan tourism destination image perceived by tourists based on data mining software and network communication, and establishes analysis categories by using content analysis method. It also analyzes the image, tourism image, the components of tourism image and the influencing factors of the formation of tourism image, and probes into the spread of cross-border tourism image in Hainan.;;;https://dl.acm.org/doi/10.1145/3469213.3472789;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Open-world Learning and Application to Product Classification;;;['Hu Xu', 'Bing Liu', 'Lei Shu', 'P. Yu'];;;May 2019;;;WWW '19: The World Wide Web Conference;;;Classic supervised learning makes the closed-world assumption that the classes seen in testing must have appeared in training. However, this assumption is often violated in real-world applications. For example, in a social media site, new topics emerge constantly and in e-commerce, new categories of products appear daily. A model that cannot detect new/unseen topics or products is hard to function well in such open environments. A desirable model working in such environments must be able to (1) reject examples from unseen classes (not appeared in training) and (2) incrementally learn the new/unseen classes to expand the existing model. This is called open-world learning (OWL). This paper proposes a new OWL method based on meta-learning. The key novelty is that the model maintains only a dynamic set of seen classes that allows new classes to be added or deleted with no need for model re-training. Each class is represented by a small set of training examples. In testing, the meta-classifier only uses the examples of the maintained seen classes (including the newly added classes) on-the-fly for classification and rejection. Experimental results with e-commerce product classification show that the proposed method is highly effective1.;;;https://dl.acm.org/doi/10.1145/3308558.3313644;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Blind Source Separation Approach for Audio Signals based on Support Vector Machine Classification;;;['H. Abouzid', 'O. Chakkor'];;;November 2017;;;ICCWCS'17: Proceedings of the 2nd International Conference on Computing and Wireless Communication Systems;;;Audio signals are surrounding us everywhere, existing in many forms (speech, music, noise background, ...), but they exist all mixed together and separating them is a real serious problem. It is required to arrange them in order to be separated to use them an easy way in such many various applications such as blind source separation, extraction of speech segments, audio visual analysis,.... In this work, we introduce a new method to separate audio signals arrived mixed to a couple of microphones implemented on a head of a humanoid robot to solve the blind source separation (BSS) problem using the support vector machine (SVM). Thus, we provide a theoretical introduction to present the SVM method which has frequently been proposed for classification and regression tasks. The observations are classified by SVM method using some standard recordings which have been taken in a room. The experimental results after using the SVM technique are given at the end of this paper.;;;https://dl.acm.org/doi/10.1145/3167486.3167526;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Hidden stratification causes clinically meaningful failures in machine learning for medical imaging;;;['Luke Oakden-Rayner', 'Jared Dunnmon', 'Gustavo Carneiro', 'Christopher Re'];;;April 2020;;;CHIL '20: Proceedings of the ACM Conference on Health, Inference, and Learning;;;Machine learning models for medical image analysis often suffer from poor performance on important subsets of a population that are not identified during training or testing. For example, overall performance of a cancer detection model may be high, but the model may still consistently miss a rare but aggressive cancer subtype. We refer to this problem as hidden stratification, and observe that it results from incompletely describing the meaningful variation in a dataset. While hidden stratification can substantially reduce the clinical efficacy of machine learning models, its effects remain difficult to measure. In this work, we assess the utility of several possible techniques for measuring hidden stratification effects, and characterize these effects both via synthetic experiments on the CIFAR-100 benchmark dataset and on multiple real-world medical imaging datasets. Using these measurement techniques, we find evidence that hidden stratification can occur in unidentified imaging subsets with low prevalence, low label quality, subtle distinguishing features, or spurious correlates, and that it can result in relative performance differences of over 20% on clinically important subsets. Finally, we discuss the clinical implications of our findings, and suggest that evaluation of hidden stratification should be a critical component of any machine learning deployment in medical imaging.;;;https://dl.acm.org/doi/10.1145/3368555.3384468;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Under-bagging nearest neighbors for imbalanced classification;;;['Hanyuan Hang', 'Yuchao Cai', 'Hanfang Yang', 'Zhouchen Lin'];;;None;;;The Journal of Machine Learning Research;;;In this paper, we propose an ensemble learning algorithm called under-bagging k-nearest neighbors (under-bagging k-NN) for imbalanced classification problems. On the theoretical side, by developing a new learning theory analysis, we show that with properly chosen parameters, i.e., the number of nearest neighbors k, the expected sub-sample size s, and the bagging rounds B, optimal convergence rates for under-bagging k-NN can be achieved under mild assumptions w.r.t. the arithmetic mean (AM) of recalls. Moreover, we show that with a relatively small B, the expected sub-sample size s can be much smaller than the number of training data n at each bagging round, and the number of nearest neighbors k can be reduced simultaneously, especially when the data are highly imbalanced, which leads to substantially lower time complexity and roughly the same space complexity. On the practical side, we conduct numerical experiments to verify the theoretical results on the benefits of the under-bagging technique by the promising AM performance and efficiency of our proposed algorithm.;;;https://dl.acm.org/doi/10.5555/3586589.3586707;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Mining Significant Microblogs for Misinformation Identification: An Attention-Based Approach;;;['Qiang Liu', 'Feng Yu', 'Shu Wu', 'Liang Wang'];;;None;;;ACM Transactions on Intelligent Systems and Technology;;;With the rapid growth of social media, massive misinformation is also spreading widely on social media, e.g., Weibo and Twitter, and brings negative effects to human life. Today, automatic misinformation identification has drawn attention from academic and industrial communities. Whereas an event on social media usually consists of multiple microblogs, current methods are mainly constructed based on global statistical features. However, information on social media is full of noise, which should be alleviated. Moreover, most of the microblogs about an event have little contribution to the identification of misinformation, where useful information can be easily overwhelmed by useless information. Thus, it is important to mine significant microblogs for constructing a reliable misinformation identification method. In this article, we propose an attention-based approach for identification of misinformation (AIM). Based on the attention mechanism, AIM can select microblogs with the largest attention values for misinformation identification. The attention mechanism in AIM contains two parts: content attention and dynamic attention. Content attention is the calculated-based textual features of each microblog. Dynamic attention is related to the time interval between the posting time of a microblog and the beginning of the event. To evaluate AIM, we conduct a series of experiments on the Weibo and Twitter datasets, and the experimental results show that the proposed AIM model outperforms the state-of-the-art methods.;;;https://dl.acm.org/doi/10.1145/3173458;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Meta-Learning for Neural Relation Classification with Distant Supervision;;;['Zhenzhen Li', 'Jian-Yun Nie', 'Benyou Wang', 'Pan Du', 'Yuhan Zhang', 'Lixin Zou', 'Dongsheng Li'];;;October 2020;;;CIKM '20: Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management;;;Distant supervision provides a means to create a large number of weakly labeled data at low cost for relation classification. However, the resulting labeled instances are very noisy, containing data with wrong labels. Many approaches have been proposed to select a subset of reliable instances for neural model training, but they still suffer from noisy labeling problem or underutilization of the weakly-labeled data. To better select more reliable training instances, we introduce a small amount of manually labeled data as reference to guide the selection process. In this paper, we propose a meta-learning based approach, which learns to reweight noisy training data under the guidance of reference data. As the clean reference data is usually very small, we propose to augment it by dynamically distilling the most reliable elite instances from the noisy data. Experiments on several datasets demonstrate that the reference data can effectively guide the selection of training data, and our augmented approach consistently improves the performance of relation classification comparing to the existing state-of-the-art methods.;;;https://dl.acm.org/doi/10.1145/3340531.3412039;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Merging Live Video Feeds for Remote Monitoring of a Mining Machine;;;['Andrew T Flangas', 'Javad Sattarvand', 'Sergiu M Dascalu', 'Frederick C Harris'];;;November 2021;;;ESSE '21: Proceedings of the 2021 European Symposium on Software Engineering;;;This research entails using virtual reality to interpret video recordings in Unity from cameras on an unmanned machine used for mining excavations. The purpose of using a machine of this nature is to send it into hazardous mining environments rather than sending workers and having their lives jeopardized. This work is significant because it demonstrates how two separate fields, such as virtual reality and robotics, can be combined to complete useful tasks. It also illustrates how machines can be used to replace workers in hazardous conditions not only in the field of mining, but in other fields as well. The main contribution of the work presented in this paper is the creation of a panorama of live video feeds captured by several webcams, which can be seen using a VR headset. As also described in the paper the software developed for this engineering application has been created using appropriate software engineering techniques and tools. Results of merging live video feeds and testing camera placements are also presented and planned directions of future work are outlined.;;;https://dl.acm.org/doi/10.1145/3501774.3501776;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Imbalanced Time Series Classification for Flight Data Analyzing with Nonlinear Granger Causality Learning;;;['Hao Huang', 'Chenxiao Xu', 'Shinjae Yoo', 'Weizhong Yan', 'Tianyi Wang', 'Feng Xue'];;;October 2020;;;CIKM '20: Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management;;;Identifying the faulty class of multivariate time series is crucial for today's flight data analysis. However, most of the existing time series classification methods suffer from imbalanced data and lack of model interpretability, especially on flight data of which faulty events are usually uncommon with a limited amount of data. Here, we present a neural network classification model for imbalanced multivariate time series by leveraging the information learned from normal class, which can also learn the nonlinear Granger causality for each class, so that we can pinpoint how time series classes differ from each other. Experiments on simulated data and real flight data shows that this model can achieve high accuracy of identifying anomalous flights.;;;https://dl.acm.org/doi/10.1145/3340531.3412710;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Correlation-Based Incremental Learning Network with Sliding Window for Perfume Classification;;;['Panida Lorwongtrakool', 'Phayung Meesad'];;;July 2020;;;IAIT '20: Proceedings of the 11th International Conference on Advances in Information Technology;;;Contamination inspection or quality inspection of raw materials or products is a very important task, especially in the perfume industry that requires an expert for inspection. However, the human nose has limitations such as fatigue, which affects the accuracy. Therefore, an electronic nose or sensor array has been developed to assist in the inspection. The signal data from electronic nose is fed into machine learning models to learn and process. Since the data change over time, the input data fluctuate according to the changing environment. In addition, when there are new data with features that change from the original patterns, the classification outcome may not be correct and the model will not be able to classify as effective as the original model. Therefore, to solve the problem mentioned this research proposes Correlation-Based Incremental Learning Network with Sliding Window (CILNS), which learns automatically by adapting to new data while maintaining the existing knowledge. The experiments were conducted on classifying perfumes. The experimental data were divided into 4 batches. Batch 1 was used as the training data and the other batches were used as the testing data. The proposed algorithm was compared with other well-known classifiers. The results showed that the proposed CILNS algorithm model 4-1 (Window size = 4, step size = 1) provides the highest accuracy of 95.16%.;;;https://dl.acm.org/doi/10.1145/3406601.3406649;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Using Machine Learning Classifiers to Identify the Critical Proteins in Down Syndrome;;;['Handan Kulan', 'Tamer Dag'];;;October 2018;;;ICCBB '18: Proceedings of the 2018 2nd International Conference on Computational Biology and Bioinformatics;;;Pharmacotherapies of intellectual disability (ID) are largely unknown as the abnormalities at the complex molecular level which causes ID are difficult to understand. Down syndrome (DS) which is the prevalent cause of ID and caused by an extra copy of the human chromosome21 (Hsa21) has been investigated on protein levels by using the Ts65Dn mouse model of DS which are orthologs of %50 of Hsa21 classical protein coding genes. Recent works have applied the classification methods to understand critical factors in DS as it is believed that the problem was naturally related to classification problem since the determination of proteins discriminatory between classes of mice was required. In this study, we apply forward feature selection method to identify correlated proteins and their interactions in DS. After identification, we report supervised learning model of expression levels of selected proteins in order to understand the critical proteins for diagnosing and explaining DS. The proposed technique depicts optimum classification results achieved by optimizing parameters with grid search. When compared with the former work, our classification results give higher accuracy.;;;https://dl.acm.org/doi/10.1145/3290818.3290831;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Clustering based personality prediction on turkish tweets;;;['Esen Tutaysalgir', 'Pinar Karagoz', 'Ismail H. Toroslu'];;;August 2019;;;ASONAM '19: Proceedings of the 2019 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining;;;In this paper, we present a framework for predicting the personality traits by analyzing tweets written in Turkish. The prediction model is constructed with a clustering based approach. Since the model is based on linguistic features, it is language specific. The prediction model uses features applicable to Turkish language and related to writing style of Turkish Twitter users. Our approach uses anonymous BIG5 questionnaire scores of volunteer participants as the ground truth in order to generate personality model from Twitter posts. Experiment results show that constructed model can predict personality traits of Turkish Twitter users with relatively small errors.;;;https://dl.acm.org/doi/10.1145/3341161.3343513;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
IPGOD: An Integrated Visualization Platform Based on Big Data Mining and Cloud Computing;;;['Wei-Yu Chen', 'Peggy Joy Lu', 'Steven Shiau'];;;May 2019;;;ICBDC '19: Proceedings of the 4th International Conference on Big Data and Computing;;;With big data analytics and open data mining becoming increasingly important in this information explosion era, a highly efficient approach to providing an integrated service is by combining these two topics. Therefore, to maximize the convenience of Taiwan's open data utilization and to enrich users' experiences with big data analytics, this paper proposes the Integrated Platform for Government Open Data (IPGOD). The platform consists of a "Data System" based on a cloud data warehouse and an "Analytics System" based on machine learning utilities; these two systems can work individually or in an integrated manner. Moreover, we leverage the Apache Spark cloud platform to enhance low latency response and high performance. The experimental results demonstrate that the proposed IPGOD realizes the open data warehouse effectively and derives machine learning visualization in a user-friendly and intelligent way.;;;https://dl.acm.org/doi/10.1145/3335484.3335494;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Fast, Accurate, and Flexible Algorithms for Dense Subtensor Mining;;;['Kijung Shin', 'Bryan Hooi', 'Christos Faloutsos'];;;None;;;ACM Transactions on Knowledge Discovery from Data;;;Given a large-scale and high-order tensor, how can we detect dense subtensors in it? Can we spot them in near-linear time but with quality guarantees? Extensive previous work has shown that dense subtensors, as well as dense subgraphs, indicate anomalous or fraudulent behavior (e.g., lockstep behavior in social networks). However, available algorithms for detecting dense subtensors are not satisfactory in terms of speed, accuracy, and flexibility. In this work, we propose two algorithms, called M-Zoom and M-Biz, for fast and accurate dense-subtensor detection with various density measures. M-Zoom gives a lower bound on the density of detected subtensors, while M-Biz guarantees the local optimality of detected subtensors. M-Zoom and M-Biz can be combined, giving the following advantages: (1) Scalable: scale near-linearly with all aspects of tensors and are up to 114× faster than state-of-the-art methods with similar accuracy, (2) Provably accurate: provide a guarantee on the lowest density and local optimality of the subtensors they find, (3) Flexible: support multi-subtensor detection and size bounds as well as diverse density measures, and (4) Effective: successfully detected edit wars and bot activities in Wikipedia, and spotted network attacks from a TCP dump with near-perfect accuracy (AUC = 0.98).;;;https://dl.acm.org/doi/10.1145/3154414;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Learning to Selectively Transfer: Reinforced Transfer Learning for Deep Text Matching;;;['Chen Qu', 'Feng Ji', 'Minghui Qiu', 'Liu Yang', 'Zhiyu Min', 'Haiqing Chen', 'Jun Huang', 'W. Bruce Croft'];;;January 2019;;;WSDM '19: Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining;;;Deep text matching approaches have been widely studied for many applications including question answering and information retrieval systems. To deal with a domain that has insufficient labeled data, these approaches can be used in a Transfer Learning (TL) setting to leverage labeled data from a resource-rich source domain. To achieve better performance, source domain data selection is essential in this process to prevent the "negative transfer" problem. However, the emerging deep transfer models do not fit well with most existing data selection methods, because the data selection policy and the transfer learning model are not jointly trained, leading to sub-optimal training efficiency. In this paper, we propose a novel reinforced data selector to select high-quality source domain data to help the TL model. Specifically, the data selector "acts" on the source domain data to find a subset for optimization of the TL model, and the performance of the TL model can provide "rewards" in turn to update the selector. We build the reinforced data selector based on the actor-critic framework and integrate it to a DNN based transfer learning model, resulting in a Reinforced Transfer Learning (RTL) method. We perform a thorough experimental evaluation on two major tasks for text matching, namely, paraphrase identification and natural language inference. Experimental results show the proposed RTL can significantly improve the performance of the TL model. We further investigate different settings of states, rewards, and policy optimization methods to examine the robustness of our method. Last, we conduct a case study on the selected data and find our method is able to select source domain data whose Wasserstein distance is close to the target domain data. This is reasonable and intuitive as such source domain data can provide more transferability power to the model.;;;https://dl.acm.org/doi/10.1145/3289600.3290978;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Deep learning-based semantic classification of EMF-related scientific literature;;;['Kwanghee Won', 'Hyung-do Choi', 'Sung Shin'];;;June 2021;;;ACM SIGAPP Applied Computing Review;;;Semantic classification of scientific literature using machine learning approaches is challenging due to the difficulties in labeling data and the length of the texts [2, 7]. Most of the work has been done for keyword-based categorization tasks, which take care of occurrence of important terms, whereas semantic classification requires understanding of terms and the meaning of sentences in a context. In this study, we have evaluated neural network models on a semantic classification task using 1091 labeled EMF-related scientific papers listed in the Powerwatch study. The EMF-related papers are labeled into three categories: positive, null finding, and neither. We have conducted neural architecture and hyperparameter search to find the most suitable model for the task. In experiments, we compared the performance of several neural network models in terms of classification accuracy. In addition, we have tested two different types of attention mechanisms. First, a Fully Convolutional Neural Network (FCN) has been used to identify important sentences in the text for the semantic classification. Second, the Transformer, a self-attention-based model, has been tested on the dataset. The experimental result showed that the BiLSTM performed best on both unbalanced and balanced data and the FCN was able to identify important parts in input texts.;;;https://dl.acm.org/doi/10.1145/3477127.3477131;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Adaptive Execution of Continuous and Data-intensive Workflows with Machine Learning;;;['Sérgio Esteves', 'Helena Galhardas', 'Luís Veiga'];;;November 2018;;;Middleware '18: Proceedings of the 19th International Middleware Conference;;;To extract value from evergrowing volumes of data and to drive decision making, organizations frequently resort to the composition of data processing workflows. The typical workflow model enforces strict temporal synchronization across processing steps without accounting the actual effect of intermediate computations on the final workflow output. However, this is not the most desirable in a multitude of scenarios. We identify a class of applications for continuous data processing where the workflow output changes slowly and without great significance in a short time window, thus squandering compute resources with current approaches. To overcome such inefficiency, we introduce a novel workflow model, for continuous and data-intensive processing, capable of relaxing triggering semantics according to the impact that input data is assessed to have on changing the workflow output. To estimate this impact, learn the correlation between input and output variation, and guarantee correctness within a given tolerated error constant, we rely on Machine Learning. The functionality of this model is implemented in SmartFlux, a middleware framework which can be integrated with existing workflow managers. Experimental results indicate substantial savings in resource usage, while not deviating the workflow output beyond a small error constant with a high confidence level.;;;https://dl.acm.org/doi/10.1145/3274808.3274827;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Mining Tourist's Perception toward Indonesia Tourism Destination Using Sentiment Analysis and Topic Modelling;;;['Herry Irawan', 'Gina Akmalia', 'Riefvan Achmad Masrury'];;;September 2019;;;CCIOT '19: Proceedings of the 2019 4th International Conference on Cloud Computing and Internet of Things;;;Indonesia's Tourism industries is the second-best contributor to country's foreign exchange income for years. The growth it produced were in range of 7 to 10 percent per year since 2009. In reality, Bali is always at the top of the mind among majority of international tourists inspite of many hidden gems with spectacular qualities to rival Bali's popularity. Therefore, Indonesia's government has set new tourist destinations to increase their presence thus increasing visitation numbers. Researches on utilizing big data to support industry 4.0 model in tourism businesses are encouraged as part of national research priorities. Data Analytics models such as Sentiment Analysis and Topic Modelling can be used to reveal hidden patterns from abundant user-generated content data available in social media sites, one of which, TripAdvisor. This study aims to mine the visitors' perceptions of 10 most visited sites in Indonesia. Emotions and topics discussed in comments are two features to be extracted. Using data mining framework, five types of emotion and topics related to tourism were discovered. Data collection was done using Parsehub to acquire 3494 comments generated in 4 years. Both Sentiment Analysis and Topic Modelling were processed in Orange 3. Results shows that Joy is the most prominent emotion accompanying visitors' experiences. Topic modeling shows several important keywords toward preferences. Results of this study can be used to improve Indonesia's tourism stakeholder's decision quality especially in terms of marketing and operations.;;;https://dl.acm.org/doi/10.1145/3361821.3361829;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Multiple Classification with Split Learning;;;['Jongwon Kim', 'Sungho Shin', 'Yeonguk Yu', 'Junseok Lee', 'Kyoobin Lee'];;;September 2020;;;SMA 2020: The 9th International Conference on Smart Media and Applications;;;Privacy issues were raised in the process of training deep learning in medical, mobility, and other fields. To solve this problem, we present privacy-preserving distributed deep learning method that allow clients to learn a variety of data without direct exposure. We divided a single deep learning architecture into a common extractor, a cloud model and a local classifier for the distributed learning. First, the common extractor, which is used by local clients, extracts secure features from the input data. The secure features also take the role that the cloud model can employ various task and diverse types of data. The feature contain the most important information that helps to proceed various task. Second, the cloud model including most parts of the whole training model gets the embedded features from the massive local clients, and performs most of deep learning operations which takes severe computing cost. After the operations in cloud model finished, outputs of the cloud model send back to local clients. Finally, the local classifier determined classification results and delivers the results to local clients. When clients train models, our model does not directly expose sensitive information to exterior network. During the test, the average performance improvement was 2.63% over the existing local training model. However, in a distributed environment, there is a possibility of inversion attack due to exposed features. For this reason, we experimented with the common extractor to prevent data restoration. The quality of restoration of the original image was tested by adjusting the depth of the common extractor. As a result, we found that the deeper the common extractor, the restoration score decreased to 89.74.;;;https://dl.acm.org/doi/10.1145/3426020.3426131;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Multi-task learning for smile detection, emotion recognition and gender classification;;;['Dinh Viet Sang', 'Le Tran Bao Cuong', 'Vu Van Thieu'];;;December 2017;;;SoICT '17: Proceedings of the 8th International Symposium on Information and Communication Technology;;;Facial expression analysis plays a key role in analyzing emotions and human behaviors. Smile detection, emotion recognition and gender classification are special tasks in facial expression analysis with various potential applications. In this paper, we propose an effective architecture of Convolutional Neural Network (CNN) which can jointly learn representations for three tasks: smile detection, emotion recognition and gender classification. In addition, this model can be trained from multiple sources of data with different kinds of task-specific class labels. The extensive experiments show that our model achieves superior accuracy over recent state-of-the-art techniques in all of three tasks on popular benchmarks. We also show that the joint learning helps the tasks with less data considerably benefit from other tasks with richer data.;;;https://dl.acm.org/doi/10.1145/3155133.3155207;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Complementing machine learning classifiers via dynamic symbolic execution: "human vs. bot generated" tweets;;;['Sohil L. Shrestha', 'Saroj Panda', 'Christoph Csallner'];;;May 2018;;;RAISE '18: Proceedings of the 6th International Workshop on Realizing Artificial Intelligence Synergies in Software Engineering;;;Recent machine learning approaches for classifying text as human-written or bot-generated rely on training sets that are large, labeled diligently, and representative of the underlying domain. While valuable, these machine learning approaches ignore programs as an additional source of such training sets. To address this problem of incomplete training sets, this paper proposes to systematically supplement existing training sets with samples inferred via program analysis. In our preliminary evaluation, training sets enriched with samples inferred via dynamic symbolic execution were able to improve machine learning classifier accuracy for simple string-generating programs.;;;https://dl.acm.org/doi/10.1145/3194104.3194111;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Multiple Classification with Split Learning;;;['Jongwon Kim', 'Sungho Shin', 'Yeonguk Yu', 'Junseok Lee', 'Kyoobin Lee'];;;September 2020;;;SMA 2020: The 9th International Conference on Smart Media and Applications;;;Privacy issues were raised in the process of training deep learning in medical, mobility, and other fields. To solve this problem, we present privacy-preserving distributed deep learning method that allow clients to learn a variety of data without direct exposure. We divided a single deep learning architecture into a common extractor, a cloud model and a local classifier for the distributed learning. First, the common extractor, which is used by local clients, extracts secure features from the input data. The secure features also take the role that the cloud model can employ various task and diverse types of data. The feature contain the most important information that helps to proceed various task. Second, the cloud model including most parts of the whole training model gets the embedded features from the massive local clients, and performs most of deep learning operations which takes severe computing cost. After the operations in cloud model finished, outputs of the cloud model send back to local clients. Finally, the local classifier determined classification results and delivers the results to local clients. When clients train models, our model does not directly expose sensitive information to exterior network. During the test, the average performance improvement was 2.63% over the existing local training model. However, in a distributed environment, there is a possibility of inversion attack due to exposed features. For this reason, we experimented with the common extractor to prevent data restoration. The quality of restoration of the original image was tested by adjusting the depth of the common extractor. As a result, we found that the deeper the common extractor, the restoration score decreased to 89.74.;;;https://dl.acm.org/doi/10.1145/3426020.3426131;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Roman Urdu reviews dataset for aspect based opinion mining;;;['Rabail Zahid', 'Muhammad Owais Idrees', 'Hasan Mujtaba', 'Mirza Omer Beg'];;;September 2020;;;ASE '20: Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering;;;Social media, today, demonstrates the rapid growth of modern society as it becomes the main platform for Internet users to communicate and express themselves. People around the world, use a number of devices and resources to access the Internet, set up social networks, conduct online business, e-commerce, e-surveys, etc. Currently, social media is not only a technology that provides information to consumers, it also encourages users to connect and share their views and perspectives. It leads to an increase in inspiration towards Opinion Mining (OM), which is important for both customers and companies in making decisions. Individuals like to see the opinions provided by other customers about a particular product or a service. Companies need to analyze their customer's feedback to strengthen their business decisions. A lot of research has been performed in various languages in the field of Aspect Based OM (ABOM). However, there are still certain languages that need to be explored, such as Roman Urdu (RU). This paper presents a proposed reviews data-set (a RU data-set) of mobile reviews that has been manually annotated with multi-aspect sentiment labels at the sentence-level. It presents base-line results using different Machine Learning (ML) algorithms. The results demonstrate 71% F1-score for aspect detection and 64% for aspect-based polarity.;;;https://dl.acm.org/doi/10.1145/3417113.3423377;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Multi-task learning for smile detection, emotion recognition and gender classification;;;['Dinh Viet Sang', 'Le Tran Bao Cuong', 'Vu Van Thieu'];;;December 2017;;;SoICT '17: Proceedings of the 8th International Symposium on Information and Communication Technology;;;Facial expression analysis plays a key role in analyzing emotions and human behaviors. Smile detection, emotion recognition and gender classification are special tasks in facial expression analysis with various potential applications. In this paper, we propose an effective architecture of Convolutional Neural Network (CNN) which can jointly learn representations for three tasks: smile detection, emotion recognition and gender classification. In addition, this model can be trained from multiple sources of data with different kinds of task-specific class labels. The extensive experiments show that our model achieves superior accuracy over recent state-of-the-art techniques in all of three tasks on popular benchmarks. We also show that the joint learning helps the tasks with less data considerably benefit from other tasks with richer data.;;;https://dl.acm.org/doi/10.1145/3155133.3155207;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Arthroscopic Tool Classification using Deep Learning;;;['Bryce Palmer', 'Gunnar Sundberg', 'James Dials', 'Bayazit Karaman', 'Doga Demirel', 'Muhammad Abid', 'Tansel Halic', 'Shahryar Ahmadi'];;;May 2020;;;ICISDM '20: Proceedings of the 2020 the 4th International Conference on Information System and Data Mining;;;Shoulder arthroscopy is a common surgery to diagnose and treat tears to improve patient's quality of life. Quality of cleaning the tear during shoulder arthroscopy significantly affects the outcome of the surgery. Appropriate cleaning is necessary to reduce healing time and avoid feature pain in the area. In this paper, we used convolutional neural networks to automatically differentiate between two tools-electrocautery and shaver tools- that are used during the cleaning phase of a shoulder arthroscopy. We captured images from the actual shoulder arthroscopy videos. We used 8,691 images that contain the shaver tool, 7,773 images that contain the electrocautery tool, and 4,834 images that contain no tools. Our results showed that average accuracy of our model is 99.1(+/- 0.49) %. For the electrocautery tool precision and sensitivity was calculated as 0.988 and 0. 988, respectively. For the shaver tool precision and sensitivity was calculated as 0.993 and 0. 988, respectively. For the no tool scenes precision and sensitivity was calculated as 1.0 and 1. 0, respectively.;;;https://dl.acm.org/doi/10.1145/3404663.3404672;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Zigbee-based remote environmental monitoring for smart industrial mining;;;['Abdellah Chehri', 'Rachid Saadane'];;;October 2019;;;SCA '19: Proceedings of the 4th International Conference on Smart City Applications;;;Wireless sensor networks (WSNs) consist of large number of small and low-cost devices equipped with sensing and communication facilities to monitor the environment. The collected data are transmitted to one or more base stations which can attach to other networks and/or databases. WSNs show particular promises in applications that involve complex, human-made systems such as underground mines, factory and industrial installation. In this paper, smart sensor network architecture for temperature and fire monitoring in underground mine is evaluated. Based on application requirements and site surveys, we develop a general architecture for this class of industrial applications. The architecture is based on multiple complementary wireless communications access networks between the environment and external environment, by using IEEE802.15/ZigBee, IEEE 802.11 and the Internet.;;;https://dl.acm.org/doi/10.1145/3368756.3369099;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Clustering stream data by exploring the evolution of density mountain;;;['Shufeng Gong', 'Yanfeng Zhang', 'Ge Yu'];;;None;;;Proceedings of the VLDB Endowment;;;Stream clustering is a fundamental problem in many streaming data analysis applications. Comparing to classical batch-mode clustering, there are two key challenges in stream clustering: (i) Given that input data are changing continuously, how to incrementally update their clustering results efficiently? (ii) Given that clusters continuously evolve with the evolution of data, how to capture the cluster evolution activities? Unfortunately, most of existing stream clustering algorithms can neither update the cluster result in real-time nor track the evolution of clusters.In this paper, we propose a stream clustering algorithm EDMStream by exploring the Evolution of Density Mountain. The density mountain is used to abstract the data distribution, the changes of which indicate data distribution evolution. We track the evolution of clusters by monitoring the changes of density mountains. We further provide efficient data structures and filtering schemes to ensure that the update of density mountains is in real-time, which makes online clustering possible. The experimental results on synthetic and real datasets show that, comparing to the state-of-the-art stream clustering algorithms, e.g., D-Stream, DenStream, DBSTREAM and MR-Stream, our algorithm is able to response to a cluster update much faster (say 7-15x faster than the best of the competitors) and at the same time achieve comparable cluster quality. Furthermore, EDMStream successfully captures the cluster evolution activities.;;;https://dl.acm.org/doi/10.1145/3186728.3164136;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Helicobacter Pylori Infection Classification Based on Convolutional Neural Network and Self-Supervised Learning;;;['Guo-Zhang Jian', 'Guo-Shiang Lin', 'Chuin-Mu Wang', 'Sheng-Lei Yan'];;;June 2021;;;ICGSP '21: Proceedings of the 5th International Conference on Graphics and Signal Processing;;;In this paper, a computer-aided diagnosis (CAD) method based on self-supervised learning was proposed for helicobacter pylori (HP) infection classification. The proposed method is composed of an encoder and a prediction head. The encoder can be trained by using self-supervised learning and contrastive loss. After obtaining the trained encoder, the prediction head can be trained by using the small medical image dataset. To evaluate the performance of the proposed method, some medical images are collected for testing. According to experimental results, the F1-score rates of the CAD system based on VGGNet-16 are 0.89 and 0.9 for HP+ and HP- images, respectively. The results show that the proposed method composed of VGGNet-16 and a multi-layer neural network can distinguish HP+ images from HP- images well. Compared with ResNet-50 and InceptionV3, VGGNet-16 can achieve a better classification performance. The experimental results show that VGG-16 can extract useful features from endoscopic images for HP infection classification via self-supervised contrastive learning.;;;https://dl.acm.org/doi/10.1145/3474906.3474912;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Efficient Graph Convolution for Joint Node Representation Learning and Clustering;;;['Chakib Fettal', 'Lazhar Labiod', 'Mohamed Nadif'];;;February 2022;;;WSDM '22: Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining;;;Attributed graphs are used to model a wide variety of real-world networks. Recent graph convolutional network-based representation learning methods have set state-of-the-art results on the clustering of attributed graphs. However, these approaches deal with clustering as a downstream task while better performances can be attained by incorporating the clustering objective into the representation learning process. In this paper, we propose, in a unified framework, an objective function taking into account both tasks simultaneously. Based on a variant of the simple graph convolutional network, our model does clustering by minimizing the difference between the convolved node representations and their reconstructed cluster representatives. We showcase the efficiency of the derived algorithm against state-of-the-art methods both in terms of clustering performance and computational cost on thede facto benchmark graph clustering datasets. We further demonstrate the usefulness of the proposed approach for graph visualization through generating embeddings that exhibit a clustering structure.;;;https://dl.acm.org/doi/10.1145/3488560.3498533;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Study on Classification of Flue-cured Tobacco Planting area Based on Different Clustering Analysis Methods;;;['Xu Ruyan', 'Hu Zongyu', 'Xu Qiang', 'Chen Haiqing', 'Li Shaopeng', 'Chu Xu'];;;December 2020;;;EBIMCS '20: Proceedings of the 2020 3rd International Conference on E-Business, Information Management and Computer Science;;;In order to analyze the quality similarity of tobacco leaves in different tobacco planting areas, 21 quality indices of flue-cured tobacco were collected from different production areas, extracted principal components by factor analysis, classified by 3 clustering analysis methods, and the classification results were compared and statistically tested. The result indicated that: (1) The quality of tobacco leaves was different, and high degree of information overlap was detected among different indices of tobacco appearance, chemical and sensory quality; (2) The cumulative variance contribution rate of 5 extracted principal component factors was 85.445%, and the eigenvalues were 7.761, 4.758, 2.472, 1.674 and 1.278, respectively; (3) The results of 3 cluster analysis methods were not the same. The results of the weighted principal component distance cluster and the weighted principal component cluster were similar, which were different from the general principal component cluster; (4) The results of statistical test showed that the weighted principal component distance cluster method had the largest F-test value (5.900), the smallest sum of squares within the group (8.164), and the largest sum of squares between groups (19.267). And the weighting results for different principal component factors were more reasonable which also had more objective classification results. The cluster results of weighted principal component distance and weighted principal component were better than that of general principal component. And the cluster results of weighted principal component distance were more interpretable which had better the statistical test results.;;;https://dl.acm.org/doi/10.1145/3453187.3453416;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Application of data mining for young children education using emotion information;;;['Liu Yue', 'Zhang Chunhong', 'Tian Chujie', 'Zhao Xiaomeng', 'Zhang Ruizhi', 'Ji Yang'];;;July 2018;;;DSIT '18: Proceedings of the 2018 International Conference on Data Science and Information Technology;;;The current preschool education is still facing many difficulties. First, unlike primary and secondary schools which have test scores, there are few good ways to assess the learning situation of young children. Second, it is hard for teachers and parents to give thoughtful care all the time to each child. In particular, recent incidents of child abuse have been exposed frequently, causing social panic. However, as research of young children's mental health and emotion is still in its infancy due to the lack of relevant data, methods that focus on measuring and analyzing young children's mental health and emotional states are lacking. Furthermore, on the one hand, the principal goal of preschool education is to stimulate interest and enhance cognitive ability. On the other hand, assimilation and accommodation which are two specific stages of cognitive development require an active learner, not a passive one. Thus, emotion analysis can solve these problems to some extent. In this paper, we design an intelligent system, obtaining video clips in a kindergarten's classroom and managing to leverage the emotion data to portray cognitive learning rules and mental states of young children. At the same time, with the augmentation by data analysis, it brings broader applications developing educational policy and teaching practice. For example, children with abnormal behaviors such as violent mood swings and unusual time nodes during courses can be detected and notified to parents and teachers. And it is meaningful to measure the children's acceptance and preference of course activities and content which has been explained in our experiments.;;;https://dl.acm.org/doi/10.1145/3239283.3239321;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Exploiting implicit beliefs to resolve sparse usage problem in usage-based specification mining;;;['Samantha Syeda Khairunnesa', 'Hoan Anh Nguyen', 'Tien N. Nguyen', 'Hridesh Rajan'];;;None;;;Proceedings of the ACM on Programming Languages;;;Frameworks and libraries provide application programming interfaces (APIs) that serve as building blocks in modern software development. As APIs present the opportunity of increased productivity, it also calls for correct use to avoid buggy code. The usage-based specification mining technique has shown great promise in solving this problem through a data-driven approach. These techniques leverage the use of the API in large corpora to understand the recurring usages of the APIs and infer behavioral specifications (preconditions and postconditions) from such usages. A challenge for such technique is thus inference in the presence of insufficient usages, in terms of both frequency and richness. We refer to this as a "sparse usage problem." This paper presents the first technique to solve the sparse usage problem in usage-based precondition mining. Our key insight is to leverage implicit beliefs to overcome sparse usage. An implicit belief (IB) is the knowledge implicitly derived from the fact about the code. An IB about a program is known implicitly to a programmer via the language's constructs and semantics, and thus not explicitly written or specified in the code. The technical underpinnings of our new precondition mining approach include a technique to analyze the data and control flow in the program leading to API calls to infer preconditions that are implicitly present in the code corpus, a catalog of 35 code elements in total that can be used to derive implicit beliefs from a program, and empirical evaluation of all of these ideas. We have analyzed over 350 millions lines of code and 7 libraries that suffer from the sparse usage problem. Our approach realizes 6 implicit beliefs and we have observed that adding single-level context sensitivity can further improve the result of usage based precondition mining. The result shows that we achieve overall 60% in precision and 69% in recall and the accuracy is relatively improved by 32% in precision and 78% in recall compared to base usage-based mining approach for these libraries.;;;https://dl.acm.org/doi/10.1145/3133907;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Deep Learning for Plant Species Classification Using Leaf Vein Morphometric;;;['Jing wei Tan', 'Siow-Wee Chang', 'Sameem Abdul-Kareem', 'Hwa Jen Yap', 'Kien-Thai Yong'];;;None;;;IEEE/ACM Transactions on Computational Biology and Bioinformatics;;;An automated plant species identification system could help botanists and layman in identifying plant species rapidly. Deep learning is robust for feature extraction as it is superior in providing deeper information of images. In this research, a new CNN-based method named D-Leaf was proposed. The leaf images were pre-processed and the features were extracted by using three different Convolutional Neural Network (CNN) models namely pre-trained AlexNet, fine-tuned AlexNet, and D-Leaf. These features were then classified by using five machine learning techniques, namely, Support Vector Machine (SVM), Artificial Neural Network (ANN), k-Nearest-Neighbor (k-NN), Na&#x00EF;ve-Bayes (NB), and CNN. A conventional morphometric method computed the morphological measurements based on the Sobel segmented veins was employed for benchmarking purposes. The D-Leaf model achieved a comparable testing accuracy of 94.88 percent as compared to AlexNet (93.26 percent) and fine-tuned AlexNet (95.54 percent) models. In addition, CNN models performed better than the traditional morphometric measurements (66.55 percent). The features extracted from the CNN are found to be fitted well with the ANN classifier. D-Leaf can be an effective automated system for plant species identification as shown by the experimental results.;;;https://dl.acm.org/doi/10.1109/TCBB.2018.2848653;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Classification of Wildlife Based on Transfer Learning;;;['Xihao Wang', 'Peihan Li', 'Chengxi Zhu'];;;December 2020;;;ICVIP '20: Proceedings of the 2020 4th International Conference on Video and Image Processing;;;Wildlife is an important biological resource in China. Classifying images of wildlife through computer technology can help people identify wildlife, which is of great significance to help people understand and protect wildlife. Therefore, this issue is worth studying. Traditional methods mostly use standard Convolutional Neural Networks (CNN) to classify wild animal images, but these methods have disadvantages such as slow computing speed, long time consumption and low accuracy. With an attempt to address such issues, this paper proposes a method based on transfer-learning for classifying wild animal images. By using the pre-trained model it can save a lot of training time. The experimental results on Oregon Wildlife, using a public wildlife data set, show that the method proposed in this paper achieved 99.01% accuracy and is 57.82% more accurate than the standard Convolutional Neural Networks (CNN) method. Moreover, in terms of running time, the method presented in this paper has achieved higher efficiency, and the training time is 50% shorter than the standard method, which proves the superiority of the method proposed in this paper.;;;https://dl.acm.org/doi/10.1145/3447450.3447487;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Mining User Reviews for Mobile App Comparisons;;;['Yuanchun Li', 'Baoxiong Jia', 'Yao Guo', 'Xiangqun Chen'];;;None;;;Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies;;;As the number of mobile apps keeps increasing, users often need to compare many apps, in order to choose one that best fits their needs. Fortunately, as there are so many users sharing an app market, it is likely that some other users with the same preferences have already made the comparisons and shared their opinions. For example, a user may state that an app is better in power consumption than another app in a review, then the review would help other users who care about battery life while choosing apps. This paper presents a method to identify comparative reviews for mobile apps from an app market, which can be used to provide fine-grained app comparisons based on different topics. According to experiments on 5 million reviews from Google Play and manual assessments on 900 reviews, our method is able to identify opinions accurately and provide meaningful comparisons between apps, which could in turn help users find desired apps based on their preferences.;;;https://dl.acm.org/doi/10.1145/3130935;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Self-supervised Learning for Small Shot COVID-19 Classification;;;['Yujie Zhu'];;;June 2021;;;ITCC '21: Proceedings of the 2021 3rd International Conference on Information Technology and Computer Communications;;;Recently, COVID-19 has become one of the most severe and widespread diseases with an increasing number of infections and deaths. An accurate and high-speed automatic classifier will increase the efficiency of diagnosis and reduce fatigue misdiagnosis. Given the contradiction that many previous classifiers require a large amount of data for training while it is difficult to collect the medical images of COVID-19 with labels, we propose a classification model based on self-supervised learning and transfer learning, which uses rotation and division as labels and then transfers the parameters to the classifier. It solves the overfitting problem caused by insufficient data set and improves the accuracy by nearly 30%;;;https://dl.acm.org/doi/10.1145/3473465.3473472;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Clustering stream data by exploring the evolution of density mountain;;;['Shufeng Gong', 'Yanfeng Zhang', 'Ge Yu'];;;None;;;Proceedings of the VLDB Endowment;;;Stream clustering is a fundamental problem in many streaming data analysis applications. Comparing to classical batch-mode clustering, there are two key challenges in stream clustering: (i) Given that input data are changing continuously, how to incrementally update their clustering results efficiently? (ii) Given that clusters continuously evolve with the evolution of data, how to capture the cluster evolution activities? Unfortunately, most of existing stream clustering algorithms can neither update the cluster result in real-time nor track the evolution of clusters.In this paper, we propose a stream clustering algorithm EDMStream by exploring the Evolution of Density Mountain. The density mountain is used to abstract the data distribution, the changes of which indicate data distribution evolution. We track the evolution of clusters by monitoring the changes of density mountains. We further provide efficient data structures and filtering schemes to ensure that the update of density mountains is in real-time, which makes online clustering possible. The experimental results on synthetic and real datasets show that, comparing to the state-of-the-art stream clustering algorithms, e.g., D-Stream, DenStream, DBSTREAM and MR-Stream, our algorithm is able to response to a cluster update much faster (say 7-15x faster than the best of the competitors) and at the same time achieve comparable cluster quality. Furthermore, EDMStream successfully captures the cluster evolution activities.;;;https://dl.acm.org/doi/10.1145/3164135.3164136;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Application of Machine Learning Algorithms in Audit Data Analysis;;;['Jianyu Zhou'];;;December 2021;;;ICASIT 2021: 2021 International Conference on Aviation Safety and Information Technology;;;In recent years, with the rapid development of information technology, computer technology and the Internet, various sectors of society have collected a large amount of data. At present, traditional statistical analysis models have limitations. Machine learning system is currently one of the main means to effectively solve problems such as data development and mining. Machine learning is a process of self-improvement using the computer system itself. Therefore, computer applications written by computers can be automated by accumulating practical experience. This article aims to study the application of machine learning algorithms in audit data analysis. Based on the analysis of audit information construction, audit data analysis system design principles, and audit data analysis system non-functional requirements analysis, the audit data analysis system is designed. The association rule algorithm in machine learning is used in audit data mining. Finally, the performance of the system is tested. The test results show that the performance of the system designed in this paper is unified with the pre-demand, which shows that the effectiveness of the system can be satisfied.;;;https://dl.acm.org/doi/10.1145/3510858.3510881;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Challenges in Classifying Privacy Policies by Machine Learning with Word-based Features;;;['Keishiro Fukushima', 'Toru Nakamura', 'Daisuke Ikeda', 'Shinsaku Kiyomoto'];;;March 2018;;;ICCSP 2018: Proceedings of the 2nd International Conference on Cryptography, Security and Privacy;;;In this paper, we discuss challenges when we try to automatically classify privacy policies using machine learning with words as the features. Since it is difficult for general public to understand privacy policies, it is necessary to support them to do that. To this end, the authors believe that machine learning is one of the promising ways because users can grasp the meaning of policies through outputs by a machine learning algorithm. Our final goal is to develop a system which automatically translates privacy policies into privacy labels [1]. Toward this goal, we classify sentences in privacy policies with category labels, using popular machine learning algorithms, such as a naive Bayes classifier.We choose these algorithms because we could use trained classifiers to evaluate keywords appropriate for privacy labels. Therefore, we adopt words as the features of those algorithms. Experimental results show about 85% accuracy. We think that much higher accuracy is necessary to achieve our final goal. By changing learning settings, we identified one reason of low accuracies such that privacy policies include many sentences which are not direct description of information about categories. It seems that such sentences are redundant but maybe they are essential in case of legal documents in order to prevent misinterpreting. Thus, it is important for machine learning algorithms to handle these redundant sentences appropriately.;;;https://dl.acm.org/doi/10.1145/3199478.3199486;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Learning Interpretable Metric between Graphs: Convex Formulation and Computation with Graph Mining;;;['Tomoki Yoshida', 'Ichiro Takeuchi', 'Masayuki Karasuyama'];;;July 2019;;;KDD '19: Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining;;;Graph is a standard approach to modeling structured data. Although many machine learning methods depend on the metric of the input objects, defining an appropriate distance function on graph is still a controversial issue. We propose a novel supervised metric learning method for a subgraph-based distance, called interpretable graph metric learning (IGML). IGML optimizes the distance function in such a way that a small number of important subgraphs can be adaptively selected. This optimization is computationally intractable with naive application of existing optimization algorithms. We construct a graph mining based efficient algorithm to deal with this computational difficulty. Important advantages of our method are 1) guarantee of the optimality from the convex formulation, and 2) high interpretability of results. To our knowledge, none of the existing studies provide an interpretable subgraph-based metric in a supervised manner. In our experiments, we empirically verify superior or comparable prediction performance of IGML to other existing graph classification methods which do not have clear interpretability. Further, we demonstrate usefulness of IGML through some illustrative examples of extracted subgraphs and an example of data analysis on the learned metric space.;;;https://dl.acm.org/doi/10.1145/3292500.3330845;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Fruit Image Classification Based on MobileNetV2 with Transfer Learning Technique;;;['Qian Xiang', 'Xiaodan Wang', 'Rui Li', 'Guoling Zhang', 'Jie Lai', 'Qingshuang Hu'];;;October 2019;;;CSAE '19: Proceedings of the 3rd International Conference on Computer Science and Application Engineering;;;Fruit image classification is the key technology for robotic picking which can tremendously save costs and effectively improve fruit producer's competitiveness in the international fruit market. In the image classification field, deep learning technologies especially DCNNs are state-of-the-art technologies and have achieved remarkable success. But the requirements of high computation and storage resources prohibit the usages of DCNNs on resource-limited environments such as automatic harvesting robots. Therefore, we need to choose a lightweight neural network to achieve the balance of resource limitations and recognition accuracy. In this paper, a fruit image classification method based on a lightweight neural network MobileNetV2 with transfer learning technique was used to recognize fruit images. We used a MobileNetV2 network pre-trained by ImageNet dataset as a base network and then replace the top layer of the base network with a conventional convolution layer and a Softmax classifier. We applied dropout to the new-added conv2d at the same time to reduce overfitting. The pre-trained MobileNetV2 was used to extract features and the Softmax classifier was used to classify features. We trained this new model in two stages using Adam optimizer of different learning rate. This method finally achieved a classification accuracy of 85.12% in our fruit image dataset including 3670 images of 5 fruits. Compared with other network such as MobileNetV1, InceptionV3 and DenseNet121, this hybrid network implemented by Google open source deep learning framework Tensorflow can make a good compromise between accuracy and speed. Since MobileNetV2 is a lightweight neural network, the method in this paper can be deployed in low-power and limited-computing devices such as mobile phone.;;;https://dl.acm.org/doi/10.1145/3331453.3361658;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Research on Classification of Scientific and Technological Documents Based on Naive Bayes;;;['Hong Zhang', 'Hanshuo Wei', 'Yeye Tang', 'Qiumei Pu'];;;February 2019;;;ICMLC '19: Proceedings of the 2019 11th International Conference on Machine Learning and Computing;;;Text classification is an important step for text mining in the direction of data mining. Today, text categorization techniques are widely used in various fields, such as user behavior analysis in shopping recommendation systems, and spam filtering, but text categories based on scientific literature are seldom studied. This article uses biological material information. The scientific literature of the aspect is text, and the naive Bayesian method is used to classify the literature into different topic types. It is evaluated through the model test standard in data mining to verify the validity of the method. Finally, the research trend of biological materials A simple analysis was performed.;;;https://dl.acm.org/doi/10.1145/3318299.3318330;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Environment Agnostic Invariant Risk Minimization for Classification of Sequential Datasets;;;['Praveen Venkateswaran', 'Vinod Muthusamy', 'Vatche Isahagian', 'Nalini Venkatasubramanian'];;;August 2021;;;KDD '21: Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining;;;The generalization of predictive models that follow the standard risk minimization paradigm of machine learning can be hindered by the presence of spurious correlations in the data. Identifying invariant predictors while training on data from multiple environments can influence models to focus on features that have an invariant causal relationship with the target, while reducing the effect of spurious features. Such invariant risk minimization approaches heavily rely on clearly defined environments and data being perfectly segmented into these environments for training. However, in real-world settings, perfect segmentation is challenging to achieve and these environment-aware approaches prove to be sensitive to segmentation errors. In this work, we present an environment-agnostic approach to develop generalizable models for classification tasks in sequential datasets without needing prior knowledge of environments. We show that our approach results in models that can generalize to out-of-distribution data and are not influenced by spurious correlations. We evaluate our approach on real-world sequential datasets from various domains.;;;https://dl.acm.org/doi/10.1145/3447548.3467324;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Research on Key Technologies of Customer Consultation Hotspots Mining;;;['Zhang Mingzhu', 'Cui Xiuqing', 'Chen Yan', 'Liu Yuxi', 'Zhao Jiakui', 'Ouyang Hong', 'Yuan Bao'];;;March 2019;;;ICIAI '19: Proceedings of the 2019 3rd International Conference on Innovation in Artificial Intelligence;;;In order to better support customer consultation hotspot analysis, improving the accuracy of identifying customer intent is necessary. In this paper, we focus on the research of new words found in one of the key technologies of customer consultation hotspot mining. According to industry characteristics, most of the power vocabulary consists of professional terms, synthetic words, and abbreviations. To solve the new word discovery problem of power industry corpus, we proposed a new word recognition method. This method transforms the problem of new word discovery into the problem of calculating the probability of word formation and the annotation of word position. Especially, based on the analysis and mining of large-scale power industry corpus, the influence of mutual information-information entropy and conditional random field algorithm on the discovery results of new words in the power industry is compared.. Experiment results show that based on the example of 150M power industry documents, the mutual information-information entropy algorithm tends to identify high-frequency power professional vocabulary and synthetic vocabulary. Besides, the conditional random field has an outstanding performance in the mining industry and can better identify the power industry abbreviations.;;;https://dl.acm.org/doi/10.1145/3319921.3319944;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Design and Application of University Evaluation Performance Intelligent Analysis Based on Data Mining;;;['Cheng Wei'];;;June 2019;;;ICMLT '19: Proceedings of the 2019 4th International Conference on Machine Learning Technologies;;;Colleges and universities usually have problems in implementing their performance evaluation plans due to the deep involvement of subjective factors in making the plan and limited performance evaluation methods. Analysis methods based on big data could help get natural rules existing in data and improve the efficiency of analysis. By using data mining technology to analyze existing information related to teachers in higher learning institutions, the author aims to build a performance evaluation platform based on a multi-angle and multi-tech framework for analyzing teachers' information and optimizing teachers' performance evaluation plan. This intelligent platform could help reduce the influence of subjective factors in implementing performance evaluation plans, expand performance evaluation methods, monitor teaching activities and research achievements dynamically, and offer supports in decision-making while developing a more reasonable performance evaluation plan.;;;https://dl.acm.org/doi/10.1145/3340997.3341014;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Generative adversarial network for improving deep learning based malware classification;;;['Yan Lu', 'Jiang Li'];;;December 2019;;;WSC '19: Proceedings of the Winter Simulation Conference;;;The generative adversarial network (GAN) had been successfully applied in many domains in the past, the GAN network provides a new approach for solving computer vision, object detection and classification problems by learning, mimicking and generating any distribution of data. One of the difficulties in deep learning-based malware detection and classification tasks is lacking of training malware samples. With insufficient training data the classification performance of the deep model could be compromised significantly. To solve this issue, in this paper, we propose a method which uses the Deep Convolutional Generative Adversarial Network (DCGAN) to generate synthetic malware samples. Our experiment results show that by using the DCGAN generated adversarial synthetic malware samples, the classification accuracy of the classifier --- a 18-layer deep residual network is significantly improved by approximately 6%.;;;https://dl.acm.org/doi/10.5555/3400397.3400445;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
E-commerce Customer Segmentation via Unsupervised Machine Learning;;;['Boyu Shen'];;;January 2021;;;CONF-CDS 2021: The 2nd International Conference on Computing and Data Science;;;Customer segmentation through data mining could help companies conduct customer-oriented marketing and build differentiated strategies targeted at diverse customers. However, there has not been a guideline for systematic implementation of customer segmentation given the raw transaction data. This study focuses on a real-world database from an online transaction platform with the purpose to develop a guideline for customer segmentation for the business. Since the raw data are unlabeled, unsupervised machine learning methods are utilized. This study firstly employs the RFM model to create behavioral features; next, the TF-IDF method is applied to the product descriptions to generate product categories; then, K-means clustering algorithm is used to group customers. After customers are grouped, association rules mining by Apriori Algorithm is used to analyze purchased products. Principle Component Analysis (PCA) and T-Distributed Stochastic Neighbor Embedding (T-sne) methods are utilized to reduce the dimension of data in order to create visualizations. Finally, some concrete recommendations for the business based on the results are provided accordingly.;;;https://dl.acm.org/doi/10.1145/3448734.3450775;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
KNN-fuzzy classification for cloud service selection;;;['Humaira Nadeem', 'Imran Mujaddid Rabbani', 'Muhammad Aslam', 'Martinez Enriquez A. M'];;;June 2018;;;ICFNDS '18: Proceedings of the 2nd International Conference on Future Networks and Distributed Systems;;;Cloud computing is an emerging technology that provides services to its users via Internet. It also allows sharing of resources there by reducing cost, money and space. With the popularity of cloud and its advantages, the trend of information industry shifting towards cloud services is increasing tremendously. Different cloud service providers are there on internet to provide services to the users. These services provided have certain parameters to provide better usage. It is difficult for the users to select a cloud service that is best suited to their requirements. Our proposed approach is based on data mining classification technique with fuzzy logic. Proposed algorithm uses cloud service design factors (security, agility and assurance etc.) and international standards to suggest the cloud service. The main objective of this research is to enable the end cloud users to choose best service as per their requirements and meeting international standards. We test our system with major cloud provider Google, Microsoft and Amazon.;;;https://dl.acm.org/doi/10.1145/3231053.3231133;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Minimally-Supervised Structure-Rich Text Categorization via Learning on Text-Rich Networks;;;['Xinyang Zhang', 'Chenwei Zhang', 'Xin Luna Dong', 'Jingbo Shang', 'Jiawei Han'];;;April 2021;;;WWW '21: Proceedings of the Web Conference 2021;;;Text categorization is an essential task in Web content analysis. Considering the ever-evolving Web data and new emerging categories, instead of the laborious supervised setting, in this paper, we focus on the minimally-supervised setting that aims to categorize documents effectively, with a couple of seed documents annotated per category. We recognize that texts collected from the Web are often structure-rich, i.e., accompanied by various metadata. One can easily organize the corpus into a text-rich network, joining raw text documents with document attributes, high-quality phrases, label surface names as nodes, and their associations as edges. Such a network provides a holistic view of the corpus’ heterogeneous data sources and enables a joint optimization for network-based analysis and deep textual model training. We therefore propose a novel framework for minimally supervised categorization by learning from the text-rich network. Specifically, we jointly train two modules with different inductive biases – a text analysis module for text understanding and a network learning module for class-discriminative, scalable network learning. Each module generates pseudo training labels from the unlabeled document set, and both modules mutually enhance each other by co-training using pooled pseudo labels. We test our model on two real-world datasets. On the challenging e-commerce product categorization dataset with 683 categories, our experiments show that given only three seed documents per category, our framework can achieve an accuracy of about 92%, significantly outperforming all compared methods; our accuracy is only less than 2% away from the supervised BERT model trained on about 50K labeled documents.;;;https://dl.acm.org/doi/10.1145/3442381.3450114;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Transductive Event Classification through Heterogeneous Networks;;;['Brucce Neves dos Santos', 'Rafael Geraldeli Rossi', 'Ricardo Marcondes Marcacini'];;;October 2017;;;WebMedia '17: Proceedings of the 23rd Brazillian Symposium on Multimedia and the Web;;;Events can be defined as "something that occurs at specific place and time associated with some specific actions". In general, events extracted from news articles and social networks are used to map the information from web to the various phenomena that occur in our physical world. One of the main steps to perform this relationship is the use of machine learning algorithms for event classification, which has received great attention in the web document engineering field in recent years. Traditional machine learning algorithms are based on vector space model representations and supervised classification. However, events are composed of multiple representations such as textual data, temporal information, geographic location and other types of metadata. All these representations are poorly represented together in a vector space model. Moreover, supervised classification requires the labeling of a significant sample of events to construct a training set for learning process, thereby hampering the practical application of event classification. In this paper, we propose a method called TECHN (Transductive Event Classification through Heterogeneous Networks), which considers event metadata as different objects in an heterogeneous network. Besides, the TECHN method has the ability to automatically learn which types of network objects (event metadata) are most efficient in the classification task. In addition, our TECHN method is based on a transductive classification that considers both labeled events and a vast amount of unlabeled events. The experimental results show that TECHN method obtains promising results, especially when we consider different weights of importance for each type of event metadata and a small set of labeled events.;;;https://dl.acm.org/doi/10.1145/3126858.3126893;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Functional analysis of the 2020 U.S. elections on Twitter and Facebook using machine learning;;;['Saud Alashri', 'Turki Alalola'];;;December 2020;;;ASONAM '20: Proceedings of the 12th IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining;;;Social Networking Sites (SNS), such as Facebook and Twitter, are important tools for political campaigns. A line of related work analyzed political campaigns online. The initial efforts in analyzing campaign discourse functions relied on human analysis, which is time consuming and does not scale well with big data. To address these gaps, we propose a model to detect the type of campaign topics: Policy vs. Character, and how the public (commentators) responded to these messages. The proposed model yielded an accuracy of 78% (F-measure) in detecting post type. Moreover, experimental results show the analysis of commentators linguistic and psychological characteristics.;;;https://dl.acm.org/doi/10.1109/ASONAM49781.2020.9381302;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Data Mining the Smartphone Manipulation Skills in a Coffee Farming Community: A Step for Risk Analysis;;;['Melidiossa V. Pagudpud', 'Thelma D. Palaoag'];;;February 2019;;;ICSCA '19: Proceedings of the 2019 8th International Conference on Software and Computer Applications;;;The Philippines is largely an agricultural country, and the importance of coffee in the Philippines cannot be undervalued. However, the coffee plantations are generally confronted with various insect pests and diseases. This is the reason why authorities continue to look for solutions through technological applications for coffee farming. Smartphones are becoming a functional tool in agriculture because its mobility served as an advantage to agriculture. However, challenges regarding the level of ICT, particularly of smartphones technology usage among the rural community is low due to limited knowledge and skills. Thus, this study has the primary objective to apply data mining to the smartphone manipulation skills of possible users' dataset in the province of Quirino, Philippines. Specifically, it sought to determine the optimal number of the types of potential users and to identify the different types of possible users and their skills that emerged from the clustering. The result shows that k=4 is the best choice for the dataset. The four clusters formed to represent the four groups of possible users are the good users with 25 instances, skilled users with 35 instances, the users with limited skills with 83 instances and finally, the expert users with 32 instances. Each of the groups possesses their distinct skills which emerged from the clustering technique implemented.;;;https://dl.acm.org/doi/10.1145/3316615.3316693;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Visualization of educational data mined from the moodle e-learning platform;;;['Elias Misailidis', 'Angelos Charitopoulos', 'Maria Rangoussi'];;;November 2018;;;PCI '18: Proceedings of the 22nd Pan-Hellenic Conference on Informatics;;;Educational data, collected when learners interact with an e-learning platform and stored in the platform databases, are sources of valuable information for the improvement of the educational process, of the learning outcomes and of the learning experience. Data visualization is a domain that has received considerable attention recently, in connection to the Data Mining paradigm. The visualization of educational data mined from e-learning platforms and analyzed to extract answers to research questions or models for student behavior is an open and challenging task. This paper presents the design, development and use of a new plug-in for the visualization of student evaluation data drawn from a moodle platform. The new plug-in is embedded in an active, operational moodle server, with satisfactory visualization results obtained on real-field undergraduate student data collected over the period of the last three academic years.;;;https://dl.acm.org/doi/10.1145/3291533.3291568;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
API Usage Change Rules Mining based on Fine-grained Call Dependency Analysis;;;['Ping Yu', 'Fei Yang', 'Chun Cao', 'Hao Hu', 'Xiaoxing Ma'];;;September 2017;;;Internetware '17: Proceedings of the 9th Asia-Pacific Symposium on Internetware;;;Software frameworks are widely used in application development. But APIs of a framework may change when it evolves to accommodate new feature requests or to fix bugs. Those changes may break existing client programs of the framework, so client programs need to be migrated to the updated release when the framework evolves. Some technologies (e.g. call dependency analysis) have been proposed to find replacement APIs between the old and new framework releases. However, existing approaches based on call dependency analysis take whole method body as an analysis unit. The context in which a method is called is ignored. In this paper, we present a fine-grained approach named AUC-Miner to infer API usage change rules between two releases of the framework. To take method invocation context into consideration, we propose an approach to get more precise call relationship changes by code splitting. We also analyze indirect method invocations to re-fine call dependency analysis. After elaborating API usage change transactions, we adopt frequent item-set mining to generate API replacement rules. Text similarity and some heuristics to identify evolution of root methods are also applied in the mining progress. The evaluation of AUC-Miner on three popular frameworks shows that its precision is higher than basic call dependency analysis and another API replacement recommendation tool named AURA.;;;https://dl.acm.org/doi/10.1145/3131704.3131707;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Construction of a bank customer data warehouse and an application of data mining;;;['Shaoying Cui', 'Ning Ding'];;;February 2018;;;ICMLC '18: Proceedings of the 2018 10th International Conference on Machine Learning and Computing;;;In this era of strong competition, data mining can provide effective support to bank operators in their effort to analyze and forecast the real needs of their customers. Applying bank data mining results to the actual business enables banks to develop products that not only meet customer needs but also deliver maximum bank profitability. In this paper, a data mining model for bank customers is established, and after extraction and transformation, the data are loaded into a data warehouse specifically built for that purpose. Using the data mining platform, we conduct multidimensional analysis of the customer information to uncover characteristics of their preferences. The goal of this research is to help facilitate new ideas and methods for the analysis and prediction of bank customer data.;;;https://dl.acm.org/doi/10.1145/3195106.3195178;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Towards Clustering Validation in Big Data Context;;;['Soumeya Zerabi', 'Souham Meshoul', 'Amina Merniz', 'Radia Melal'];;;March 2017;;;BDCA'17: Proceedings of the 2nd international Conference on Big Data, Cloud and Applications;;;Clustering1is an essential task in many areas such as machine learning, data mining and computer vision among others. Cluster validation aims to assess the quality of partitions obtained by clustering algorithms. Several indexes have been developed for cluster validation purpose. They can be external or internal depending on the availability of ground truth clustering. This paper deals with the issue of cluster validation of large data set. Indeed, in the era of big data this task becomes even more difficult to handle and requires parallel and distributed approaches. In this work, we are interested in external validation indexes. More specifically, this paper proposes a model for purity based cluster validation in parallel and distributed manner using Map-Reduce paradigm in order to be able to scale with increasing dataset sizes. The experimental results show that our proposed model is valid and achieves properly cluster validation of large datasets.;;;https://dl.acm.org/doi/10.1145/3090354.3090370;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Clustering Data Stream with Rough Set;;;['Renxia Wan', 'Yanyan Li'];;;October 2019;;;ICCPR '19: Proceedings of the 2019 8th International Conference on Computing and Pattern Recognition;;;In this paper, the upper and lower approximations of rough set are introduced to describe the micro-cluster feature in the procedure of clustering uncertain data stream. The proposed algorithm employs presents the micro-cluster timestamp with the time decay and uses agglomerative clustering method to emerge new cluster in the buffer of outliers. Experimental results show that the proposed algorithm can generate natural clusters and outperforms the existing method in term of accuracy.;;;https://dl.acm.org/doi/10.1145/3373509.3373521;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Predicting Vocational Personality Type from Socio-demographic Features Using Machine Learning Methods;;;['Eugenia Bogacheva', 'Filipp Tatarenko', 'Ivan Smetannikov'];;;October 2020;;;CCRIS '20: Proceedings of the 2020 1st International Conference on Control, Robotics and Intelligent System;;;This study aimed to apply supervised machine learning techniques to one domain of psychological research: vocational interests. Socio-demographic factors can be considered strong predictors of vocational interests, which might have far-reaching practical implications for professional counselling and social network analysis. The dataset used in this study is a collection of answers to the RIASEC (Holland Codes) psychological test. Different Machine Learning architectures were used to predict RIASEC scales using socio-demographic features. The problem was treated as a multioutput regression task, multiclass and multilabel classification. The following models were used: independent regression, regression chains, three-letter code classification, inferring label relations. Models comparison showed that the models that exploit intercorrelations between RIASEC scales yielded the best results.;;;https://dl.acm.org/doi/10.1145/3437802.3437819;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Application of Data Mining Techniques for Predicting Student Success in English Exit Exam;;;['Wichai Puarungroj', 'Narong Boonsirisumpun', 'Pathapong Pongpatrakant', 'Suchada Phromkhot'];;;January 2018;;;IMCOM '18: Proceedings of the 12th International Conference on Ubiquitous Information Management and Communication;;;The students' English proficiency has become an important requirement for job seeking after graduation. The universities in non-native English speaking countries find their challenges in improving their students' English language skills. Loei Rajabhat University has dealt with this issue for a long time by delivering various English language courses and tests to students. These activities have been carried out repeatedly year by year as a common routine. However, the real status of student success and the predictors of this issue have never known. This research, therefore, explored the available data: English test results (English placement test and exit exam) and data of students, who graduated in 2013, 2014, and 2015 by using the decision tree technique (C4.5). The research constructed and tested classification models for predicting student success in English exit exam. The research results also suggest that the English placement test result was a key attribute for predicting the result of English exit exam. These two attributes were plotted against each other by using the scatter plot where the regression analysis was carried out and the regression line and equation were generated to predict the students' English exit exam scores.;;;https://dl.acm.org/doi/10.1145/3164541.3164638;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Early Abnormal Heartbeat Multistage Classification by using Decision Tree and K-Nearest Neighbor;;;['Mohamad Sabri bin Sinal', 'Eiji Kamioka'];;;December 2018;;;AICCC '18: Proceedings of the 2018 Artificial Intelligence and Cloud Computing Conference;;;Heart diseases contribute to the highest cause of death around the world particularly for middle aged and elderly people. There are various types of heart disease symptoms. One of the most common types is Arrhythmia which is considered as a dangerous heart condition since the symptom itself may initiate more chronic heart diseases and result in death if it is not treated earlier. However, the detection of Arrhythmia by humans is regarded as a challenging task because the natures of the symptom appear at random times. Therefore, an automatic detection method of abnormal heartbeat in ECG (electrocardiogram) data is needed to overcome the issue. In this paper, a novel multistage classification approach using K-Nearest Neighbor and decision tree of the 3 segments in the ECG cycle is proposed to detect Arrhythmia heartbeat from the early minute of ECG data. Specific attributes based on feature extraction in each heartbeat are used to classify the Normal Sinus Rhythm and Arrhythmia. The experimental result shows that the proposed multistage classification approach is able to detect the Arrhythmia heartbeat with 90.6% accuracy for the P and the Q peak segments, 91.1% accuracy for the Q, R and S peak segments and lastly, 97.7% accuracy for the S and the T peak segments, outperforming the other data mining techniques.;;;https://dl.acm.org/doi/10.1145/3299819.3299848;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Structure-Aware Deep Learning for Product Image Classification;;;['Zhineng Chen', 'Shanshan Ai', 'Caiyan Jia'];;;None;;;ACM Transactions on Multimedia Computing, Communications, and Applications;;;Automatic product image classification is a task of crucial importance with respect to the management of online retailers. Motivated by recent advancements of deep Convolutional Neural Networks (CNN) on image classification, in this work we revisit the problem in the context of product images with the existence of a predefined categorical hierarchy and attributes, aiming to leverage the hierarchy and attributes to improve classification accuracy. With these structure-aware clues, we argue that more advanced deep models could be developed beyond the flat one-versus-all classification performed by conventional CNNs. To this end, novel efforts of this work include a salient-sensitive CNN that gazes into the product foreground by inserting a dedicated spatial attention module; a multiclass regression-based refinement that is expected to predict more accurately by merging prediction scores from multiple preceding CNNs, each corresponding to a distinct classifier in the hierarchy; and a multitask deep learning architecture that effectively explores correlations among categories and attributes for categorical label prediction. Experimental results on nearly 1 million real-world product images basically validate the effectiveness of the proposed efforts individually and jointly, from which performance gains are observed.;;;https://dl.acm.org/doi/10.1145/3231742;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Compressing and mining social network data;;;['Connor C. J. Hryhoruk', 'Carson K. Leung'];;;November 2021;;;ASONAM '21: Proceedings of the 2021 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining;;;Nowadays, social networking is popular. As such, numerous social networking sites (e.g., Facebook, YouTube, Instagram) are generating very large volumes of social data rapidly. Valuable knowledge and information is embedded into these big social data. As the social network can be very sparse, it is awaiting to be (a) compressed via social network data compression and (b) analyzed and mined via social network analysis and mining. We present in this paper a solution for compressing and mining social networks. It gives an interpretable compressed representation of sparse social network, and discovers interesting patterns from the social network. Results of our evaluation show the effectiveness of our solution in explaining the compression and mining of the sparse social network data.;;;https://dl.acm.org/doi/10.1145/3487351.3489472;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Semi-Supervised Granular Classification Framework for Resource Constrained Short-texts: Towards Retrieving Situational Information During Disaster Events;;;['Samujjwal Ghosh', 'Maunendra Sankar Desarkar'];;;July 2020;;;WebSci '20: Proceedings of the 12th ACM Conference on Web Science;;;During the time of disasters, lots of short-texts are generated containing crucial situational information. Proper extraction and identification of situational information might be useful for various rescue and relief operations. Few specific types of infrequent situational information might be critical. However, obtaining labels for those resource-constrained classes is challenging as well as expensive. Supervised methods pose limited usability in such scenarios. To overcome this challenge, we propose a semi-supervised learning framework which utilizes abundantly available unlabelled data by self-learning. The proposed framework improves the performance of the classifier for resource-constrained classes by selectively incorporating highly confident samples from unlabelled data for self-learning. Incremental incorporation of unlabelled data, as and when they become available, is suitable for ongoing disaster mitigation. Experiments on three disaster-related datasets show that such improvement results in overall performance increase over standard supervised approach.;;;https://dl.acm.org/doi/10.1145/3394231.3397892;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Machine Learning in Tourism;;;['Fatemehalsadat Afsahhosseini', 'Yaseen Al-Mulla'];;;September 2020;;;MLMI '20: Proceedings of the 2020 3rd International Conference on Machine Learning and Machine Intelligence;;;Machine Learning is a subset of Artificial Intelligence, which is a process of learning from different types of data to make accurate predictions. Data in tourism is various such as Statistics, Photos, Maps, and Texts. Also, each tourism cycle has different stages: Pre, During, and After Trip. In this paper application of machine learning in tourism related data and trip stages are introduced in detailed.;;;https://dl.acm.org/doi/10.1145/3426826.3426837;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Improvements of fuzzy C-means clustering performance using particle swarm optimization on student grouping based on learning activity in a digital learning media;;;['Ahmad Afif Supianto', "Nur Sa'diyah", 'Candra Dewi', 'Retno Indah Rokhmawati', 'Satrio Agung Wicaksono', 'Hanifah Muslimah Az-Zahra', 'Satrio Hadi Wijoyo', 'Yusuke Hayashi', 'Tsukasa Hirashima'];;;November 2020;;;SIET '20: Proceedings of the 5th International Conference on Sustainable Information Engineering and Technology;;;The field of learning media has been developing rapidly in recent years, especially in an effort to support students' learning process. The amount of recorded learning process data has also significantly increased. The recorded data represents the students' thinking process in building a solution for a problem. The sheer size of the recorded data proves to be quite a challenge in an effort to mine the students' thinking process, especially when done manually. Additionally, to group the recorded data into clusters is also another form of challenge that needs to be faced. In general, the entire process of mining students' thinking patterns aims to utilize the data to gather hidden information which can also be used to give appropriate and proper feedback to the students. This paper aims to employ the Fuzzy C-Means and Particle Swarm Optimization (FCMPSO) method to cluster students based on their learning activity to a digital learning media and compare its performance to original Fuzzy C-Means (FCM) method. Particle Swarm Optimization (PSO) algorithm is proposed to optimize the performance of the FCM algorithm, in which this algorithm is inherently sensitive towards centroid on the initial clustering process that utilizes the Silhouette coefficient as an evaluation method. Based on the experiments that have been done to 12 assignments, each assignment forms a different number of optimal clusters. This shows that each student faces and uses different strategies to solve their assignments. The formed groups are dominated by two major clusters, namely the high-performance students, and the low-performance students. Additionally, the adaptation of PSO to FCM improves the clustering quality significantly based on the observed average Silhouette coefficient.;;;https://dl.acm.org/doi/10.1145/3427423.3427449;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Trajectory mining from VMS data for identifying fishing tackles;;;['Sathorn Pornsupikul', 'Luepol Pipanmaekaporn', 'Suwatchai Kamonsantiroj'];;;September 2017;;;ICRCA '17: Proceedings of the 2nd International Conference on Robotics, Control and Automation;;;Automatic identification of fishing equipment has a big impact on fisheries managements and illegal fishing surveillance. For many years, existing approaches to recognize fishing gear types have been proposed based on analysis of Vessel Monitoring System (VMS) data. However, the ship tracking data typically contain irrelevant and meaningless information that can limit their effectiveness. An innovative approach present in this paper is to identify types of fishing equipment from VMS records. Our approach first tries to identify activities of interest in a fishing using an unsupervised way. It then generates possible trajectories for the local movements and performs feature extraction. Two types of trajectory-based features are extracted to describe both global and local characteristics of fishing movement patterns. We finally perform dimension reduction and build the classifier using machine learning. Experiments conducted on historical VMS records from 180 commercial fishing boats with three major types of fishing gears in Thailand show that our approach achieves encouraging performance of recognition rates.;;;https://dl.acm.org/doi/10.1145/3141166.3141174;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Neyman-Pearson classification: parametrics and sample size requirement;;;['Xin Tong', 'Lucy Xia', 'Jiacheng Wang', 'Yang Feng'];;;None;;;The Journal of Machine Learning Research;;;The Neyman-Pearson (NP) paradigm in binary classification seeks classifiers that achieve a minimal type II error while enforcing the prioritized type I error controlled under some user-specified level α. This paradigm serves naturally in applications such as severe disease diagnosis and spam detection, where people have clear priorities among the two error types. Recently, Tong et al. (2018) proposed a nonparametric umbrella algorithm that adapts all scoring-type classification methods (e.g., logistic regression, support vector machines, random forest) to respect the given type I error (i.e., conditional probability of classifying a class 0 observation as class 1 under the 0-1 coding) upper bound α with high probability, without specific distributional assumptions on the features and the responses. Universal the umbrella algorithm is, it demands an explicit minimum sample size requirement on class 0, which is often the more scarce class, such as in rare disease diagnosis applications. In this work, we employ the parametric linear discriminant analysis (LDA) model and propose a new parametric thresholding algorithm, which does not need the minimum sample size requirements on class 0 observations and thus is suitable for small sample applications such as rare disease diagnosis. Leveraging both the existing nonparametric and the newly proposed parametric thresholding rules, we propose four LDA-based NP classifiers, for both low- and high-dimensional settings. On the theoretical front, we prove NP oracle inequalities for one proposed classifier, where the rate for excess type II error benefits from the explicit parametric model assumption. Furthermore, as NP classifiers involve a sample splitting step of class 0 observations, we construct a new adaptive sample splitting scheme that can be applied universally to NP classifiers, and this adaptive strategy reduces the type II error of these classifiers. The proposed NP classifiers are implemented in the R package nproc.;;;https://dl.acm.org/doi/10.5555/3455716.3455728;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Popularity Prediction of Social Media based on Multi-Modal Feature Mining;;;['Chih-Chung Hsu', 'Li-Wei Kang', 'Chia-Yen Lee', 'Jun-Yi Lee', 'Zhong-Xuan Zhang', 'Shao-Min Wu'];;;October 2019;;;MM '19: Proceedings of the 27th ACM International Conference on Multimedia;;;Popularity prediction of social media becomes a more attractive issue in recent years. It consists of multi-type data sources such as image, meta-data, and text information. In order to effectively predict the popularity of a specified post in the social network, fusing multi-feature from heterogeneous data is required. In this paper, a popularity prediction framework for social media based on multi-modal feature mining is presented. First, we discover image semantic features by extracting their image descriptions generated by image captioning. Second, an effective text-based feature engineering is used to construct an effective word-to-vector model. The trained word-to-vector model is used to encode the text information and the semantic image features. Finally, an ensemble regression approach is proposed to aggregate these encoded features and learn the final regressor. Extensive experiments show that the proposed method significantly outperforms other state-of-the-art regression models. We also show that the multi-modal approach could effectively improve the performance in the social media prediction challenge.;;;https://dl.acm.org/doi/10.1145/3343031.3356064;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Impact-Learning: A Robust Machine Learning Algorithm;;;['Md. Kowsher', 'Anik Tahabilder', 'Saydul Akbar Murad'];;;July 2020;;;ICCCM '20: Proceedings of the 8th International Conference on Computer and Communications Management;;;The ultimate goal of this research paper is to introduce a robust machine learning algorithm called Impact-Learning, which is being used widely to achieve more advanced results on many machine-learning related challenges. Impact learning is a supervised machine learning algorithm for resolving classification and linear or polynomial regression knowledge from examples. It also contributes to analyzing systems for competitive data. This algorithm is unique for being capable of learning from a competition, which is the impact of independent features. In other words, it is trained by the impacts of the features from the intrinsic rate of natural increase (RNI). The input to the Impact Learning is a training set of numerical data. In this work, we used six datasets related to regressions and classifications as the experiment of the Impact Learning, and the comparison indicates that at outperforms other standard machine learning regressions and classifications algorithms such as Random forest tree, SVM, Naive Bayes, Logistic regression and so forth.;;;https://dl.acm.org/doi/10.1145/3411174.3411185;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Nepal Stock Market Movement Prediction with Machine Learning;;;['Shunan Zhao'];;;May 2021;;;ICISDM '21: Proceedings of the 2021 5th International Conference on Information System and Data Mining;;;Financial market predicting is a popular theme of lots of researches in recent years. However, the majority of previous studies are focus on markets in great countries like China and United States, while some small countries are drawn less attention. To cover this shortage in current literature, we determined to use and compare 17 types of machine learning models to foresee Nepal market in this paper. Based on stock prices, 10 technical indicators were computed as input features. In addition, we also added emotional factors extracted from financial news to improve the prediction performance, which was evaluated by accuracy and F1 score. We predicted whether the closing price would rise or descend after three horizons: 1-day movement, 15-day movement and 30-day movement. From our experiment results, we found that linear SVM and XGBoost perform best and are the best options for further consideration in the trading process.;;;https://dl.acm.org/doi/10.1145/3471287.3471289;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
DIDroid: Android Malware Classification and Characterization Using Deep Image Learning;;;['Abir Rahali', 'Arash Habibi Lashkari', 'Gurdip Kaur', 'Laya Taheri', 'FRANCOIS GAGNON', 'Frédéric Massicotte'];;;November 2020;;;ICCNS '20: Proceedings of the 2020 10th International Conference on Communication and Network Security;;;The unrivaled threat of android malware is the root cause of various security problems on the internet. Although there are remarkable efforts in detection and classification of android malware based on machine learning techniques, a small number of attempts are made to classify and characterize it using deep learning. Detecting android malware in smartphones is an essential target for cyber community to get rid of menacing malware samples. This paper proposes an image-based deep neural network method to classify and characterize android malware samples taken from a huge malware dataset with 12 prominent malware categories and 191 eminent malware families. This work successfully demonstrates the use of deep image learning to classify and characterize android malware with an accuracy of 93.36% and log loss of less than 0.20 for training and testing set.;;;https://dl.acm.org/doi/10.1145/3442520.3442522;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Weakly-Supervised Deep Learning for Domain Invariant Sentiment Classification;;;['Pratik Kayal', 'Mayank Singh', 'Pawan Goyal'];;;January 2020;;;CoDS COMAD 2020: Proceedings of the 7th ACM IKDD CoDS and 25th COMAD;;;The task of learning a sentiment classification model that adapts well to any target domain, different from the source domain, is a challenging problem. Majority of the existing approaches focus on learning a common representation by leveraging both source and target data during training. In this paper, we introduce a two-stage training procedure that leverages weakly supervised datasets for developing simple lift-and-shift-based predictive models without being exposed to the target domain during the training phase. Experimental results show that transfer with weak supervision from a source domain to various target domains provides performance very close to that obtained via supervised training on the target domain itself.;;;https://dl.acm.org/doi/10.1145/3371158.3371194;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Amazon SageMaker Clarify: Machine Learning Bias Detection and Explainability in the Cloud;;;['Michaela Hardt', 'Xiaoguang Chen', 'Xiaoyi Cheng', 'Michele Donini', 'Jason Gelman', 'Satish Gollaprolu', 'John He', 'Pedro Larroy', 'Xinyu Liu', 'Nick McCarthy', 'Ashish Rathi', 'Scott Rees', 'Ankit Siva', 'ErhYuan Tsai', 'Keerthan Vasist', 'Pinar Yilmaz', 'Muhammad Bilal Zafar', 'Sanjiv Das', 'Kevin Haas', 'Tyler Hill', 'Krishnaram Kenthapadi'];;;August 2021;;;KDD '21: Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining;;;Understanding the predictions made by machine learning (ML) models and their potential biases remains a challenging and labor-intensive task that depends on the application, the dataset, and the specific model. We present Amazon SageMaker Clarify, an explainability feature for Amazon SageMaker that launched in December 2020, providing insights into data and ML models by identifying biases and explaining predictions. It is deeply integrated into Amazon SageMaker, a fully managed service that enables data scientists and developers to build, train, and deploy ML models at any scale. Clarify supports bias detection and feature importance computation across the ML lifecycle, during data preparation, model evaluation, and post-deployment monitoring. We outline the desiderata derived from customer input, the modular architecture, and the methodology for bias and explanation computations. Further, we describe the technical challenges encountered and the tradeoffs we had to make. For illustration, we discuss two customer use cases. We present our deployment results including qualitative customer feedback and a quantitative evaluation. Finally, we summarize lessons learned, and discuss best practices for the successful adoption of fairness and explanation tools in practice.;;;https://dl.acm.org/doi/10.1145/3447548.3467177;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
An Improved Pedestrian Motion Tracking System Assisted by Machine Learning?;;;['Yuming Chen', 'Wei Li', 'Zhuoyin Si'];;;July 2019;;;DSIT 2019: Proceedings of the 2019 2nd International Conference on Data Science and Information Technology;;;Pedestrian motion tracking based on the Micro-electromechanical inertial measurement unit (MEMS-IMU) possesses the unique advantages in terms of autonomy and anti-disturbance, which has been widely approved as a promising selection in indoor positioning. For the traditional pedestrian indoor positioning system, the accuracy of Zero-velocity interval detection and the stability of Kalman Filter (KF) are the key problem that restricting the development of indoor positioning system. To overcome the drawbacks of traditional Zero-velocity detection algorithm in robustness and adaptability, a novel Zero-velocity detection algorithm based on Support Vector Machine (SVM) is proposed. The construction of the SVM model based on the characteristics of pedestrian foot movement, and genetic algorithm is utilized to online optimizing the key parameters of the SVM. Then, incorporating the concept of strong tracking into the KF to improve the accuracy and stability of KF, a novel Zero Velocity Update (ZUPT) method based on the strong tracking KF (STKF) is presented. The experiment results show that the proposed method has better positioning accuracy and robustness than traditional indoor positioning method.;;;https://dl.acm.org/doi/10.1145/3352411.3352427;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Mining cross-domain apps for software evolution: a feature-based approach;;;['MD Kafil Uddin', 'Qiang He', 'Jun Han', 'Caslon Chua'];;;November 2021;;;ASE '21: Proceedings of the 36th IEEE/ACM International Conference on Automated Software Engineering;;;The skyrocketing growth of mobile apps and mobile devices has significantly fueled the competition among app developers. They have leveraged the app store capabilities to analyse app data and identify app improvement opportunities. Existing research has shown that app developers mostly rely on in-domain (i.e., same domain or same app) data to improve their apps. However, relying on in-domain data results in low diversity and lacks novelty in recommended features. In this work, we present an approach that automatically identifies, classifies and ranks relevant popular features from cross-domain apps for recommendation to any given target app. It includes the following three steps: 1) identify cross-domain apps that are relevant to the target app in terms of their features; 2) filter and group semantically the features of the relevant cross-domain apps that are complementary to the target app; 3) rank and prioritize the complementary cross-domain features (in terms of their domain, app, feature and popularity characteristics) for adoption by the target app's developers. We have run extensive experiments on 100 target apps from 10 categories over 15,200 cross-domain apps from 31 categories. The experimental results have shown that our approach to identifying, grouping and ranking complementary cross-domain features for recommendation has achieved an accuracy level of over 89%. Our semantic feature grouping technique has also significantly outperformed two existing baseline techniques. The empirical evaluation validates the efficacy of our approach in providing personalised feature recommendation and enhancing app's user serendipity.;;;https://dl.acm.org/doi/10.1109/ASE51524.2021.9678514;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Automatic Classification of Exudates in Color Fundus Images Using an Augmented Deep Learning Procedure;;;['Lei Wang', 'Ying Huang', 'Bing Lin', 'Wencan Wu', 'Hao Chen', 'Jiantao Pu'];;;August 2019;;;ISICDM 2019: Proceedings of the Third International Symposium on Image Computing and Digital Medicine;;;Automatic classification of hard and soft exudates in color fundus images is very helpful for computer-aided diagnosis of retina related diseases, such as diabetic retinopathy (DR). In this study, we developed a novel method for this purpose based on the emerging deep learning technology known as convolutional neural networks (CNNs) by leveraging its strength of explicitly extracting the underlying image textures. We specifically investigate whether the emphasis of the image characteristic within an exudate spot could improve the classification performance. To verify this, we collected a database of fundus image that contains soft and hard exudates. The exudate regions were cropped from fundus images. There are a total of 550 cropped image patches (275 hard and 275 soft) with a fixed dimension of 128×128 pixels. These patches were further thresholded to exclude image background, resulting in another version of image patches merely containing exudate regions. Each version of image patches was randomly divided into 440 for training and 110 for testing, and then fed into the developed deep learning network in a separate or combinatorial way. Experimental results showed that the classification accuracy of this method was 93.41% when the thresholded version of the dataset was used as an augmented learning procedure, as compared to 90.80% and 87.41% when the original and background excluded datasets were used for training, respectively. This suggests that the augmented CNN can provide more accurate classification performance when the region-of-interest (ROI) and the original images were integrated.;;;https://dl.acm.org/doi/10.1145/3364836.3364843;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Few-Shot Ensemble Learning for Video Classification with SlowFast Memory Networks;;;['Mengshi Qi', 'Jie Qin', 'Xiantong Zhen', 'Di Huang', 'Yi Yang', 'Jiebo Luo'];;;October 2020;;;MM '20: Proceedings of the 28th ACM International Conference on Multimedia;;;In the era of big data, few-shot learning has recently received much attention in multimedia analysis and computer vision due to its appealing ability of learning from scarce labeled data. However, it has been largely underdeveloped in the video domain, which is even more challenging due to the huge spatial-temporal variability of video data. In this paper, we address few-shot video classification by learning an ensemble of SlowFast networks augmented with memory units. Specifically, we introduce a family of few-shot learners based on SlowFast networks which are used to extract informative features at multiple rates, and we incorporate a memory unit into each network to enable encoding and retrieving crucial information instantly. Furthermore, we propose a choice controller network to leverage the diversity of few-shot learners by learning to adaptively assign a confidence score to each SlowFast memory network, leading to a strong classifier for enhanced prediction. Experimental results on two widely-adopted video datasets demonstrate the effectiveness of the proposed method, as well as its superior performance over the state-of-the-art approaches.;;;https://dl.acm.org/doi/10.1145/3394171.3416269;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Pornographic content classification using deep-learning;;;['André Tabone', 'Kenneth Camilleri', 'Alexandra Bonnici', 'Stefania Cristina', 'Reuben Farrugia', 'Mark Borg'];;;August 2021;;;DocEng '21: Proceedings of the 21st ACM Symposium on Document Engineering;;;Controlling the distribution of sensitive content such as pornography has become paramount with the ever-growing accessibility to the internet. Manual filtering of such large volumes of data is practically impossible, thus, the automatic detection of said material is sought after by Law Enforcement Agencies (LEAs) and has been tackled in various manners. However, the sorting of flagged pornographic documents is still done manually using scales that describe hierarchical degrees of content severity. In this paper, we address pornography detection by creating a model capable of locating and labelling sexual organs in images and extend this model to perform image classification to provide the user with one of 19 semantically meaningful descriptors of the content. Generating these descriptors serves as a proof of concept before approaching LEAs to work with illegal CSA material and scales such as COPINE. After creating our own custom sexual organ object detection dataset for the task at hand, we achieved an object detection mean average precision score of 63.63% and a top-3 classification accuracy of 87.78%.;;;https://dl.acm.org/doi/10.1145/3469096.3469867;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Improvements of fuzzy C-means clustering performance using particle swarm optimization on student grouping based on learning activity in a digital learning media;;;['Ahmad Afif Supianto', "Nur Sa'diyah", 'Candra Dewi', 'Retno Indah Rokhmawati', 'Satrio Agung Wicaksono', 'Hanifah Muslimah Az-Zahra', 'Satrio Hadi Wijoyo', 'Yusuke Hayashi', 'Tsukasa Hirashima'];;;November 2020;;;SIET '20: Proceedings of the 5th International Conference on Sustainable Information Engineering and Technology;;;The field of learning media has been developing rapidly in recent years, especially in an effort to support students' learning process. The amount of recorded learning process data has also significantly increased. The recorded data represents the students' thinking process in building a solution for a problem. The sheer size of the recorded data proves to be quite a challenge in an effort to mine the students' thinking process, especially when done manually. Additionally, to group the recorded data into clusters is also another form of challenge that needs to be faced. In general, the entire process of mining students' thinking patterns aims to utilize the data to gather hidden information which can also be used to give appropriate and proper feedback to the students. This paper aims to employ the Fuzzy C-Means and Particle Swarm Optimization (FCMPSO) method to cluster students based on their learning activity to a digital learning media and compare its performance to original Fuzzy C-Means (FCM) method. Particle Swarm Optimization (PSO) algorithm is proposed to optimize the performance of the FCM algorithm, in which this algorithm is inherently sensitive towards centroid on the initial clustering process that utilizes the Silhouette coefficient as an evaluation method. Based on the experiments that have been done to 12 assignments, each assignment forms a different number of optimal clusters. This shows that each student faces and uses different strategies to solve their assignments. The formed groups are dominated by two major clusters, namely the high-performance students, and the low-performance students. Additionally, the adaptation of PSO to FCM improves the clustering quality significantly based on the observed average Silhouette coefficient.;;;https://dl.acm.org/doi/10.1145/3427423.3427449;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Rhabdomyosarcoma Histology Classification using Ensemble of Deep Learning Networks;;;['Saloni Agarwal', 'Mohamedelfatih Eltigani', 'Osman Abaker', 'Xinyi Zhang', 'Ovidiu Daescu', 'Donald A. Barkauskas', 'Erin R. Rudzinski', 'Patrick Leavey'];;;September 2020;;;BCB '20: Proceedings of the 11th ACM International Conference on Bioinformatics, Computational Biology and Health Informatics;;;A significant number of machine learning methods have been developed to identify major tumor types in histology images, yet much less is known about automatic classification of tumor subtypes. Rhabdomyosarcoma (RMS), the most common type of soft tissue cancer in children, has several subtypes, the most common being Embryonal, Alveolar, and Spindle Cell. Classifying RMS to the right subtype is critical, since subtypes are known to respond to different treatment protocols. Manual classification requires high expertise and is time consuming due to subtle variance in appearance of histopathology images. In this paper, we introduce and compare machine learning based architectures for automatic classification of Rhabdomyosarcoma into the three major subtypes, from whole slide images (WSI). For training purpose, we only know the class assigned to a WSI, having no manual annotations on the image, while most related work on tumor classification requires manual region or nuclei annotations on WSIs. To predict the class of a new WSI we first divide it into tiles, predict the class of each tile, then use thresholding with soft voting to convert tile level predictions to WSI level prediction. We obtain 94.87% WSI tumor subtype classification accuracy on a large and diverse test dataset. We achieve such accurate classification at 5X magnification level of WSIs, departing from related work, that uses 20X or 10X for best results. A direct advantage of our method is that both training and testing can be performed much faster computationally due to the lower image resolution.;;;https://dl.acm.org/doi/10.1145/3388440.3412486;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Mining micro-influencers from social media posts;;;['Simone Leonardi', 'Diego Monti', 'Giuseppe Rizzo', 'Maurizio Morisio'];;;March 2020;;;SAC '20: Proceedings of the 35th Annual ACM Symposium on Applied Computing;;;Micro-influencers have triggered the interest of commercial brands, public administrations, and other stakeholders because of their demonstrated capability of sensitizing people within their close reach. However, due to their lower visibility in social media platforms, they are challenging to be identified. This work proposes an approach to automatically detect micro-influencers and to highlight their personality traits and community values by computationally analyzing their writings. We introduce two learning methods to retrieve Five Factor Model and Basic Human Values scores. These scores are then used as feature vectors of a Support Vector Machines classifier. We define a set of rules to create a micro-influencer gold standard dataset of more than two million tweets and we compare our approach with three baseline classifiers. The experimental results favor recall meaning that the approach is inclusive in the identification.;;;https://dl.acm.org/doi/10.1145/3341105.3373954;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Multi-Task Pharmacovigilance Mining from Social Media Posts;;;['Shaika Chowdhury', 'Chenwei Zhang', 'Philip S. Yu'];;;April 2018;;;WWW '18: Proceedings of the 2018 World Wide Web Conference;;;Social media has grown to be a crucial information source for pharmacovigilance studies where an increasing number of people post adverse reactions to medical drugs that are previously unreported. Aiming to effectively monitor various aspects of Adverse Drug Reactions (ADRs) from diversely expressed social medical posts, we propose a multi-task neural network framework that learns several tasks associated with ADR monitoring with different levels of supervisions collectively. Besides being able to correctly classify ADR posts and accurately extract ADR mentions from online posts, the proposed framework is also able to further understand reasons for which the drug is being taken, known as »indications», from the given social media post. A coverage-based attention mechanism is adopted in our framework to help the model properly identify »phrasal» ADRs and Indications that are attentive to multiple words in a post. Our framework is applicable in situations where limited parallel data for different pharmacovigilance tasks are available. We evaluate the proposed framework on real-world Twitter datasets, where the proposed model outperforms the state-of-the-art alternatives of each individual task consistently.;;;https://dl.acm.org/doi/10.1145/3178876.3186053;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Structure-Aware Deep Learning for Product Image Classification;;;['Zhineng Chen', 'Shanshan Ai', 'Caiyan Jia'];;;None;;;ACM Transactions on Multimedia Computing, Communications, and Applications;;;Automatic product image classification is a task of crucial importance with respect to the management of online retailers. Motivated by recent advancements of deep Convolutional Neural Networks (CNN) on image classification, in this work we revisit the problem in the context of product images with the existence of a predefined categorical hierarchy and attributes, aiming to leverage the hierarchy and attributes to improve classification accuracy. With these structure-aware clues, we argue that more advanced deep models could be developed beyond the flat one-versus-all classification performed by conventional CNNs. To this end, novel efforts of this work include a salient-sensitive CNN that gazes into the product foreground by inserting a dedicated spatial attention module; a multiclass regression-based refinement that is expected to predict more accurately by merging prediction scores from multiple preceding CNNs, each corresponding to a distinct classifier in the hierarchy; and a multitask deep learning architecture that effectively explores correlations among categories and attributes for categorical label prediction. Experimental results on nearly 1 million real-world product images basically validate the effectiveness of the proposed efforts individually and jointly, from which performance gains are observed.;;;https://dl.acm.org/doi/10.1145/3231742;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Mining and exploration of attributed graphs: theory and applications;;;['Mehdi Kargar', 'Morteza Zihayat', 'Jaroslaw Szlichta'];;;November 2019;;;CASCON '19: Proceedings of the 29th Annual International Conference on Computer Science and Software Engineering;;;Much of the world's high-quality enterprise and social data are structured or at least semi-structured. This includes large-scale relational databases, knowledge graphs, and social networks. Almost all structured and semi-structured enterprise data can be modeled as attributed graphs, meaning that their nodes are labelled with textual information such as personal data, expertise or interests. Over the past decade, we have witnessed a number of rigorous studies on mining graphs for interesting patterns (e.g., subgraphs), but we have not seen much progress in pattern mining over attributed graphs. In this workshop, we present recent progress in building efficient and effective systems to empower users to mine and explore attributed graphs and how we incorporate IBM technologies to build such systems. First, as for any data-driven platform, we have to make sure that our system is built based on reliable data. Therefore, we present challenges and different approaches of cleaning attributed graphs. Then, we provide different search systems to explore attributed graphs, with a focus on systems that assist non-technical users (the systems that provide a Google-like search experience). Finally, our focus will be on mining attributed graphs for different purposes including user modeling and significant pattern discovery. We also discuss a variety of applications of such systems in different domains, and specifically how we use these systems to improve the user experience in IBM products.;;;https://dl.acm.org/doi/10.5555/3370272.3370339;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Lateralized learning for robustness against adversarial attacks in a visual classification system;;;['Abubakar Siddique', 'Will N. Browne', 'Gina M. Grimshaw'];;;June 2020;;;GECCO '20: Proceedings of the 2020 Genetic and Evolutionary Computation Conference;;;Deep learning is an important field of machine learning. It is playing a critical role in a variety of applications ranging from self-driving cars to security and surveillance. However, deep networks have deep flaws. For example, they are highly vulnerable to adversarial attacks. One reason may be the homogeneous nature of their knowledge representation, which allows a single disruptive pattern to cause miss-classification. Biological intelligence has lateral asymmetry, which allows heterogeneous, modular learning at different levels of abstraction, enabling different representations of the same object. This work aims to incorporate lateralization and modular learning at different levels of abstraction in an evolutionary machine learning system. The results of image classification tasks show that the lateralized system efficiently learns hierarchical distributions of knowledge, demonstrating performance that is similar to (or better than) other state-of-the-art deep systems as it reasons using multiple representations. Crucially, the novel system outperformed all the state-of-the-art deep models for the classification of normal and adversarial images by 0.43% -- 2.56% and 2.15% -- 25.84%, respectively. Lateralisation enabled the system to exhibit robustness beyond previous work, which advocates for the creation of data sets that enable components of objects and the objects themselves to be learned specifically or in an end-to-end manner.;;;https://dl.acm.org/doi/10.1145/3377930.3390164;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Impact-Learning: A Robust Machine Learning Algorithm;;;['Md. Kowsher', 'Anik Tahabilder', 'Saydul Akbar Murad'];;;July 2020;;;ICCCM '20: Proceedings of the 8th International Conference on Computer and Communications Management;;;The ultimate goal of this research paper is to introduce a robust machine learning algorithm called Impact-Learning, which is being used widely to achieve more advanced results on many machine-learning related challenges. Impact learning is a supervised machine learning algorithm for resolving classification and linear or polynomial regression knowledge from examples. It also contributes to analyzing systems for competitive data. This algorithm is unique for being capable of learning from a competition, which is the impact of independent features. In other words, it is trained by the impacts of the features from the intrinsic rate of natural increase (RNI). The input to the Impact Learning is a training set of numerical data. In this work, we used six datasets related to regressions and classifications as the experiment of the Impact Learning, and the comparison indicates that at outperforms other standard machine learning regressions and classifications algorithms such as Random forest tree, SVM, Naive Bayes, Logistic regression and so forth.;;;https://dl.acm.org/doi/10.1145/3411174.3411185;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Identifying important citations using contextual information from full text;;;['Saeed-Ul Hassan', 'Anam Akram', 'Peter Haddawy'];;;June 2017;;;JCDL '17: Proceedings of the 17th ACM/IEEE Joint Conference on Digital Libraries;;;In this paper we address the problem of classifying cited work into important and non-important to the developments presented in a research publication. This task is vital for the algorithmic techniques that detect and follow emerging research topics and to qualitatively measure the impact of publications in increasingly growing scholarly big data. We consider cited work as important to a publication if that work is used or extended in some way. If a reference is cited as background work or for the purpose of comparing results, the cited work is considered to be non-important. By employing five classification techniques (Support Vector Machine, Naïve Bayes, Decision Tree, K-Nearest Neighbors and Random Forest) on an annotated dataset of 465 citations, we explore the effectiveness of eight previously published features and six novel features (including context based, cue words based and textual based). Within this set, our new features are among the best performing. Using the Random Forest classifier we achieve an overall classification accuracy of 0.91 AUC.;;;https://dl.acm.org/doi/10.5555/3200334.3200340;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Negative results on mining crypto-API usage rules in Android apps;;;['Jun Gao', 'Pingfan Kong', 'Li Li', 'Tegawendé F. Bissyandé', 'Jacques Klein'];;;May 2019;;;MSR '19: Proceedings of the 16th International Conference on Mining Software Repositories;;;Android app developers recurrently use crypto-APIs to provide data security to app users. Unfortunately, misuse of APIs only creates an illusion of security and even exposes apps to systematic attacks. It is thus necessary to provide developers with a statically-enforceable list of specifications of crypto-API usage rules. On the one hand, such rules cannot be manually written as the process does not scale to all available APIs. On the other hand, a classical mining approach based on common usage patterns is not relevant in Android, given that a large share of usages include mistakes. In this work, building on the assumption that "developers update API usage instances to fix misuses", we propose to mine a large dataset of updates within about 40 000 real-world app lineages to infer API usage rules. Eventually, our investigations yield negative results on our assumption that API usage updates tend to correct misuses. Actually, it appears that updates that fix misuses may be unintentional: the same misuses patterns are quickly re-introduced by subsequent updates.;;;https://dl.acm.org/doi/10.1109/MSR.2019.00065;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
ECG Heartbeat Classification: An Exploratory Study;;;['Loren Kersey', 'Kat Lilly', 'Noel Park'];;;December 2018;;;AIW'18: Proceedings of the Australasian Joint Conference on Artificial Intelligence - Workshops;;;This paper presents an exploratory study of the ECG heart beat classification problem that employs a number of machine learning models. Using the feature schemes of the state-of-the-art, we investigate the classification both for individual and cross-patient scenarios. A cascade system made of a neural network and a support vector machine is proposed and gives competitive performance on a benchmark dataset.;;;https://dl.acm.org/doi/10.1145/3314487.3314491;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Improving Classification Performance of Deep Learning Models Using Bio-Inspired Computing;;;['Vaishali Baviskar', 'Madhushi Verma', 'Pradeep Chatterjee'];;;August 2021;;;IC3-2021: Proceedings of the 2021 Thirteenth International Conference on Contemporary Computing;;;Deep learning models have paved the way towards generating high-efficiency classification systems for multiple applications. These applications include lung disease classification, electrocardiogram classification, electroencephalogram classification; forest cover classification, etc. All these applications rely on efficient feature selection capabilities of deep learning models. Models like convolutional neural network (CNN), recurrent neural networks (RNNs), long-short-term-memory (LSTM) etc. are used for this purpose. These models tend to evaluate all possible feature combinations via iterative window-based feature processing. Thereby trying to cover indefinite number of feature combinations in order to classify a definite number of features into a definite number of classes. All these models have a stopping-criteria, which depends upon the error rate difference of previous current iteration. If the error rate is less than a particular threshold, and number of iterations are above a certain predefined value, then training of these networks is stopped. This property of deep learning models limits their real-time performance, because training stops even if the accuracy is lower than expected. The reason for this low accuracy is high dimensionality of search space, due to which selection of the most optimum features is skipped. In order to reduce the probability of such conditions, this text proposes a bio-inspired Genetic Algorithm model for accuracy-based feature selection. The selected features are given to different deep learning models like LSTM RNN, and their internal performance is evaluated. Here, heart failure disease dataset from kaggle is used, and it is observed that due to pre-feature selection process, overall accuracy of these models is improved by 10, while precision, recall fMeasure scores are improved by 15 for heart disease data sets. The specificity and sensitivity performance is improved by 20 when compared with RNN and LSTM models individually.;;;https://dl.acm.org/doi/10.1145/3474124.3474174;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Classification of Contractual Conflicts via Learning of Semantic Representations;;;['João Paulo Aires', 'Roger Granada', 'Juarez Monteiro', 'Rodrigo Coelho Barros', 'Felipe Meneguzzi'];;;May 2019;;;AAMAS '19: Proceedings of the 18th International Conference on Autonomous Agents and MultiAgent Systems;;;Contracts are the main medium through which parties formalize their trade relations, be they the exchange of goods or the specification of mutual obligations. While electronic contracts allow automated processes to verify their correctness, most agreements in the real world are still written in natural language, which need substantial human revision effort to eliminate possible conflicting statements in long and complex contracts. In this paper, we formalize a typology of conflict types between clauses suitable for machine learning and develop techniques to review contracts by learning to identify and classify such conflicts, facilitating the task of contract revision. We evaluate the effectiveness of our techniques using a manually annotated contract conflict corpus with results close to the current state-of-the-art for conflict identification, while introducing a more complex classification task of such conflicts for which our method surpasses the state-of-the art method.;;;https://dl.acm.org/doi/10.5555/3306127.3331911;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Semi-Supervised Granular Classification Framework for Resource Constrained Short-texts: Towards Retrieving Situational Information During Disaster Events;;;['Samujjwal Ghosh', 'Maunendra Sankar Desarkar'];;;July 2020;;;WebSci '20: Proceedings of the 12th ACM Conference on Web Science;;;During the time of disasters, lots of short-texts are generated containing crucial situational information. Proper extraction and identification of situational information might be useful for various rescue and relief operations. Few specific types of infrequent situational information might be critical. However, obtaining labels for those resource-constrained classes is challenging as well as expensive. Supervised methods pose limited usability in such scenarios. To overcome this challenge, we propose a semi-supervised learning framework which utilizes abundantly available unlabelled data by self-learning. The proposed framework improves the performance of the classifier for resource-constrained classes by selectively incorporating highly confident samples from unlabelled data for self-learning. Incremental incorporation of unlabelled data, as and when they become available, is suitable for ongoing disaster mitigation. Experiments on three disaster-related datasets show that such improvement results in overall performance increase over standard supervised approach.;;;https://dl.acm.org/doi/10.1145/3394231.3397892;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Negative Confidence-Aware Weakly Supervised Binary Classification for Effective Review Helpfulness Classification;;;['Xi Wang', 'Iadh Ounis', 'Craig Macdonald'];;;October 2020;;;CIKM '20: Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management;;;The incompleteness of positive labels and the presence of many unlabelled instances are common problems in binary classification applications such as in review helpfulness classification. Various studies from the classification literature consider all unlabelled instances as negative examples. However, a classification model that learns to classify binary instances with incomplete positive labels while assuming all unlabelled data to be negative examples will often generate a biased classifier. In this work, we propose a novel Negative Confidence-aware Weakly Supervised approach (NCWS), which customises a binary classification loss function by discriminating the unlabelled examples with different negative confidences during the classifier's training. NCWS allows to effectively, unbiasedly identify and separate positive and negative instances after its integration into various binary classifiers from the literature, including SVM, CNN and BERT-based classifiers. We use the review helpfulness classification as a test case for examining the effectiveness of our NCWS approach. We thoroughly evaluate NCWS by using three different datasets, namely one from Yelp (venue reviews), and two from Amazon (Kindle and Electronics reviews). Our results show that NCWS outperforms strong baselines from the literature including an existing SVM-based approach (i.e. SVM-P), the positive and unlabelled learning-based approach (i.e. C-PU) and the positive confidence-based approach (i.e. P-conf) in addressing the classifier's bias problem. Moreover, we further examine the effectiveness of NCWS by using its classified helpful reviews in a state-of-the-art review-based venue recommendation model (i.e. DeepCoNN) and demonstrate the benefits of using NCWS in enhancing venue recommendation effectiveness in comparison to the baselines.;;;https://dl.acm.org/doi/10.1145/3340531.3411978;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A Hybrid Similarity Measure Based on Binary and Decimal Data for Data Mining;;;['Soyeong Jeong'];;;April 2019;;;ICCAI '19: Proceedings of the 2019 5th International Conference on Computing and Artificial Intelligence;;;We suggest a new similarity measure to improve the quality of data mining, especially for recommender system. A similarity measure is widely used for classification, clustering, anomaly detection and so on. Many recommender systems predict unrated score through clustering similar users. This method is so called collaborative filtering(CF), which is being widely used. In CF, how to define a similarity measure is a major concern. Conventional measures based on Pearson Correlation Coefficient(PCC) are hard to reflect the implicit and explicit information at the same time. We propose a hybrid similarity measure, named BD PCC, which is a type of PCC, named after the first letter of 'Binary' and 'Decimal' types respectively. As we suggest from its name, BD PCC is defined by concatenating two PCCs on two different types of data. Although other hybrid measures need some processes to concatenate, BD PCC is free from scale issue. Because it consists of both PCCs unlike other hybrid measures consisting of values in different ranges. Since PCC for binary data can be defined if the user bought at least one item, BD PCC relieves the sparsity of data. We tested the proposed similarity measure in recommender systems and the prediction accuracy has been improved for real data sets, MovieLens 100K[8], MovieLens 1M[8], MovieLens latest small[8], and FilmTrust 35K[9].;;;https://dl.acm.org/doi/10.1145/3330482.3330520;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Exploring the limits of transfer learning with a unified text-to-text transformer;;;['Colin Raffel', 'Noam Shazeer', 'Adam Roberts', 'Katherine Lee', 'Sharan Narang', 'Michael Matena', 'Yanqi Zhou', 'Wei Li', 'Peter J. Liu'];;;None;;;The Journal of Machine Learning Research;;;Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned on a downstream task, has emerged as a powerful technique in natural language processing (NLP). The effectiveness of transfer learning has given rise to a diversity of approaches, methodology, and practice. In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework that converts all text-based language problems into a text-to-text format. Our systematic study compares pretraining objectives, architectures, unlabeled data sets, transfer approaches, and other factors on dozens of language understanding tasks. By combining the insights from our exploration with scale and our new "Colossal Clean Crawled Corpus", we achieve state-of-the-art results on many benchmarks covering summarization, question answering, text classification, and more. To facilitate future work on transfer learning for NLP, we release our data set, pre-trained models, and code.;;;https://dl.acm.org/doi/10.5555/3455716.3455856;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A Behavior-cluster Based Imbalanced Classification Method for Credit Card Fraud Detection;;;['Qi Li', 'Yu Xie'];;;July 2019;;;DSIT 2019: Proceedings of the 2019 2nd International Conference on Data Science and Information Technology;;;Credit card fraud detection has been paid more and more attention by researchers. The credit card transactions are represented by highly imbalanced data sets. The number of genuine transactions is far more than fraudulent transactions, which will greatly affect the detection of fraud. Existing methods mainly consider how to balance the two classes only based on data volume, without considering the complexity of user behavior in credit card transactions, that is, the behavior noise. In this paper, we propose a behavior-cluster based imbalanced classification method. The main idea is to divide user behaviors into several group behaviors, remove behavior noise, and then hierarchical sampling. Experiments on a large scale credit card transaction data provided by a financial institution and 18 UCI data sets show that our method is superior to the existing method.;;;https://dl.acm.org/doi/10.1145/3352411.3352433;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Adversarial classification: necessary conditions and geometric flows;;;['Nicol´s García Trillos', 'Ryan Murray'];;;None;;;The Journal of Machine Learning Research;;;We study a version of adversarial classification where an adversary is empowered to corrupt data inputs up to some distance ε, using tools from variational analysis. In particular, we describe necessary conditions associated with the optimal classifier subject to such an adversary. Using the necessary conditions, we derive a geometric evolution equation which can be used to track the change in classification boundaries as ε varies. This evolution equation may be described as an uncoupled system of differential equations in one dimension, or as a mean curvature type equation in higher dimension. In one dimension, and under mild assumptions on the data distribution, we rigorously prove that one can use the initial value problem starting from ε = 0, which is simply the Bayes classifier, in order to solve for the global minimizer of the adversarial problem for small values of ε. In higher dimensions we provide a similar result, albeit conditional to the existence of regular solutions of the initial value problem. In the process of proving our main results we obtain a result of independent interest connecting the original adversarial problem with an optimal transport problem under no assumptions on whether classes are balanced or not. Numerical examples illustrating these ideas are also presented.;;;https://dl.acm.org/doi/10.5555/3586589.3586776;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Rock classification model based on transfer learning and convolutional neural network;;;['Huaian Yi', 'Jinzhao Su', 'Runji Fang'];;;July 2021;;;ICIIP '21: Proceedings of the 6th International Conference on Intelligent Information Processing;;;None;;;https://dl.acm.org/doi/10.1145/3480571.3480595;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Weakly-supervised Learning Using Pretraining for Classification in HER2 Immunohistochemistry Image of Breast Cancer;;;['Zhengnan Wang', 'Yeting Ma', 'Yali Zheng', 'Peiqin Feng', 'Fangbo Yu'];;;March 2021;;;ICMAI '21: Proceedings of the 2021 6th International Conference on Mathematics and Artificial Intelligence;;;Recently supervised deep learning method has achieved good performance in image classification tasks. However, it is very difficult to annotate pathological images accurately for supervised learning tasks. So, the limited amount of labeled data brings great challenges to the supervised learning model. In this paper we propose a weakly-supervised learning method which combines the pretraining technology of transfer learning with deep learning in the HER2 immunohistochemistry (IHC) pathological image classification task of breast cancer. It is worth mentioning that on the network architecture of VGG16 model, we train the model with three different images from pathological images, apply the pretraining model to the HER2 IHC image classification task of breast cancer. The experimental results show that the weakly-supervised learning implemented by the pretraining technology of transfer learning can significantly improve the performance of HER2 IHC pathological image classification task.;;;https://dl.acm.org/doi/10.1145/3460569.3460586;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Clustering Individual Transactional Data for Masses of Users;;;['Riccardo Guidotti', 'Anna Monreale', 'Mirco Nanni', 'Fosca Giannotti', 'Dino Pedreschi'];;;August 2017;;;KDD '17: Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining;;;Mining a large number of datasets recording human activities for making sense of individual data is the key enabler of a new wave of personalized knowledge-based services. In this paper we focus on the problem of clustering individual transactional data for a large mass of users. Transactional data is a very pervasive kind of information that is collected by several services, often involving huge pools of users. We propose txmeans, a parameter-free clustering algorithm able to efficiently partitioning transactional data in a completely automatic way. Txmeans is designed for the case where clustering must be applied on a massive number of different datasets, for instance when a large set of users need to be analyzed individually and each of them has generated a long history of transactions. A deep experimentation on both real and synthetic datasets shows the practical effectiveness of txmeans for the mass clustering of different personal datasets, and suggests that txmeans outperforms existing methods in terms of quality and efficiency. Finally, we present a personal cart assistant application based on txmeans;;;https://dl.acm.org/doi/10.1145/3097983.3098034;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Improved classification rates for localized SVMs;;;['Ingrid Blaschzyk', 'Ingo Steinwart'];;;None;;;The Journal of Machine Learning Research;;;Localized support vector machines solve SVMs on many spatially defined small chunks and besides their computational benefit compared to global SVMs one of their main characteristics is the freedom of choosing arbitrary kernel and regularization parameter on each cell. We take advantage of this observation to derive global learning rates for localized SVMs with Gaussian kernels and hinge loss. It turns out that our rates outperform under suitable sets of assumptions known classification rates for localized SVMs, for global SVMs, and other learning algorithms based on e.g., plug-in rules or trees. The localized SVM rates are achieved under a set of margin conditions, which describe the behavior of the data-generating distribution, and no assumption on the existence of a density is made. Moreover, we show that our rates are obtained adaptively, that is without knowing the margin parameters in advance. The statistical analysis of the excess risk relies on a simple partitioning based technique, which splits the input space into a subset that is close to the decision boundary and into a subset that is sufficiently far away. A crucial condition to derive then improved global rates is a margin condition that relates the distance to the decision boundary to the amount of noise.;;;https://dl.acm.org/doi/10.5555/3586589.3586754;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
A machine learning model to classify the feature model maintainability;;;['Publio Silva', 'Carla I. M. Bezerra', 'Ivan Machado'];;;September 2021;;;SPLC '21: Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume A;;;Software Product Lines (SPL) are generally specified using a Feature Model (FM), an artifact designed in the early stages of the SPL development life cycle. This artifact can quickly become too complex, which makes it challenging to maintain an SPL. Therefore, it is essential to evaluate the artifact's maintainability continuously. The literature brings some approaches that evaluate FM maintainability through the aggregation of maintainability measures. Machine Learning (ML) models can be used to create these approaches. They can aggregate the values of independent variables into a single target data, also called a dependent variable. Besides, when using white-box ML models, it is possible to interpret and explain the ML model results. This work proposes white-box ML models intending to classify the FM maintainability based on 15 measures. To build the models, we performed the following steps: (i) we compared two approaches to evaluate the FM maintainability through a human-based oracle of FM maintainability classifications; (ii) we used the best approach to pre-classify the ML training dataset; (iii) we generated three ML models and compared them against classification accuracy, precision, recall, F1 and AUC-ROC; and, (iv) we used the best model to create a mechanism capable of providing improvement indicators to domain engineers. The best model used the decision tree algorithm that obtained accuracy, precision, and recall of 0.81, F1-Score of 0.79, and AUC-ROC of 0.91. Using this model, we could reduce the number of measures needed to evaluate the FM maintainability from 15 to 9 measures.;;;https://dl.acm.org/doi/10.1145/3461001.3471152;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Multi-View Mammographic Density Classification by Dilated and Attention-Guided Residual Learning;;;['Cheng Li', 'Jingxu Xu', 'Qiegen Liu', 'Yongjin Zhou', 'Lisha Mou', 'Zuhui Pu', 'Yong Xia', 'Hairong Zheng', 'Shanshan Wang'];;;None;;;IEEE/ACM Transactions on Computational Biology and Bioinformatics;;;Breast density is widely adopted to reflect the likelihood of early breast cancer development. Existing methods of mammographic density classification either require steps of manual operations or achieve only moderate classification accuracy due to the limited model capacity. In this study, we present a radiomics approach based on dilated and attention-guided residual learning for the task of mammographic density classification. The proposed method was instantiated with two datasets, one clinical dataset and one publicly available dataset, and classification accuracies of 88.7 and 70.0 percent were obtained, respectively. Although the classification accuracy of the public dataset was lower than the clinical dataset, which was very likely related to the dataset size, our proposed model still achieved a better performance than the naive residual networks and several recently published deep learning-based approaches. Furthermore, we designed a multi-stream network architecture specifically targeting at analyzing the multi-view mammograms. Utilizing the clinical dataset, we validated that multi-view inputs were beneficial to the breast density classification task with an increase of at least 2.0 percent in accuracy and the different views lead to different model classification capacities. Our method has a great potential to be further developed and applied in computer-aided diagnosis systems. Our code is available at <uri>https://github.com/lich0031/Mammographic_Density_Classification</uri>.;;;https://dl.acm.org/doi/10.1109/TCBB.2020.2970713;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Diagnosis of Methylmalonic Acidemia using Machine Learning Methods;;;['Xin Li', 'Xiaoxing Yang', 'Wushao Wen'];;;June 2019;;;ICMLT '19: Proceedings of the 2019 4th International Conference on Machine Learning Technologies;;;Methylmalonic acidemia (MMA) is an autosomal recessive metabolic disorder. Traditional diagnosis needs physicians' personal level of professional medical knowledge and clinical experience. In this paper, we employ machine learning methods to diagnose MMA based on patients' laboratory blood tests and laboratory urine tests, in order to make a timely diagnosis and reduce dependence on physicians' personal level of professional medical knowledge and clinical experience. By comparing different machine learning algorithms for diagnosing MMA, we obtain the following conclusions: (a) machine learning methods can perform well for diagnosing MMA (all established predictive models obtain high accuracies and AUC values which are greater than 0.85 over all data sets, and some of these results are even more than 0.98); (b) random forest algorithm performs best among the compared algorithms; and (c) diagnosis based on the data combining both urine tests and blood tests is better than diagnosis based on single test alone in general. The conclusions show that applying machine learning algorithms to the diagnosis of MMA can achieve good performance. Thus, it is credible to build machine learning models to give an initial diagnosis without professional medical knowledge.;;;https://dl.acm.org/doi/10.1145/3340997.3341000;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Machine Learning-based Pipeline for Enterprise Cross-department Conflict Data Management;;;['Guannan Wang', 'Wenjia Wang', 'Xueliang Song', 'Jiayi Chen'];;;November 2021;;;ICCBD 2021: 2021 4th International Conference on Computing and Big Data;;;None;;;https://dl.acm.org/doi/10.1145/3507524.3507530;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Classifying News Media Coverage for Corruption Risks Management with Deep Learning and Web Intelligence;;;['Albert Weichselbraun', 'Sandro Hörler', 'Christian Hauser', 'Anina Havelka'];;;June 2020;;;WIMS 2020: Proceedings of the 10th International Conference on Web Intelligence, Mining and Semantics;;;A substantial number of international corporations have been affected by corruption. The research presented in this paper introduces the Integrity Risks Monitor, an analytics dashboard that applies Web Intelligence and Deep Learning to english and german-speaking documents for the task of (i) tracking and visualizing past corruption management gaps and their respective impacts, (ii) understanding present and past integrity issues, (iii) supporting companies in analyzing news media for identifying and mitigating integrity risks. Afterwards, we discuss the design, implementation, training and evaluation of classification components capable of identifying English documents covering the integrity topic of corruption. Domain experts created a gold standard dataset compiled from Anglo-American media coverage on corruption cases that has been used for training and evaluating the classifier. The experiments performed to evaluate the classifiers draw upon popular algorithms used for text classification such as Naïve Bayes, Support Vector Machines (SVM) and Deep Learning architectures (LSTM, BiLSTM, CNN) that draw upon different word embeddings and document representations. They also demonstrate that although classical machine learning approaches such as Naïve Bayes struggle with the diversity of the media coverage on corruption, state-of-the art Deep Learning models perform sufficiently well in the project's context.;;;https://dl.acm.org/doi/10.1145/3405962.3405988;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Nepal Stock Market Movement Prediction with Machine Learning;;;['Shunan Zhao'];;;May 2021;;;ICISDM '21: Proceedings of the 2021 5th International Conference on Information System and Data Mining;;;Financial market predicting is a popular theme of lots of researches in recent years. However, the majority of previous studies are focus on markets in great countries like China and United States, while some small countries are drawn less attention. To cover this shortage in current literature, we determined to use and compare 17 types of machine learning models to foresee Nepal market in this paper. Based on stock prices, 10 technical indicators were computed as input features. In addition, we also added emotional factors extracted from financial news to improve the prediction performance, which was evaluated by accuracy and F1 score. We predicted whether the closing price would rise or descend after three horizons: 1-day movement, 15-day movement and 30-day movement. From our experiment results, we found that linear SVM and XGBoost perform best and are the best options for further consideration in the trading process.;;;https://dl.acm.org/doi/10.1145/3471287.3471289;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
The Need for a Multimodal Means of Effective Digital Learning through Data Mining and Institutional Knowledge Repository: A Proposed System for Polytechnics in Northern Nigeria;;;['Aminu Abbas Gumel', 'Abdullahi Bashir Abdullahi', 'Ugochukwu Matthew O.'];;;April 2019;;;ICCTA '19: Proceedings of the 2019 5th International Conference on Computer and Technology Applications;;;Educational institutions, information and knowledge givers in Nigeria are faced with numerous challenges of carrying everyone on the same page through the lack of proper digital learning and knowledge preservation tools simply regarded as a digital library. In any learning institution, digital libraries and institutional repositories are the keys to a qualitative knowledge stockpiling and delivery. The main aim of the paper is to propose a viable means of effective digital learning for the Polytechnics in Northern Nigeria. This paper also attempted to highlight the major information system components needed to develop a digital learning that will fit the Institutions with an approach through Multimedia data mining and suggests an Institutional Knowledge repository for proper academic data storage such as journals, thesis, lecture notes, dissertations, undergraduate student projects etc. The proposed system is expected to serve as a step towards bridging the gap between the polytechnics learning system and the tertiary institutions in the developed nations.;;;https://dl.acm.org/doi/10.1145/3323933.3324068;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Machine Learning Algorithms on Botnet Traffic: Ensemble and Simple Algorithms;;;['Rob McKay', 'Brian Pendleton', 'James Britt', 'Ben Nakhavanit'];;;March 2019;;;ICCDA '19: Proceedings of the 2019 3rd International Conference on Compute and Data Analysis;;;The authors introduce the Bronte machine learning evaluation study for consistent detection of malware, specifically honed for botnets. Machine learning algorithms are already being used to detect malware in dynamic environments. This evaluation utilizes a static measurement approach that could be implemented on edge network devices. It was generated from conversation-based network traffic. This study fully enumerated the network traffic features to allow various machine learning algorithms to build various training sets to deploy against dual test sets. Utilizing the Waikato Environment for Knowledge Analysis (WEKA) datamining and analysis tool, various algorithmic experiments were deployed against the modern and large CICIDS2017 dataset. This evaluation study aimed to push non-IP address features through a series of machine learning classifiers. The study was conducted differently and more methodically than other related studies by using three highly randomized training sets and two test data sets. The test sets were different in that one was a real world based 98.9 benign traffic and one was 50/50 benign to bot traffic. The instance based nearest neighbor and decision tree classifiers ranked highest only using the training sets; but the J48, an expanded ID3 decision tree classifier, clearly produced the highest predictions against both test sets.;;;https://dl.acm.org/doi/10.1145/3314545.3314569;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Evaluation of Machine Learning-based Anomaly Detection Algorithms on an Industrial Modbus/TCP Data Set;;;['Simon Duque Anton', 'Suneetha Kanoor', 'Daniel Fraunholz', 'Hans Dieter Schotten'];;;August 2018;;;ARES '18: Proceedings of the 13th International Conference on Availability, Reliability and Security;;;In the context of the Industrial Internet of Things, communication technology, originally used in home and office environments, is introduced into industrial applications. Commercial off-the-shelf products, as well as unified and well-established communication protocols make this technology easy to integrate and use. Furthermore, productivity is increased in comparison to classic industrial control by making systems easier to manage, set up and configure. Unfortunately, most attack surfaces of home and office environments are introduced into industrial applications as well, which usually have very few security mechanisms in place. Over the last years, several technologies tackling that issue have been researched. In this work, machine learning-based anomaly detection algorithms are employed to find malicious traffic in a synthetically generated data set of Modbus/TCP communication of a fictitious industrial scenario. The applied algorithms are Support Vector Machine (SVM), Random Forest, k-nearest neighbour and k-means clustering. Due to the synthetic data set, supervised learning is possible. Support Vector Machine and k-nearest neighbour perform well with different data sets, while k-nearest neighbour and k-means clustering do not perform satisfactorily.;;;https://dl.acm.org/doi/10.1145/3230833.3232818;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Machine Learning for Identifying Group Trajectory Outliers;;;['Asma Belhadi', 'Youcef Djenouri', 'Djamel Djenouri', 'Tomasz Michalak', 'Jerry Chun-Wei Lin'];;;None;;;ACM Transactions on Management Information Systems;;;Prior works on the trajectory outlier detection problem solely consider individual outliers. However, in real-world scenarios, trajectory outliers can often appear in groups, e.g., a group of bikes that deviates to the usual trajectory due to the maintenance of streets in the context of intelligent transportation. The current paper considers the Group Trajectory Outlier (GTO) problem and proposes three algorithms. The first and the second algorithms are extensions of the well-known DBSCAN and kNN algorithms, while the third one models the GTO problem as a feature selection problem. Furthermore, two different enhancements for the proposed algorithms are proposed. The first one is based on ensemble learning and computational intelligence, which allows for merging algorithms’ outputs to possibly improve the final result. The second is a general high-performance computing framework that deals with big trajectory databases, which we used for a GPU-based implementation. Experimental results on different real trajectory databases show the scalability of the proposed approaches.;;;https://dl.acm.org/doi/10.1145/3430195;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Multi-Initialization Graph Meta-Learning for Node Classification;;;['Feng Zhao', 'Donglin Wang', 'Xintao Xiang'];;;August 2021;;;ICMR '21: Proceedings of the 2021 International Conference on Multimedia Retrieval;;;Meta-learning aims to acquire common knowledge from a large amount of similar tasks and then adapts to unseen tasks within few gradient updates. Existing graph meta-learning algorithms show appealing performance in a variety of domains such as node classification and link prediction. These methods find a single common initialization for entire tasks and ignore the diversity of task distributions, which might be insufficient for multi-modal tasks. Recent approaches adopt modulation network to generate task-specific parameters for further achieving multiple initializations, which shows excellent performance for multi-modal image classification. However, different from image classification, how to design an effective modulation network to handle graph-structure dataset is still challenging. In this paper, we propose a Multi-Initialization Graph Meta-Learning (MI-GML) network for graph node classification, mainly consisting of local and global modulation neworks and meta learner. In terms of modulation network, we exploit local and global graph structure information to extract task-specific modulation parameters. On this basis, the meta learner is further modulated by the corresponding modulation parameter to produce task-specific representation for node classification. Experimental results on three graph-structure datasets demonstrate the effectiveness of MI-GML in few-shot node classification tasks.;;;https://dl.acm.org/doi/10.1145/3460426.3463604;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Classification of Glomeruli with Membranous Nephropathy on Renal Digital Pathological Images with Deep Learning;;;['Fang Hao', 'Ming Li', 'Xueyu Liu', 'Xinyu Li', 'Junhong Yue', 'Weixia Han'];;;October 2020;;;CAIH2020: Proceedings of the 2020 Conference on Artificial Intelligence and Healthcare;;;Membranous nephropathy (MN) is the one of the most common pathological types that cause adult nephrotic syndrome (NS). Recently, the incidence of MN has shown a clear upward trend. Nevertheless, there is no more accurate and fast artificial intelligence algorithm for diagnose of MN which work is laborintensive and time-consuming if it is done manually. In this article, MN-Net, a CNN-based method, is applied to glomeruli detection and classification on whole slide images (WSIs). This work is mainly divided into two parts, a glomerulus detection network and a classification network. The detection network is utilized to locate glomeruli on WSIs. Multiple instance learning (MIL), a weakly supervised classification network following detection network classifies the glomeruli detected earlier. Our network is training on PASM-stained WSIs of 1281 cases collected from multi-centers. Experimental results prove that our method is effective with a high precision of 99.66% for glomeruli detection and 99.53% for MN glomeruli classification on this dataset. In summary, this method has been proved to be an effective method with advantages of speed, high accuracy, strong robustness, and low cost of data annotation that can be applied to the diagnosis of renal pathology. In the future, this method can also be extended to the classification of other glomerular diseases under light microscope (LM). The introduction of glomerular basement membrane (GBM) segmentation and measurement models can further improve the reliability of this model.;;;https://dl.acm.org/doi/10.1145/3433996.3434486;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
What Is Hard about Teaching Machine Learning to Non-Majors? Insights from Classifying Instructors’ Learning Goals;;;['Elisabeth Sulmont', 'Elizabeth Patitsas', 'Jeremy R. Cooperstock'];;;None;;;ACM Transactions on Computing Education;;;Given its societal impacts and applications to numerous fields, machine learning (ML) is an important topic to understand for many students outside of computer science and statistics. However, machine-learning education research is nascent, and research on this subject for non-majors thus far has only focused on curricula and courseware. We interviewed 10 instructors of ML courses for non-majors, inquiring as to what their students find both easy and difficult about machine learning. While ML has a reputation for having algorithms that are difficult to understand, in practice our participating instructors reported that it was not the algorithms that were difficult to teach, but the higher-level design decisions. We found that the learning goals that participants described as hard to teach were consistent with higher levels of the Structure of Observed Learning Outcomes (SOLO) taxonomy, such as making design decisions and comparing/contrasting models. We also found that the learning goals that were described as easy to teach, such as following the steps of particular algorithms, were consistent with the lower levels of the SOLO taxonomy. Realizing that higher-SOLO learning goals are more difficult to teach is useful for informing course design, public outreach, and the design of educational tools for teaching ML.;;;https://dl.acm.org/doi/10.1145/3336124;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Entropy Slicing Extraction and Transfer Learning Classification for Early Diagnosis of Alzheimer Diseases with sMRI;;;['S. Sambath Kumar', 'M. Nandhini'];;;None;;;ACM Transactions on Multimedia Computing, Communications, and Applications;;;Alzheimer’s Disease (AD) is an irreversible neurogenerative disorder that undergoes progressive decline in memory and cognitive function and is characterized by structural brain Magnetic Resonance Images (sMRI). In recent years, sMRI data has played a vital role in the evaluation of brain anatomical changes, leading to early detection of AD through deep networks. The existing AD problems such as preprocessing complexity and unreliability are major concerns at present. To overcome these, a model (FEESCTL) has been proposed with an entropy slicing for feature extraction and Transfer Learning for classification. In the present study, the entropy image slicing method is attempted for selecting the most informative MRI slices during training stages. The ADNI dataset is trained on Transfer Learning adopted by VGG-16 network for classifying the AD with normal individuals. The experimental results reveal that the proposed model has achieved an accuracy level of 93.05%, 86.39%, 92.00% for binary classifications (AD/MCI, MCI/CN, AD/CN) and 93.12% for ternary classification (AD/MCI/CN), respectively, and henceforth the efficiency in diagnosing AD is proved through comparative analysis.;;;https://dl.acm.org/doi/10.1145/3383749;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Classification by Retrieval: Binarizing Data and Classifiers;;;['Fumin Shen', 'Yadong Mu', 'Yang Yang', 'Wei Liu', 'Li Liu', 'Jingkuan Song', 'Heng Tao Shen'];;;August 2017;;;SIGIR '17: Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval;;;This paper proposes a generic formulation that significantly expedites the training and deployment of image classification models, particularly under the scenarios of many image categories and high feature dimensions. As the core idea, our method represents both the images and learned classifiers using binary hash codes, which are simultaneously learned from the training data. Classifying an image thereby reduces to retrieving its nearest class codes in the Hamming space. Specifically, we formulate multiclass image classification as an optimization problem over binary variables. The optimization alternatingly proceeds over the binary classifiers and image hash codes. Profiting from the special property of binary codes, we show that the sub-problems can be efficiently solved through either a binary quadratic program (BQP) or a linear program. In particular, for attacking the BQP problem, we propose a novel bit-flipping procedure which enjoys high efficacy and a local optimality guarantee. Our formulation supports a large family of empirical loss functions and is, in specific, instantiated by exponential and linear losses. Comprehensive evaluations are conducted on several representative image benchmarks. The experiments consistently exhibit reduced computational and memory complexities of model training and deployment, without sacrificing classification accuracy.;;;https://dl.acm.org/doi/10.1145/3077136.3080767;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
TipTap: Approximate Mining of Frequent k-Subgraph Patterns in Evolving Graphs;;;['Muhammad Anis Uddin Nasir', 'Cigdem Aslay', 'Gianmarco De Francisci Morales', 'Matteo Riondato'];;;None;;;ACM Transactions on Knowledge Discovery from Data;;;“Perhaps he could dance first and think afterwards, if it isn’t too much to ask him.”S. Beckett, Waiting for GodotGiven a labeled graph, the collection of k-vertex induced connected subgraph patterns that appear in the graph more frequently than a user-specified minimum threshold provides a compact summary of the characteristics of the graph, and finds applications ranging from biology to network science. However, finding these patterns is challenging, even more so for dynamic graphs that evolve over time, due to the streaming nature of the input and the exponential time complexity of the problem. We study this task in both incremental and fully-dynamic streaming settings, where arbitrary edges can be added or removed from the graph. We present TipTap, a suite of algorithms to compute high-quality approximations of the frequent k-vertex subgraphs w.r.t. a given threshold, at any time (i.e., point of the stream), with high probability. In contrast to existing state-of-the-art solutions that require iterating over the entire set of subgraphs in the vicinity of the updated edge, TipTap operates by efficiently maintaining a uniform sample of connected k-vertex subgraphs, thanks to an optimized neighborhood-exploration procedure. We provide a theoretical analysis of the proposed algorithms in terms of their unbiasedness and of the sample size needed to obtain a desired approximation quality. Our analysis relies on sample-complexity bounds that use Vapnik–Chervonenkis dimension, a key concept from statistical learning theory, which allows us to derive a sufficient sample size that is independent from the size of the graph. The results of our empirical evaluation demonstrates that TipTap returns high-quality results more efficiently and accurately than existing baselines.;;;https://dl.acm.org/doi/10.1145/3442590;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Interactive Document Clustering Revisited: A Visual Analytics Approach;;;['Ehsan Sherkat', 'Seyednaser Nourashrafeddin', 'Evangelos E. Milios', 'Rosane Minghim'];;;March 2018;;;IUI '18: 23rd International Conference on Intelligent User Interfaces;;;Document clustering is an efficient way to get insight into large text collections. Due to the personalized nature of document clustering, even the best fully automatic algorithms cannot create clusters that accurately reflect the user»s perspectives. To incorporate the user»s perspective in the clustering process and, at the same time, effectively visualize document collections to enhance user's sense-making of data, we propose a novel visual analytics system for interactive document clustering. We built our system on top of clustering algorithms that can adapt to user's feedback. First, the initial clustering is created based on the user-defined number of clusters and the selected clustering algorithm. Second, the clustering result is visualized to the user. A collection of coordinated visualization modules and document projection is designed to guide the user towards a better insight into the document collection and clusters. The user changes clusters and key-terms iteratively as a feedback to the clustering algorithm until the result is satisfactory. In key-term based interaction, the user assigns a set of key-terms to each target cluster to guide the clustering algorithm. A set of quantitative experiments, a use case, and a user study have been conducted to show the advantages of the approach for document analytics based on clustering.;;;https://dl.acm.org/doi/10.1145/3172944.3172964;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Data Mining in Health Care Sector: Literature Notes;;;['Ahed Abugabah', 'Ahmad Al Smadi', 'Alaa Abuqabbeh'];;;November 2019;;;CIIS '19: Proceedings of the 2019 2nd International Conference on Computational Intelligence and Intelligent Systems;;;A standout amongst the most essential strides of the knowledge discovery in database KDD is data mining. Data mining is defined as a basic advance during the time spent learning discovery in databases in which understanding strategies are utilized in order to pattern discovery. Due to the huge amount of data available within the healthcare systems, data mining is important for the healthcare sector in the clinical and diagnosis diseases. However, data mining and healthcare organizations have developed some of dependable early discovery frameworks and different healthcare related frameworks from the clinical treatment and analysis information. The main motivation of this paper is to give a survey of data extraction in health care. In addition, the benefits and obstacles of the use of data extraction strategies in health care and therapeutic information have been thought.;;;https://dl.acm.org/doi/10.1145/3372422.3372451;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Classification of Bacterial and Viral Childhood Pneumonia Using Deep Learning in Chest Radiography;;;['Xianghong Gu', 'Liyan Pan', 'Huiying Liang', 'Ran Yang'];;;March 2018;;;ICMIP '18: Proceedings of the 3rd International Conference on Multimedia and Image Processing;;;Over decades, computer aided diagnosis (CAD) system has been investigated for detection of lung diseases based on chest X-ray images. Incited by the great success of deep learning, in this work, we propose a novel CAD system to identify bacterial and viral pneumonia in chest radiography. The method consists of two parts, lung regions identification and pneumonia category classification. First, left and right lung regions are segmented and extracted with a fully convolutional networks (FCN) model. The model is trained and tested on the open Japanese society of radiological technology database (JSRT, 241 images) and Montgomery County, Md (MC, 138 images) dataset. After segmentation, a deep convolutional neural network (DCNN) model is used to classify the target lung regions. Then, based on the DCNN model, features of the target lung regions are extracted automatically and the performance is compared with that of manual features. Finally, the DCNN features and manual features are fused together and are put into support vector machines (SVM) classifier for binary classification. The proposed method is evaluated on a dataset of Guangzhou Women and Children's Medical Center, China, with 4,513 pediatric patients in total, aged from 1 to 9 years old, during the period from 2003 to 2017. The performances are measured by different criteria: accuracy, precision, sensitivity, specificity and area under the curve (AUC), which is a comprehensive criterion. The experimental results showed better accuracy (0.8048±0.0202) and sensitivity (0.7755±0.0296) in extracting features by DCNN with transfer learning. The values of AUC varied from 0.6937 to 0.8234. And an ensemble of different kinds of features slightly improved the AUC value from 0.8160±0.0162 to 0.8234±0.0014.;;;https://dl.acm.org/doi/10.1145/3195588.3195597;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
Deep Learning Based Tumor Type Classification Using Gene Expression Data;;;['Boyu Lyu', 'Anamul Haque'];;;August 2018;;;BCB '18: Proceedings of the 2018 ACM International Conference on Bioinformatics, Computational Biology, and Health Informatics;;;The differential analysis is the most significant part of RNA-Seq analysis. Conventional methods of the differential analysis usually match the tumor samples to the normal samples, which are both from the same tumor type. Such method would fail in differentiating tumor types because it lacks the knowledge from other tumor types. The Pan-Cancer Atlas provides us with abundant information on 33 prevalent tumor types which could be used as prior knowledge to generate tumor-specific biomarkers. In this paper, we embedded the high dimensional RNA-Seq data into 2-D images and used a convolutional neural network to make classification of the 33 tumor types. The final accuracy we got was 95.59%. Furthermore, based on the idea of Guided Grad Cam, as to each class, we generated significance heat-map for all the genes. By doing functional analysis on the genes with high intensities in the heat-maps, we validated that these top genes are related to tumor-specific pathways, and some of them have already been used as biomarkers, which proved the effectiveness of our method. As far as we know, we are the first to apply a convolutional neural network on Pan-Cancer Atlas for the classification of tumor types, and we are also the first to use gene's contribution in classification to the importance of genes to identify candidate biomarkers. Our experiment results show that our method has a good performance and could also apply to other genomics data.;;;https://dl.acm.org/doi/10.1145/3233547.3233588;;;Text AND Mining OR Clustering OR Classification OR Machine AND Learning OR Data AND Mining
